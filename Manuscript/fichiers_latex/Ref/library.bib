Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Petersen2019,
author = {Petersen, Steffen and Kristensen, Martin Heine and Knudsen, Michael Dahl},
doi = {10.1016/j.enbuild.2018.10.035},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778818315688-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
month = {jan},
pages = {1--16},
title = {{Prerequisites for reliable sensitivity analysis of a high fidelity building energy model}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818315688},
volume = {183},
year = {2019}
}
@article{Sakuma2019,
abstract = {Energy and environmental problems have attracted attention worldwide. Energy consumption in residential sectors accounts for a large percentage of total consumption. Several retrofit schemes, which insulate building envelopes to increase energy efficiency, have been adapted to address residential energy problems. However, these schemes often fail to balance the installment cost with savings from the retrofits. To maximize the benefit, selecting houses with low thermal performance by a cost-effective method is inevitable. Therefore, an accurate, low-cost, and undemanding housing assessment method is required. This paper proposes a thermal performance assessment method for residential housing. The proposed method enables assessments under the existing conditions of residential housings and only requires a simple and affordable monitoring system of power meters for an air conditioner (AC), simple sensors (three thermometers at most), a BLE beacon, and smartphone application. The proposed method is evaluated thoroughly by using both simulation and experimental data. Analysis of estimation errors is also conducted. Our method shows that the accuracy achieved with the proposed three-room model is 9.8{\%} (relative error) for the simulation data. Assessments on the experimental data also show that our proposed method achieved Ua value estimations using a low-cost system, satisfying the requirements of housing assessments for retrofits.},
author = {Sakuma and Nishi},
doi = {10.3390/en12152950},
file = {:home/sarah/OneDrive/Travail/Sources/Estimation{\_}of{\_}Building{\_}Thermal{\_}Performance{\_}Using{\_}S.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {building thermal performance assessment,gap,hems,house energy management system,performance,smart home,system identification,ua -value},
month = {jul},
number = {15},
pages = {2950},
title = {{Estimation of Building Thermal Performance Using Simple Sensors and Air Conditioners}},
url = {https://www.mdpi.com/1996-1073/12/15/2950},
volume = {12},
year = {2019}
}
@phdthesis{Chong2017b,
author = {Chong, Adrian},
file = {:home/sarah/Dropbox/These/Sources/Bay{\'{e}}sien/Bayesian Calibration of Building Energy Models for Large Datasets.pdf:pdf},
pages = {1--129},
school = {Carnegie Mellon University},
title = {{Bayesian Calibration of Building Energy Models for Energy Retrofit Decision-Making Under Uncertainty}},
year = {2017}
}
@techreport{Gelfand1990,
author = {Gelfand, Alan E and Smith, A.F.M. and Lee, T-M.},
booktitle = {Methods},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelfand, Smith, Lee - 1990 - Bayesian analysis of constrained parameter and truncated data problems.pdf:pdf},
institution = {Department of STatistics, University of Stanford},
keywords = {Gibbs sampling},
mendeley-tags = {Gibbs sampling},
number = {90},
title = {{Bayesian analysis of constrained parameter and truncated data problems}},
year = {1990}
}
@inproceedings{Vandaele2010,
abstract = {After the successful conclusion of a series of large European research actions in the field of passive solar energy applications to buildings (PASSYS I and II, COMPASS, PASLINK, PV-HYBRID-PAS, etc.), the research community involved created the European Economic Interest Grouping PASLINK to consolidate the research findings and the operational structure built up and to make it accessible to the building community. Major efforts were spent to develop common test methods, test facilities and simulation tools, which resulted in a powerful method based on outdoor tests in well-defined test facilities and on scaling and replication of the results from testing to real buildings. In later projects (IQ-TEST, DAME-BC) the quality procedures for testing and evaluation were improved and upgraded. And finally the dissemination efforts led to the creation of a new structure and to a series of conferences. The concept for dynamic analysis, simulation and testing of the energy and environmental performance of buildings and building components has now reached maturity and it is ready for broad uptake by the research community. Thereto new networking activities were set up. The structure of the PASLINK grouping has been abandoned and is replaced by the informal network DYNASTEE, working as a platform within INIVE EEIG.},
address = {Brussels},
author = {Vandaele, Luk and Peter, Wouters and Hans, Bloem},
booktitle = {DYNASTEE international workshop : Dynamic Methods for Building Energy Assessment},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandaele, Peter, Hans - 2010 - From paslink to dynastee short history of dynamic performance testing and analysis.pdf:pdf},
keywords = {analysis,building components,energy performance,evaluation,testing},
pages = {1--8},
title = {{From paslink to dynastee: short history of dynamic performance testing and analysis}},
year = {2010}
}
@article{Gevers2009,
abstract = {In prediction error identification, the information matrix plays a central role. Specifically, when the system is in the model set, the covariance matrix of the parameter estimates converges asymptotically, up to a scaling factor, to the inverse of the information matrix. The existence of a finite covariance matrix thus depends on the positive definiteness of the information matrix, and the rate of convergence of the parameter estimate depends on its ¿size¿. The information matrix is also the key tool in the solution of optimal experiment design procedures, which have become a focus of recent attention. Introducing a geometric framework, we provide a complete analysis, for arbitrary model structures, of the minimum degree of richness required to guarantee the nonsingularity of the information matrix. We then particularize these results to all commonly used model structures, both in open loop and in closed loop. In a closed-loop setup, our results provide an unexpected and precisely quantifiable trade-off between controller degree and required degree of external excitation.},
author = {Gevers, Michel and Bazanella, Alexandre Sanfelice and Bombois, Xavier and Mi{\v{s}}kovi{\'{c}}, Ljubi{\v{s}}a},
doi = {10.1109/TAC.2009.2034199},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevers et al. - 2009 - Identification and the information matrix How to get just sufficiently rich.pdf:pdf},
isbn = {0018-9286 VO - 54},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Identifiability,Information matrix,Input richness,Transfer of excitation},
number = {12},
pages = {2828--2840},
title = {{Identification and the information matrix: How to get just sufficiently rich?}},
volume = {54},
year = {2009}
}
@article{Foreman-Mackey2012,
abstract = {We introduce a stable, well tested Python implementation of the affine-invariant ensemble sampler for Markov chain Monte Carlo (MCMC) proposed by Goodman {\&} Weare (2010). The code is open source and has already been used in several published projects in the astrophysics literature. The algorithm behind emcee has several advantages over traditional MCMC sampling methods and it has excellent performance as measured by the autocorrelation time (or function calls per independent sample). One major advantage of the algorithm is that it requires hand-tuning of only 1 or 2 parameters compared to {\$}\backslashsim N{\^{}}2{\$} for a traditional algorithm in an N-dimensional parameter space. In this document, we describe the algorithm and the details of our implementation and API. Exploiting the parallelism of the ensemble method, emcee permits any user to take advantage of multiple CPU cores without extra effort. The code is available online at http://dan.iel.fm/emcee under the MIT License.},
archivePrefix = {arXiv},
arxivId = {1202.3665},
author = {Foreman-Mackey, Daniel and Hogg, David W and Lang, Dustin and Goodman, Jonathan},
doi = {10.1086/670067},
eprint = {1202.3665},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foreman-Mackey et al. - 2013 - emcee The MCMC Hammer.pdf:pdf},
month = {feb},
title = {{emcee: The MCMC Hammer}},
url = {https://arxiv.org/pdf/1202.3665.pdf http://arxiv.org/abs/1202.3665 http://dx.doi.org/10.1086/670067},
year = {2012}
}
@article{Ljung1993,
author = {Ljung, Lennart},
doi = {10.1016/s1474-6670(17)48409-6},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/ljungpaper.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
month = {jan},
number = {2},
pages = {931--939},
title = {{Perspectives on the Process of Identification}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0967066195903127},
volume = {26},
year = {1993}
}
@article{Raue2009,
abstract = {MOTIVATION: Mathematical description of biological reaction networks by differential equations leads to large models whose parameters are calibrated in order to optimally explain experimental data. Often only parts of the model can be observed directly. Given a model that sufficiently describes the measured data, it is important to infer how well model parameters are determined by the amount and quality of experimental data. This knowledge is essential for further investigation of model predictions. For this reason a major topic in modeling is identifiability analysis.$\backslash$n$\backslash$nRESULTS: We suggest an approach that exploits the profile likelihood. It enables to detect structural non-identifiabilities, which manifest in functionally related model parameters. Furthermore, practical non-identifiabilities are detected, that might arise due to limited amount and quality of experimental data. Last but not least confidence intervals can be derived. The results are easy to interpret and can be used for experimental planning and for model reduction.$\backslash$n$\backslash$nAVAILABILITY: An implementation is freely available for MATLAB and the PottersWheel modeling toolbox at http://web.me.com/andreas.raue/profile/software.html.$\backslash$n$\backslash$nSUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
annote = {On distingue deux types de non identifiabilit{\'{e}} : la structurelle (voir Cobelli et Di Stefano 1980) et la pratique.

La non identifiabilit{\'{e}} pratique est due un peu au mod{\`{e}}le mais aussi la quantit{\'{e}} et la qualit{\'{e}} insuffisante des donn{\'{e}}es disponibles

On caract{\'{e}}rise la non identifiabilit{\'{e}} d'un parameter estimate si son intervalle de confiance est infini.

Le profil de vraisemblance d'un param{\`{e}}tre non identifiable dans la pratique a un minimum mais son seuil ne d{\'{e}}passe pas Delta/alpha (seuil d'identifiabilit{\'{e}}). Un param{\`{e}}tre structurellement non identifiable a un profil de vraisemblance uniforme.},
author = {Raue, Andreas and Kreutz, Clemens and Maiwald, T. and Bachmann, J. and Schilling, M. and Klingmuller, U and Timmer, Jens},
doi = {10.1093/bioinformatics/btp358},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raue et al. - 2009 - Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {15},
pages = {1923--1929},
pmid = {19505944},
title = {{Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood}},
volume = {25},
year = {2009}
}
@article{Heo2012,
abstract = {Retrofitting existing buildings is urgent given the increasing need to improve the energy efficiency of the existing building stock. This paper presents a scalable, probabilistic methodology that can support large scale investments in energy retrofit of buildings while accounting for uncertainty. The methodology is based on Bayesian calibration of normative energy models. Based on CEN-ISO standards, normative energy models are light-weight, quasi-steady state formulations of heat balance equations, which makes them appropriate for modeling large sets of buildings efficiently. Calibration of these models enables improved representation of the actual buildings and quantification of uncertainties associated with model parameters. In addition, the calibrated models can incorporate additional uncertainties coming from retrofit interventions to generate probabilistic predictions of retrofit performance. Probabilistic outputs can be straightforwardly translated to quantify risks of under-performance associated with retrofit interventions. A case study demonstrates that the proposed methodology with the use of normative models can correctly evaluate energy retrofit options and support risk conscious decision-making by explicitly inspecting risks associated with each retrofit option.},
author = {Heo, Yeonsook and Choudhary, Ruchi and Augenbroe, Godfried},
doi = {10.1016/j.enbuild.2011.12.029},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heo, Choudhary, Augenbroe - 2012 - Calibration of building energy models for retrofit analysis under uncertainty.pdf:pdf},
isbn = {{\textless}null{\textgreater}},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Assess model fit,Bayesian calibration,Normative energy models,Retrofit analysis,Uncertainty analysis},
mendeley-tags = {Assess model fit},
month = {apr},
pages = {550--560},
title = {{Calibration of building energy models for retrofit analysis under uncertainty}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037877881100644X},
volume = {47},
year = {2012}
}
@techreport{Leroy2010,
author = {Leroy, Michel},
file = {:home/sarah/OneDrive/Travail/Sources/note{\_}technique37.pdf:pdf},
institution = {METEO FRANCE},
title = {{Note technique n°37 Classification de performance maintenue}},
year = {2010}
}
@article{Meshkat2014,
abstract = {Parameter identifiability problems can plague biomodelers when they reach the quantification stage of development, even for relatively simple models. Structural identifiability (SI) is the primary question, usually understood as knowing which of P unknown biomodel parameters p1,{\ldots}, pi,{\ldots}, pP are-and which are not-quantifiable in principle from particular input-output (I-O) biodata. It is not widely appreciated that the same database also can provide quantitative information about the structurally unidentifiable (not quantifiable) subset, in the form of explicit algebraic relationships among unidentifiable pi. Importantly, this is a first step toward finding what else is needed to quantify particular unidentifiable parameters of interest from new I-O experiments. We further develop, implement and exemplify novel algorithms that address and solve the SI problem for a practical class of ordinary differential equation (ODE) systems biology models, as a user-friendly and universally-accessible web application (app)-COMBOS. Users provide the structural ODE and output measurement models in one of two standard forms to a remote server via their web browser. COMBOS provides a list of uniquely and non-uniquely SI model parameters, and-importantly-the combinations of parameters not individually SI. If non-uniquely SI, it also provides the maximum number of different solutions, with important practical implications. The behind-the-scenes symbolic differential algebra algorithms are based on computing Gr{\"{o}}bner bases of model attributes established after some algebraic transformations, using the computer-algebra system Maxima. COMBOS was developed for facile instructional and research use as well as modeling. We use it in the classroom to illustrate SI analysis; and have simplified complex models of tumor suppressor p53 and hormone regulation, based on explicit computation of parameter combinations. It's illustrated and validated here for models of moderate complexity, with and without initial conditions. Built-in examples include unidentifiable 2 to 4-compartment and HIV dynamics models.},
annote = {http://biocyb1.cs.ucla.edu/combos/},
author = {Meshkat, Nicolette and {Er-zhen Kuo}, Christine and DiStefano, Joseph},
doi = {10.1371/journal.pone.0110261},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meshkat, Er-zhen Kuo, DiStefano - 2014 - On finding and using identifiable parameter combinations in nonlinear dynamic systems biology m.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pmid = {25350289},
title = {{On finding and using identifiable parameter combinations in nonlinear dynamic systems biology models and combos: A novel web implementation}},
volume = {9},
year = {2014}
}
@book{ASHRAE2013,
author = {ASHRAE},
isbn = {978-1-936504-46-6},
publisher = {ASHRAE},
title = {{ASHRAE Handbook - Fundamentals}},
year = {2013}
}
@article{Qiu2018,
abstract = {When modeling the energy performance of existing buildings, model calibration always serves as an essential and necessary step to ensure the accuracy and applicability of building models. Model calibration for detailed energy models, which is also known as calibrated simulation (CS), refers to the process of tuning model's input parameters to narrow down the mismatch between the simulation result and the real-monitored data of building energy consumptions. Two major problems of current CS are: (1) a successful calibration requires HVAC domain knowledge of modelers. (2) Traditional building calibration process is labor-intensive and time-consuming. To solve these problems, a normative energy modeling based quick auto-calibration approach is proposed in this study. This approach is able to reduce the modeling time and simplify the calibration procedures. Firstly, this paper demonstrates the working principles and the credibility of Normative Energy Modeling (NEM). Then, the methodology of the proposed quick auto-calibration approach is elaborated. The energy performance model of a large hotel located in Shanghai, China with NEM is used as a case study to investigate the effectiveness of the proposed quick auto-calibration approach. The simulation result of the case study suggests that the proposed approach can significantly simplify the procedures of model calibrations while still achieve a good accuracy specified by ASHRAE Guideline 14 [1]. Besides, the results further confirm that such method requires much less time and computational power for modeling, compared with other counterparts (e.g., “Autotune” calibration [2]). With the advantage of speed and accuracy, the auto-calibration proposed in this paper is promising to be applied in both engineering and research field.},
author = {Qiu, Shunian and Li, Zhengwei and Pang, Zhihong and Zhang, Weijie and Li, Zhenhai},
doi = {10.1016/j.enbuild.2018.04.053},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu et al. - 2018 - A quick auto-calibration approach based on normative energy models.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Automatic calibration,Normative energy modeling,Sensitivity analysis},
month = {aug},
pages = {35--46},
publisher = {Elsevier B.V.},
title = {{A quick auto-calibration approach based on normative energy models}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818301051 https://doi.org/10.1016/j.enbuild.2018.04.053},
volume = {172},
year = {2018}
}
@article{Grandjean2017,
abstract = {Structural identifiability is a critical aspect of modelling that has been overlooked in the vast majority of Li-ion battery modelling studies. It considers whether it is possible to obtain a unique solution for the unknown model parameters from experimental data. This is a fundamental prerequisite of the modelling process, especially when the parameters represent physical battery attributes and the proposed model is utilised to estimate them. Numerical estimates for unidentifiable parameters are effectively meaningless since unidentifiable parameters have an infinite number of possible numerical solutions. It is demonstrated that the physical phenomena assignment to a two-RC (resistor–capacitor) network equivalent circuit model (ECM) is not possible without additional information. Established methods to ascertain structural identifiability are applied to 12 ECMs covering the majority of model templates used previously. Seven ECMs are shown not to be uniquely identifiable, reducing the confidence in the accuracy of the parameter values obtained and highlighting the relevance of structural identifiability even for relatively simple models. Suggestions are proposed to make the models identifiable and, therefore, more valuable in battery management system applications. The detailed analyses illustrate the importance of structural identifiability prior to performing parameter estimation experiments, and the algebraic complications encountered even for simple models.},
annote = {Bonne description des m{\'{e}}thodes de d{\'{e}}veloppement des s{\'{e}}ries de Taylor et de l'alg diff},
author = {Grandjean, Thomas and McGordon, Andrew and Jennings, Paul},
doi = {10.3390/en10010090},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grandjean, McGordon, Jennings - 2017 - Structural Identifiability of Equivalent Circuit Models for Li-Ion Batteries.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {equivalent circuit models,lithium ion battery modelling,structural identifiability},
month = {jan},
number = {1},
pages = {90},
title = {{Structural Identifiability of Equivalent Circuit Models for Li-Ion Batteries}},
url = {http://www.mdpi.com/1996-1073/10/1/90},
volume = {10},
year = {2017}
}
@article{Li2018,
annote = {complete (E+) model calibration

Chaudhary G et al Evaluation of autotune calibration against manual calibrayion of building energy models --{\textgreater} applied energy 2016},
author = {Li, Wancheng and Tian, Zhe and Lu, Yakai and Fu, Fawei},
doi = {10.1016/j.enbuild.2018.10.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Stepwise calibration for residential building thermal performance model using hourly heat consumption data.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building thermal performance model,Model calibration,Schedule,Stepwise calibration},
month = {dec},
pages = {10--25},
publisher = {Elsevier B.V.},
title = {{Stepwise calibration for residential building thermal performance model using hourly heat consumption data}},
url = {https://doi.org/10.1016/j.enbuild.2018.10.001 https://linkinghub.elsevier.com/retrieve/pii/S0378778818324757},
volume = {181},
year = {2018}
}
@article{Brouns2013a,
abstract = {Building performance simulation often fails to predict accurately the real energy performance, mostly due to great uncertainties in the input data. Errors in computed performance are particularly significant in the case of existing buildings, for which the amount of information about intrinsic characteristics is low. However, efficient energy retrofit operations make necessary an accurate understanding of the initial state of a building using a calibrated prediction model. Several works have investigated the use of identification techniques for model calibration. The present paper investigates the use of such techniques to derive an energy audit procedure suitable to be an efficient aid for retrofit. In particular, we study here the possibility to determine the unknown thermal conductivity of the envelope and the internal gains based on temperature measurements only. We show how the adjoint method can be used to solve efficiently the inverse problem, while providing a fast method for computing model's sensitivities. Copyright {\textcopyright} 2011 by IPAC'11/EPS-AG.},
author = {Brouns, Jordan and Nassiopoulos, Alexandre and Bourquin, Fr{\'{e}}d{\'{e}}ric and Limam, Karim},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brouns et al. - 2013 - State-parameter identification problems for accurate building energy audits(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brouns et al. - 2013 - State-parameter identification problems for accurate building energy audits.pdf:pdf},
journal = {Proceedings of BS 2013: 13th Conference of the International Building Performance Simulation Association},
pages = {1224--1230},
title = {{State-parameter identification problems for accurate building energy audits}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84886648972{\&}partnerID=tZOtx3y1},
year = {2013}
}
@unpublished{Sedoglavic2006,
author = {Sedoglavic, Alexandre},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedoglavic - 2006 - Des d{\'{e}}fauts d'un test d'observabilit{\'{e}} structurelle purement num{\'{e}}rique.pdf:pdf},
pages = {1--6},
title = {{Des d{\'{e}}fauts d'un test d'observabilit{\'{e}} structurelle purement num{\'{e}}rique}},
year = {2006}
}
@article{Brastein2018,
abstract = {a b s t r a c t Good models for building thermal behaviour are an important part of developing building energy man-agement systems that are capable of reducing energy consumption for space heating through model pre-dictive control. A popular approach to modelling the temperature variations of buildings is grey-box mod-els based on lumped parameter thermal networks. By creating simplified models and calibrating their parameters from measurement data, the resulting model is both accurate and shows good generalisation capabilities. Often, parameters of such models are assumed to be a combination of different physical at-tributes of the building, hence they have some physical interpretation. In this paper, we investigate the dispersion of parameter estimates by use of randomisation. We show that there is significant dispersion in the parameter estimates when using randomised initial conditions for a numerical optimisation algo-rithm. Further, we claim that in order to assign a physical interpretation to grey-box model parameters, we require the estimated parameters to converge independently of the initial conditions and different datasets. Despite the dispersion of estimated parameters, the prediction capability of calibrated grey-box models is demonstrated by validating the models on independent data. This shows that the models are usable in a model predictive control system.},
author = {Brastein, O. M. and Perera, D.W.U. and Pfeifer, C and Skeie, N.-O},
doi = {10.1016/j.enbuild.2018.03.057},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brastein et al. - 2018 - Accepted Manuscript Parameter estimation for grey-box models of building thermal behaviour(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brastein et al. - 2018 - Parameter estimation for grey-box models of building thermal behaviour(2).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Dispersion of estimated parameters,Grey-box models,Monte Carlo methods,Parameter estimation,Thermal network model},
month = {jun},
pages = {58--68},
title = {{Parameter estimation for grey-box models of building thermal behaviour}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0378778817331791/1-s2.0-S0378778817331791-main.pdf?{\_}tid=4c71de00-a7d6-46ec-be0c-d7d5c305727a{\&}acdnat=1525072760{\_}7d966dfd208e1bbcb4bed29b492c38e3 https://linkinghub.elsevier.com/retrieve/pii/S0378778817331791 ht},
volume = {169},
year = {2018}
}
@article{Poirier1998,
abstract = {A Bayesian analysis of a nonidentified model is always possible if a proper prior on all the parameters is specified. There is, however, no Bayesian free lunch. The “price” is that there exist quantities about which the data are uninformative, i.e., their marginal prior and posterior distributions are identical. In the case of improper priors the analysis is problematic—resulting posteriors can be improper. This study investigates both proper and improper cases through a series of examples.},
author = {Poirier, Dale J.},
doi = {10.1017/s0266466698144043},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/revising-beliefs-in-nonidentified-models.pdf:pdf},
issn = {0266-4666},
journal = {Econometric Theory},
number = {4},
pages = {483--509},
publisher = {{\textless}b{\textgreater}Universit{\'{e}} Savoie Mont Blanc{\textless}/b{\textgreater}},
title = {{Revising Beliefs in Nonidentified Models}},
volume = {14},
year = {1998}
}
@article{Raue2014,
abstract = {MOTIVATION: Modeling of dynamical systems using ordinary differential equations is a popular approach in the field of Systems Biology. The amount of experimental data that are used to build and calibrate these models is often limited. In this setting, the model parameters may not be uniquely determinable. Structural or a priori identifiability is a property of the system equations that indicates whether, in principle, the unknown model parameters can be determined from the available data.$\backslash$r$\backslash$n$\backslash$r$\backslash$nRESULTS: We performed a case study using three current approaches for structural identifiability analysis for an application from cell biology. The approaches are conceptually different and are developed independently. The results of the three approaches are in agreement. We discuss strength and weaknesses of each of them and illustrate how they can be applied to real world problems.$\backslash$r$\backslash$n$\backslash$r$\backslash$nAVAILABILITY AND IMPLEMENTATION: For application of the approaches to further applications, code representations (DAISY, Mathematica and MATLAB) for benchmark model and data are provided on the authors webpage.$\backslash$r$\backslash$n$\backslash$r$\backslash$nCONTACT: andreas.raue@fdm.uni-freiburg.de.},
author = {Raue, Andreas and Karlsson, Johan and Saccomani, Maria Pia and Jirstrand, Mats and Timmer, Jens},
doi = {10.1093/bioinformatics/btu006},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raue et al. - 2014 - Comparison of approaches for parameter identifiability analysis of biological systems.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {10},
pages = {1440--1448},
pmid = {24463185},
title = {{Comparison of approaches for parameter identifiability analysis of biological systems}},
volume = {30},
year = {2014}
}
@article{Biddulph2014,
abstract = {Evaluating how much heat is lost through external walls is a key requirement for building energy simulators and is necessary for quality assurance and successful decision making in policy making and building design, construction and refurbishment. Heat loss can be estimated using the temperature differences between the inside and outside air and an estimate of the thermal transmittance (U-value) of the wall. Unfortunately the actual U-value may be different from those values obtained using assumptions about the materials, their properties and the structure of the wall after a cursory visual inspection. In-situ monitoring using thermometers and heat flux plates enables more accurate characterisation of the thermal properties of walls in their context. However, standard practices require that the measurements are carried out in winter over a two-week period to significantly reduce the dynamic effects of the wall's thermal mass from the data. A novel combination of a lumped thermal mass model, together with Bayesian statistical analysis is presented to derive estimates of the U-value and effective thermal mass. The method needs only a few days of measurements, provides an estimate of the effective thermal mass and could potentially be used in summer. {\textcopyright} 2014 The Authors.},
annote = {"The application of Bayesian inference to building energy characterisation, while very promising"
"When applied to building physics, inverse methods always rely on a simplified modelling of the buildings (RC models)"
Ref trouv{\'{e}}e dans la proposition d{\'{e}}taill{\'{e}} BAYREB (e-biblio dropbox)


Les m{\'{e}}thodes usuelles ne permettent pas bien de quantifier l'erreur r{\'{e}}percut{\'{e}}es par les hypoth{\`{e}}ses. La caract{\'{e}}risation par m{\'{e}}thode steady-state sont lentes et ne permettent pas de caract{\'{e}}riser le thermal mass. Un caract{\'{e}}risation en dynamique sera plus holistique.


Le probl{\`{e}}me inverse est r{\'{e}}solu {\`{a}} l'aide de mesures de temp{\'{e}}ratures {\`{a}} l'ext{\'{e}}rieur, dans la brique, {\`{a}} l'int{\'{e}}rieur et une mesure de flux du c{\^{o}}t{\'{e}} int{\'{e}}rieur.


Comparaison de r{\'{e}}sultats  partir de deux mod{\`{e}}les : l'un avec et l'autre sans thermal mass. La premi{\`{e}}re m{\'{e}}thode calcul directement la r{\'{e}}sistance thermique de la paroi par "average method". La deuxi{\`{e}}me est un mod{\`{e}}le 2R1C
Comme connaissance a priori des caract{\'{e}}ristiques des murs, les auteurs utilisent des distributions uniformes.


Premier r{\'{e}}sultat : on est dans la bande de 1{\%} autour de la valeur finale apr{\`{e}}s 3 jours de mesure en mod{\`{e}}le 2R1C et apr{\`{e}}s 10 jours en average method. Le mod{\`{e}}le RC permet mieux de pr{\'{e}}dire le flux thermique, du fait de la prise en compte de la masse thermique dans le mod{\`{e}}le.


Dans ce cas, le mod{\`{e}}le 2R1C est le plus "complexe" qui ait pu {\^{e}}tre utilis{\'{e}}, pour plus complexe, le probl{\`{e}}me aurait {\'{e}}t{\'{e}} mal pos{\'{e}} et d'autres mesures auraient {\'{e}}t{\'{e}} n{\'{e}}cessaires.


L'avantage de la m{\'{e}}thode en dynamique est qu'elle ne n{\'{e}}cessite pas de grande diff{\'{e}}rence de temp{\'{e}}rature (alors que le steady-state le demande)


Algo utilis{\'{e}} : CERN MINUTI, algo en Fortran ou C++, outil de minimisation de fonction (Chi-Square, ou likelihood)},
author = {Biddulph, Phillip and Gori, Virginia and Elwell, Clifford A. and Scott, Cameron and Rye, Caroline and Lowe, Robert and Oreszczyn, Tadj},
doi = {10.1016/j.enbuild.2014.04.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biddulph et al. - 2014 - Inferring the thermal resistance and effective thermal mass of a wall using frequent temperature and heat flux.pdf:pdf},
isbn = {03787788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian Statistics,External wall,Heat Transfer,In-situ Measurements,R-value,Thermal Mass,U-Value},
pages = {10--16},
publisher = {Elsevier B.V.},
title = {{Inferring the thermal resistance and effective thermal mass of a wall using frequent temperature and heat flux measurements}},
url = {http://dx.doi.org/10.1016/j.enbuild.2014.04.004},
volume = {78},
year = {2014}
}
@book{MadsenThyregod2010,
author = {Madsen, Henrik},
doi = {10.1201/9781439891148},
file = {:home/sarah/OneDrive/Travail/Sources/[Chapman {\&} Hall{\_}CRC Texts in Statistical Science] Madsen, Henrik{\_} Thyregod, Poul - Introduction to General and Generalized Linear Models (2010, CRC Press).pdf:pdf},
isbn = {9781439891148},
keywords = {明治期の地方自治権論},
month = {nov},
pages = {316},
publisher = {CRC Press},
title = {{Introduction to General and Generalized Linear Models}},
url = {https://www.taylorfrancis.com/books/9781439891148},
year = {2010}
}
@article{Hostettler2018,
author = {Hostettler, Roland and Tronarp, Filip and S{\"{a}}rkk{\"{a}}, Simo},
doi = {10.1016/j.ifacol.2018.09.137},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hostettler, Tronarp, S{\"{a}}rkk{\"{a}} - 2018 - Modeling the Drift Function in Stochastic Differential Equations using Reduced Rank Gaussian Proc.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Bayesian methods,Gaussian processes,Nonlinear system identification,estimation,filtering,nonparametric methods,smoothing},
number = {15},
pages = {778--783},
publisher = {Elsevier B.V.},
title = {{Modeling the Drift Function in Stochastic Differential Equations using Reduced Rank Gaussian Processes}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896318317981},
volume = {51},
year = {2018}
}
@article{Yi2019,
author = {Yi, Dong Hyuk and Kim, Deuk Woo and Park, Cheol Soo},
doi = {10.1016/j.enbuild.2019.06.012},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1-s2.0-S0378778819301574-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian Inference,Biplot,Likelihood Confidence Interval,Likelihood Confidence Region,Parameter Identifiability},
month = {jun},
publisher = {Elsevier B.V.},
title = {{Parameter identifiability in Bayesian inference for building energy models}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778819301574},
year = {2019}
}
@article{Fan2019,
abstract = {The development of advanced data-driven approaches for building energy management is becoming increasingly essential in the era of big data. Machine learning techniques have gained great popularity in predictive modeling due to their excellence in capturing nonlinear and complicated relationships. However, it is a big challenge for building professionals to fully understand the inference mechanism learnt and put trust into the prediction made, as the models developed are typically of high complexity and low interpretability. To enhance the practical value of advanced machine learning techniques in the building field, this study proposes a comprehensive methodology to explain and evaluate data-driven building energy performance models. The methodology is developed based on the framework of interpretable machine learning. It can help building professionals to understand the inference mechanism learnt, e.g., why a certain prediction is made and what are the supporting and conflicting evidences towards the prediction. A novel metric, i.e., trust, is proposed as an alternative approach other than conventional accuracy metrics to evaluate model performance. The methodology has been validated based on actual building operational data. The results obtained are valuable for the development of intelligent and user-friendly building management systems.},
author = {Fan, Cheng and Xiao, Fu and Yan, Chengchu and Liu, Chengliang and Li, Zhengdao and Wang, Jiayuan},
doi = {10.1016/j.apenergy.2018.11.081},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261918317975-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Big data analytics,Building energy management,Building operational performance,Data-driven models,Interpretable machine learning},
number = {October 2018},
pages = {1551--1560},
publisher = {Elsevier},
title = {{A novel methodology to explain and evaluate data-driven building energy performance models based on interpretable machine learning}},
url = {https://doi.org/10.1016/j.apenergy.2018.11.081},
volume = {235},
year = {2019}
}
@article{Cattarin2016,
abstract = {In the past decades the construction sector experienced the diffusion of a wide variety of complex building envelope components and passive elements and strategies, characterized by a dynamic response to the climatic parameters. Many of these components have been claimed to contribute to reducing building energy use and improving occupants׳ comfort. These kind of envelope elements need nevertheless to be tested under laboratory and real dynamic weather conditions in order to characterise, and possibly to model, their behaviour and their effectiveness both in terms of energy saving and indoor environmental quality. Both indoor laboratories and outdoor test cells have been developed in order to tackle the challenging issue of experimentally characterising innovative envelope elements. However, not always the experimental methodologies are fully and explicitly described in the available literature, and they are rarely compared to other types of experimental procedures. The aim of the present paper is to describe and review recent state of the art technologies for outdoor test cells. The paper starts with a short introduction on potentialities and limitations of outdoor facilities with respect to indoor laboratories and real buildings field tests, and it continues with a detailed classification and description of the most relevant outdoor test cells developed in recent years.},
author = {Cattarin, G. and Causone, F. and Kindinis, A. and Pagliano, L.},
doi = {10.1016/j.rser.2015.10.012},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/TestCell{\_}PrePrint.pdf:pdf},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
month = {feb},
pages = {606--625},
publisher = {Pergamon},
title = {{Outdoor test cells for building envelope experimental characterisation – A literature review}},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115010874?dgcid=raven{\_}sd{\_}recommender{\_}email https://linkinghub.elsevier.com/retrieve/pii/S1364032115010874},
volume = {54},
year = {2016}
}
@inproceedings{Mantesi2019,
address = {Rome},
author = {Mantesi, Eirini and Mourkos, Konstantinos and Hopfe, Christina J and Mcleod, Robert S and Kersken, Matthias and Strachan, Paul},
booktitle = {16th Conference of IBPSA},
file = {:home/sarah/OneDrive/Travail/Sources/IBPSA2019/BS2019{\_}144{\_}1{\_}210460{\_}Mantesi{\_}2019-06-25{\_}14-12{\_}a.pdf:pdf},
title = {{Deploying Building Simulation to Enhance the Experimental Design of a Full-scale Empirical Validation Project}},
year = {2019}
}
@article{Widanage2016a,
abstract = {An Equivalent Circuit Model (ECM) of a lithium ion (Li-ion) battery is an empirical, linear dynamic model and the bandwidth of the input current signal and level of non-linearity in the voltage response are important for the model's validity. An ECM is, however, generally parametrised with a pulse current signal, which is low in signal bandwidth (Part 1) and any non-linear dependence of the voltage on the current due to transport limitations is ignored. This paper presents a general modelling methodology which utilises the higher bandwidth and number of signal levels of a pulse-multisine signal to estimate the battery dynamics and non-linear characteristics without the need of a 3D look-up table for the model parameters. In the proposed methodology a non-parametric estimate of the battery dynamics and non-linear characteristics are first obtained which assists in the model order selection, and to assess the level of non-linearity. The new model structure, termed as the Non-linear ECM (NL-ECM), gives a lower Root Mean Square (RMS) and peak error when compared to an ECM estimated using a pulse data set.},
author = {Widanage, W. D. and Barai, A. and Chouchelamane, G. H. and Uddin, K. and McGordon, A. and Marco, J. and Jennings, P.},
doi = {10.1016/j.jpowsour.2016.05.015},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/1-s2.0-S0378775316305511-main.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Sereine/1-s2.0-S037877531630550X-main.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {Drive-cycle,Equivalent circuit modelling,Li-ion battery,Multisine signal,Multisine signals,Sigmoid function},
pages = {61--69},
publisher = {Elsevier B.V},
title = {{Design and use of multisine signals for Li-ion battery equivalent circuit modelling. Part 1: Signal design}},
url = {http://dx.doi.org/10.1016/j.jpowsour.2016.05.015 http://dx.doi.org/10.1016/j.jpowsour.2016.05.014},
volume = {324},
year = {2016}
}
@article{Lim2017,
abstract = {a b s t r a c t Many efforts are used to eliminate the gaps between physical measurements and simulation results. The Bayesian calibration technique is one of the popular automatic calibration methods Allowing for all sources of uncertainty, the method attempts to correct inadequate models and parameters that produce discrepancies between prediction and observed data. Bayesian calibration requires numerous iterations of simulation. To reduce the computational cost, a meta-model is often used to replace the original detailed model. This paper evaluates and analyzes the influence of meta-model accuracy on the outcomes of the Bayesian calibration for building energy simulation model. The following five meta-models: mul-tiple linear regression model, neural network, support vector machine, multivariate adaptive regression splines, and Gaussian process emulator are investigated and compared. The study varies the ranges of input parameters to explore the associated accuracy of the built meta-models. The calibration results are evaluated and compared using three criteria: simulation time, the coefficient of variation with root mean square error (CVRMSE) to true input parameter values, and CVRMSE to observed outputs (monthly and annual energy use intensity). The paper confirms that there are significant differences in simulation time and accuracy for different types of meta-models. The most accurate meta-model tested is the Gaussian process emulator (GPE), while it requires the longest computing time. The multiple linear regression model is the fastest but shows the worst performance in the calibration for the true input parameters. All the calibrated models, however, can predict well the outputs against the observations.},
author = {Lim, Hyunwoo and Zhai, Zhiqiang John},
doi = {10.1016/j.enbuild.2017.09.009},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim, Zhai - 2017 - Comprehensive evaluation of the influence of meta-models on Bayesian calibration.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,Building energy modeling,Meta-model,Sensitivity analysis,Surrogate model},
month = {nov},
pages = {66--75},
title = {{Comprehensive evaluation of the influence of meta-models on Bayesian calibration}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0378778817316869/1-s2.0-S0378778817316869-main.pdf?{\_}tid=bf91c09c-acc5-11e7-98b5-00000aab0f02{\&}acdnat=1507535278{\_}5fc889b539b96fecb230b1383e4730f4 https://linkinghub.elsevier.com/retrieve/pii/S0378778817316869},
volume = {155},
year = {2017}
}
@article{Fisher1959,
author = {Fisher, F},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher - 1959 - Generalization of the Rank and Order Conditions for Identifiability.pdf:pdf},
number = {3},
pages = {431--447},
title = {{Generalization of the Rank and Order Conditions for Identifiability}},
volume = {27},
year = {1959}
}
@article{Plumlee2017a,
abstract = {The vast majority of stochastic simulation models are imperfect in that they fail to exactly emulate real system dynamics. The inexactness of the simulation model, or model discrepancy, can impact the predictive accuracy and usefulness of the simulation for decision-making. This paper proposes a systematic framework to integrate data from both the simulation responses and the real system responses to learn this discrepancy and quantify the resulting uncertainty. Our framework addresses the theoretical and computational requirements for stochastic estimation in a Bayesian setting. It involves an optimization-based procedure to compute confidence bounds on the target outputs that elicit desirable large-sample statistical properties. We illustrate the practical value of our framework with a call center example and a manufacturing line case study.},
archivePrefix = {arXiv},
arxivId = {1707.06544},
author = {Plumlee, Matthew and Lam, Henry},
eprint = {1707.06544},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Plumlee, Lam - Unknown - An Uncertainty Quantification Method for Inexact Simulation Models.pdf:pdf},
keywords = {Bayesian methods,model calibration,optimization,simulation},
title = {{An Uncertainty Quantification Method for Inexact Simulation Models}},
url = {https://arxiv.org/pdf/1707.06544.pdf http://arxiv.org/abs/1707.06544},
year = {2017}
}
@article{Wolsztynski2005,
author = {Wolsztynski, Eric and Thierry, Eric and Pronzato, Luc},
doi = {10.1016/j.sigpro.2004.11.028},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolsztynski, Thierry, Pronzato - 2005 - Minimum-entropy estimation in semi-parametric models.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
month = {may},
number = {5},
pages = {937--949},
title = {{Minimum-entropy estimation in semi-parametric models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405000150},
volume = {85},
year = {2005}
}
@article{Higham1995,
abstract = {Various normwise relative condition numbers that measure the sensitivity of matrix inversion and the solution of linear systems are characterized. New results are derived for the cases where two common, noninduced matrix norms are used, and where different vector norms are used for the domain and range of the matrix. Condition numbers that respect the structure of symmetric problems are also analyzed. The sensitivity of the condition number itself is then investigated, and we obtain sharp examples of Demmel's general result that for certain problems in numerical analysis " the condition number of the condition number is the condition number. " Finally, upper bounds are derived for the sensitivity of componentwise condition numbers.},
author = {Higham, Desmond J.},
doi = {10.1016/0024-3795(93)00066-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Higham 1995 Conditioning number.pdf.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
month = {jan},
number = {C},
pages = {193--213},
title = {{Condition numbers and their condition numbers}},
url = {http://ac.els-cdn.com.camphrier-2.grenet.fr/0024379593000669/1-s2.0-0024379593000669-main.pdf?{\_}tid=dda7a5aa-20f8-11e7-99f7-00000aab0f26{\&}acdnat=1492164070{\_}50e92b7b4d138f3d95a4d679f06c2eca http://linkinghub.elsevier.com/retrieve/pii/0024379593000669 https:/},
volume = {214},
year = {1995}
}
@article{Hardy2018,
abstract = {Improving the energy efficiency of the UK housing stock is important both to meet carbon emission reduction targets and to reduce fuel poverty. For this reason, domestic properties are frequently retrofitted with energy saving measures. This study looks at how the energy consumption, thermal properties and internal temperature of 14 dwellings change as a result of a solid wall insulation (SWI) retrofit. A decrease in heat transfer coefficient of 11 +6 −7 {\%} was calculated for 2 dwellings, which is slightly lower than the previously modelled value of 18{\%}. However, many houses displayed evidence that the full benefit of SWI was not being realised as, for example, energy savings were offset with increases in internal temperature. Future retrofit schemes should therefore consider supplementing the changes in fabric with increased guidance for the occupant.},
author = {Hardy, A and Glew, D and Gorse, Chris and Fletcher, M},
doi = {10.1016/j.enbuild.2018.01.053},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardy et al. - 2018 - Validating Solid Wall Insulation Retrofits with In-Use Data(2).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {In-Use data,Retrofits,Solid Wall Insulation},
month = {apr},
pages = {200--205},
title = {{Validating solid wall insulation retrofits with in-use data}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0378778817328682/1-s2.0-S0378778817328682-main.pdf?{\_}tid=982471b0-07f3-11e8-ae22-00000aab0f26{\&}acdnat=1517560524{\_}53b5429f8ee1a7b0e0218d6225ab17ff https://linkinghub.elsevier.com/retrieve/pii/S0378778817328682},
volume = {165},
year = {2018}
}
@article{DeSchutter2000,
abstract = {We give a survey of the results in connection with the minimal state-space realization problem for linear time-invariant systems. We start with a brief historical overview and a short introduction to linear system theory. Next we present some of the basic algorithms for the reduction of nonminimal state-space realizations and for the minimal state-space realization of infinite or finite sequences of Markov parameters of linear time-invariant systems. Finally, we discuss some extensions of this problem to other classes of systems and point out some related problems.},
author = {{De Schutter}, Bart},
doi = {10.1016/S0377-0427(00)00341-1},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Schutter - 2000 - Minimal state-space realization in linear system theory An overview Minimal State-Space Realization in Linear Syst.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {linear system theory,minimal realization,state space models},
number = {1},
pages = {331--354},
title = {{Minimal state-space realization in linear system theory: An overview}},
url = {http://www.dcsc.tudelft.nl http://pub.deschutter.info/abs/99{\_}07.html},
volume = {121},
year = {2000}
}
@article{Bellu2007,
abstract = {A priori global identifiability is a structural property of biological and physiological models. It is considered a prerequisite for well-posed estimation, since it concerns the possibility of recovering uniquely the unknown model parameters from measured input-output data, under ideal conditions (noise-free observations and error-free model structure). Of course, determining if the parameters can be uniquely recovered from observed data is essential before investing resources, time and effort in performing actual biomedical experiments. Many interesting biological models are nonlinear but identifiability analysis for nonlinear system turns out to be a difficult mathematical problem. Different methods have been proposed in the literature to test identifiability of nonlinear models but, to the best of our knowledge, so far no software tools have been proposed for automatically checking identifiability of nonlinear models. In this paper, we describe a software tool implementing a differential algebra algorithm to perform parameter identifiability analysis for (linear and) nonlinear dynamic models described by polynomial or rational equations. Our goal is to provide the biological investigator a completely automatized software, requiring minimum prior knowledge of mathematical modelling and no in-depth understanding of the mathematical tools. The DAISY (Differential Algebra for Identifiability of SYstems) software will potentially be useful in biological modelling studies, especially in physiology and clinical medicine, where research experiments are particularly expensive and/or difficult to perform. Practical examples of use of the software tool DAISY are presented. DAISY is available at the web site http://www.dei.unipd.it/∼pia/. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Bellu, Giuseppina and Saccomani, Maria Pia and Audoly, Stefania and D'Angi{\`{o}}, Leontina},
doi = {10.1016/j.cmpb.2007.07.002},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellu et al. - 2007 - DAISY A new software tool to test global identifiability of biological and physiological systems.pdf:pdf},
isbn = {0169-2607},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {A priori global identifiability,Differential algebra,Identifiability,Identifiability software,Linear and nonlinear dynamical systems,Model identification},
number = {1},
pages = {52--61},
pmid = {17707944},
title = {{DAISY: A new software tool to test global identifiability of biological and physiological systems}},
volume = {88},
year = {2007}
}
@incollection{Walter1982,
author = {Walter, Eric},
doi = {10.1007/978-3-642-61823-9_5},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter - 1982 - Global Identifiability of Linear Models.pdf:pdf},
pages = {79--96},
title = {{Global Identifiability of Linear Models}},
url = {http://link.springer.com/10.1007/978-3-642-61823-9{\_}5},
year = {1982}
}
@article{Hedegaard2017,
abstract = {The ability to obtain reliable estimates the actual thermal characteristics of whole buildings through fitting dynamical resistance-capacitance grey-box models to measurement data was investigated. The actual total heat loss coefficient was identified with a maximum deviation of 4{\%} for all the evaluated model structures. The best performing models tended to overestimate the effective thermal mass by 10-32 {\%} compared to the Effective Thickness Method of ISO 13786. The results also indicated that identifying the distribution of the total heat loss into transmission and infiltration heat losses is unlikely to be achieved from typical building measurement data.},
author = {Hedegaard, Rasmus Elb{\ae}k and Petersen, Steffen},
doi = {10.1016/j.egypro.2017.09.692},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hedegaard, Petersen - 2017 - Evaluation of Grey-Box Model Parameter Estimates Intended for Thermal Characterization of Buildings.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Building thermal characterization,Estimation of heat losses,Identifiability analysis,Model structure selection,System Identification},
pages = {982--987},
publisher = {Elsevier B.V.},
title = {{Evaluation of Grey-Box Model Parameter Estimates Intended for Thermal Characterization of Buildings}},
url = {https://doi.org/10.1016/j.egypro.2017.09.692},
volume = {132},
year = {2017}
}
@article{Li2016b,
abstract = {a b s t r a c t Calibration of building energy models is widely used in building energy audits and retrofit practices. Li et al. (2015) proposed a lightweight approach for the Bayesian calibration of dynamic building energy models, which alleviate the computation issues by the use of a linear regression emulator. As a fur-ther extension, this paper has the following contributions. First, it provides a brief literature review that motivates the original work. Second, it explained the detailed calibration methodology and its mathemat-ical formulas, and in addition the prediction using meta-models. Third, it introduced new performance metrics for evaluating predictive distributions under uncertainty. Fourth, it used the standard Bayesian calibration method as the benchmark, assessed the capability of regression emulators of different com-plexity, and showed the comparison result in a case study. Compared to the standard Gaussian process emulator, the linear regression emulator including main and interaction effects is much simpler both in interpretation and implementation, calibrations are performed much more quickly, and the calibra-tion performances are similar. This indicates a capability to perform fast risk-conscious calibration for most current retrofit practice where only monthly consumption and demand data from utility bills are available.},
author = {Li, Qi and Augenbroe, Godfried and Brown, Jason},
doi = {10.1016/j.enbuild.2016.04.025},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Augenbroe, Brown - 2016 - Assessment of linear emulators in lightweight Bayesian calibration of dynamic building energy models for p.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,Building energy,Dynamic model,Multiple responses,Parameter estimation,Probabilistic prediction,Regression,Retrofit analysis},
month = {jul},
pages = {194--202},
title = {{Assessment of linear emulators in lightweight Bayesian calibration of dynamic building energy models for parameter estimation and performance prediction}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0378778816302808/1-s2.0-S0378778816302808-main.pdf?{\_}tid=cb0b15cc-acc5-11e7-a6e8-00000aab0f26{\&}acdnat=1507535297{\_}b1da2ad0048dea795bfb5d331c8a7cef https://linkinghub.elsevier.com/retrieve/pii/S0378778816302808},
volume = {124},
year = {2016}
}
@article{Johnson1990,
abstract = {Beginning with an arbitrary set and a distance defined on it, we develop the notions of minimax and maximin distance sets (designs). These are intended for use in the selection-of-sites problem when the underlying surface is modeled by a prior distribution and observations are made without error. It is shown that such designs have quite general asymptotically optimum (and dual) characteristics under what are termed the G- and D-criteria. There are many examples given, dealing espeacially with the unit square and with k factors at two levels. {\textcopyright} 1990.},
author = {Johnson, M. E. and Moore, L. M. and Ylvisaker, D.},
doi = {10.1016/0378-3758(90)90122-B},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-037837589090122B-main.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Bayesian design,asymptotic optimality,computer experiments},
number = {2},
pages = {131--148},
title = {{Minimax and maximin distance designs}},
volume = {26},
year = {1990}
}
@article{Wit2012,
abstract = {In this article, we introduce the concept of model uncertainty. We review the frequentist and Bayesian ideas underlying model selection, which serve as an introduction to the rest of this special issue on 'All models are wrong. ', a workshop under the same name was held in March 2011 in Groningen to critically examined the field of statistical model selection methods over the past 40 years. We briefly introduce the philosophical debate that is concerned with model selection. We present the results of a questionnaire that was distributed under the participants of the workshop, showing that the field has not yet reached a comforting consensus and is still in full swing. {\textcopyright} 2012 The Authors. Statistica Neerlandica {\textcopyright} 2012 VVS.},
author = {Wit, Ernst and van den Heuvel, Edwin and Romeijn, Jan-Willem},
doi = {10.1111/j.1467-9574.2012.00530.x},
file = {:home/sarah/OneDrive/Travail/Sources/j.1467-9574.2012.00530.x.pdf:pdf},
issn = {00390402},
journal = {Statistica Neerlandica},
keywords = {Bayesian,Confirmation theory,Foundations,Frequentist,Model selection,Model uncertainty,Questionnaire},
month = {aug},
number = {3},
pages = {217--236},
title = {{‘All models are wrong...': an introduction to model uncertainty}},
url = {http://doi.wiley.com/10.1111/j.1467-9574.2012.00530.x},
volume = {66},
year = {2012}
}
@article{Iooss2011,
abstract = {Cet article a pour objectif d'effectuer un survol rapide, mais dans un cadre m{\'{e}}thodologique relativement complet, des diff{\'{e}}rentes m{\'{e}}thodes d'analyse de sensibilit{\'{e}} globale d'un mod{\`{e}}le num{\'{e}}rique. Faisant appel {\`{a}} de nombreux outils statistiques (r{\'{e}}gression, lissage, tests, apprentissage, techniques de Monte Carlo, . . . ), celles-ci permettent de d{\'{e}}terminer quelles sont les variables d'entr{\'{e}}e d'un mod{\`{e}}le qui contribuent le plus {\`{a}} une quantit{\'{e}} d'int{\'{e}}r{\^{e}}t calcul{\'{e}}e {\`{a}} l'aide de ce mod{\`{e}}le (par exemple la variance d'une variable de sortie). Trois grandes classes de m{\'{e}}thodes sont ainsi distingu{\'{e}}es : le criblage (tri grossier des entr{\'{e}}es les plus influentes parmi un grand nombre), les mesures d'importance (indices quantitatifs donnant l'influence de chaque entr{\'{e}}e) et les outils d'exploration du mod{\`{e}}le (mesurant les effets des entr{\'{e}}es sur tout leur domaine de variation). Une m{\'{e}}thodologie progressive d'application de ces techniques est illustr{\'{e}}e sur une application {\`{a}} vocation p{\'{e}}dagogique. Une synth{\`{e}}se est alors formul{\'{e}}e afin de situer chaque m{\'{e}}thode selon trois axes : co{\^{u}}t en nombre d'{\'{e}}valuations du mod{\`{e}}le, complexit{\'{e}} du mod{\`{e}}le et type d'information apport{\'{e}}e},
author = {Iooss, Bertrand},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iooss - 2011 - Revue sur l'analyse de sensibilit{\'{e}} globale de mod{\`{e}}les num{\'{e}}riques(2).pdf:pdf},
issn = {0037-914X},
journal = {Journal de la Soci{\'{e}}t{\'{e}} Fran{\c{c}}aise de Statistique {\&} revue de statistique appliqu{\'{e}}e},
keywords = {Code de calcul,Exp{\'{e}}rience num{\'{e}}rique,Incertitude,M{\'{e}}tamod{\`{e}}le,Plan d'exp{\'{e}}riences},
number = {1},
pages = {3--25},
title = {{Revue sur l'analyse de sensibilit{\'{e}} globale de mod{\`{e}}les num{\'{e}}riques}},
url = {https://hal.archives-ouvertes.fr/hal-00503179/document},
volume = {152},
year = {2011}
}
@book{Walter1997,
abstract = {The book is produced as a natural consequence of the authors' research and teaching colloboration for many years. It is aimed at two groups of readers. The first consists of students wishing to study the basic methods for system identification and parameter and/or state estimation. The other one consists of researchers and engineers who have to squeeze parameters out of experimental data.$\backslash$par The book consists of seven chapters, which cover choice of the structure of the mathematical model, choice of a performance criterion to compare models, optimization of the performance criteria, evaluation of the uncertainty contained in the estimated parameters, experiment designs, and critical analysis of the model.$\backslash$par Chapter 2 is devoted to the choice of a structure for the mathematical model. In particular, the authors present the methods for testing linear and nonlinear models for identifiability and distinguishability among linear and nonlinear models, continuous- and discrete-time models, and deterministic and stochastic models.$\backslash$par Chapter 3 is devoted to introducing various types of criteria and their properties. An emphasis on other criteria than the least squares one and the importance of robustness are presented too.$\backslash$par Chapter 4 is devoted to a detailed treatment of parametric optimization, including much more considerations of numerical aspects than usual (evaluation of the effect of rounding errors, generation of derivatives of the cost function with respect to the parameters, global optimization $\backslash$dots). It takes more than one third of the book and presents most optimization methods in common use, such as the least squares method, the Kalman filter method, the gradient method, the one-dimensional optimization method, the Newton method, the Gauss-Newton method, the Levenberg-Marquardt method, the quasi-Newton method, the conjugated-gradient method, and so on.$\backslash$par Chapter 5 is devoted to evaluating the uncertainty contained in the estimated parameters. It is also important to evaluate the uncertainty, taking into account the one in the data and the numerical errors. The authors present deterministic and statistical methods of characterizing the uncertainty in the parameter resulting from the the one in the data.$\backslash$par Chapter 6 is devoted to experiment designs (in much more detail than usual) for the collection of numerical data to be used to estimate the parameters of a given model. The authors consider a scalar function of the Fisher information matrix as the criterion and present local designs, robust designs, and the designs for Bayesian estimation.$\backslash$par Chapter 7 is devoted to questioning the parameter estimation, i.e. testing the validation of the model produced. This step is of paramount importance. Most of the techniques are based on analysis of residuals. The testing items include the testing for homogeneity, normality, stationarity, and independence.$\backslash$par In a word, the book is practical and readable.},
author = {Walter, Eric and Pronzato, Luc},
file = {:home/sarah/OneDrive/Travail/Sources/Probl{\`{e}}mes inverses/Eric Walter and Luc Pronzato. - Identification of parametric models from experimental data.pdf:pdf},
isbn = {3540761195},
pages = {413},
publisher = {Springer},
title = {{Identification of parametric models from experimental data}},
year = {1997}
}
@article{Iooss2013,
author = {Iooss, Bertrand},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iooss - 2013 - M{\'{e}}tamod{\`{e}}le.pdf:pdf},
pages = {1--90},
title = {{M{\'{e}}tamod{\`{e}}le}},
year = {2013}
}
@techreport{Rouchier2015,
author = {Rouchier, Simon},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier - 2015 - Bayesian inference for optimising the energy refurbishment of existing buildings - BAYREB Approche Bay{\'{e}}sienne.pdf:pdf},
pages = {1--26},
title = {{Bayesian inference for optimising the energy refurbishment of existing buildings - BAYREB Approche Bay{\'{e}}sienne pour l ' audit {\'{e}}nerg{\'{e}}tique et l ' optimisation de la r{\'{e}}habilitation des b{\^{a}}timents existants}},
year = {2015}
}
@article{Gu2007,
abstract = {The airflow network model in EnergyPlus provides the ability to simulate multizone wind-driven airflows. The model is also able to simulate the impacts of forced air distribution systems, including supply and return air leaks. The air distribution system portion of the model is currently applicable for constant-air-volume systems. Future enhancements will include adding hybrid ventilation control and possible extension to include variable- air-volume distribution systems. This paper describes the input objects, calculation procedures, model validation, and example results. The model inputs consist of five main objects: simulation control, multizone data, node data, component data, and linkage data. The model calculates pressure at each node and airflow through each component based on the pressure versus airflow relationship defined for each component. Using these airflow rates and HVAC equipment models, temperature and humidity ratio at each air node are then calculated. All cooling/heating loads resulting from the multizone airflow and air distribution system model are then summed and passed to EnergyPlus' zone air heat and moisture balance model which calculates zone air temperature and humidity ratio. The loads from multizone air flows are used to predict required system loads, while the loads due to the air distribution system are used to recalculate zone air temperatures and humidity ratios. EnergyPlus' airflow network model was validated against measured data from both the Oak Ridge National Laboratory (ORNL) and the Florida Solar Energy Center (FSEC). Whole building energy simulations were performed using EnergyPlus in addition to validating specific portions of its airflow network model. There was good agreement between the simulation results and the measured data.},
author = {Gu, Lixing},
file = {:home/sarah/OneDrive/Travail/Sources/FSEC-PF-428-07.pdf:pdf},
journal = {IBPSA 2007 - International Building Performance Simulation Association 2007},
keywords = {Air distribution system,Airflow and pressure,And outdoors,HVAC system,Interactions among envelope},
number = {December},
pages = {964--971},
title = {{Airflow network modeling in energyplus}},
year = {2007}
}
@misc{ISO13789,
author = {{ISO 13789}},
keywords = {BUILDINGS,COMPUTATION,HEAT LOSSES,HEAT TRANSFER,HEAT TRANSFER COEFFICIENT},
title = {{Thermal performance of buildings - Transmission and ventilation heat transfer coefficients - Calculation method}},
url = {https://viewer.afnor.org/Html/Display/3UElv0MjQus1{\#}},
year = {2017}
}
@article{Cai2015,
author = {Cai, Jie and Braun, James E.},
doi = {10.1080/19401493.2015.1108999},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Braun - 2015 - An inverse hygrothermal model for multi-zone buildings.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {building inverse model,building thermal and moisture,hygrothermal model,responses,system identification},
number = {November},
pages = {1--19},
title = {{An inverse hygrothermal model for multi-zone buildings}},
url = {http://www.tandfonline.com/doi/full/10.1080/19401493.2015.1108999},
volume = {1493},
year = {2015}
}
@article{Huebner2013,
abstract = {Heating patterns and temperatures are among the most important determinants of English home energy use. Consequently, building stock models, widely used for informing UK energy policy, are highly sensitive to the assumptions they make on how occupants heat their homes. This study examined heating patterns in English living rooms and compared them to model assumptions. A time-series of winter spot temperature measurements was translated into statements of the heating system being on or off during weekdays and weekend days, and the heating demand temperature estimated. The analysis showed that weekdays and weekend days are far more similar than commonly assumed. Contrary to model assumptions, homes were frequently heated outside assumed heating hours and not all homes were heated at the same time or followed the same pattern. The estimated demand temperature was about 20.6°C, and the average temperature during heating periods was about 19.5°C, both lower than the commonly assumed 21°C used in models. Significantly, variability between homes in demand temperature and hours of heating was substantial. The results indicate the need to revisit some assumptions made in building stock models, and to take account of variability between homes when aiming at predicting space heating demand for an individual home. {\textcopyright} 2013 The Authors.},
author = {Huebner, Gesche M. and McMichael, Megan and Shipworth, David and Shipworth, Michelle and Durand-Daubin, Mathieu and Summerfield, Alex},
doi = {10.1016/j.buildenv.2013.08.028},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0360132313002540-main.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {BREDEM,Building stock models,Heating demand temperature,Heating duration,Heating patterns,Occupancy schedules},
month = {dec},
pages = {298--305},
title = {{Heating patterns in English homes: Comparing results from a national survey against common model assumptions}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360132313002540},
volume = {70},
year = {2013}
}
@article{Walter1996a,
abstract = {Testing parametric models for identifiability and distinguishability is important when the parameters to be estimated have a physical meaning or when the model is to be used to reconstruct physically meaningful state variables that cannot be measured directly. Examples are used to explain why and indicate briefly how, with special emphasis on nonlinear models.},
author = {Walter, Eric and Pronzato, Luc},
doi = {10.1016/0378-4754(95)00123-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter, Pronzato - 1996 - On the identifiability and distinguishability of nonlinear parametric models.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter, Pronzato - 1996 - On the identifiability and distinguishability of nonlinear parametric models(2).pdf:pdf},
isbn = {0378-4754},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
number = {2-3},
pages = {125--134},
title = {{On the identifiability and distinguishability of nonlinear parametric models}},
url = {http://www.sciencedirect.com/science/article/pii/0378475495001239},
volume = {42},
year = {1996}
}
@article{Margaria2004,
abstract = {In this paper we identify biologically relevant families of models whose struc- tural identifiability analysis could not be performed with available techniques directly. The models considered come from both the immunological and epidemiological literature.},
annote = {From Duplicate 1 (Structural identifiability analysis of some highly structured families of statespace models using differential algebra - Margaria, Gabriella; Riccomagno, Eva; White, Lisa J)

Description claire de l'alg diff

utilisation du package diffalg {\&} observabilityTest

From Duplicate 2 (Structural identifiability analysis of some highly structured families of statespace models using differential algebra - Margaria, Gabriella; Riccomagno, Eva; White, Lisa J)

From Duplicate 2 (Structural identifiability analysis of some highly structured families of statespace models using differential algebra - Margaria, Gabriella; Riccomagno, Eva; White, Lisa J)

From Duplicate 2 (Structural identifiability analysis of some highly structured families of statespace models using differential algebra - Margaria, Gabriella; Riccomagno, Eva; White, Lisa J)

Description claire de l'alg diff

utilisation du package diffalg {\&} observabilityTest

Biologie des syst{\`{e}}mes --{\textgreater} les auteurs travaillent sur des "mod{\`{e}}les sym{\'{e}}triques hautement structur{\'{e}}s".


Les auteurs n'utilisent pas le mot calibration mais estimation des param{\`{e}}tres.
--{\textgreater} TERMINOLOGIE Quand on cherche les param{\`{e}}tres pour ce qu'ils repr{\'{e}}sentent, on estime les param{\`{e}}tres, quand on d{\'{e}}termine les param{\`{e}}tres pour ce que le mod{\`{e}}le repr{\'{e}}sente, on calibre le mod{\`{e}}le.


Dans le cas de mod{\`{e}}les d{\'{e}}finis par des polyn{\^{o}}mes ou des rapports de polyn{\^{o}}mes, on utilisera l'alg{\`{e}}bre diff{\'{e}}rentielle. Le principe est qu'un couple (u,$\theta$) qui satisfait le mod{\`{e}}le M (u,x $\theta$) satisfait aussi des {\'{e}}quations issues de combinaisons lin{\'{e}}aires, produits et diff{\'{e}}rentiels. Si alors on est capable de d{\'{e}}terminer des {\'{e}}quations de la forme B1(u,y) + $\theta$1.B2(u,y) alors on peut identifier $\theta$1
On appelle le set d'{\'{e}}quations obtenues le "model ideal".


Le calcul des polyn{\^{o}}mes du "model ideal" peuvent se faire num{\'{e}}riquement par algo (sous Maple dans le cas de cet article)
Dans certains cas, il n'est pas possible de d{\'{e}}terminer ces polyn{\^{o}}mes (mod{\`{e}}le non identifiable). A ce moment, une {\'{e}}tude des param{\`{e}}tres obtenus permet parfois de transformer le mod{\`{e}}le en un mod{\`{e}}le identifiable.},
author = {Margaria, Gabriella and Riccomagno, Eva and White, Lisa J},
doi = {10.1007/s00285-003-0261-3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Margaria, Riccomagno, White - 2004 - Structural identifiability analysis of some highly structured families of statespace models using d.pdf:pdf},
issn = {0303-6812},
journal = {Journal of Mathematical Biology},
keywords = {diffalg,differential algebra,or phrases,statespace models,structural identifiability},
mendeley-tags = {diffalg,differential algebra},
month = {nov},
number = {5},
pages = {433--454},
title = {{Structural identifiability analysis of some highly structured families of statespace models using differential algebra}},
url = {http://link.springer.com/10.1007/s00285-003-0261-3},
volume = {49},
year = {2004}
}
@article{Fabrizio2015,
abstract = {Buildings do not usually perform during operation as well as predicted during the design stage. Disagreement between simulated and metered energy consumption represents a common issue in building simulation. For this reason, the calibration of building simulation models is of growing interest. Sensitivity and uncertainty analyses play an important role in building model accuracy. They can be used to identify the building model parameters most influent on the energy consumption. Given this, these analyses should be integrated within calibration methodologies and applications for tuning the parameters. This paper aims at providing a picture of the state of the art of calibration methodologies in the domain of building energy performance assessment. First, the most common methodologies for calibration are presented, emphasizing criticalities and gaps that can be faced. In particular the main issues to be addressed, when carrying out calibrated simulation, are discussed. The standard statistical criteria for considering the building models calibrated and for evaluating their goodness-of-fit are also presented. Second, the commonly used techniques for investigating uncertainties in building models are reviewed. Third, a review of the latest main studies in the calibrated simulation domain is presented. Criticalities and recommendations for new studies are finally provided.},
author = {Fabrizio, Enrico and Monetti, Valentina},
doi = {10.3390/en8042548},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fabrizio, Monetti - 2015 - Methodologies and Advancements in the Calibration of Building Energy Models.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {building performance simulation,calibration methodologies,existing buildings,sensitivity analysis,uncertainty analysis},
month = {mar},
number = {4},
pages = {2548--2574},
title = {{Methodologies and Advancements in the Calibration of Building Energy Models}},
url = {http://www.mdpi.com/1996-1073/8/4/2548},
volume = {8},
year = {2015}
}
@inproceedings{Ghoshal2018,
abstract = {The problem of learning structural equation models (SEMs) from data is a fundamental problem in causal inference. We develop a new algorithm --- which is computationally and statistically efficient and works in the high-dimensional regime --- for learning linear SEMs from purely observational data with arbitrary noise distribution. We consider three aspects of the problem: identifiability, computational efficiency, and statistical efficiency. We show that when data is generated from a linear SEM over {\$}p{\$} nodes and maximum degree {\$}d{\$}, our algorithm recovers the directed acyclic graph (DAG) structure of the SEM under an identifiability condition that is more general than those considered in the literature, and without faithfulness assumptions. In the population setting, our algorithm recovers the DAG structure in {\$}\backslashmathcal{\{}O{\}}(p(d{\^{}}2 + \backslashlog p)){\$} operations. In the finite sample setting, if the estimated precision matrix is sparse, our algorithm has a smoothed complexity of {\$}\backslashwidetilde{\{}\backslashmathcal{\{}O{\}}{\}}(p{\^{}}3 + pd{\^{}}7){\$}, while if the estimated precision matrix is dense, our algorithm has a smoothed complexity of {\$}\backslashwidetilde{\{}\backslashmathcal{\{}O{\}}{\}}(p{\^{}}5){\$}. For sub-Gaussian noise, we show that our algorithm has a sample complexity of {\$}\backslashmathcal{\{}O{\}}(\backslashfrac{\{}d{\^{}}8{\}}{\{}\backslashvarepsilon{\^{}}2{\}} \backslashlog (\backslashfrac{\{}p{\}}{\{}\backslashsqrt{\{}\backslashdelta{\}}{\}})){\$} to achieve {\$}\backslashvarepsilon{\$} element-wise additive error with respect to the true autoregression matrix with probability at most {\$}1 - \backslashdelta{\$}, while for noise with bounded {\$}(4m){\$}-th moment, with {\$}m{\$} being a positive integer, our algorithm has a sample complexity of {\$}\backslashmathcal{\{}O{\}}(\backslashfrac{\{}d{\^{}}8{\}}{\{}\backslashvarepsilon{\^{}}2{\}} (\backslashfrac{\{}p{\^{}}2{\}}{\{}\backslashdelta{\}}){\^{}}{\{}1/m{\}}){\$}.},
author = {Ghoshal, Asish and Honorio, Jean},
booktitle = {International Conference on Artificial Intelligence and Statistics, AISTATS 2018},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghoshal, Honorio - Unknown - Learning linear structural equation models in polynomial time and sample complexity.pdf:pdf},
keywords = {A creuser,Structural equation models},
mendeley-tags = {A creuser,Structural equation models},
pages = {1466--1475},
title = {{Learning linear structural equation models in polynomial time and sample complexity}},
url = {https://arxiv.org/pdf/1707.04673.pdf},
year = {2018}
}
@article{Ricciu2019,
abstract = {This study investigates energy efficiency in buildings. The accurate evaluation of energy consumption in existing buildings is a difficult task, particularly due to the Mediterranean climate, which is in the temperate zone. Among the various analytical models, the most effective measurement of the energy consumption of buildings is the dynamic type. In evaluating the energy consumption of buildings, the greatest contribution is provided by opaque components and particularly by the external walls of that building. In the model, which is reported in the EN ISO 13786, the thermal properties (the specific heat (J/kgK) and thermal conductivity (W/mK) of the layers of the wall were tested, and the technical standard reported that the physical properties (from which they derive the phase shift and decrement factor) transferred through the wall when a sinusoidal wave temperature variation was applied in a periodic steady state. We propose an inverse approach to measure the sinusoidal periodic steady state (temperature and thermal flux) on the two faces of the wall. With this approach, it is possible to obtain the thermal properties of the wall through an inverse analytical model. The model was applied in a real experiment on a full-size wall in a climatic chamber to verify the dynamic thermal and physical properties of the layers.},
author = {Ricciu, Roberto},
doi = {10.1016/J.ENBUILD.2019.01.035},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ricciu - 2019 - Thermal properties of building walls Indirect estimation using the inverse method with a harmonic approach.pdf:pdf},
issn = {0378-7788},
journal = {Energy and Buildings},
keywords = {Building external wall,Energy efficiency,Heat transfer,Inverse method,Sinusoidal Steady-State Analysis,Thermal comfort},
publisher = {Elsevier B.V.},
title = {{Thermal properties of building walls: Indirect estimation using the inverse method with a harmonic approach}},
url = {https://www.sciencedirect.com/science/article/pii/S0378778818313689?dgcid=raven{\_}sd{\_}aip{\_}email},
year = {2019}
}
@article{Martinez-Camblor2012,
abstract = {The bootstrap is a intensive computer - based method originally mainly devoted to estimate the standard deviations , confidence intervals and bias of the studied statistic . This technique is useful in a wide variety of statistical procedures , however its use for hypothesis testing , when the data structure is complex , is not straightforward and each case must be particularly treated . A general bootstrap method for hypothesis testing is studied . The considered method preserves the data structure of each group independently and the null hypothesis is only used in order to compute the bootstrap statistic values (not at the resampling , as usual) . The asymptotic distribution is developed and several case studies are discussed .},
author = {Mart{\'{i}}nez-Camblor, Pablo and Corral, Norberto},
doi = {10.1016/j.jspi.2011.09.003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mart{\'{i}}nez-Camblor - Unknown - A general bootstrap algorithm for hypothesis testing.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Competing risk,Cumulative incidence function,Gini index,Survival model},
month = {feb},
number = {2},
pages = {589--600},
title = {{A general bootstrap algorithm for hypothesis testing}},
url = {https://www.researchgate.net/profile/Pablo{\_}Martinez-Camblor/publication/244300312{\_}A{\_}general{\_}bootstrap{\_}algorithm{\_}for{\_}hypothesis{\_}testing/links/0046351d3bf2b43763000000/A-general-bootstrap-algorithm-for-hypothesis-testing.pdf https://linkinghub.elsevier.com/},
volume = {142},
year = {2012}
}
@book{Sarkka2013,
abstract = {Filtering and smoothing methods are used to produce an accurate estimate of the state of a time-varying system based on multiple observational inputs (data). Interest in these methods has exploded in recent years, with numerous applications emerging in fields such as navigation, aerospace engineering, telecommunications and medicine. This compact, informal introduction for graduate students and advanced undergraduates presents the current state-of-the-art filtering and smoothing methods in a unified Bayesian framework. Readers learn what non-linear Kalman filters and particle filters are, how they are related, and their relative advantages and disadvantages. They also discover how state-of-the-art Bayesian parameter estimation methods can be combined with state-of-the-art filtering and smoothing algorithms. The book's practical and algorithmic approach assumes only modest mathematical prerequisites. Examples include MATLAB computations, and the numerous end-of-chapter exercises include computational assignments. MATLAB/GNU Octave source code is available for download at www.cambridge.org/sarkka, promoting hands-on work with the methods.},
address = {Cambridge},
author = {S{\"{a}}rkk{\"{a}}, Simo},
booktitle = {Bayesian Filtering and Smoothing},
doi = {10.1017/CBO9781139344203},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\"{a}}rkk{\"{a}} - 2013 - BAYESIAN FILTERING AND SMOOTHING.pdf:pdf},
isbn = {9781139344203},
keywords = {Bayesian filtering,Kalman},
mendeley-tags = {Bayesian filtering,Kalman},
pages = {1--232},
publisher = {Cambridge University Press},
title = {{Bayesian filtering and smoothing}},
url = {www.cambridge.org/sarkka. http://ebooks.cambridge.org/ref/id/CBO9781139344203},
year = {2010}
}
@article{Vivian2017a,
abstract = {a b s t r a c t Simple, reliable building models have been receiving quite a bit of attention recently particularly with regard to diverse applications, such as building design for inexpert energy modellers, simulation of neigh-bourhood or city districts and model predictive control. The International Standard ISO 13790 and the German Guideline VDI 6007 use two different lumped-capacitance models (5R1C and 7R2C, respectively) based on deterministic, analytical procedures to identify their parameters. The current work investigates the suitability of these models in calculating peak loads and seasonal energy needs and their accuracy in estimating buildings' dynamic behaviour. A room and an apartment were thus simulated using simplified models and with the benchmarked software TRNSYS. Four reference envelopes with different thermal insulation and heat capacities were examined in four climatic conditions. Each of the models was able to estimate quite precisely energy needs in both the heating and cooling modes, although the 7R2C model was slightly more accurate. The 5R1C model was, however, unable to follow the thermal response of the buildings during the cooling season, which in turn implied a systematic underestimation of the cooling peak load. The 7R2C model identified a significant reduction in the root mean squared error (RMSE) both in the indoor air temperature and in the heating/cooling loads with respect to the reference profiles. That model would seem then more suitable for the dynamic simulation of single thermal zones with hourly time steps in both heating and cooling modes.},
author = {Vivian, Jacopo and Zarrella, Angelo and Emmi, Giuseppe and {De Carli}, Michele},
doi = {10.1016/j.enbuild.2017.06.021},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vivian et al. - 2017 - An evaluation of the suitability of lumped-capacitance models in calculating energy needs and thermal behaviour o.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building simulation,ISO 13790,Lumped-capacitance model,Simplified model,TRNSYS,VDI 6007},
month = {sep},
pages = {447--465},
title = {{An evaluation of the suitability of lumped-capacitance models in calculating energy needs and thermal behaviour of buildings}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0378778816314244/1-s2.0-S0378778816314244-main.pdf?{\_}tid=3442502e-d9c5-11e7-ad43-00000aab0f6b{\&}acdnat=1512482847{\_}cd5e28b6dd8f7e3077edd031bcf400f3 https://linkinghub.elsevier.com/retrieve/pii/S0378778816314244},
volume = {150},
year = {2017}
}
@article{Tarantola2006a,
abstract = {We present two methods for the estimation of main effects in global sensitivity analysis. The methods adopt Satterthwaite's application of random balance designs in regression problems, and extend it to sensitivity analysis of model output for non-linear, non-additive models. Finite as well as infinite ranges for model input factors are allowed. The methods are easier to implement than any other method available for global sensitivity analysis, and reduce significantly the computational cost of the analysis. We test their performance on different test cases, including an international benchmark on safety assessment for nuclear waste disposal originally carried out by OECD/NEA. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
author = {Tarantola, Stefano and Gatelli, D. and Mara, Thierry},
doi = {10.1016/j.ress.2005.06.003},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/Tarantola06RESS{\_}HAL.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Computational models,Global sensitivity analysis,Uncertainty analysis},
number = {6},
pages = {717--727},
title = {{Random balance designs for the estimation of first order global sensitivity indices}},
volume = {91},
year = {2006}
}
@article{Wang2004,
abstract = {A Bayesian inference approach is presented for the solution of the inverse heat conduction problem. The posterior probability density function (PPDF) of the boundary heat flux is computed given temperature measurements within a conducting solid. Uncertainty in temperature measurements is modeled as stationary zero-mean white noise. The inverse solution is obtained by computing the expectation of the PPDF. The posterior state space is exploited using Markov chain Monte Carlo (MCMC) algorithms in order to obtain estimates of the statistics of the unknown heat flux. The MCMC sampling strategy enables the extension of the Bayesian inference approach to inverse problems having high-dimensional, non-standard distribution, and/or complex PPDFs. The ill-posedness (un-identifability) of the inverse problem is cured through prior distribution modeling (Bayesian prior regularization) of the unknown heat flux. A special model of Markov random eld (MRF) is adopted for prior distribution modeling of the unknown heat flux. An augmented Bayesian model is proposed for estimating the statistics of the measurement noise as well as the unknown heat flux. Two inverse heat conduction examples are presented to demonstrate the potential of the MCMC-based Bayesian approach. The simulation results indicate that MRF provides an effective prior regularization, the estimates using MCMC samples are accurate and the Bayesian approach captures very well the probability distribution of the unknown heat flux.},
author = {Wang, J and Zabaras, N},
doi = {10.1016/j.ijheatmasstransfer.2004.02.028},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Zabaras - 2004 - A Bayesian Inference Approach To The Inverse Heat Conduction Problem.pdf:pdf},
issn = {00179310},
journal = {International Journal of Heat and Mass Transfer},
number = {17},
pages = {13},
title = {{A Bayesian Inference Approach To The Inverse Heat Conduction Problem}},
volume = {47},
year = {2004}
}
@book{IEA2014,
abstract = {Reliable building energy performance characterisation based on full scale dynamic measurements in Buildings Background : Renewed interest in full scale testing Interest},
author = {IEA},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/IEA - 2014 - Annex 58 Final report ST4a.pdf:pdf},
isbn = {9789460189906},
number = {May},
pages = {1--11},
title = {{Annex 58 Final report ST4a}},
year = {2014}
}
@techreport{Enjumet2016,
author = {Enjumet, Alexandre},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Enjumet - 2016 - RAPPORT DE STAGE FI4 Instrumentation pour le diagnostic in situ des b{\^{a}}timents.pdf:pdf},
title = {{RAPPORT DE STAGE FI4 Instrumentation pour le diagnostic in situ des b{\^{a}}timents}},
year = {2016}
}
@article{Fedorov2010,
author = {Fedorov, Valerii},
doi = {10.1002/wics.100},
file = {:home/sarah/OneDrive/Travail/Sources/Fedorov-2010-Wiley{\_}Interdisciplinary{\_}Reviews{\_}{\_}Computational{\_}Statistics.pdf:pdf},
issn = {19395108},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {convex optimization,design of experiments},
month = {sep},
number = {5},
pages = {581--589},
title = {{Optimal experimental design}},
url = {http://doi.wiley.com/10.1002/wics.100},
volume = {2},
year = {2010}
}
@article{Denis-Vidal2003,
abstract = {A system identification based on physical laws often involves a parameter estimation. Before performing an estimation problem, it is necessary to investigate its identifiability. This investigation leads often to painful calculations. Generally, the numerical computation of the parameters does not use these calculus. In this contribution we propose least-squares methods to link identifiability approaches with numerical parameter estimation.},
author = {Denis-Vidal, Lilianne and Joly-Blanchard, Ghislaine and Noiret, C{\'{e}}line},
doi = {10.1023/B:NUMA.0000005366.05704.88},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Denis-Vidal, Joly-Blanchard, Noiret - 2003 - System Identifiability (Symbolic Computation) and Parameter Estimation (Numerical Computati.pdf:pdf},
issn = {1017-1398},
journal = {Numerical Algorithms},
keywords = {93c15,93c95,ams subject classification,estimation of parameters,macokinetic applications,nonlinear autonomous and uncontrolled,phar-,systems},
number = {2},
pages = {283--292},
title = {{System Identifiability (Symbolic Computation) and Parameter Estimation (Numerical Computation)}},
url = {http://dx.doi.org/10.1023/B:NUMA.0000005366.05704.88},
volume = {34},
year = {2003}
}
@article{Saltelli2010a,
abstract = {Mathematical modelers from different disciplines and regulatory agencies worldwide agree on the importance of a careful sensitivity analysis (SA) of model-based inference. The most popular SA practice seen in the literature is that of 'one-factor-at-a-time' (OAT). This consists of analyzing the effect of varying one model input factor at a time while keeping all other fixed. While the shortcomings of OAT are known from the statistical literature, its widespread use among modelers raises concern on the quality of the associated sensitivity analyses. The present paper introduces a novel geometric proof of the inefficiency of OAT, with the purpose of providing the modeling community with a convincing and possibly definitive argument against OAT. Alternatives to OAT are indicated which are based on statistical theory, drawing from experimental design, regression analysis and sensitivity analysis proper. {\textcopyright} 2010 Elsevier Ltd.},
author = {Saltelli, Andrea and Annoni, Paola},
doi = {10.1016/j.envsoft.2010.04.012},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/Saltelli{\_}OAT.pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling and Software},
keywords = {Mathematical modeling,One-at-a-time,Robustness,Sensitivity analysis,Uncertainty analysis},
number = {12},
pages = {1508--1517},
title = {{How to avoid a perfunctory sensitivity analysis}},
volume = {25},
year = {2010}
}
@article{Lee2014,
abstract = {In South Korea, heating degree-days (HDD) and cooling degree-days (CDD) have been widely used as climatic indicators for the assessment of the impact of climate change, but arbitrary or customary base temperatures have been used for calculation of HDD and CDD. The purpose of this study is to determine real base temperatures to accurately calculate HDD and CDD for South Korea, using monthly electric energy consumption and mean temperature data from 2001 to 2010. The results reveal that the regional electricity demand generally depends on air temperature in a V-shaped curve in urban settings but in an L-shaped curve in rural settings, indicating that the sensitivity of the electricity demand to the temperature change is affected by the size of cities. The South Korean regional base temperatures, defined by a piecewise linear regression method, range from 14.7° to 19.4°C. These results suggest that the assessment of climate change impacts on the energy sector in South Korea should be carried out on a regional scale. {\textcopyright} 2014 American Meteorological Society.},
author = {Lee, Kyoungmi and Baek, Hee Jeong and Cho, Chun Ho},
doi = {10.1175/JAMC-D-13-0220.1},
file = {:home/sarah/OneDrive/Travail/Sources/jamc-d-13-0220.1.pdf:pdf},
issn = {15588424},
journal = {Journal of Applied Meteorology and Climatology},
keywords = {Climate change,Statistical techniques,Urban meteorology},
number = {2},
pages = {300--309},
title = {{The estimation of base temperature for heating and cooling degree-days for South Korea}},
volume = {53},
year = {2014}
}
@article{Petojevic2018,
abstract = {The dynamic thermal characteristics of the components of a building have a primary influence on the energy performance of the building's envelope under real environmental conditions. In this study, a novel approach for estimation of the thermal impulse response (TIR) functions and determination of the dynamic thermal characteristics of a multilayer fa{\c{c}}ade wall with unknown thermal properties, structure, and dimensions is proposed. Unlike existing approaches, such as those presented by Luo et al. (2010) and Fernandes et al. (2015), which are based on the use of known physical parameters and dimensions of the considered structure for determination of the transfer function, the proposed framework is based solely on data from in-situ experimental measurements of surface temperatures and thermal fluxes through the inner and outer wall surfaces in a dynamic regime. Consequently, the estimated TIR functions and dynamic thermal characteristics reflect the actual physical conditions of the considered building wall. The building wall is modelled as a two-input, two-output linear time-invariant (LTI) dynamic system where the surface temperatures and fluxes from both sides are used as system inputs and outputs, respectively. The input and output quantities are related by the convolution integrals and TIR functions. The TIR functions are obtained using the measured data and the least square estimator. As the corresponding system of linear equations is ill-posed, the Tikhonov regularization technique with a single parameter is implemented to overcome the numerical difficulties. The optimal regularization parameter is obtained using the L-curve approach. The estimated TIR functions are validated by comparison with the analytical solutions. The dynamic thermal characteristics of the considered building wall with unknown parameters are determined using the Fourier transform (FT) of the estimated TIR functions. The practical applications of the estimated TIR functions related to the energy performance of buildings (EPB) and energy efficiency, along with additional validation, are demonstrated by the evaluation of the dynamic thermal characteristics, cumulative heat losses, heat accumulation, conductive part of thermal transmittance (U-value), and surface heat fluxes, using only the estimated TIR functions and a control set of the experimental data.},
author = {Petojevi{\'{c}}, Zorana and Gospavi{\'{c}}, Radovan and Todorovi{\'{c}}, Goran},
doi = {10.1016/j.apenergy.2018.06.083},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0306261918309541-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Building wall,Dynamical thermal characteristics,Energy efficiency,Thermal impulse response,Tikhonov regularization},
number = {June},
pages = {468--486},
title = {{Estimation of thermal impulse response of a multi-layer building wall through in-situ experimental measurements in a dynamic regime with applications}},
volume = {228},
year = {2018}
}
@techreport{Judkoff1995a,
author = {Judkoff, Ron and Neymark, Joel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Judkoff, Neymark - 1995 - International Energy Agency Building Energy Simulation Test (BESTEST) and Diagnostic Model.pdf:pdf},
keywords = {BESTEST,February 1995,NREL/TP-472-6231,Reference,building energy software,diagnostic methodology,users manual,whole-building energy simulation programs},
mendeley-tags = {BESTEST,Reference},
title = {{International Energy Agency Building Energy Simulation Test (BESTEST) and Diagnostic Model}},
url = {https://www.nrel.gov/docs/legosti/old/6231.pdf},
year = {1995}
}
@article{Parker2019,
annote = {complete (E+) model calibration

Chaudhary G et al Evaluation of autotune calibration against manual calibrayion of building energy models --{\textgreater} applied energy 2016},
author = {Parker, James and Farmer, David and Johnston, David and Fletcher, Martin and Thomas, Felix and Gorse, Chris and Stenlund, Steven},
doi = {10.1016/j.enbuild.2018.12.010},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parker et al. - 2019 - Measuring and modelling retrofit fabric performance in solid wall conjoined dwellings.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Calibration,Coheating,Domestic,Retrofit,Thermal mo},
month = {feb},
pages = {49--65},
publisher = {Elsevier B.V.},
title = {{Measuring and modelling retrofit fabric performance in solid wall conjoined dwellings}},
url = {https://doi.org/10.1016/j.enbuild.2018.12.010 https://linkinghub.elsevier.com/retrieve/pii/S0378778818324964},
volume = {185},
year = {2019}
}
@article{Brynjarsdottir2014,
abstract = {Science-based simulation models are widely used to predict the behavior of complex physical systems. It is also common to use observations of the physical system to solve the inverse problem, i.e. to learn about the values of parameters within the model, a process often called calibration. The main goal of calibration is usually to improve the predictive performance of the simulator but the values of the parameters in the model may also be of intrinsic scientific interest in their own right. In order to make appropriate use of observations of the physical system it is impor-tant to recognise model discrepancy, the difference between reality and the simulator output. We illustrate through a simple example that an analysis that does not account for model discrepancy may lead to biased and over-confident parameter estimates and predictions. The challenge with incorporating model discrepancy in statistical inverse problems is the confounding with calibration parameters, which will only be resolved with mean-ingful priors. For our simple example, we model the model-discrepancy via a Gaus-sian Process and demonstrate that by accounting for model discrepancy our prediction within the range of data is correct. However, only with realistic priors on the model discrepancy do we uncover the true parameter values. Through theoretical arguments we show that these findings are typical of the general problem of learning about physical parameters and the underlying physical system using science-based mechanistic models.},
author = {Brynjarsdottir, Jenny and O'Hagan, Anthony},
doi = {10.1088/0266-5611/30/11/114007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brynjarsd{\'{o}}ttir, O 'hagan - 2014 - Learning about physical parameters The importance of model discrepancy.pdf:pdf},
issn = {0266-5611},
journal = {Inverse Problems},
keywords = {Calibration,Computer models,Extrapolation,Model bias,Model error,Model form error,Model inadequacy,Simulation model,Structural uncertainty,Uncertainty Quantification},
month = {nov},
number = {11},
pages = {114007},
title = {{Learning about physical parameters: the importance of model discrepancy}},
url = {http://www.tonyohagan.co.uk/academic/pdf/simmach.pdf http://stacks.iop.org/0266-5611/30/i=11/a=114007?key=crossref.7b886360dda7b385609c577ad82450aa},
volume = {30},
year = {2014}
}
@article{Burnham2004,
abstract = {AICc justification},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Burnham, Kenneth P. and Anderson, David R.},
doi = {10.1177/0049124104268644},
eprint = {arXiv:1011.1669v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burnham, Anderson - 2004 - Multimodel inference Understanding AIC and BIC in model selection.pdf:pdf},
isbn = {00491241 (ISSN)},
issn = {00491241},
journal = {Sociological Methods and Research},
keywords = {AIC,BIC,Model averaging,Model selection,Multimodel inference},
number = {2},
pages = {261--304},
pmid = {21699709},
title = {{Multimodel inference: Understanding AIC and BIC in model selection}},
volume = {33},
year = {2004}
}
@phdthesis{Bonnet2008,
author = {Bonnet, Marc},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonnet - 2008 - Probl{\`{e}}mes Inverses.pdf:pdf},
number = {1},
title = {{Probl{\`{e}}mes Inverses}},
year = {2008}
}
@techreport{Andrews1995,
address = {Upton, Long Island},
author = {Andrews, J. W.},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrews - 1995 - Electric coheating as a means to test duct efficiency A review and analysis of the literature.pdf:pdf},
institution = {Brookhaven National Laboratory},
keywords = {Coheating,Systematic error},
mendeley-tags = {Coheating,Systematic error},
pages = {29},
title = {{Electric coheating as a means to test duct efficiency: A review and analysis of the literature}},
url = {https://www.osti.gov/scitech/servlets/purl/150896},
year = {1995}
}
@article{Kost2018,
author = {Kost, Oliver and Dun{\'{i}}k, Jindřich and Straka, Ondřej},
doi = {10.1016/j.ifacol.2018.09.107},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kost, Dun{\'{i}}k, Straka - 2018 - Noise Moment and Parameter Estimation of State-Space Model.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
number = {15},
pages = {891--896},
title = {{Noise Moment and Parameter Estimation of State-Space Model}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896318317683},
volume = {51},
year = {2018}
}
@phdthesis{Patel2018,
abstract = {The central theme of this thesis is to understand two related question. When can a differential system model be identifiable from observations? If the model is identifiable, how can we identify it practically? While these questions are by no means new, we study them in a modern context where systems and models are more complex, observations are more frequent, and the stochastic nature of the underlying phenomenon must be considered. Chapter 1 discusses the nuances of these two questions in this modern context. Chapters 2 and 3 delve into first question by refining notions of identifiability and by contributing necessary conditions for identifiability of certain differential equation models. Chapters 4 to 7 delve into the second question from the perspective of designing computable estimators to handle the higher frequency of observations. Chapter 8 also addresses the second question by designing a novel optimization framework to address phenomenon with a stochastic nature.},
author = {Patel, Vivak},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patel - 2018 - IDENTIFICATION OF DYNAMICAL SYSTEMS IDENTIFIABILITY TO STOCHASTIC OPTIMIZATION.pdf:pdf},
number = {August},
school = {University of Chicago},
title = {{IDENTIFICATION OF DYNAMICAL SYSTEMS: IDENTIFIABILITY TO STOCHASTIC OPTIMIZATION}},
year = {2018}
}
@inproceedings{Sun2013,
abstract = {Traditional uncertainty quantification (UQ) in the design of energy efficient buildings is limited to the propagation of parameter uncertainties in model input variables. Some models inside building simulation are inherently inaccurate, which introduces additional uncertainties in model predictions. Therefore, quantification of this type of uncertainty (i.e., modelling, or more strictly speaking model form uncertainty) is a necessary step toward the complete UQ of model predictions. This paper quantifies the model form uncertainty of a widely used sky model developed by Perez (1990), which computes solar diffuse irradiation on inclined surfaces. We collect a dataset from measured solar irradiation on surfaces with multiple tilt angles and orientations, covering a wide spectrum of sky conditions. We first show statistical evidence for the model inadequacy based on our collected data and some results in published studies. Then, we develop a two-phase regression model, quantifying the model form uncertainty, which de facto constitutes an alternative for the Perez model. Model validation results show that model bias errors and root mean square errors are considerably reduced by the new model formulation for every tilted surface. Lastly, we study the significance of this model form uncertainty in the energy consumption predictions obtained with whole building simulation.},
author = {Sun, Yuming and Su, Heng and Wu, C F Jeff and Augenbroe, Godfried},
booktitle = {13th Conference of International Building Performance Simulation Association},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2013 - UNCERTAINTY QUANTIFICATION OF SOLAR DIFFUSE IRRADIATION ON INCLINED SURFACES FOR BUILDING ENERGY SIMULATION.pdf:pdf},
title = {{Uncertainty quantification of solar diffuse irradiation on inclined surfaces for building energy simulation}},
url = {http://www.ibpsa.org/proceedings/BS2013/p{\_}1288.pdf},
year = {2013}
}
@unpublished{MIT2014,
author = {MIT},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MIT - 2014 - Python Notes Cheat Sheet.pdf:pdf},
number = {December},
pages = {1--7},
title = {{Python Notes / Cheat Sheet}},
year = {2014}
}
@article{Miller2019a,
abstract = {Feature engineering and data-driven classification models are at the forefront of analysis of large temporal sensor data from the built environment. In previous efforts, temporal features were engineered from the whole building hourly electrical meter data from 507 non-residential buildings. These features fall within the three general categories of statistics, model, and pattern-based and can be used to identify various behavior in the structure of the whole building electrical meter data. In this paper, a deeper investigation is made of exactly what types of behavior are most important in the context of two classification scenarios: the primary use of a building and the level of performance the building has when compared to its peers. The highly comparative time-series analysis (hctsa) toolkit is used to analyze the most important temporal features for the classification of various building performance attributes. In the first analysis, a comparison is made to distinguish the behavior between university dormitories (70 buildings) and laboratories (95 buildings) as an example of interpreting the classification of the primary-use-type of a building. In the second analysis, a comparison of buildings with high (165 buildings) versus low (169 buildings) consumption is used to extract and understand the behavior that indicates the level of the energy performance of a building. These two case study examples provide a foundation for further explainable machine learning techniques in both classification and prediction as applied to buildings. This effort is the first example of machine learning with an explicit focus on the interpretability of classification for smart meter data from non-residential buildings.},
author = {Miller, Clayton},
doi = {10.1016/j.enbuild.2019.07.019},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778819311260-main.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Clayton(2019).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building performance analysis,Customer segmentation,Data science,Energy efficiency,Explainable machine learning,Interpretable machine learning,Load clustering,Performance classification,Smart meter,Temporal feature engineering,Time-series analysis},
month = {sep},
number = {July},
pages = {523--536},
publisher = {Elsevier B.V.},
title = {{What's in the box?! Towards explainable machine learning applied to non-residential building smart meter classification}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778819311260},
volume = {199},
year = {2019}
}
@inproceedings{Meulemans2018,
address = {Kiruna, Sweden},
author = {Meulemans, Johann},
booktitle = {Cold Climate HVAC 2018 - The 9th International Cold Climate Conference},
file = {:home/sarah/OneDrive/Travail/Sources/Meulemans - Cold Climate HVAC 2018 - HAL.pdf:pdf},
keywords = {Heat loss coefficient,ISO 9869-1,QUB/e method,U-values},
title = {{An assessment of the QUB / e method for fast in situ measurements of the thermal performance of building fabrics in cold climates To cite this version : HAL Id : hal-01737563 An assessment of the QUB / e method for fast in situ measurements of the thermal}},
year = {2018}
}
@article{Wetter2009,
author = {Wetter, Michael},
doi = {10.1080/19401490902818259},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
month = {jun},
number = {2},
pages = {143--161},
title = {{Modelica-based modelling and simulation to support research and development in building energy and control systems}},
url = {https://www.tandfonline.com/doi/full/10.1080/19401490902818259},
volume = {2},
year = {2009}
}
@inproceedings{Juricic2011,
author = {Juricic, Sarah and {Van Dijken}, Froukje and Boerstra, Atze C},
booktitle = {12th International Conference on Indoor Air Quality and Climate 2011},
isbn = {9781627482721},
keywords = {CBE's Occupant IEQ Survey,Classrooms,Perceived indoor environmental quality,Post occupancy evaluation},
pages = {1048--1049},
title = {{Building performance evaluation of newly built school buildings - A pilot study}},
volume = {2},
year = {2011}
}
@article{Srinath2010a,
abstract = {a b s t r a c t Mathematical modeling has become an integral component in biotechnology, in which these models are frequently used to design and optimize bioprocesses. Canonical models, like power-laws within the Bio-chemical Systems Theory, offer numerous mathematical and numerical advantages, including built-in flexibility to simulate general nonlinear behavior. The construction of such models relies on the esti-mation of unknown case-specific model parameters by way of experimental data fitting, also known as inverse modeling. Despite the large number of publications on this topic, this task remains the bottleneck in canonical modeling of biochemical systems. The focus of this paper concerns with the question of iden-tifiability of power-law models from dynamic data, that is, whether the parameter values can be uniquely and accurately identified from time-series data. Existing and newly developed parameter identifiability methods were applied to two power-law models of biochemical systems, and the results pointed to the lack of parametric identifiability as the root cause of the difficulty faced in the inverse modeling. Despite the focus on power-law models, the analyses and conclusions are extendable to other canonical models, and the issue of parameter identifiability is expected to be a common problem in biochemical system modeling.},
annote = {Bonne description des m{\'{e}}thodes d'identif a posteriori.

Si on pond{\`{e}}re les moindres carr{\'{e}}s avec l'inverse de la matrice de covariance, cela revient {\`{a}} utiliser un estimateur du max de vraissemblance.

Attention, les mod{\`{e}}les utilis{\'{e}}s ici n'ont pas de terme input U (pas de sollicitations externes) !},
author = {Srinath, Sridharan and Gunawan, Rudiyanto},
doi = {10.1016/j.jbiotec.2010.02.019},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srinath, Gunawan - 2010 - Parameter identifiability of power-law biochemical system models.pdf:pdf},
issn = {01681656},
journal = {Journal of Biotechnology},
keywords = {Biochemical Systems Theory,Confidence region,Identifiability analysis,Inverse modeling,Power-law models},
month = {sep},
number = {3},
pages = {132--140},
title = {{Parameter identifiability of power-law biochemical system models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168165610001057},
volume = {149},
year = {2010}
}
@unpublished{Kosmina2016,
author = {Kosmina, Ludmilla},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kosmina - 2016 - In-situ measurement of U-value.pdf:pdf},
number = {September},
pages = {1--13},
title = {{In-situ measurement of U-value}},
year = {2016}
}
@article{Walter1982a,
abstract = {Whenever a model is not identifiable, there exist several parameter vectors $\theta$ which yield the same input-output behavior, so that any further interprtation of $\theta$ is questionable. In this paper two methods which can be used to test state-space models for identifiability with a global approach are presented. While the first one is useful for nonlinear and/or time-varying models, the second one is suitable for linear time-invariant models. An appendix provides tools for the solution of he sets of polynomial equations involved in both methods. {\textcopyright} 1982.},
author = {Walter, Eric and Lecourtier, Yves},
doi = {10.1016/0378-4754(82)90645-0},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter, Lecourtier - 1982 - GLOBAL APPROACHES TO IDENTIFIABILITY TESTING FOR LINEAR AND NONLINEAR STATE SPACE MODELS.pdf:pdf},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
month = {dec},
number = {6},
pages = {472--482},
title = {{Global approaches to identifiability testing for linear and nonlinear state space models}},
url = {http://ac.els-cdn.com.camphrier-1.grenet.fr/0378475482906450/1-s2.0-0378475482906450-main.pdf?{\_}tid=c3d30c94-1ad8-11e7-adaa-00000aacb35d{\&}acdnat=1491490576{\_}d470f20fc59781d9275f1e422e0e393c https://linkinghub.elsevier.com/retrieve/pii/0378475482906450},
volume = {24},
year = {1982}
}
@article{Catchpole1997,
abstract = {Necessary and sufficient conditions are established for the parameter redundancy of a wide class of nonlinear models for data distributed according to the exponential family . The likelihood surfaces for parameter - redundant models possess completely flat ridges . Whether a model is parameter redundant can be established by checking the rank of a derivative matrix , using a symbolic algebra package . A feature of contingency table appli - cations is the need to extend conclusions from particular to general dimensions . We meet this via an extension theorem . Examples are given from the area of animal survival esti - mation using mark - recapture / recovery data .},
annote = {Parameter redundancy = overparametrisation in the model , one of the most obvious causes of non identifiability
To prove redundancy, study the singularitt of the information matrix trhough a simple algebraic test from its derivative.
Can be used for complex stochastic models},
author = {Catchpole, E.},
doi = {10.1093/biomet/84.1.187},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Catchpole - 1997 - Detecting parameter redundancy.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
keywords = {Contingency table,Diagnostics,Identifiability,Likelihood,Nonlinear model,Parameter redundancy,Recapture data,Recovery data,Ridge,Some key words,Stochastic models,Symbolic algebra,redundancy,structural identifiability},
mendeley-tags = {Stochastic models,redundancy,structural identifiability},
month = {mar},
number = {1},
pages = {187--196},
title = {{Detecting parameter redundancy}},
url = {https://www.researchgate.net/profile/Byron{\_}Morgan2/publication/31327027{\_}Detecting{\_}parameter{\_}redundancy/links/0deec5299ddc9ccd1a000000.pdf https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/84.1.187},
volume = {84},
year = {1997}
}
@misc{BigLadderSoftware2016,
author = {{Big Ladder Software}},
title = {{InputOutput Reference - Group – Simulation Parameters}},
url = {https://bigladdersoftware.com/epx/docs/8-5/input-output-reference/group-simulation-parameters.html},
urldate = {2019-10-10},
year = {2016}
}
@inproceedings{Ranganath2016,
abstract = {Variational inference is an umbrella term for algorithms which cast Bayesian inference as optimization. Classically, variational inference uses the Kullback-Leibler divergence to define the optimization. Though this divergence has been widely used, the resultant posterior approximation can suffer from undesirable statistical properties. To address this, we reexamine variational inference from its roots as an optimization problem. We use operators, or functions of functions, to design variational objectives. As one example, we design a variational objective with a Langevin-Stein operator. We develop a black box algorithm, operator variational inference (OPVI), for optimizing any operator objective. Importantly, operators enable us to make explicit the statistical and computational tradeoffs for variational inference. We can characterize different properties of variational objectives, such as objectives that admit data subsampling---allowing inference to scale to massive data---as well as objectives that admit variational programs---a rich class of posterior approximations that does not require a tractable density. We illustrate the benefits of OPVI on a mixture model and a generative model of images.},
author = {Ranganath, Rajesh and Altosaar, Jaan and Tran, Dustin and Blei, David M},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranganath et al. - Unknown - Operator Variational Inference(2).pdf:pdf},
issn = {10495258},
pages = {496--504},
title = {{Operator variational inference}},
url = {https://arxiv.org/pdf/1610.09033.pdf},
year = {2016}
}
@article{Pereira2018,
author = {Pereira, Pedro F. and Ramos, Nuno M.M. and Almeida, Ricardo M.S.F. and Sim{\~{o}}es, M. Lurdes},
doi = {10.1016/j.buildenv.2018.09.047},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira et al. - 2018 - Methodology for detection of occupant actions in residential buildings using indoor environment monitoring syste.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
pages = {107--118},
publisher = {Elsevier Ltd},
title = {{Methodology for detection of occupant actions in residential buildings using indoor environment monitoring systems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S036013231830605X},
volume = {146},
year = {2018}
}
@phdthesis{Thomassin2005,
author = {Thomassin, Magalie},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomassin - 2005 - Estimation de retard dans des conditions exp{\'{e}}rimentales passives. Application {\`{a}} l'identification d'un bief de rivi.pdf:pdf},
keywords = {automatis{\'{e}}e,dfd automatique et production,informatique automatique,sciences et techniques math{\'{e}}matiques,{\'{e}}cole doctorale iaem lorraine},
school = {Universit{\'{e}} Henri Poincar{\'{e}}, Nancy 1},
title = {{Estimation de retard dans des conditions exp{\'{e}}rimentales passives. Application {\`{a}} l'identification d'un bief de rivi{\`{e}}re.}},
year = {2005}
}
@article{Albisser2018,
author = {Albisser, Marie and Dobre, Simona},
doi = {10.1016/j.ifacol.2018.09.069},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Albisser, Dobre - 2018 - Sensitivity Analysis for Global Parameter Identification. Application to Aerodynamic Coefficients.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Estimation parameters,Free-flight data,Identifiability,Multiple fit strategy,Nonlinear models,Sensitivity analysis,Space probes,identifiability},
number = {15},
pages = {963--968},
publisher = {Elsevier B.V.},
title = {{Sensitivity Analysis for Global Parameter Identification. Application to Aerodynamic Coefficients}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896318317294},
volume = {51},
year = {2018}
}
@inproceedings{Sonderegger1978,
abstract = {Two different approaches to the determination of the thermal response of buildings are possible : deterministic models and methods based on equivalent thermal parameters (ETP's) of a building. While the former are computer applications of heat tranfer theory, the latter consist of data oriented techniques that infer the ETP's of a particular building by multiple corelation of indoor temperature and weather. The ETP method is convenient to provide a rank ordering of different houses by their thermal performance and to assess the overall effects of retrofits on a house. Like deterministiv methods, the ETP method can also predict accurate free-floating indoor temepratures ad heating loads as a function of weather. A convenient set of ETP's si established for a residential townhouse by means of a simple, single thermal mass model. Multiple step regressions of actual data on indoor temperature and weather yield estimates for the ETP's. The model tracks the emasured data well. The regressed ETP's agree with what is expected from theoritcal calculations and are consistent with the result from a dfferent, costant indoor temperature experiment.},
address = {Atlanta},
author = {Sonderegger, Robert},
booktitle = {ASHRAE Meeting},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sonderegger - 1978 - Diagnostic tests determining the thermal response of a house.pdf:pdf},
keywords = {ion implantation,nanoelectronics,quantum computer,single atom},
title = {{Diagnostic tests determining the thermal response of a house}},
year = {1978}
}
@article{Maclaren2018,
abstract = {Profile likelihood is the key tool for dealing with nuisance parameters in likelihood theory. It is often asserted, however, that profile likelihood is not a 'true' likelihood. One implication is that likelihood theory lacks the generality of e.g. Bayesian inference, wherein marginalization is the universal tool for dealing with nuisance parameters. Here we argue that profile likelihood has as much claim to being a true likelihood as a marginal probability has to being a true probability distribution. The crucial point we argue is that a likelihood function is naturally interpreted as a maxitive possibility measure: given this, the associated theory of integration with respect to maxitive measures delivers profile likelihood as the direct analogue of marginal probability in additive measure theory. Thus, given a background likelihood function, we argue that profiling over the likelihood function is as natural (or as unnatural, as the case may be) as marginalizing over a background probability measure. The connections to Bayesian inference can also be further clarified with the introduction of a suitable logarithmic distance function, in which case the present theory can be naturally described as 'Tropical Bayes' in the sense of tropical algebra.},
archivePrefix = {arXiv},
arxivId = {1801.04369},
author = {Maclaren, Oliver J},
eprint = {1801.04369},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maclaren - 2018 - Is profile likelihood a true likelihood An argument in favor(2).pdf:pdf},
keywords = {Estimation,Idempotent Integration,Inference,Marginalization,Maxitive Measure Theory,Nuisance Parame-ters,Profile Likelihood},
month = {jan},
title = {{Is profile likelihood a true likelihood? An argument in favor}},
url = {https://arxiv.org/pdf/1801.04369.pdf http://arxiv.org/abs/1801.04369},
year = {2018}
}
@article{Taylor1990,
abstract = {The current generation of building simulation software is based upon separate building and mechanical system and equipment simulations. This scheme evolved primarily because of memory limitations of the computers which were used to develop the programs. These limitations are no longer important so the separate building and system scheme needs to be reevaluated. This paper will specifically discuss experience resulting from introducing simultaneous system simulations into the BLAST program. BLAST currently uses a linear univariate control profile to describe the heating and cooling provided by the fan system as a function of room temperature during the loads calculation part of the simulation. Control profiles for each thermal zone are used to model the system response during the system simulation. This model of the fan system works very well for systems that provide amounts of heating or cooling that are dependent only on zone temperature. When the output of the fan system is affected by the outdoor temperature or conditions in other zones, the control profile model is no longer adequate. The conditions in the zones must be known in order to calculate the system output, but the system output must be known in order to calculate the conditions in the zones. So a more sophisticated representation of the mechanical systems is needed. This paper specifically discusses the results of doing a complete system simulation within the loads calculation portion of the program by using a shortened time step combined with lagging the two parts of the simulation. The effects of time step length on accuracy and computation time are presented.},
author = {Taylor, Russell D and Pedersen, Curtis O and Lawrie, L. K.},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/10.1.1.533.1698.pdf:pdf},
journal = {Proceedings of the 3rd International Conference on System Simulation in Buildings},
pages = {1},
title = {{Simultaneous simulation of buildings and mechanical systems in heat balance based energy analysis programs}},
url = {http://apps1.eere.energy.gov/buildings/energyplus/pdfs/bibliography/simultaneous{\_}simulation{\_}taylor.pdf},
year = {1990}
}
@article{Girardin2018,
abstract = {Zighera (App Stoch Mod Data Anal 1:93–108 1985) introduced a new parame-terization of log-linear models for analyzing categorical data, directly linked to a thorough analysis of discrimination information through Kullback-Leibler divergence. The method mainly aims at quantifying in terms of information the variations of a binary variable of interest, by comparing two contingency tables – or sub-tables – through effects of explana-tory categorical variables. The present paper settles the mathematical background necessary to rigorously apply Zighera's parameterization to any categorical data. In particular, iden-tifiability and good properties of asymptotically $\chi$ 2 -distributed test statistics are proven to hold. Determination of parameters and all tests of effects due to explanatory variables are simultaneous. Application to classical data sets illustrates contribution with respect to existing methods.},
author = {Girardin, Val{\'{e}}rie and Lequesne, Justine and Ricordeau, Anne},
doi = {10.1007/s11009-017-9597-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girardin, Lequesne, Ricordeau - Unknown - Information-based Parameterization of the Log-linear Model for Categorical Data Analysis.pdf:pdf},
issn = {1387-5841},
journal = {Methodology and Computing in Applied Probability},
keywords = {Kullback-Leibler},
mendeley-tags = {Kullback-Leibler},
month = {dec},
number = {4},
pages = {1105--1121},
title = {{Information-based Parameterization of the Log-linear Model for Categorical Data Analysis}},
url = {https://link-springer-com.camphrier-2.grenet.fr/content/pdf/10.1007{\%}2Fs11009-017-9597-9.pdf http://link.springer.com/10.1007/s11009-017-9597-9},
volume = {20},
year = {2018}
}
@article{Godfrey2005,
abstract = {There has been a rapid increase recently in the number of software packages available to generate different types of perturbation signals for the purpose of system identification in the frequency domain. The types of signal include both computer-optimised signals, which are designed to match a specified power spectrum as closely as possible, and pseudo-random signals, which have fixed spectra. Several of these signals are now readily available directly from the World Wide Web. The objective of this paper is to review what packages are available, and from where, and to outline some of the application areas in which they might be used. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
author = {Godfrey, Keith Richard and Tan, A. H. and Barker, H. Anthony and Chong, B.},
doi = {10.1016/j.conengprac.2004.12.012},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/1-s2.0-S0967066105000080-main.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Computer-optimised signals,Frequency methods,Multi-frequency signals,Non-parametric identification,Nonlinear systems,Perturbation signals,Pseudo-random signals,System identification},
number = {11},
pages = {1391--1402},
title = {{A survey of readily accessible perturbation signals for system identification in the frequency domain}},
volume = {13},
year = {2005}
}
@article{Brastein2019a,
abstract = {Obtaining accurate models that can predict the behaviour of dynamic systems is important for a variety of applications. Often, models contain parameters that are difficult to calculate from system descriptions. Hence, parameter estimation methods are important tools for creating dynamic system models. Almost all dynamic system models contain uncertainty, either epistemic, due to simplifications in the model, or aleatoric, due to inherent randomness in physical effects such as measurement noise. Hence, obtaining an estimate for the uncertainty of the estimated parameters, typically in the form of confidence limits, is an important part of any statistically solid estimation procedure. Some uncertainty estimation methods can also be used to analyse the practical and structural identifiability of the parameters, as well as parameter inter-dependency and the presence of local minima in the objective function. In this paper, selected methods for estimation and analysis of parameters are reviewed. The methods are compared and demonstrated on the basis of both simulated and real world calibration data for two different case models. Recommendations are given for what applications each of the methods are suitable for. Further, differences in requirements for system excitation are discussed for each of the methods. Finally, a novel adaption of the Profile Likelihood method applied to a moving window is used to test the consistency of dynamic information in the calibration data for a particular model structure.},
author = {Brastein, O. M. and Lie, B. and Pfeiffer, C. and Skeie, N. O.},
doi = {10.4173/mic.2019.4.3},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/Estimating{\_}uncertainty{\_}of{\_}model{\_}parameters{\_}obtaine.pdf:pdf},
issn = {18901328},
journal = {Modeling, Identification and Control},
keywords = {Bootstrapping,Parameter estimation,Profile Likelihood,Uncertainty analysis},
number = {4},
pages = {213--243},
title = {{Estimating uncertainty of model parameters obtained using numerical optimisation}},
volume = {40},
year = {2019}
}
@misc{Kreutz2017,
abstract = {The feasibility of uniquely estimating parameters of dynamical systems from observations is a widely discussed aspect of mathematical modelling. Several approaches have been published for analyzing identifiability. However, they are typically computationally demanding, difficult to perform and/or not applicable in many application settings. Here, an intuitive approach is presented which enables quickly testing of parameter identifiability. Numerical optimization with a penalty in radial direction enforcing displacement of the parameters is used to check whether estimated parameters are unique, or whether the parameters can be altered without loss of agreement with the data indicating non-identifiability. This Identifiability-Test by Radial Penalization (ITRP) can be employed for every model where optimization-based fitting like least-squares or maximum likelihood is feasible and is therefore applicable for all typical deterministic models. The approach is illustrated and tested using 11 ordinary differential equation (ODE) models. The presented approach can be implemented without great efforts in any modelling framework. It is available within the free Matlab-based modelling toolbox Data2Dynamics. Source code is available at https://github.com/Data2Dynamics.},
archivePrefix = {arXiv},
arxivId = {1708.03532},
author = {Kreutz, Clemens},
booktitle = {pre-print},
doi = {10.1093/bioinformatics/bty035},
eprint = {1708.03532},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kreutz - 2017 - An easy and efficient approach for testing identifiability of parameters.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kreutz - 2018 - An easy and efficient approach for testing identifiability(2).pdf:pdf},
issn = {1367-4803},
month = {aug},
number = {January},
title = {{An easy and efficient approach for testing identifiability of parameters}},
url = {https://arxiv.org/pdf/1708.03532.pdf http://arxiv.org/abs/1708.03532},
year = {2017}
}
@article{Bagheri2017,
abstract = {The thermal network method is a reliable approach to study the thermal performance of buildings. It is able to simulate the indoor temperature, heating and cooling loads by means of a set of ordinary differential equations. In this work, a 4R3C thermal network has been proposed to study a detached building. Combinations of thermal networks are addressed in order to consider the effects of adjacent walls in other typologies (semi-Attached and terraced). Corresponding models, generated by the TRNSYS software, provide the training data used to identify the parameters in the thermal networks. At the end, the accuracy of the model's output and identified parameters is discussed.},
annote = {pr{\'{e}}vu pour simulation/pr{\'{e}}diction --{\textgreater} conclusion que les valeurs calibr{\'{e}}es sont pas toutes physiques},
author = {Bagheri, Ali and Feldheim, V{\'{e}}ronique and Thomas, Dimitrios and Ioakimidis, Christos S.},
doi = {10.1016/j.egypro.2017.07.359},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bagheri et al. - 2017 - The adjacent walls effects in simplified thermal model of buildings.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Adjacent wall,Building's simplified model,System identification,Thermal networks},
pages = {619--624},
publisher = {Elsevier B.V.},
title = {{The adjacent walls effects in simplified thermal model of buildings}},
url = {https://doi.org/10.1016/j.egypro.2017.07.359},
volume = {122},
year = {2017}
}
@article{Gevers1986,
abstract = {The purpose of the design of identification experiments is to make the collected data maximally informative with respect to the intended use of the model, subject to constraints that might be at hand. When the true system is replaced by an estimated model, there results a performance degradation that is due to the error in the transfer function estimates. Using some recent asymptotic expressions for the bias and the variance of the estimated transfer function, it is shown how this performance degradation can be minimized by a proper experiment design. Several applications, where it is beneficial to let the experiment be carried out in closed loop, are highlighted. {\textcopyright} 1986.},
author = {Gevers, Michel and Ljung, Lennart},
doi = {10.1016/0005-1098(86)90064-6},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevers, Ljung - 1986 - Optimal Experiment Designs with Respect to the Intended Model Application.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Identification,frequency domain,optimization},
month = {sep},
number = {5},
pages = {543--554},
title = {{Optimal experiment designs with respect to the intended model application}},
url = {http://ac.els-cdn.com/0005109886900646/1-s2.0-0005109886900646-main.pdf?{\_}tid=e8952382-2bfe-11e7-ba5d-00000aacb35f{\&}acdnat=1493376128{\_}05d3e56e541a7dad9b14bbfdb432b5ba https://linkinghub.elsevier.com/retrieve/pii/0005109886900646},
volume = {22},
year = {1986}
}
@article{Berger2016,
abstract = {In this paper, the use of Bayesian inference is explored for estimating both the thermal conductivity and the internal convective heat transfer coefficient of an old historic building wall. The room air temperature, as well as the temperatures at the surface and within the wall have been monitored during one year and then used to solve the identification problem. With Bayesian inference, the posterior distributions of the unknown parameters are explored based on their prior distributions and on the likelihood function that models the measurement errors. In this work, the Markov Chain Monte Carlo method is used to explore the posterior distribution. The error of the inadequacy of mathematical model are considered using the approximation error model. The distribution of the estimated parameters have a small standard deviation, which illustrates the accuracy of the method. The parameters have been compared to the standard values from the French thermal regulations. The heat flux at the internal surface has been calculated with the estimated parameters and the standard values. It is shown that the standard values underestimate the heat flux of an order by 10{\%}. This study also illustrates the importance of the preliminary diagnosis of a building with the estimation of the thermal properties of the wall for model calibration.},
annote = {Utilise la formulation physique pour poser la mod{\'{e}}lisation.
R{\'{e}}solution du probl{\`{e}}me inverse par un algo MCMC Metropolis et Hastings
On calcule les coefficients de sensibilit{\'{e}} r{\'{e}}duit pour {\'{e}}valuer la possibilit{\'{e}} d'utiliser le set de mesures pour estimer les param{\`{e}}tres.
Utilisation de donn{\'{e}}es d'une ann{\'{e}}e enti{\`{e}}re
Conclut entre autres que le calcul d'ordre 10{\^{}}5 est {\'{e}}lev{\'{e}} et qu'une r{\'{e}}duction de mod{\`{e}}le serait int{\'{e}}ressante.},
author = {Berger, Julien and Orlande, Helcio R. B and Mendes, Nathan and Guernouti, Sihem},
doi = {10.1016/j.buildenv.2016.06.037},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger et al. - 2016 - Bayesian inference for estimating thermal properties of a historic building wall.pdf:pdf},
isbn = {5541977436},
issn = {03601323},
journal = {Building and Environment},
keywords = {Bayesian inference,Identification problem,Inverse heat transfer problem,Model calibration,Real thermal performance},
pages = {327--339},
publisher = {Elsevier Ltd},
title = {{Bayesian inference for estimating thermal properties of a historic building wall}},
url = {http://dx.doi.org/10.1016/j.buildenv.2016.06.037},
volume = {106},
year = {2016}
}
@article{Janssen2013,
abstract = {Monte Carlo analysis has become nearly ubiquitous since its introduction, now over 65 years ago. It is an important tool in many assessments of the reliability and robustness of systems, structures or solutions. As the deterministic core simulation can be lengthy, the computational costs of Monte Carlo can be a limiting factor. To reduce that computational expense as much as possible, sampling efficiency and convergence for Monte Carlo are investigated in this paper. The first section shows that non-collapsing space-filling sampling strategies, illustrated here with the maximin and uniform Latin hypercube designs, highly enhance the sampling efficiency, and render a desired level of accuracy of the outcomes attainable with far lesser runs. In the second section it is demonstrated that standard sampling statistics are inapplicable for Latin hypercube strategies. A sample-splitting approach is put forward, which in combination with a replicated Latin hypercube sampling allows assessing the accuracy of Monte Carlo outcomes. The assessment in turn permits halting the Monte Carlo simulation when the desired levels of accuracy are reached. Both measures form fairly noncomplex upgrades of the current state-of-the-art in Monte-Carlo based uncertainty analysis but give a substantial further progress with respect to its applicability. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Janssen, Hans},
doi = {10.1016/j.ress.2012.08.003},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-S0951832012001536-main.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Monte Carlo,Sample-splitting,Sampling convergence,Sampling efficiency,Space-filling Latin hypercube,Uncertainty analysis},
pages = {123--132},
publisher = {Elsevier},
title = {{Monte-Carlo based uncertainty analysis: Sampling efficiency and sampling convergence}},
url = {http://dx.doi.org/10.1016/j.ress.2012.08.003},
volume = {109},
year = {2013}
}
@article{Reichert2011,
abstract = {a b s t r a c t Many model-based investigation techniques, such as sensitivity analysis, optimization, and statistical inference, require a large number of model evaluations to be performed at different input and/or parameter values. This limits the application of these techniques to models that can be implemented in computationally efficient computer codes. Emulators, by providing efficient interpolation between outputs of deterministic simulation models, can considerably extend the field of applicability of such computationally demanding techniques. So far, the dominant techniques for developing emulators have been priors in the form of Gaussian stochastic processes (GASP) that were conditioned with a design data set of inputs and corresponding model outputs. In the context of dynamic models, this approach has two essential disadvantages: (i) these emulators do not consider our knowledge of the structure of the model, and (ii) they run into numerical difficulties if there are a large number of closely spaced input points as is often the case in the time dimension of dynamic models. To address both of these problems, a new concept of developing emulators for dynamic models is proposed. This concept is based on a prior that combines a simplified linear state space model of the temporal evolution of the dynamic model with Gaussian stochastic processes for the innovation terms as functions of model parameters and/or inputs. These innovation terms are intended to correct the error of the linear model at each output step. Conditioning this prior to the design data set is done by Kalman smoothing. This leads to an efficient emulator that, due to the consideration of our knowledge about dominant mechanisms built into the simulation model, can be expected to outperform purely statistical emulators at least in cases in which the design data set is small. The feasibility and potential difficulties of the proposed approach are demonstrated by the application to a simple hydrological model.},
author = {Reichert, P and White, G and Bayarri, M. J. and Pitman, E.B.},
doi = {10.1016/j.csda.2010.10.011},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reichert et al. - 2011 - Computational Statistics and Data Analysis Mechanism-based emulation of dynamic simulation models Concept and a.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Dynamic model,Emulator,Optimization,Sensitivity analysis,Statistical inference},
month = {apr},
number = {4},
pages = {1638--1655},
title = {{Mechanism-based emulation of dynamic simulation models: Concept and application in hydrology}},
url = {http://ac.els-cdn.com.camphrier-2.grenet.fr/S0167947310003993/1-s2.0-S0167947310003993-main.pdf?{\_}tid=c8ee2ae8-9c4b-11e7-b302-00000aab0f02{\&}acdnat=1505723676{\_}89062392c4923795938bfead746ed6a1 https://linkinghub.elsevier.com/retrieve/pii/S0167947310003993},
volume = {55},
year = {2011}
}
@inproceedings{Madsen2010,
abstract = {This paper describes a number of statistical methods and models for describing the thermal characteristics of buildings using frequent readings of heat consumption, ambient air temperature, and other available climate variables. For some of the methods frequent readings of the indoor air temperature are needed or beneficial. The suite of models described consists of nonlinear stochastic models, linear stochas- tic models, transfer function models, frequency response function models, impulse response models and regression models. The final choice of model depends on the purpose of the modelling, existence of prior physical knowledge, the data and the available statistical soft- ware tools. The importance of statistical model validation is discussed, and some simple tools for that purpose are demonstrated. This paper also briefly describes some of the most frequently used software tools for modelling the thermal characteristics of buildings. Many of the stochastic models are developed and tested using data from outdoor test- ing during a number of EU projects (PASSYS, PASLINK, DAME-BC, ..). These projects have provided the background for new methods for using frequent readings of the energy consumption to an assessment of the energy performance of buildings. Smart meters are now used more and more often. A smart meter facilitates frequent read- ing of the energy consumption, and together with some local meteorological measurements, which almost always are available, the scene is now set for using the developed methods for time series modelling or system identification. Applying these methods the following can be achieved: Characterization of the energy performance of buildings (including energy labelling), identification of how to improve the thermal performance of the building, and improved control of the energy supply.},
address = {Brussels},
author = {Madsen, Henrik and Bacher, Peder and Delff, Philip},
booktitle = {DYNASTEE international workshop : Dynamic Methods for Building Energy Assessment},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madsen, Bacher, Delff - 2010 - Mathematical and Statistical Models and Methods for Describing the Thermal Characteristics of Buildings.pdf:pdf},
keywords = {buildings,continuous time modelling,dk,dtu,email address,energy labelling,grey-box models,heat consumption,heat dynamics,henrik madsen,hm,http,imm,smart meters,stochastic differential equations,thermal dynamics,url,www2},
title = {{Mathematical and Statistical Models and Methods for Describing the Thermal Characteristics of Buildings}},
year = {2010}
}
@article{Krause2005,
abstract = {The evaluation of hydrologic model behaviour and performance is commonly made and reported through com- parisons of simulated and observed variables. Frequently, comparisons are made between simulated and measured streamflow at the catchment outlet. In distributed hydrolog- ical modelling approaches, additional comparisons of sim- ulated and observed measurements for multi-response val- idation may be integrated into the evaluation procedure to assess overall modelling performance. In both approaches, single and multi-response, efficiency criteria are commonly used by hydrologists to provide an objective assessment of the “closeness” of the simulated behaviour to the observed measurements. While there are a few efficiency criteria such as the Nash-Sutcliffe efficiency, coefficient of determination, and index of agreement that are frequently used in hydrologic modeling studies and reported in the literature, there are a large number of other efficiency criteria to choose from. The selection and use of specific efficiency criteria and the inter- pretation of the results can be a challenge for even the most experienced hydrologist since each criterion may place dif- ferent emphasis on different types of simulated and observed behaviours. In this paper, the utility of several efficiency criteria is investigated in three examples using a simple observed streamflow hydrograph.},
author = {Krause, P and Boyle, D P and B{\"{a}}se, F},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krause, Boyle, B{\"{a}}se - 2005 - Comparison of different efficiency criteria for hydrological model assessment Comparison of different effi.pdf:pdf},
journal = {Advances in Geosciences},
keywords = {model calibration,model fit assessment},
mendeley-tags = {model calibration,model fit assessment},
number = {5},
pages = {89--97},
title = {{Comparison of different efficiency criteria for hydrological model assessment Comparison of different efficiency criteria for hydrological model assessment. Advances in}},
url = {https://hal.archives-ouvertes.fr/hal-00296842},
year = {2005}
}
@article{Saccomani2003a,
abstract = {Identifiability is a fundamental prerequisite for model identification; it concerns uniqueness of the model parameters determined from the input-output data, under ideal conditions of noise-free observations and error-free model structure. In the late 1980s concepts of differential algebra have been introduced in control and system theory. Recently, differential algebra tools have been applied to study the identifiability of dynamic systems described by polynomial equations. These methods all exploit the characteristic set of the differential ideal generated by the polynomials defining the system. In this paper, it will be shown that the identifiability test procedures based on differential algebra may fail for systems which are started at specific initial conditions and that this problem is strictly related to the accessibility of the system from the given initial conditions. In particular, when the system is not accessible from the given initial conditions, the ideal I having as generators the polynomials defining the dynamic system may not correctly describe the manifold of the solution. In this case a new ideal that includes all differential polynomials vanishing at the solution of the dynamic system started from the initial conditions should be calculated. An identifiability test is proposed which works, under certain technical hypothesis, also for systems with specific initial conditions.},
annote = {From Duplicate 1 (Parameter identifiability of nonlinear systems: the role of initial conditions - Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

R{\^{o}}le des cond init??? Croiser avec ce que Simon disait sur l'importance de bien choisir ses conditions initiales dans dymola

From Duplicate 2 (Parameter identifiability of nonlinear systems: The role of initial conditions - Saccomani, Maria Pia; Audoly, Stefania; D'Angi{\`{o}}, Leontina; Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

From Duplicate 2 (Parameter identifiability of nonlinear systems: The role of initial conditions - Saccomani, Maria Pia; Audoly, Stefania; D'Angi{\`{o}}, Leontina; Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

From Duplicate 1 (Parameter identifiability of nonlinear systems: the role of initial conditions - Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

R{\^{o}}le des cond init??? Croiser avec ce que Simon disait sur l'importance de bien choisir ses conditions initiales dans dymola

From Duplicate 3 (Parameter identifiability of nonlinear systems: The role of initial conditions - Saccomani, Maria Pia; Audoly, Stefania; D'Angi{\`{o}}, Leontina; Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

From Duplicate 1 (Parameter identifiability of nonlinear systems: the role of initial conditions - Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

R{\^{o}}le des cond init??? Croiser avec ce que Simon disait sur l'importance de bien choisir ses conditions initiales dans dymola

From Duplicate 2 (Parameter identifiability of nonlinear systems: The role of initial conditions - Saccomani, Maria Pia; Audoly, Stefania; D'Angi{\`{o}}, Leontina; Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

From Duplicate 1 (Parameter identifiability of nonlinear systems: the role of initial conditions - Pia Saccomani, Maria; Audoly, Stefania; D'Angi{\`{o}}, Leontina)

R{\^{o}}le des cond init??? Croiser avec ce que Simon disait sur l'importance de bien choisir ses conditions initiales dans dymola},
author = {Saccomani, Maria Pia and Audoly, Stefania and D'Angi{\`{o}}, Leontina and {Pia Saccomani}, Maria and Audoly, Stefania and D'Angi{\`{o}}, Leontina},
doi = {10.1016/S0005-1098(02)00302-3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saccomani et al. - 2003 - Parameter identifiability of nonlinear systems The role of initial conditions.pdf:pdf},
isbn = {0005-1098},
issn = {00051098},
journal = {Automatica},
keywords = {A priori global identifiability,Accessibility,Differential algebra,Model identification,Nonlinear system},
month = {apr},
number = {4},
pages = {619--632},
title = {{Parameter identifiability of nonlinear systems: The role of initial conditions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109802003023},
volume = {39},
year = {2003}
}
@article{Kim2016,
abstract = {Identification approaches applied to semi-physical thermal network structures, so called gray-box modeling approaches, are popular in building science for energy audits, retrofit analysis and advanced building controls, e.g. model predictive control. However conventional identification approaches applied to thermal networks fail when there are significant unmeasured heat gains that influence building responses. This paper presents a method to obtain improved gray-box building models from closed loop data having significant unmeasured disturbances. The method estimates both physical parameters of a building thermal network model and also a disturbance model that characterizes the unmeasured inputs. The performance of the algorithm is demonstrated using numerical and experimental results.},
author = {Kim, Donghun and Cai, Jie and Ariyur, Kartik B. and Braun, James E.},
doi = {10.1016/j.buildenv.2016.07.007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2016 - System identification for building thermal systems under the presence of unmeasured disturbances in closed loop oper.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Building control,Building modeling,Gray box model,Thermal network,Unmeasured building disturbances},
pages = {169--180},
publisher = {Elsevier Ltd},
title = {{System identification for building thermal systems under the presence of unmeasured disturbances in closed loop operation: Lumped disturbance modeling approach}},
url = {http://dx.doi.org/10.1016/j.buildenv.2016.07.007},
volume = {107},
year = {2016}
}
@misc{EU2018,
author = {{THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION}},
title = {{Directive 2018/844 of the European Parliament and of the Council of 30 May 2018 amending Directive 2010/31/EU on the energy performance of buildings and Directive 2012/27/EU on energy efficiency}},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:32018L0844},
year = {2018}
}
@article{Peuportier1990,
abstract = {A simplified simulation module has been developed to calculate the thermal performances of multizone buildings, using modal analysis. This technique reduces the computation time and therefore allows architects to perform accurate simulations using a low cost micro computer (type AT for instance). The thermal calculations are based upon a data structure in which the building is decomposed into elements (thermal zones, walls, windows, materials, ...). Each building element has been modeled as a computer object. Components of higher complexity are linked to simple components via pointers. Thus, if a component is modified, the modification is automatically transmitted through the whole structure. This environment is particularly adapted to connect the thermal calculation module (COMFIE) to an expert interface. At the moment, no expert system or inference engine is implemented, but simple algorithms which work in the following way. The user inputs a project and several characteristics (heat losses, solar gains, ...) are studied by the expert tool, which then proposes alternative designs. The user may test these modifications by repeating the simulation. This tandem simulation/expert interface takes into account the specificity of the project and its climate when applying the expert knowledge. A few expert rules are proposed, in order to enhance the energy savings and the thermal comfort. New expert rules may also be generated and/or validated. This design tool not only provides the user with fast and accurate simulations, but also offers him an opportunity to include the thermal aspects in his design approach with the help of expert rules, and this constitutes a real computer aided design.},
annote = {NULL},
author = {Peuportier, Bruno and {Sommereux Blanc}, Isabelle},
doi = {10.1080/01425919008909714},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peuportier, Sommereux Blanc - 1990 - Simulation tool with its expert interface for the thermal design of multizone buildings.pdf:pdf},
issn = {0142-5919},
journal = {International Journal of Solar Energy},
keywords = {Expert interface,Modal analysis,Multizone,Object oriented programming,Passive solar architecture,Simplified simulation tool},
month = {jan},
number = {2},
pages = {109--120},
title = {{Simulation tool with its expert interface for the thermal design of multizone buildings}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01425919008909714},
volume = {8},
year = {1990}
}
@article{Margaria2000,
abstract = {In this paper methods from diierential algebra are used to study the structural identiiability of biological models expressed in state-space form and with rational polynomial structure. The focus is on the examples and on eecient, automatic methods to test identiiability f o r various input-output experiments. Diierential algebra is coupled with Grr obner basis, Lie derivatives and the Taylor series expansion in order to obtain eecient algorithms. Two algorithms are discussed in details. In particular an upper bound on the numb e r o f d e r i v atives needed for the Taylor series approach i s g i v en.},
annote = {NULL},
author = {Margaria, Gabriella and Riccomagno, Eva and Chappell, Mike J and Wynn, Henry P},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Margaria et al. - 2000 - Diierential algebra methods for the study of the structural identiiability of biological rational polynomial mo.pdf:pdf},
keywords = {State-space models,Tay-lor series,diierential algebra,structural identiiability},
title = {{Diierential algebra methods for the study of the structural identiiability of biological rational polynomial models}},
url = {http://www.eurandom.tue.nl/reports/2000/013-report.pdf},
year = {2000}
}
@article{Rodler2019,
abstract = {Non-destructive thermal diagnosis is necessary for identification and quantification of structural defects and verification of construction performances. In this paper, we test different inverse heat transfer models to identify the thermal conductivity of a building's wall in its environment. The approaches proposed and used in this paper rely only on non-intrusive measurements: inside and outside wall surface temperatures and heat flow through the wall. First, a Bayesian statistical dynamic inference method, which has the advantage to quantify the unknown parameter and its credible interval, is presented. This method considers the uncertainties of the measured temperature and heat flow data and of the unknown thermal properties. Markov chain Monte Carlo (MCMC) algorithm is used to explore the posterior distribution. Then, the average and the dynamic procedures ISO 9869 (I. 9869-1, 2014) are introduced. Finally, the probabilistic distributions of the unknown parameters are presented and compared to the standard results. The impact of experimental conditions (average indoor-to-outdoor temperature) and the measurements length on the accuracy of the results are discussed. The relationship between the number of iterations of the MCMC, time series length, shape of the prior distribution and accuracy are studied as well as the simulation time to run the inverse models. The Bayesian approach gives the most accurate results and has the advantage of considering several unknowns (conductivity and volumetric heat capacity), which is not the case for the studied standard. The Bayesian method needs much shorter time series than the ISO standard and produces robust results at all times of year, including when the average indoor-to-outdoor temperature difference was low.},
author = {Rodler, Auline and Guernouti, Sihem and Musy, Marjorie},
doi = {10.1016/j.conbuildmat.2018.11.110},
file = {:home/sarah/OneDrive/Travail/Sources/Caract{\'{e}}risation de param{\`{e}}tre/1-s2.0-S0950061818327946-main.pdf:pdf},
issn = {09500618},
journal = {Construction and Building Materials},
keywords = {Bayesian statistics,Cob,Dynamic modelling,In situ measurements,Inverse heat transfer,Thermal properties,U-value,Uncertainty analysis},
month = {jan},
pages = {574--593},
publisher = {Elsevier Ltd},
title = {{Bayesian inference method for in situ thermal conductivity and heat capacity identification: Comparison to ISO standard}},
url = {https://doi.org/10.1016/j.conbuildmat.2018.11.110 https://linkinghub.elsevier.com/retrieve/pii/S0950061818327946},
volume = {196},
year = {2019}
}
@book{Dobre2010a,
abstract = {In systems biology, a common approach to model biological processes is to use large systems of differential equations.The associated parameter estimation problem requires to prior handle identifiability and sensitivity issues in a practical biological framework. The lack of method to assess global practical identifiability has leaded us to analyze and establish bridges between global sensitivity and identifiability measures. Specifically, we are interested in deriving conditions of global practical non-identifiability in association with global sensitivity results. Two cases are considered: i) insensitive (or non-observable) parameters ; ii) two (or more) correlated sensitivity measures of the model output with respect to model parameters. Propositions of relationships between sensitivity and identifiability, and their proofs are developped herein. Academic examples are also treated in order to illustrate contents of these propositions. {\textcopyright} 2010 IFAC.},
author = {Dobre, Simona and Bastogne, Thierry and Richard, Alain},
booktitle = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
doi = {10.3182/20100707-3-BE-2012.0045},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dobre, Bastogne, Richard - 2010 - Global sensitivity and identifiability implications in systems biology.pdf:pdf},
isbn = {9783902661708},
issn = {14746670},
keywords = {Identifiability,Nonlinear systems,Sensitivity analysis,Systems biology},
number = {PART 1},
pages = {54--59},
publisher = {IFAC},
title = {{Global sensitivity and identifiability implications in systems biology}},
url = {http://dx.doi.org/10.3182/20100707-3-BE-2012.0045},
volume = {11},
year = {2010}
}
@book{Casella2006,
abstract = {Review From the reviews: .,."There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006 "The reader sees not only how measure theory is used to develop probability theory, but also how probability theory is used in applications. a The discourse is delivered in a theorem proof format and thus is better suited for classroom a . The authors prose is generally well thought out a . will make an attractive choice for a two-semester course on measure and probability, or as a second course for students with a semester of measure or probability theory under their belt." (Peter C. Kiessler, Journal of the American Statistical Association, Vol. 102 (479), 2007) "The book is a well written self-contained textbook on measure and probability theory. It consists of 18 chapters. Every chapter contains many well chosen examples and ends with several problems related to the earlier developed theory (some with hints). a At the very end of the book there is an appendix collecting necessary facts from set theory, calculus and metric spaces. The authors suggest a few possibilities on how to use their book." (Kazimierz Musial, Zentralblatt MATH, Vol. 1125 (2), 2008) "The title of the book consists of the names of its two basic parts. The booka (TM)s third part is comprised of some special topics from probability theory. a The authors suggest using the book intwo-semester graduate programs in statistics or a one-semester seminar on special topics. The material of the book is standard a is clear, comprehensive and a {\~{}}without being intimidatinga (TM)." (Rimas NorvaiAa, Mathematical Reviews, Issue 2007 f) Product Description This is a graduate level textbook on measure theory and probability theory. The book can be used as a text for a two semester sequence of courses in measure theory and probability theory, with an option to include supplemental material on stochastic processes and special topics. It is intended primarily for first year Ph.D. students in mathematics and statistics although mathematically advanced students from engineering and economics would also find the book useful. Prerequisites are kept to the minimal level of an understanding of basic real analysis concepts such as limits, continuity, differentiability, Riemann integration, and convergence of sequences and series. A review of this material is included in the appendix. The book starts with an informal introduction that provides some heuristics into the abstract concepts of measure and integration theory, which are then rigorously developed. The first part of the book can be used for a standard real analysis course for both mathematics and statistics Ph.D. students as it provides full coverage of topics such as the construction of Lebesgue-Stieltjes measures on real line and Euclidean spaces, the basic convergence theorems, L p spaces, signed measures, Radon-Nikodym theorem, Lebesgue's decomposition theorem and the fundamental theorem of Lebesgue integration on R, product spaces and product measures, and Fubini-Tonelli theorems. It also provides an elementary introduction to Banach and Hilbert spaces, convolutions, Fourier series and Fourier and Plancherel transforms. Thus part I would be particularly useful for students in a typical Statistics Ph.D. program if a separate course on real analysis is not a standard requirement. Part II (chapters 6-13) provides full coverage of standard graduate level probability theory. It starts with Kolmogorov's probability model and Kolmogorov's existence theorem. It then treats thoroughly the laws of large numbers including renewal theory and ergodic theorems with applications and then weak convergence of probability distributions, characteristic functions, the Levy-Cramer continuity theorem and the central limit theorem as well as stable laws. It ends with conditional expectations and conditional probability, and an introduction to the theory of discrete time martingales. Part III (chapters 14-18) provides a modest coverage of discrete time Markov chains with countable and general state spaces, MCMC, continuous time discrete space jump Markov processes, Brownian motion, mixing sequences, bootstrap methods, and branching processes. It could be used for a topics/seminar course or as an introduction to stochastic processes. From the reviews: "...There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Casella, George and Fienberg, Stephen and Olkin, Ingram},
booktitle = {Design},
doi = {10.1016/j.peva.2007.06.006},
eprint = {arXiv:1011.1669v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, Fienberg, Olkin - 2006 - Introduction to Statistical Learning with R.pdf:pdf},
isbn = {9780387781884},
issn = {01621459},
pages = {618},
pmid = {10911016},
title = {{Introduction to Statistical Learning with R}},
url = {http://books.google.com/books?id=9tv0taI8l6YC},
volume = {102},
year = {2006}
}
@article{Kivits2018,
author = {Kivits, E M M and Hof, Paul M. J. Van Den},
doi = {10.1016/j.ifacol.2018.09.120},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kivits, Hof - 2018 - On Representations of Linear Dynamic Networks.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {dynamic networks,system identification},
number = {694504},
pages = {838--843},
publisher = {Elsevier B.V.},
title = {{On Representations of Linear Dynamic Networks}},
url = {https://doi.org/10.1016/j.ifacol.2018.09.120},
volume = {51},
year = {2018}
}
@misc{Maclaren2019,
abstract = {Here we consider, in the context of causal inference, the basic question: 'what can be estimated from data?'. We call this the question of estimability. We consider the usual definition adopted in the causal inference literature -- identifiability -- in a general mathematical setting and show why it is an inadequate formal translation of the concept of estimability. Despite showing that identifiability implies the existence of a Fisher-consistent estimator, we show that this estimator may be discontinuous, and hence unstable, in general. The difficulty arises because the causal inference problem is in general an ill-posed inverse problem. Inverse problems have three conditions which must be satisfied in order to be considered well-posed: existence, uniqueness, and stability of solutions. We illustrate how identifiability corresponds to the question of uniqueness; in contrast, we take estimability to mean satisfaction of all three conditions, i.e. well-posedness. It follows that mere identifiability does not guarantee well-posedness of a causal inference procedure, i.e. estimability, and apparent solutions to causal inference problems can be essentially useless with even the smallest amount of imperfection. These concerns apply, in particular, to causal inference approaches that focus on identifiability while ignoring the additional stability requirements needed for estimability.},
archivePrefix = {arXiv},
arxivId = {1904.02826},
author = {Maclaren, Oliver J and Nicholson, Ruanui},
booktitle = {pre-print},
eprint = {1904.02826},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maclaren, Nicholson - 2019 - What can be estimated Identifiability, estimability, causal inference and ill-posed inverse problems.pdf:pdf},
keywords = {bust statistics,causal inference,estimability,identifiability,inverse problems,nonparametric statistics,ro-,sensitive parameters,stability,statistical learning theory},
month = {apr},
pages = {1--34},
title = {{What can be estimated? Identifiability, estimability, causal inference and ill-posed inverse problems}},
url = {http://arxiv.org/abs/1904.02826},
year = {2019}
}
@article{Blazere2018,
abstract = {Stochastic inversion problems arise when it is wanted to estimate the probability distribution of a stochastic input from indirect observable and noisy information and the limited knowledge of an operator that connects the inputs to the observable output. While such problems are characterized by strong identifiability conditions, well-posedness conditions of "signal over noise" nature should be respected priori to collect observations. In addition to well-known Hadamard' well-posedness condition, a new one is established based on the predictive transmission of input uncertainty to output, which can be interpreted as the result provided by a sensitivity analysis if the problem were solved. This new condition should take part within the input model itself, which adds a constraint in established frequentist or Bayesian methodologies of stochastic inversion. While this article mainly deals with linearizable operators, the lack of constrast typical of linear problems suggest that the proposed condition should be used in more general settings, provided the operator owns diffferentiability properties.},
archivePrefix = {arXiv},
arxivId = {1806.03440},
author = {Blaz{\`{e}}re, M{\'{e}}lanie and Bousquet, Nicolas},
eprint = {1806.03440},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blaz{\`{e}}re, Bousquet - 2018 - Well-posedness conditions in stochastic inversion problems.pdf:pdf},
pages = {1--15},
title = {{Well-posedness conditions in stochastic inversion problems}},
url = {http://arxiv.org/abs/1806.03440},
year = {2018}
}
@book{Gilks1996,
annote = {Tolbiac - Haut-de-jardin - Sciences et techniques - Salle C - Math{\'{e}}matiques
519.2 GILK m 
support : livre},
author = {Gilks, W. R. (Wally R.) and Richardson, S. (Sylvia) and Spiegelhalter, David J.},
isbn = {0412055511},
pages = {486},
publisher = {Chapman {\&} Hall},
title = {{Markov chain Monte Carlo in practice}},
url = {http://catalogue.bnf.fr/ark:/12148/cb37478643b},
year = {1996}
}
@article{Goyal2011,
abstract = {Constructing a model of thermal dynamics of a multi-zone building requires modeling heat conduction through walls as well as convection due to air-flows among the zones. Reduced order models of conduction in terms of RC-networks are well established, while currently the only way to model convection is through CFD (Computational Fluid Dynamics). This limits convection models to a single zone or a small number of zones in a building. In this paper we present a novel method of identifying a reduced order thermal model of a multi-zone building from measured space temperature data. The method consists of first identifying the underlying network structure, in particular, the paths of convective interaction among zones, which corresponds to edges of a building graph. Convective interaction among a pair of zones is modeled as a RC network, in a manner analogous to conduction models. The second step of the proposed method involves estimating the parameters of the RC network model for the convection edges. The identified convection edges, along with the associated R and C values, are used to augment a thermal dynamics model of a building that is originally constructed to model only conduction. Predictions by the augmented model and the conduction-only model are compared with space temperatures measured in a multi-zone building in the University of Florida campus. The identified model is seen to predict the temperatures more accurately than a conduction-only model.},
annote = {Interpr{\'{e}}tation de la question de l'identifiabilit{\'{e}}.
Structure identification problem : identify conditionnal independance between random variables by estimating P = inv(cov(X,X)) where X is the Xi vector (Xi at each node)
Parameter estimation problem : simplify model of each conduction branc by supposing all resitors and all capacitors are equal},
author = {Goyal, Siddharth and Liao, Chenda and Barooah, Prabir},
doi = {10.1109/CDC.2011.6161387},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal, Liao, Barooah - 2011 - Identification of multi-zone building thermal interaction model from data.pdf:pdf},
isbn = {9781612848006},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
keywords = {Estimation,Identifiability,Identification for control,Network analysis and control},
mendeley-tags = {Identifiability},
pages = {181--186},
title = {{Identification of multi-zone building thermal interaction model from data}},
year = {2011}
}
@techreport{Deliverable2016,
author = {{Pouget Consultants}},
file = {:home/sarah/OneDrive/Travail/Sources/R{\'{e}}novation/FR{\_}EPISCOPE{\_}LocalCaseStudy{\_}Pouget.pdf:pdf},
institution = {EPISCOPE},
number = {March},
title = {{National report on pilot actions - EPISCOPE}},
year = {2015}
}
@article{Rouchier2019,
author = {Rouchier, Simon and Jim{\'{e}}nez, Maria Jos{\'{e}} and Casta{\~{n}}o, Sergio},
doi = {10.1016/j.enbuild.2019.01.045},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier, Jim{\'{e}}nez, Casta{\~{n}}o - 2019 - Sequential Monte Carlo for on-line parameter estimation of a lumped building energy model.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
month = {mar},
pages = {86--94},
title = {{Sequential Monte Carlo for on-line parameter estimation of a lumped building energy model}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818317924},
volume = {187},
year = {2019}
}
@article{Ji2019,
abstract = {Thermal modelling tools have widely been used in the construction industry at the design stage, either for new build or retrofitting existing buildings, providing data for informed decision-making. The accuracy of thermal models has been subject of much research in recent decades due to the potential large difference between predicted and ‘in-use' performance – the so called ‘performance gap'. A number of studies suggested that better representation of building physics and operation details in thermal models can improve the accuracy of predictions. However, full-scale model calibration has always been challenging as it is difficult to measure all the necessary boundary conditions in an open environment. Thus, the Energy House facility at the University of Salford – a full-sized end terrace house constructed within an environmental chamber – presents a unique opportunity to conduct full-scale model calibration. The aim of this research is to calibrate Energy House thermal models using various full-scale measurements. The measurements used in this research include the co-heating tests for a whole house retrofit case study, and thermal resistance from window coverings and heating controls with thermostatic radiator valves (TRVs). Thermal models were created using an IESVE (Integrated Environment Solutions Virtual Environment). IESVE is a well-established dynamic thermal simulation tool widely used in analysing the dynamic response of a building based on the hourly input of weather data. The evidence from this study suggests that thermal models using measured U-values and infiltration rates do perform better than the models using calculated thermal properties and assumed infiltration rates. The research suggests that better representations of building physics help thermal models reduce the performance gap. However, discrepancies still exist due to various other underlying uncertainties which need to be considered individually with each case. In relative terms, i.e. variations in percentage, the predictions from thermal models tend to be more reliable than predicting the absolute numbers.},
author = {Ji, Yingchun and Lee, Angela and Swan, Will},
doi = {10.1016/J.ENBUILD.2019.03.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ji, Lee, Swan - 2019 - Building dynamic thermal model calibration using the Energy House facility at Salford.pdf:pdf},
issn = {0378-7788},
journal = {Energy and Buildings},
keywords = {Co-heating,Dynamic thermal modelling,IESVE,Model calibration,Retrofit},
publisher = {Elsevier B.V.},
title = {{Building dynamic thermal model calibration using the Energy House facility at Salford}},
url = {https://www.sciencedirect.com/science/article/pii/S0378778818337885?dgcid=rss{\_}sd{\_}all},
year = {2019}
}
@article{Ma2017,
abstract = {We propose a new additive spatio-temporal Gaussian process approximation to model complex dependence structures for large spatio-temporal data. The proposed approximation method incorporates a computational-complexity-reduction method and a separable covariant function, which can capture different scales of variation and spatio-temporal interactions. The first component is able to capture nonseparable variation while the second component captures the separable variation of all scales. The Bayesian inference is carried out through a Markov chain Monte Carlo algorithm based on the hierarchical representation of the model. Through this representation we are able to utilize the computational advantages of both components. To demonstrate the inferential and computational benefits of the proposed method, we carry out four different simulation studies as well as a real application that concerns the spatio-temporal measurements of ground-level ozone in the Eastern United States.},
archivePrefix = {arXiv},
arxivId = {1801.00319},
author = {Ma, Pulong and Konomi, Bledar and Kang, Emily L},
eprint = {1801.00319},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Konomi, Kang - Unknown - Low-Cost Bayesian Inference for Additive Approximate Gaussian Process arXiv 1801 . 00319v1 stat . ME 31(2).pdf:pdf},
keywords = {additive model,bayesian inference,gaussian process,metropolis-within-gibbs,nonseparable covariance function,sampler,spatio-temporal data},
month = {dec},
title = {{An Additive Gaussian Process Approximation for Large Spatio-Temporal Data}},
url = {http://arxiv.org/abs/1801.00319},
year = {2017}
}
@article{Villaverde2017,
abstract = {Dynamic modelling is a powerful tool for studying biological networks. Reachability (controllability), observability, and structural identifiability are classical system-theoretic properties of dynamical models. A model is structurally identifiable if the values of its parameters can in principle be determined from observations of its outputs. If model parameters are considered as constant state variables, structural identifiability can be studied as a generalization of observability. Thus, it is possible to assess the identifiability of a nonlinear model by checking the rank of its augmented observability matrix. When such rank test is performed symbolically, the result is of general validity for almost all numerical values of the variables. However, for special cases, such as specific values of the initial conditions, the result of such test can be misleading-that is, a structurally unidentifiable model may be classified as identifiable. An augmented observability rank test that specializes the symbolic states to particular numerical values can give hints of the existence of this problem. Sometimes it is possible to find such problematic values analytically, or via optimization. This manuscript proposes procedures for performing these tasks and discusses the relation between loss of identifiability and loss of reachability, using several case studies of biochemical networks.},
author = {Villaverde, Alejandro F. and Banga, Julio R},
doi = {10.3390/pr5020029},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/processes-05-00029-v2.pdf:pdf},
issn = {22279717},
journal = {Processes},
keywords = {Controllability,Differential geometry,Identifiability,Nonlinear systems,Observability,Parameter estimation,Reachability},
number = {2},
title = {{Structural properties of dynamic systems biology models: Identifiability, reachability, and initial conditions}},
volume = {5},
year = {2017}
}
@unpublished{Baillon2010,
author = {Baillon, Fabien},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baillon - 2010 - Aide-m{\'{e}}moire pour Maxima.pdf:pdf},
number = {9},
pages = {1--6},
title = {{Aide-m{\'{e}}moire pour Maxima}},
year = {2010}
}
@article{Leyten2014,
author = {Leyten, Joe L and Raue, Arjen K and Kurvers, Stanley R},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leyten, Raue, Kurvers - 2014 - Robust Design for high workers ' performance and low absenteeism – An alternative approach.pdf:pdf},
keywords = {adaptive thermal comfort,building robustness,indoor air quality,performance,sickness absenteeism,workers},
number = {April},
pages = {10--13},
title = {{Robust Design for high workers ' performance and low absenteeism – An alternative approach}},
year = {2014}
}
@article{Liu2008,
abstract = {A major question for the application of computer models is Does the computer model adequately represent reality? Viewing the computer models as a potentially biased representation of reality, Bayarri et al. [M. Bayarri, J. Berger, R. Paulo, J. Sacks, J. Cafeo, J. Cavendish, C. Lin, J. Tu, A framework for validation of computer models, Technometrics 49 (2) (2007) 138-154] develop the simulator assessment and validation engine (SAVE) method as a general framework for answering this question. In this paper, we apply the SAVE method to the challenge problem which involves a thermal computer model designed for certain devices. We develop a statement of confidence that the devices modeled can be applied in intended situations. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Liu, F and Bayarri, M. J. and Berger, J. O. and Paulo, R and Sacks, J},
doi = {10.1016/j.cma.2007.05.032},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - Unknown - A Bayesian Analysis of the Thermal Challenge Problem.pdf:pdf},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Bayesian analysis,Computer model validation,Gaussian stochastic process,Thermal computer model},
number = {29-32},
pages = {2457--2466},
title = {{A Bayesian analysis of the thermal challenge problem}},
url = {http://www2.stat.duke.edu/{~}berger/papers/thermal.pdf},
volume = {197},
year = {2008}
}
@misc{CSTB,
author = {CSTB},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CSTB - Unknown - M{\'{e}}thode de calcul TH-C-E ex.pdf:pdf},
title = {{M{\'{e}}thode de calcul TH-C-E ex}}
}
@techreport{CTSM2013,
author = {Juhl, Rune and Kristensen, Niels and Bacher, Peder and Kloppenborg, Jan and Madsen, Henrik},
institution = {Technical University of Denmark},
title = {{CTSM-R user guide}},
url = {http://ctsm.info/pdfs/userguide.pdf},
year = {2013}
}
@article{Pernigotto2014,
abstract = {Representativeness of weather inputs is crucial to limit the global uncertainty of building energy simulation results. The length of the multi-year weather data series and the methodology used for the typical month selection largely influence the results of the reference year development process. In this work, we investigate two possible modifications to the EN ISO 15927-4:2005 procedure aimed at improving the representativeness of reference year heating and cooling needs. The first modification maintains the reference years independent of their final use while the second one leads to the development of specific weather files for heating or cooling analyses by introducing weighting coefficients for the different weather parameters. The study is performed for five North Italy localities with 10 or less years in the data-set and for a sample of 48 simplified buildings. Both proposed modifications brought improvements to the representativeness of the reference year results. {\textcopyright} 2013 International Building Performance Simulation Association (IBPSA).},
author = {Pernigotto, Giovanni and Prada, Alessandro and Gasparella, Andrea and Hensen, Jan L.M.},
doi = {10.1080/19401493.2013.853840},
file = {:home/sarah/OneDrive/Travail/Sources/14{\_}jbps{\_}pernigotto.pdf:pdf},
issn = {19401493},
journal = {Journal of Building Performance Simulation},
keywords = {EN ISO 15927-4:2005,building energy simulation,test reference year},
number = {6},
pages = {391--410},
title = {{Analysis and improvement of the representativeness of EN ISO 15927-4 reference years for building energy simulation}},
volume = {7},
year = {2014}
}
@article{Kruschke2012,
abstract = {The use of Bayesian methods for data analysis is creating a revolution in fields ranging from genetics to marketing. Yet, results of our literature review, including more than 10,000 articles published in 15 journals from January 2001 and December 2010, indicate that Bayesian approaches are essentially absent from the organizational sciences. Our article introduces organizational science researchers to Bayesian methods and describes why and how they should be used. We use multiple linear regression as the framework to offer a step-by-step demonstration, including the use of software, regarding how to implement Bayesian methods. We explain and illustrate how to determine the prior distribution, compute the posterior distribution, possibly accept the null value, and produce a write-up describing the entire Bayesian process, including graphs, results, and their interpretation. We also offer a summary of the advantages of using Bayesian analysis and examples of how specific published research based on frequentist analysis-based approaches failed to benefit from the advantages offered by a Bayesian approach and how using Bayesian analyses would have led to richer and, in some cases, different substantive conclusions. We hope that our article will serve as a catalyst for the adoption of Bayesian methods in organizational science research. {\textcopyright} The Author(s) 2012.},
author = {Kruschke, John K. and Aguinis, Herman and Joo, Harry},
doi = {10.1177/1094428112457829},
file = {:home/sarah/OneDrive/Travail/Sources/1094428112457829.pdf:pdf},
issn = {15527425},
journal = {Organizational Research Methods},
keywords = {Monte Carlo,bootstrapping),computer simulation procedures (e.g.,multilevel research,quantitative research},
number = {4},
pages = {722--752},
title = {{The Time Has Come: Bayesian Methods for Data Analysis in the Organizational Sciences}},
volume = {15},
year = {2012}
}
@book{Kaipio2006,
abstract = {The book develops the statistical approach to inverse problems with an emphasis on modeling and computations. The framework is the Bayesian paradigm, where all variables are modeled as random variables, the randomness reflecting the degree of belief of their values, and the solution of the inverse problem is expressed in terms of probability densities. The book discusses in detail the construction of prior models, the measurement noise modeling and Bayesian estimation. Markov Chain Monte Carlo-methods as well as optimization methods are employed to explore the probability distributions. The results and techniques are clarified with classroom examples that are often non-trivial but easy to follow. Besides the simple examples, the book contains previously unpublished research material, where the statistical approach is developed further to treat such problems as discretization errors, and statistical model reduction. Furthermore, the techniques are then applied to a number of real world applications such as limited angle tomography, image deblurring, electrical impedance tomography and biomagnetic inverse problems. The book is intended to researchers and advanced students in applied mathematics, computational physics and engineering. The first part of the book can be used as a text book on advanced inverse problems courses. The authors Jari Kaipio and Erkki Somersalo are Professors in the Applied Physics Department of the University of Kuopio, Finland and the Mathematics Department at the Helsinki University of Technology, Finland, respectively.},
author = {Kaipio, Jari P. and Somersalo, Erkki},
booktitle = {Applied Mathematical Sciences},
doi = {10.1007/b138659},
file = {:home/sarah/OneDrive/Travail/Sources/(Applied Mathematical Sciences) Kaipio J., Somersalo E. - Statistical and computational inverse problems-Springer (2005).pdf:pdf},
isbn = {9780387489162},
issn = {2196968X},
pages = {i--339},
publisher = {Springer},
title = {{Statistical and Computational Inverse Problems}},
volume = {160},
year = {2006}
}
@article{Villaverde2019,
abstract = {Observability is a modelling property that describes the possibility of inferring the internal state of a system from observations of its output. A related property, structural identifiability, refers to the theoretical possibility of determining the parameter values from the output. In fact, structural identifiability becomes a particular case of observability if the parameters are considered as constant state variables. It is possible to simultaneously analyse the observability and structural identifiability of a model using the conceptual tools of differential geometry. Many complex biological processes can be described by systems of nonlinear ordinary differential equations and can therefore be analysed with this approach. The purpose of this review article is threefold: (I) to serve as a tutorial on observability and structural identifiability of nonlinear systems, using the differential geometry approach for their analysis; (II) to review recent advances in the field; and (III) to identify open problems and suggest new avenues for research in this area.},
archivePrefix = {arXiv},
arxivId = {1812.04525},
author = {Villaverde, Alejandro F.},
doi = {10.1155/2019/8497093},
eprint = {1812.04525},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/8497093.pdf:pdf},
issn = {10990526},
journal = {Complexity},
title = {{Observability and Structural Identifiability of Nonlinear Biological Systems}},
volume = {2019},
year = {2019}
}
@book{Heiberger2015,
address = {New York, NY},
author = {Heiberger, Richard M. and Holland, Burt},
doi = {10.1007/978-1-4939-2122-5},
isbn = {978-1-4939-2121-8},
publisher = {Springer New York},
series = {Springer Texts in Statistics},
title = {{Statistical Analysis and Data Display}},
url = {http://link.springer.com/10.1007/978-1-4939-2122-5},
year = {2015}
}
@article{Weerts2018,
abstract = {A recent development in data-driven modelling addresses the problem of identifying dynamic models of interconnected systems, represented as linear dynamic networks. For these networks the notion network identifiability has been introduced recently, which reflects the property that different network models can be distinguished from each other. Network identifiability is extended to cover the uniqueness of a single module in the network model. Conditions for single module identifiability are derived and formulated in terms of path-based topological properties of the network models.},
archivePrefix = {arXiv},
arxivId = {1803.02586},
author = {Weerts, Harm and den Hof, Paul M. J. Van and Dankers, Arne},
eprint = {1803.02586},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weerts, Van Den Hof, Dankers - Unknown - Single module identifiability in linear dynamic networks(2).pdf:pdf},
month = {mar},
title = {{Single module identifiability in linear dynamic networks}},
url = {https://arxiv.org/pdf/1803.02586.pdf http://arxiv.org/abs/1803.02586},
year = {2018}
}
@article{Boesman-Finkelstein1991,
abstract = {This review discusses the feasibility of using hyperimmune bovine immunoglobulin (obtained from colostrum) to protect formula-fed infants in developing countries from diarrhoeal diseases.},
author = {Boesman-Finkelstein, M. and Finkelstein, R. A.},
doi = {10.1007/978-1-4615-3838-7_46},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/Frey{\_}et{\_}al-2002-Risk{\_}Analysis.pdf:pdf},
issn = {0065275X},
journal = {Advances in Experimental Medicine and Biology},
keywords = {critical control points,food safety,microbial risk assessment,sensitivity analysis methods},
number = {3},
pages = {361--367},
title = {{Bovine lactogenic immunity against pediatric enteropathogens}},
volume = {310},
year = {1991}
}
@article{Glover1974,
abstract = {We consider the problem of what parametrizations of linear dynamical systems are appropriate for identification (i.e., so that the identification problem has a unique solution, and all systems of a particular class can be represented). Canonical forms for controllable linear systems under similarity transformation are considered and it is shown that their use in identification may cause numerical difficulties, and an alternate approach is proposed which avoids these difficulties. Then it is assumed that the system matrices are parametrized by some unknown parameters from a priori system knowledge. The identiability of such an arbitrary parametrization is then considered in several situations. Assuming that the system transfer function can be identified asymptotically, conditions are derived for local and global identifiability. Finally, conditions for identifiability from the output spectral density are given for a system driven by unobserved white noise.},
author = {Glover, Keith and Willems, Jan C.},
doi = {10.1109/TAC.1974.1100711},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glover, Willems - 1974 - Parametrizations of Linear Dynamical Systems Canonical Forms and Identifiability.pdf:pdf},
isbn = {0018-9286 VO - 19},
issn = {15582523},
journal = {IEEE Transactions on Automatic Control},
number = {6},
pages = {640--646},
title = {{Parametrizations of Linear Dynamical Systems: Canonical Forms and Identifiability}},
volume = {19},
year = {1974}
}
@book{Wakefield2013,
address = {New York, NY},
author = {Wakefield, Jon},
doi = {10.1007/978-1-4419-0925-1},
isbn = {978-1-4419-0924-4},
publisher = {Springer New York},
series = {Springer Series in Statistics},
title = {{Bayesian and Frequentist Regression Methods}},
url = {http://link.springer.com/10.1007/978-1-4419-0925-1},
year = {2013}
}
@article{Nielsen2005,
abstract = {A simplified building simulation tool to evaluate energy demand and thermal indoor environment in the early stages of building design is presented. Simulation is performed based on few input data describing the building design, HVAC systems and control strategies. Hourly values for energy demand and indoor temperature are calculated based on hourly weather data. Calculation of the solar energy transmitted through windows takes into account the dependency of the total solar energy transmittances on the incidence angle, shades from far objects and shades from the window recess and overhangs. Several systems including heating, cooling, solar shading, venting, ventilation with heat recovery and variable insulation can be activated to control the indoor temperature and energy demand. Predicted percentages of dissatisfied occupants are calculated for a given time period to support decisions concerning the thermal indoor environment. The simplified building simulation tool gives reliable results compared to detailed tools and needs only few input data to perform a simulation. The tool is therefore useful for preliminary design tasks in the early design stages where rough estimates of the building design are given and rough estimates of energy use and thermal indoor environment are needed for decision support. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
author = {Nielsen, Toke Rammer},
doi = {10.1016/j.solener.2004.06.016},
file = {:home/sarah/OneDrive/Travail/Sources/Analogie RC/1-s2.0-S0038092X04001550-main.pdf:pdf},
issn = {0038092X},
journal = {Solar Energy},
keywords = {Building design,Building heating and cooling,Simulation,Thermal indoor environment},
number = {1},
pages = {73--83},
title = {{Simple tool to evaluate energy demand and indoor environment in the early stages of building design}},
volume = {78},
year = {2005}
}
@article{Tian2016,
abstract = {Bayesian computation has received increasing attention in calibrating building energy models due to its flexibility and accuracy. However, there has been little research on how to determine informative energy data in Bayesian calibration in building energy models. Therefore, this study aims to determine and choose informative energy data using correlation analysis and hierarchical clustering method. A case study of retail building is used to demonstrate the proposed methods to infer four unknown input parameters using EnergyPlus program. The results indicate that the different combinations of energy data can provide various levels of accuracy in estimating unknown input variables in model calibration. This suggests that Bayesian computation is suitable for inferring the parameters when there are missing energy data that can be treated as uninformative output data. The proposed method can be also used to find the redundant information on energy data in order to improve computational efficiency in Bayesian calibration.},
author = {Tian, Wei and Yang, Song and Li, Zhanyong and Wei, Shen and Pan, Wei and Liu, Yunliang},
doi = {10.1016/j.enbuild.2016.03.042},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2016 - Identifying informative energy data in Bayesian calibration of building energy models.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian computation,Building energy,Cluster analysis,Model calibration},
pages = {363--376},
publisher = {Elsevier B.V.},
title = {{Identifying informative energy data in Bayesian calibration of building energy models}},
url = {http://dx.doi.org/10.1016/j.enbuild.2016.03.042},
volume = {119},
year = {2016}
}
@article{Michalak2014,
abstract = {a b s t r a c t The Recast of the EPBD (Energy Performance of Buildings) Directive from the 2010 introduced the definition of a " nearly zero energy building " , covering its energy needs from renewable sources. In en-ergy efficient buildings the energy needs depend strongly on the running conditions. Thus, such objects require high quality calculation models where a more detailed, hourly calculation, is needed. The paper presents the application of the simple hourly dynamic calculation method from EN ISO 13790 standard with the use of Matlab/Simulink package for the calculation of annual demand of the heating and cooling energy. The control strategy described in this standard was applied in Simulink. Simulations were performed for the ten different locations, two for each of five climatic zones of Poland. Results of calculations were compared with the values obtained with two other methods: EnergyPlus detailed simulation, as a reference method, and monthly method from EN ISO 13790. The validation tests were performed for ten different locations, two for each of five climatic zones of Poland. The presented Matlab/Simulink model showed good accuracy. More significant differences were obtained for the cooling needs calculated with the monthly method. This implies the need of a further more detailed investigation on this method in Polish conditions.},
author = {Michalak, Piotr},
doi = {10.1016/j.energy.2014.08.019},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michalak - 2014 - The simple hourly method of EN ISO 13790 standard in MatlabSimulink A comparative study for the climatic conditions of.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {5R1C,EN ISO 13790,EnergyPlus,Matlab,Simple hourly method,Simulink},
month = {oct},
pages = {568--578},
title = {{The simple hourly method of EN ISO 13790 standard in Matlab/Simulink: A comparative study for the climatic conditions of Poland}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0360544214009554/1-s2.0-S0360544214009554-main.pdf?{\_}tid=314145fa-f069-11e7-bdfb-00000aab0f27{\&}acdnat=1514972205{\_}1288e633264a984fee7afd164e4fd7b9 https://linkinghub.elsevier.com/retrieve/pii/S0360544214009554},
volume = {75},
year = {2014}
}
@article{Hobert1996,
abstract = {Often, either from a lack of prior information or simply for convenience, variance components are modeled with improper priors in hierarchical linear mixed models. Although the posterior distributions for these models are rarely available in closed form, the usual conjugate structure of the prior specification allows for painless calculation of the Gibbs conditionals. Thus the Gibbs sampler may be used to explore the posterior distribution without ever having established propriety of the posterior. An example is given showing that the output from a Gibbs chain corresponding to an improper posterior may appear perfectly reasonable. Thus one cannot expect the Gibbs output to provide a “red flag,” informing the user that the posterior is improper. The user must demonstrate propriety before a Markov chain Monte Carlo technique is used. A theorem is given that classifies improper priors according to the propriety of the resulting posteriors. Applications concerning Bayesian analysis of animal breeding data and the location of maxima of unwieldy (restricted) likelihood functions are discussed. Gibbs sampling with improper posteriors is then considered in more generality. The concept of functional compatibility of conditional densities is introduced and is used to construct an invariant measure for a class of Markov chains. These results are used to show that Gibbs chains corresponding to improper posteriors are, in theory, quite ill-behaved. Copyright 1996 Taylor {\&} Francis Group, LLC.},
author = {Hobert, James P. and Casella, George},
doi = {10.1080/01621459.1996.10476714},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/BU-1356-M.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Animal breeding,Compatibility,Functional compatibility,Improper posterior,Markov chain,Monte Carlo,Variance components},
number = {436},
pages = {1461--1473},
title = {{The Effect of Improper Priors on Gibbs Sampling in Hierarchical Linear Mixed Models}},
volume = {91},
year = {1996}
}
@article{Shirt1994,
abstract = {Although experimental designs have been extensively applied for steady-state modeling of process behavior, their use in studying dynamic systems has been more limited. Optimal designs were primarily focused on minimizing uncertainty in the transfer function parameter estimates, until Ljung pointed out the importance of minimizing bias in the assumed form of the transfer function. This paper reviews existing methodologies for designing input test signals and draws comparisons among them through the use of simulation examples. Results indicate that input designs which emphasize relevant frequencies for the controller application give superior performance when either an adequate process transfer function model has been specified or bias in its form exists. In the latter case, minimization of the frequency domain bias is found to be the most important factor in ensuring reliable controller performance. Distributional results for the closed-loop performance criterion provide important insights into the dominant source of model uncertainty. {\textcopyright} 1994, American Chemical Society. All rights reserved.},
author = {Shirt, Roger W. and Harris, Thomas J. and Bacon, David W.},
doi = {10.1021/ie00035a017},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/ie00035a017.pdf:pdf},
issn = {15205045},
journal = {Industrial and Engineering Chemistry Research},
number = {11},
pages = {2656--2667},
title = {{Experimental Design Considerations for Dynamic Systems}},
volume = {33},
year = {1994}
}
@article{Wang2006a,
abstract = {Building simple and effective models are essential to many applications, such as building performance diagnosis and optimal control. Detailed physical models are time consuming and often not cost-effective. Black box models require large amount of training data and may not always reflect the physical behaviors. In this study, a method is proposed to simplify the building thermal model and to identify the parameters of the simplified model. For building envelopes, the model parameters can be determined using the easily available physical details based on the frequency characteristic analysis. For the building internal mass involving various components, it is very difficult to obtain the detailed physical properties. To overcome this problem, the building internal mass is represented by a thermal network of lumped thermal mass and the parameters are identified using operation data. Genetic algorithm (GA) estimators are developed to identify these parameters. The simplified dynamic building energy model is validated on a real commercial office building in different weather conditions. {\textcopyright} 2005 Elsevier SAS. All rights reserved.},
author = {Wang, Shengwei and Xu, Xinhua},
doi = {10.1016/j.ijthermalsci.2005.06.009},
file = {:home/sarah/OneDrive/Travail/Sources/Analogie RC/1-s2.0-S1290072905001614-main.pdf:pdf},
issn = {12900729},
journal = {International Journal of Thermal Sciences},
keywords = {Frequency characteristic analysis,Genetic algorithm,Parameter identification,Simplified model,Thermal performance},
number = {4},
pages = {419--432},
title = {{Simplified building model for transient thermal performance estimation using GA-based parameter identification}},
volume = {45},
year = {2006}
}
@article{Gaspar2018,
abstract = {The actual thermal behaviour of fa{\c{c}}ades is important to identify suitable energy-saving measures and increase the energy performance of existing buildings. However, the accuracy of in situ measurements of fa{\c{c}}ades' U-values varies widely, mostly due to inadequate test durations. The aim of this paper was to evaluate the minimum duration of in situ experimental campaigns to measure the thermal transmittance of existing buildings' fa{\c{c}}ades using the heat flow meter method, and to analyse the thermal performance of the fa{\c{c}}ade during the test. Minimum test duration was determined according to data quality criteria, variability of results criteria, and standardized criteria for different ranges of theoretical thermal transmittance and for the same range of average temperature difference. Then, the minimum test duration results were compared. The findings show that ISO criteria are more sensitive and provide more accurate results, requiring a longer test duration. However, when certification is not required, the duration of the test could be reduced by applying data quality and variability of results criteria. The minimum duration of experimental campaigns depends on the theoretical thermal transmittance and the stability of climatic conditions. Moreover, results are more accurate when the dynamic method is used.},
author = {Gaspar, Katia and Casals, Miquel and Gangolells, Marta},
doi = {10.1016/j.enbuild.2018.07.049},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778818312283-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {In situ,Thermal transmittance,U-value calculation},
month = {oct},
pages = {360--370},
publisher = {Elsevier B.V.},
title = {{Review of criteria for determining HFM minimum test duration}},
url = {https://doi.org/10.1016/j.enbuild.2018.07.049 https://linkinghub.elsevier.com/retrieve/pii/S0378778818312283 https://www-sciencedirect-com.camphrier-1.grenet.fr/science/article/pii/S0378778818312283},
volume = {176},
year = {2018}
}
@article{Kruschke2018,
abstract = {This article explains a decision rule that uses Bayesian posterior distributions as the basis for accepting or rejecting null values of parameters. This decision rule focuses on the range of plausible values indicated by the highest density interval of the posterior distribution and the relation between this range and a region of practical equivalence (ROPE) around the null value. The article also discusses considerations for setting the limits of a ROPE and emphasizes that analogous considerations apply to setting the decision thresholds for p values and Bayes factors.},
author = {Kruschke, John K.},
doi = {10.1177/2515245918771304},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Kruschke2018-HDI-ROPE-Article.pdf:pdf},
issn = {2515-2459},
journal = {Advances in Methods and Practices in Psychological Science},
month = {jun},
number = {2},
pages = {270--280},
title = {{Rejecting or Accepting Parameter Values in Bayesian Estimation}},
url = {http://journals.sagepub.com/doi/10.1177/2515245918771304},
volume = {1},
year = {2018}
}
@article{Hadamard1907,
abstract = {La question g{\'{e}}n{\'{e}}rale que nous nous proposons d'{\'{e}}tudier est la d{\'{e}}termination des solutions d'une {\'{e}}quation lin{\'{e}}aire aux d{\'{e}}riv{\'{e}}es partielles du second ordre (c'est le cas auquel nous nous bornerons) par des donn{\'{e}}es aux limites. Autrement dit, nous avons {\`{a}} r{\'{e}}sumer les r{\'{e}}sultats acquis relativ ement {\`{a}} la double question suivante : {\~{}}.° Quelles sont les donn{\'{e}}es propres {\`{a}} d{\'{e}}terminer une solution d'une {\'{e}}quation aux d{\'{e}}riv{\'{e}}es partielles ? {\_} 2° Comment peut-on calculer la solution en fonction des donn{\'{e}}es ainsi fournies ? Ces deux questions sont pr{\'{e}}cis{\'{e}}ment celles que M. Poincar{\'{e}}, dans son important discours Sur les rapports de l'Analyse pure et de la .Physique math{\'{e}}matique (Congr{\`{e}}s international des Math{\'{e}}maticiens, Zurich, 1897), citait comme exemple de l'aide que la Physique est susceptible d'apporter {\`{a}} l'Analyse. Et, en effet, il n'est peut-{\^{e}}tre aucun cas o{\`{u}} apparaisse d'une mani{\`{e}}re plus frappante la conclu-sion qu'il a d{\'{e}}velopp{\'{e}}e : C'est la physique math{\'{e}}matique qui nous montre quels probl{\`{e}}mes nous devons nous poser. C'est elle aussi qui nous fait pr{\'{e}}voir la solution. 1 1. Il n'est pas {\'{e}}tonnant que la physique nous ait pos{\'{e}}, relativement aux {\'{e}}quations aux d{\'{e}}riv{\'{e}}es partielles, des probl{\`{e}}mes auxquels nous n'aurions point song{\'{e}} sans elle. Il est, au contraire, extr{\^{e}}mement remarquable que ces probl{\`{e}}mes -et, pour ainsi dire, eux seuls -soient toujours correctement pos{\'{e}}s. Qu'entendons-nous par cette expression un peu vague de pro-bl{\`{e}}me « correctement pos{\'{e}} » ? Dans le cas d'{\'{e}}quations alg{\'{e}}briques ordinaires, il y a lieu d'ap-peler ainsi ceux pour lesquels le nombre des conditions est pr{\'{e}}cis{\'{e}}-ment {\'{e}}gal au nombre des inconnues. (1) Communication faite {\`{a}} la Soci{\'{e}}t{\'{e}} fran{\c{c}}aise de Physique, s{\'{e}}ance du 16},
author = {Hadamard, M},
doi = {10.1051/jphystap:019070060020200>},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadamard - 1907 - Les probl{\`{e}}mes aux limites dans la th{\'{e}}orie des {\'{e}}quations aux d{\'{e}}riv{\'{e}}es partielles.pdf:pdf},
journal = {J. Phys. Theor. Appl},
number = {1},
pages = {202--241},
title = {{Les probl{\`{e}}mes aux limites dans la th{\'{e}}orie des {\'{e}}quations aux d{\'{e}}riv{\'{e}}es partielles}},
url = {https://hal.archives-ouvertes.fr/jpa-00241199},
volume = {6},
year = {1907}
}
@phdthesis{Musy2010,
abstract = {Cette {\'{e}}tude a pour objet de montrer qu'il est possible de g{\'{e}}n{\'{e}}rer automatiquement des mod{\`{e}}les zonaux pour l'{\'{e}}tude du comportement thermique et a{\'{e}}raulique des b{\^{a}}timents. Les mod{\`{e}}les zonaux sont bas{\'{e}}s sur le partitionnement des pi{\`{e}}ces en un petit nombre de sous-volumes. Cette approche est interm{\'{e}}diaire entre celle des mod{\`{e}}les {\`{a}} un noeud (qui consid{\`{e}}rent que la temp{\'{e}}rature est homog{\`{e}}ne dans chaque pi{\`{e}}ce, et pour cette raison ne permettent pas de pr{\'{e}}dire le confort thermique dans une pi{\`{e}}ce) et celle des codes CFD (qui sont tr{\`{e}}s co{\^{u}}teux en temps de calcul). Pour atteindre notre objectif, nous avons reformul{\'{e}} le mod{\`{e}}le zonal. Ceci a consist{\'{e}} {\`{a}} regrouper les {\'{e}}quations de description du comportement du b{\^{a}}timent dans des sous-syst{\`{e}}mes d'{\'{e}}quations. Ce regroupement est calqu{\'{e}} sur le d{\'{e}}coupage spatial des pi{\`{e}}ces. Ainsi, les {\'{e}}quations de bilan et d'{\'{e}}tat appliqu{\'{e}}es {\`{a}} un sous-volumes forment les modules de la famille des « cellules » et celles de transfert entre deux sous-volumes forment les modules de la famille des « interfaces ». Ces familles sont constitu{\'{e}}es de plusieurs mod{\`{e}}les correspondant aux diff{\'{e}}rents types d'{\'{e}}coulement qui se d{\'{e}}veloppent dans les b{\^{a}}timents. Ceux-ci ont {\'{e}}t{\'{e}} traduits en objets SPARK, lesquels forment la biblioth{\`{e}}que de mod{\`{e}}les. Construire une simulation consiste {\`{a}} choisir les mod{\`{e}}les appropri{\'{e}}s pour d{\'{e}}crire les pi{\`{e}}ces et {\`{a}} les connecter. Cette derni{\`{e}}re {\'{e}}tape a {\'{e}}t{\'{e}} automatis{\'{e}}e, si bien qu'il ne reste plus {\`{a}} l'utilisateur qu'{\`{a}} donner le partitionnement et {\`{a}} choisir les mod{\`{e}}les qu'il d{\'{e}}sire impl{\'{e}}menter. Le syst{\`{e}}me d'{\'{e}}quations r{\'{e}}sultant est r{\'{e}}solu par le solveur de SPARK. Des r{\'{e}}sultats de simulations pour diff{\'{e}}rentes configurations d'{\'{e}}coulement dans des pi{\`{e}}ces sont pr{\'{e}}sent{\'{e}}s et compar{\'{e}}s {\`{a}} des donn{\'{e}}es exp{\'{e}}rimentales. Nous donnons {\'{e}}galement des exemples d'application de la m{\'{e}}thode zonale {\`{a}} l'{\'{e}}tude d'un groupe de deux pi{\`{e}}ces, d'un b{\^{a}}timent et d'une pi{\`{e}}ce de g{\'{e}}om{\'{e}}trie complexe.},
author = {Musy, Marjorie},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Musy - 2010 - G{\'{e}}n{\'{e}}ration automatique de mod{\`{e}}les zonaux pour l'{\'{e}}tude du comportement thermo - a{\'{e}}raulique des b{\^{a}}timents.pdf:pdf},
keywords = {Mod{\'{e}}lisation zonale,thermo-a{\'{e}}raulique},
mendeley-tags = {Mod{\'{e}}lisation zonale,thermo-a{\'{e}}raulique},
school = {Universit{\'{e}} de La Rochelle},
title = {{G{\'{e}}n{\'{e}}ration automatique de mod{\`{e}}les zonaux pour l'{\'{e}}tude du comportement thermo - a{\'{e}}raulique des b{\^{a}}timents}},
url = {https://tel.archives-ouvertes.fr/tel-00492772},
year = {2010}
}
@article{Ben-Alon2019,
author = {Ben-Alon, Lola and Loftness, Vivian and Harries, Kent A. and DiPietro, Gwen and Hameen, Erica Cochran},
doi = {10.1016/j.buildenv.2019.05.028},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0360132319303464-main.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Cob,Earthen building materials,Eco-efficiency,Embodied energy,Environmental impacts,LCA,Sensitivity analysis,earthen building materials},
number = {May},
pages = {106150},
publisher = {Elsevier},
title = {{Cradle to site Life Cycle Assessment (LCA) of natural vs conventional building materials: A case study on cob earthen material}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360132319303464},
volume = {160},
year = {2019}
}
@techreport{Madsen2015,
author = {Madsen, Henrik and Bacher, Peder and Bauwens, Geert and Deconinck, An-Heleen and Reynders, Glenn and Roels, Staf and Himpe, Eline and Leth{\'{e}}, Guillaume},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madsen et al. - 2015 - Thermal Performance Characterization using Time Series Data -IEA EBC Annex 58 Guidelines Thermal performance c(2).pdf:pdf},
institution = {IEA EBC Annex 58},
keywords = {An-Heleen,Bacher,Bauwens,Deconinck,Eline,Geert,Glenn,Guillaume,Himpe,Leth{\'{e}},Peder,Reynders,Roels,Staf},
title = {{Thermal performance characterization using time series data - statistical guidelines}},
url = {http://orbit.dtu.dk/files/127709087/guidelines{\_}IEA58{\_}statisticalModelling{\_}2016{\_}11{\_}28.pdf},
year = {2016}
}
@article{Xu2007,
abstract = {Simple and effective building energy models are essentially needed for many applications, such as building performance diagnosis and optimal control, etc. The energy model involves two important parts of building components, i.e., building envelopes and building internal mass. This paper presents a methodology for parameter optimization of 3R2C thermal network model of building envelopes (composed of three resistances and two capacitances) based on frequency domain regression using genetic algorithm (GA). First, the theoretical frequency characteristics of heat transfer through building envelope are calculated using detailed physical description within the frequency range of concern. Second, the frequency characteristics of the simplified 3R2C model are calculated with random values of individual resistances and capacitances which constrain to total thermal resistance and capacitance. Then, the errors between the theoretical frequency characteristics and the frequency characteristics of the simplified model are calculated. Finally, GA estimator is developed to optimize the parameters of the simplified model, allowing the frequency responses of the simplified model match the actual heat transfer through building envelope the best. Various case studies are conducted also to validate the parameter optimization method of the simplified 3R2C model. The accuracy of simplified models for constructions of different weights is studied. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Xu, Xinhua and Wang, Shengwei},
doi = {10.1016/j.enbuild.2006.06.010},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778806002283-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Frequency domain regression,Genetic algorithm,Parameter optimization,Simplified thermal model},
number = {5},
pages = {525--536},
title = {{Optimal simplified thermal models of building envelope based on frequency domain regression using genetic algorithm}},
volume = {39},
year = {2007}
}
@book{Abadie2016,
annote = {Livre dispo {\`{a}} la biblioth{\`{e}}que de l'IUT},
author = {Abadie, Marc and Bastide, Alain and Bennacer, Rachid and Bozonnet, Emmanuel and Brangeon, Boris and Brun, Adrien and Cinquin-Lapierre, Benjamin and Durand-Est{\`{e}}be, Baptiste and Foucquier, Aur{\'{e}}lie and Fraisse, Gilles and Goffart, Jeanne and Guiavarch, Alain and Kuznik, Fr{\'{e}}d{\'{e}}ric and Lapisa, Remon and Lopez, J{\'{e}}r{\^{o}}me and M{\'{e}}n{\'{e}}zo, Christophe and Mora, Laurent and Munaretto, Fabio and Musy, Marjorie and P{\'{e}}nicaud, Hubert and P{\'{e}}rier, R{\'{e}}mi and Peuportier, Bruno and Plantier, Christophe and Recht, Thomas and Roux, Jean-Jacques and Ruellan, Marie and Salagnac, Patrick and Schalbart, Patrick and Serodio, Eduardo and Spitz, Clara and Sutter, Yannick and Thiers, St{\'{e}}phane and Tittelein, Pierre and Vorger, Eric and Woloszyn, Monika and Wurtz, Etienne and Wurtz, Fr{\'{e}}d{\'{e}}ric},
isbn = {978},
title = {{Energ{\'{e}}tique des b{\^{a}}timents et simulation thermique}},
year = {2016}
}
@article{Acerbi2014,
abstract = {Bayesian observer models are very effective in describing human performance in perceptual tasks, so much so that they are trusted to faithfully recover hidden mental representations of priors, likelihoods, or loss functions from the data. However, the intrinsic degeneracy of the Bayesian framework, as multiple combinations of elements can yield empirically indistinguishable results, prompts the question of model identifiability. We propose a novel framework for a systematic testing of the identifiability of a significant class of Bayesian observer models, with practical applications for improving experimental design. We examine the theoretical identifiability of the inferred internal representations in two case studies. First, we show which experimental designs work better to remove the underlying degeneracy in a time interval estimation task. Second, we find that the reconstructed representations in a speed perception task under a slow-speed prior are fairly robust.},
author = {Acerbi, Luigi and Ma, Wei Ji and Vijayakumar, Sethu},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/2014 Acerbi Ma Vijayakumar.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {1026--1034},
title = {{A framework for testing identifiability of Bayesian models of perception}},
volume = {2},
year = {2014}
}
@phdthesis{Raillon2018b,
author = {Raillon, Lo{\"{i}}c},
file = {:home/sarah/Dropbox/These/Sources/A classer/PhD{\_}thesis{\_}Loic{\_}RAILLON.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/A classer/PhD{\_}thesis{\_}Loic{\_}RAILLON.pdf:pdf},
keywords = {Batch and sequential identification,Dynamic thermal models,Error propagation,Frequentist and Bayesian framework,Identifiability of grey box models,Model transformation,Sensibility analysis},
pages = {177},
school = {Universit{\'{e}} de Lyon},
title = {{Experimental Identification of Physical Thermal Models for Demand Response and Performance Evaluation}},
year = {2018}
}
@article{Hubert2006a,
abstract = {Lie group theory states that knowledge of a {\$}m{\$}-parameters solvable group of symmetries of a system of ordinary differential equations allows to reduce by {\$}m{\$} the number of equation. We apply this principle by finding dilatations and translations that are Lie point symmetries of considered ordinary differential system. By rewriting original problem in an invariant coordinates set for these symmetries, one can reduce the involved number of parameters. This process is classically call nondimensionalisation in dimensional analysis. We present an algorithm based on this standpoint and show that its arithmetic complexity is polynomial in input's size.},
archivePrefix = {arXiv},
arxivId = {cs/0604060},
author = {Hubert, {\'{E}}velyne and Sedoglavic, Alexandre},
eprint = {0604060},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubert, Sedoglavic - 2006 - Polynomial Time Nondimensionalisation of Ordinary Differential Equations via their Lie Point Symmetries.pdf:pdf},
month = {apr},
primaryClass = {cs},
title = {{Polynomial Time Nondimensionalisation of Ordinary Differential Equations via their Lie Point Symmetries}},
url = {http://www.lifl.fr/{~}sedoglav/Load/HubertSedoglavic2006.pdf http://arxiv.org/abs/cs/0604060},
year = {2006}
}
@inproceedings{Pang2019,
address = {Rome},
author = {Pang, Zhihong and O'Neill, Zheng},
booktitle = {Proceedings of the International Building Performance Simulation Association Vol. 16},
file = {:home/sarah/OneDrive/Travail/Sources/IBPSA2019/BS2019{\_}134{\_}5{\_}210209{\_}Pang{\_}2019-06-25{\_}20-51{\_}a.pdf:pdf},
publisher = {International Building Performance Association (IBPSA)},
title = {{A comparison study of various sensitivity analysis methods in building applications}},
year = {2019}
}
@article{Makowski2019,
author = {Makowski, Dominique and Ben-Shachar, Mattan and L{\"{u}}decke, Daniel},
doi = {10.21105/joss.01541},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/10.21105.joss.01541.pdf:pdf},
journal = {Journal of Open Source Software},
number = {40},
pages = {1541},
title = {{bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework}},
volume = {4},
year = {2019}
}
@techreport{Miles-shenton2010,
author = {Miles-shenton, Dominic and Bell, Malcolm},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miles-shenton, Bell - 2010 - Whole House Heat Loss Test Method ( Coheating ).pdf:pdf},
title = {{Whole House Heat Loss Test Method ( Coheating )}},
year = {2010}
}
@article{Andersen2013a,
abstract = {This paper addresses the difficulties in pinpointing reasons for unexpectedly high energy consumption in construction, and in low-energy houses especially. Statistical methods are applied to improve the insight into the energy performance and heat dynamics of a building based on consumption records and weather data. Dynamical methods separate influences from outdoor temperature, solar radiation, and wind on the energy consumption in the building. The studied building is a low-energy house in Sisimiut, Greenland. Weather conditions like large temperature differences between indoors and outdoors throughout long winters, strong winds, and very different circumstances regarding solar radiation compared to areas where low-energy houses are usually built, make the location very interesting for modeling and testing purposes. In 2011 new measurement equipment was installed in the house, which will be used to develop more detailed models of the heat dynamics and energy performance in relation to different meteorological variables, heating systems, and user behavior. This type of models is known as a graybox model and is been introduced in this paper.},
author = {Andersen, Philip Delff and Rode, Carsten and Madsen, Henrik},
doi = {10.1016/j.foar.2013.08.003},
file = {:home/sarah/OneDrive/Travail/Sources/an-arctic-low-energy-house-as-experimental-setup-for-studies-of-heat-dynamics-of-buildings.pdf:pdf},
issn = {20952635},
journal = {Frontiers of Architectural Research},
keywords = {Arctic climate,Graybox modeling,Heat dynamics,Low-energy houses,Statistical modeling},
month = {dec},
number = {4},
pages = {488--499},
publisher = {Elsevier},
title = {{An arctic low-energy house as experimental setup for studies of heat dynamics of buildings}},
url = {http://dx.doi.org/10.1016/j.foar.2013.08.003 https://linkinghub.elsevier.com/retrieve/pii/S2095263513000484},
volume = {2},
year = {2013}
}
@article{Fernandez2018,
abstract = {{\textcopyright} 2018 International Building Performance Simulation Association (IBPSA). In this paper, two different methodologies are applied to the parameter estimation problem of a computational model of a Round-Robin test box. The numerical model is developed using TRNSYS. A global sensitivity analysis is carried out to determine the most important parameters that should be considered in the subsequent calibration procedure. Using the Bayesian (probabilistic) approach, the posterior distribution of the unknown input parameters is estimated via simulation techniques. Using the deterministic approach, executed in GenOpt, the calibration is performed by the minimization of an objective function that measures the differences between model predictions and real measured data. Parameter estimation results obtained with both methodologies are then compared and discussed. A reduction of the Coefficient of Variation of the Root Mean Square Error (CV (RMSE)) after calibration over 40{\%} with both methods has been obtained, being the CV (RMSE) for calibration and validation periods on average 3.21{\%} and 2.40{\%}, respectively.},
author = {Fern{\'{a}}ndez, Marta and Conde, Borja and Egu{\'{i}}a, Pablo and Granada, Enrique},
doi = {10.1080/19401493.2017.1420824},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/10{\_}002.pdf:pdf},
issn = {19401507},
journal = {Journal of Building Performance Simulation},
keywords = {Bayesian inference,Model calibration,Optimization,Round-Robin test box},
number = {6},
pages = {623--638},
title = {{Parameter identification of a round-robin test box model using a deterministic and probabilistic methodology}},
volume = {11},
year = {2018}
}
@article{Booth2013,
abstract = {Owners of housing stocks require reliable and flexible tools to assess the impact of retrofits technologies. Bottom-up engineering-based housing stock models can help to serve such a function. These models require calibrating, using micro-level energy measurements at the building level, to improve model accuracy; however, the only publicly available data for the UK housing stock is at the macro-level, at the district, urban, or national scale. This paper outlines a method for using macro-level data to calibrate micro-level models. A hierarchical framework is proposed, utilizing a combination of regression analysis and Bayesian inference. The result is a Bayesian regression method that generates estimates of the average energy use for different dwelling types whilst quantifying uncertainty in both the empirical data and the generated energy estimates. Finally, the Bayesian regression method is validated and the use of the hierarchical Bayesian calibration framework is demonstrated. Owners of housing stocks require reliable and flexible tools to assess the impact of retrofits technologies. Bottom-up engineering-based housing stock models can help to serve such a function. These models require calibrating, using micro-level energy measurements at the building level, to improve model accuracy; however, the only publicly available data for the UK housing stock is at the macro-level, at the district, urban, or national scale. This paper outlines a method for using macro-level data to calibrate micro-level models. A hierarchical framework is proposed, utilizing a combination of regression analysis and Bayesian inference. The result is a Bayesian regression method that generates estimates of the average energy use for different dwelling types whilst quantifying uncertainty in both the empirical data and the generated energy estimates. Finally, the Bayesian regression method is validated and the use of the hierarchical Bayesian calibration framework is demonstrated.},
author = {Booth, A.T. and Choudhary, Ruchi and Spiegelhalter, David J.},
doi = {10.1080/19401493.2012.723750},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Booth, Choudhary, Spiegelhalter - 2013 - A hierarchical Bayesian framework for calibrating micro-level models with macro-level data.pdf:pdf},
isbn = {1940-1493},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {Bayesian,bayesian,calibration,housing stock,regression,retrofit,uncertainty},
number = {4},
pages = {293--318},
title = {{A hierarchical Bayesian framework for calibrating micro-level models with macro-level data}},
url = {http://www-tandfonline.com.ezproxy.uow.edu.au/doi/full/10.1080/19401493.2012.723750{\#}abstract{\%}5Cnhttp://dx.doi.org/10.1080/19401493.2012.723750{\%}5Cnhttp://www.tandfonline.com/doi/abs/10.1080/19401493.2012.723750},
volume = {6},
year = {2013}
}
@article{Madsen1995,
abstract = {This paper describes a method for estimation of continuous-time models for the heat dynamics of buildings based on discrete-time building performance data. The parameters in the continuous-time model are estimated by the maximum likelihood method where a Kalman filter is used in calculating the likelihood function. The modeling procedure is illustrated by using measurements from an experiment where the heat input from electrical heaters is controlled by a pseudorandom binary signal. For the considered building a rather simple model containing two time constants is found adequate. Owing to the continuous-time formulation the parameters of the model are directly physically interpretable. The performance of the model for both forecasting and simulation is illustrated.},
author = {Madsen, Henrik and Holst, J},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madsen, Hoist - 1995 - Estimation of continuous-time models for the heat dynamics of a building.pdf:pdf},
journal = {Energy and Buildings},
pages = {67--79},
publisher = {ELSEVIER},
title = {{Estimation of continuous-time models for the heat dynamics of a building}},
url = {http://henrikmadsen.org/wp-content/uploads/2014/05/Journal{\_}article{\_}-{\_}1995{\_}-{\_}Estimation{\_}of{\_}continuous-time{\_}models{\_}for{\_}the{\_}heat{\_}dynamics{\_}of{\_}a{\_}building.pdf},
volume = {22},
year = {1995}
}
@article{Maillet2011a,
author = {Maillet, Denis and Sablier, Michel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillet, Sablier - 2011 - Probl{\`{e}}mes inverses en diffusion thermique - Formulation et r{\'{e}}solution du probl{\`{e}}me des moindres carr{\'{e}}s.pdf:pdf},
isbn = {7200103624},
title = {{Probl{\`{e}}mes inverses en diffusion thermique - Formulation et r{\'{e}}solution du probl{\`{e}}me des moindres carr{\'{e}}s}},
year = {2011}
}
@article{Haario2001,
abstract = {A proper choice of a proposal distribution for Markov chain Monte Carlo methods, for example for the Metropolis±Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis (AM) algorithm, where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis±Hastings algorithms, and demonstrate that the AM algorithm is easy to use in practical computation.},
annote = {Justification de l'utilisation de l'Adaptive Metropolis
On met {\`{a}} jour la probabilit{\'{e}} a priori tous les x steps pour am{\'{e}}liorer la convergence.
Pas un processus markovien car certaines d{\'{e}}pendance aux pas pr{\'{e}}c{\'{e}}dents {\`{a}} cause de mise {\`{a}} jour!
Mais les propri{\'{e}}t{\'{e}}s de convergence sont maitenues},
author = {Haario, Heikki and Saksman, Eero and Tamminen, Johanna},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haario, Saksman, Tamminen - 2001 - An adaptive Metropolis algorithm.pdf:pdf},
journal = {Bernoulli},
title = {{An adaptive Metropolis algorithm}},
url = {https://projecteuclid.org/download/pdf{\_}1/euclid.bj/1080222083},
year = {2001}
}
@misc{Tarantola1987,
abstract = {The book provides an up-to-date description of the methods used for fitting experimental data, or to estimate model parameters, and to unify these methods into the Inverse Problem Theory. The first part of the book deals with problems and describes Maximum likelihood, Monte Carlo, Least squares, and Least absolute values methods. The second part deals with inverse problems involving functions. Theoretical concepts are emphasized, and the author has all the useful formulas listed, with many special cases included. The book serves as a reference manual.},
author = {Tarantola, Albert},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarantola - 1987 - Inverse problem theory Methods for data fitting and model parameter estimation.pdf:pdf},
isbn = {0-444-42765-1},
keywords = {COMPUTI,DISCRETE ORDINATE METHOD,DOCUMENT TYPES,FUNCTIONS,GENERAL AND MISCELLANEOUS//MATHEMATICS,LEAST SQUARE FIT,MATHEMATICAL MODELS,MATHEMATICS,MAXIMUM-LIKELIHOOD FIT,MONTE CARLO METHOD,NUMERICAL SOLUTION,REVIEWS},
pages = {630},
title = {{Inverse problem theory: Methods for data fitting and model parameter estimation}},
year = {1987}
}
@techreport{Erkoreka2016,
author = {Erkoreka, Aitor and Gorse, Chris and Fletcher, Martin and Martin, Koldobika},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Erkoreka et al. - 2016 - Reliable building energy performance characterisation based on full scale dynamic measurements Report of Subtas.pdf:pdf},
isbn = {9789460189883},
title = {{Reliable building energy performance characterisation based on full scale dynamic measurements Report of Subtask 2: Logic and use of the Decision Tree for optimizing full scale dynamic testing}},
url = {http://www.kuleuven.be/bwf/projects/annex58/index.htm},
year = {2016}
}
@inproceedings{Deconinck2014,
abstract = {A more precise knowledge of the as - built thermal performance of our buildings ' fabric is of prime importance for the ongoing tendency to more stringent building performance demands . The methods that are commonly used for on - site thermal characterisation , such as the average method and linear regression technique , are based on stationary boundary conditions . As the latter are never encountered on site in practice , the methods ' validity depends on outdoor weather conditions . This paper examines the practical applicability of different in - situ thermal characterisation methods based on simulated data for an insulated cavity wall . Common semi - stationary methods are compared with a more advanced dynamical data analysis method , giving special attention to the reliability of the methods ' estimation results when confronted with data sets of limited measurement time spans and different measurement periods throughout the year . From this research , it can be stated that the use of semi - stationary methods for the characterisation of an insulated south - faced cavity wall can lead to accurate results in realistic measurement time spans when applied during winter months . The methods become less reliable when the temperature difference across the wall decreases . The dynamic method showed to be less sensible to the measurement period , provides more accurate results and needs shorter measurement time spans . The analysis itself however , showed to be more time consuming .},
author = {Deconinck, An-Heleen and Roels, Staf},
booktitle = {10th Nordic Symposium on Building Physics},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deconinck, Roels - 2014 - Comparative assessment of in - situ thermal characterisation techniques.pdf:pdf},
isbn = {978-91-88722-53-9},
keywords = {Building component testing,Dynamic data analysis,Full - scale testing,In - situ thermal characterisation,Thermal performance},
pages = {pp. 525--532},
title = {{Comparative assessment of in - situ thermal characterisation techniques}},
url = {https://www.researchgate.net/profile/An{\_}Heleen{\_}Deconinck/publication/306939900{\_}Comparative{\_}assessment{\_}of{\_}in{\_}-{\_}situ{\_}thermal{\_}characterisation{\_}techniques/links/581cab2308ae40da2cab2836.pdf?origin=publication{\_}detail},
year = {2014}
}
@article{Rouchier2018,
abstract = {Due to the ill-posedness of many inverse problems, parameter estimates are often prone to a possibly large uncertainty, caused by a series of errors and approximations in the experimental and modelling work. Stochastic state-space models for time series modelling incorporate a term of process noise that represents system error; most studies on building thermal model calibration however employ deterministic models that overlook this error. This paper investigates how accounting for modelling errors affects the results of model calibration. Several simplified models are defined to simulate the indoor temperature of an experimental test cell. Some models include process noise and others do not. The parameters of each model are then learned repeatedly by using several training datasets from the test cell. The MCMC algorithm is used for training. The robustness of parameter estimates between independent trainings is evaluated. Then, the forecasting ability of the deterministic and stochastic options are compared, in terms of accuracy and robustness. Results show that stochastic modelling considerably increases the uncertainty of parameter estimates, but ensures their consistency between separate trainings, whereas deterministic models are less robust and offer a less reliable forecasting.},
author = {Rouchier, Simon and Rabouille, Micka{\"{e}}l and Oberl{\'{e}}, Pierre},
doi = {10.1016/j.buildenv.2018.02.043},
file = {:home/sarah/OneDrive/Travail/Sources/Rouchier.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Calibration,Kalman filter,MCMC,Uncertainty},
month = {apr},
number = {February},
pages = {181--190},
publisher = {Elsevier},
title = {{Calibration of simplified building energy models for parameter estimation and forecasting: Stochastic versus deterministic modelling}},
url = {https://doi.org/10.1016/j.buildenv.2018.02.043 https://linkinghub.elsevier.com/retrieve/pii/S036013231830115X},
volume = {134},
year = {2018}
}
@article{Chong2019,
author = {Chong, Adrian and Xu, Weili and Chao, Song and Ngo, Ngoc-Tri},
doi = {10.1016/j.enbuild.2019.04.017},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chong et al. - 2019 - Continuous-time Bayesian calibration of energy models using BIM and energy data.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,building information models (BIM),continuous calibration,energy simulation,green building XML (gbXML),uncertainty analysis},
publisher = {Elsevier B.V.},
title = {{Continuous-time Bayesian calibration of energy models using BIM and energy data}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818339094},
year = {2019}
}
@article{Gu2017,
abstract = {We consider the problem of calibrating inexact computer models using experimental data. To compensate for the misspecification of the computer model, a discrepancy function is usually included and modeled via a Gaussian stochastic process (GaSP), leading to better results of prediction. The calibration parameters in the computer model, however, sometimes become unidentifiable in the GaSP model, and the calibrated computer model fits the experimental data poorly as a consequence. In this work, we propose the scaled Gaussian stochastic process (S-GaSP), a novel stochastic process for calibration and prediction. This new approach bridges the gap between two predominant methods, namely the {\$}L{\_}2{\$} calibration and GaSP calibration. A computationally feasible approach is introduced for this new model under the Bayesian paradigm. The S-GaSP model not only provides a general framework for calibration, but also enables the computer model to predict well regardless of the discrepancy function. Numerical examples are also provided to illustrate the connections and differences between this new model and other previous approaches.},
archivePrefix = {arXiv},
arxivId = {1707.08215},
author = {Gu, Mengyang and Wang, Long},
eprint = {1707.08215},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Wang - 2017 - An improved approach to Bayesian computer model calibration and prediction.pdf:pdf},
keywords = {Discrepancy function,Interpretability,Model misspecification,Scaled Gaussian stochastic process},
month = {jul},
title = {{An improved approach to Bayesian computer model calibration and prediction}},
url = {https://arxiv.org/pdf/1707.08215.pdf http://arxiv.org/abs/1707.08215},
year = {2017}
}
@article{Tabares-Velasco2011,
abstract = {Verification and validation are crucial in developing and implementing models. Although there are standards to test energy simulation software, this article describes an additional set of eight test cases that are a combination of analytical cases and numerical cases for solid conduction heat transfer. These tests focus on diagnosing and verifying conductive heat transfer algorithms and boundary conditions in building envelopes or fabrics. As an example, EnergyPlus versions 5, 6 and 7 are tested using these eight test cases. The test cases were useful for detecting several bugs in the code. The authors recommend these test cases as useful complements to existing verification test cases for building envelopes. {\textcopyright} 2012 Copyright Taylor and Francis Group, LLC.},
author = {Tabares-Velasco, Paulo Cesar and Griffith, Brent},
doi = {10.1080/19401493.2011.595501},
file = {:home/sarah/OneDrive/Travail/Sources/Diagnostic test cases for verifying surface heat transfer algorithms and boundary conditions in building energy simulation programs.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {accuracy,building energy modelling,quality control,simulation,validation,verification},
month = {sep},
number = {5},
pages = {329--346},
title = {{Diagnostic test cases for verifying surface heat transfer algorithms and boundary conditions in building energy simulation programs}},
url = {http://www.tandfonline.com/doi/abs/10.1080/19401493.2011.595501},
volume = {5},
year = {2012}
}
@article{Sedoglavic2002b,
abstract = {The following questions are often encountered in system and control theory. Given an algebraic model of a physical process, which variables can be, in theory, deduced from the input–output behaviour of an experiment? How many of the remaining variables should we assume to be known in order to determine all the others? These questions are parts of the local algebraic observability problem which is concerned with the existence of a non-trivial Lie subalgebra of model's symmetries letting the inputs and the outputs be invariant. We present a probabilistic seminumerical algorithm that proposes a solution to this problem in polynomial time. A bound for the necessary number of arithmetic operations on the rational field is presented. This bound is polynomial in the complexity of evalua- tion of the model and in the number of variables. Furthermore, we show that the size of the integers involved in the computations is polynomial in the number of variables and in the degree of the system. Last, we estimate the probability of success of our algorithm.},
archivePrefix = {arXiv},
arxivId = {math/0010045},
author = {Sedoglavic, Alexandre},
doi = {10.1006/jsco.2002.0532},
eprint = {0010045},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedoglavic - 2002 - A Probabilistic Algorithm to Test Local Algebraic Observability in Polynomial Time.pdf:pdf},
isbn = {1581134177},
issn = {07477171},
journal = {Journal of Symbolic Computation},
keywords = {12h05,2000,93a30,93b07,93b40,local algebraic identifiability,local algebraic observability,mathematics subject classification,seminumerical algorithm},
month = {may},
number = {5},
pages = {735--755},
primaryClass = {math},
title = {{A Probabilistic Algorithm to Test Local Algebraic Observability in Polynomial Time}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747717102905328 https://linkinghub.elsevier.com/retrieve/pii/S0747717102905328},
volume = {33},
year = {2002}
}
@article{Kavetski2006,
abstract = {Parameter estimation in rainfall-runoff models is affected by uncertainties in the measured input/output data (typically, rainfall and runoff, respectively), as well as model error. Despite advances in data collection and model construction, we expect input uncertainty to be particularly significant (because of the high spatial and temporal variability of precipitation) and to remain considerable in the foreseeable future. Ignoring this uncertainty compromises hydrological modeling, potentially yielding biased and misleading results. This paper develops a Bayesian total error analysis methodology for hydrological models that allows (indeed, requires) the modeler to directly and transparently incorporate, test, and refine existing understanding of all sources of data uncertainty in a specific application, including both rainfall and runoff uncertainties. The methodology employs additional (latent) variables to filter out the input corruption given the model hypothesis and the observed data. In this study, the input uncertainty is assumed to be multiplicative Gaussian and independent for each storm, but the general framework allows alternative uncertainty models. Several ways of incorporating vague prior knowledge of input corruption are discussed, contrasting Gaussian and inverse gamma assumptions; the latter method avoids degeneracies in the objective function. Although the general methodology is computationally intensive because of the additional latent variables, a range of modern numerical methods, particularly Monte Carlo analysis combined with fast Newton-type optimization methods and Hessian-based covariance analysis, can be employed to obtain practical solutions. Copyright 2006 by the American Geophysical Union.},
author = {Kavetski, Dmitri and Kuczera, George and Franks, Stewart W.},
doi = {10.1029/2005WR004368},
file = {:home/sarah/OneDrive/Travail/Sources/Kavetski{\_}et{\_}al-2006-Water{\_}Resources{\_}Research.pdf:pdf},
issn = {00431397},
journal = {Water Resources Research},
keywords = {http://dx.doi.org/10.1029/2005WR004368, doi:10.102,runoff models},
number = {3},
pages = {1--9},
title = {{Bayesian analysis of input uncertainty in hydrological modeling: 1. Theory}},
volume = {42},
year = {2006}
}
@article{MohajerinEsfahani,
abstract = {In data-driven inverse optimization an observer aims to learn the preferences of an agent who solves a parametric optimization problem depending on an exogenous signal. Thus, the observer seeks the agent's objective function that best explains a historical sequence of signals and corresponding optimal actions. We focus here on situations where the observer has imperfect information, that is, where the agent's true objective function is not contained in the search space of candidate objectives, where the agent suffers from bounded rationality or implementation errors, or where the observed signal-response pairs are corrupted by measurement noise. We formalize this inverse optimization problem as a distributionally robust program minimizing the worst-case risk that the {\{}$\backslash$em predicted{\}} decision ({\{}$\backslash$em i.e.{\}}, the decision implied by a particular candidate objective) differs from the agent's {\{}$\backslash$em actual{\}} response to a random signal. We show that our framework offers rigorous out-of-sample guarantees for different loss functions used to measure prediction errors and that the emerging inverse optimization problems can be exactly reformulated as (or safely approximated by) tractable convex programs when a new suboptimality loss function is used. We show through extensive numerical tests that the proposed distributionally robust approach to inverse optimization attains often better out-of-sample performance than the state-of-the-art approaches.},
author = {{Mohajerin Esfahani}, Peyman and Shafieezadeh-Abadeh, Soroosh and Hanasusanto, Grani A and Kuhn, Daniel},
doi = {10.1007/s10107-017-1216-6},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohajerin Esfahani et al. - Unknown - Data-driven Inverse Optimization with Imperfect Information.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {90C25 Convex programming,90C47 Minimax problems,C15 Stochastic programming},
number = {1},
pages = {191--234},
title = {{Data-driven inverse optimization with imperfect information}},
url = {https://pdfs.semanticscholar.org/b27d/f630a4f69c16f68f5d906fbadc39ec5fe52a.pdf},
volume = {167},
year = {2018}
}
@article{Vogt2018,
author = {Vogt, Marcus and Remmen, Peter and Lauster, Moritz and Fuchs, Marcus and M{\"{u}}ller, Dirk},
doi = {10.1016/j.buildenv.2018.07.052},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vogt et al. - 2018 - Selecting statistical indices for calibrating building energy models.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Automated model calibration,Dynamic building energy simulation,Measured energy data,Non-residential sector,Statistical indices,dynamic building energy simulation},
month = {oct},
number = {August},
pages = {94--107},
publisher = {Elsevier},
title = {{Selecting statistical indices for calibrating building energy models}},
url = {https://doi.org/10.1016/j.buildenv.2018.07.052 https://linkinghub.elsevier.com/retrieve/pii/S0360132318304608},
volume = {144},
year = {2018}
}
@article{Ramallo-Gonzalez2018,
abstract = {{\textcopyright} 2017 International Building Performance Simulation Association (IBPSA). The reduction of energy use in buildings is a major component of greenhouse gas mitigation policy and requires knowledge of the fabric and the occupant behaviour. Hence there has been a longstanding desire to use automatic means to identify these. Smart metres and the internet-of-things have the potential to do this. This paper describes a study where the ability of inverse modelling to identify building parameters is evaluated for 6 monitored real and 1000 simulated buildings. It was found that low-order models provide good estimates of heat transfer coefficients and internal temperatures if heating, electricity use and CO 2 concentration are measured during the winter period. This implies that the method could be used with a small number of cheap sensors and enable the accurate assessment of buildings' thermal properties, and therefore the impact of any suggested retrofit. This has the potential to be transformative for the energy efficiency industry.},
author = {Ramallo-Gonz{\'{a}}lez, Alfonso P. and Brown, Matthew and Gabe-Thomas, Elizabeth and Lovett, Tom and Coley, David A.},
doi = {10.1080/19401493.2016.1273390},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/preprint{\_}final{\_}all{\_}2.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {energy efficiency,inverse modelling,lumped parameter model,smart metre},
month = {jan},
number = {1},
pages = {65--83},
title = {{The reliability of inverse modelling for the wide scale characterization of the thermal properties of buildings}},
url = {https://www.tandfonline.com/doi/full/10.1080/19401493.2016.1273390},
volume = {11},
year = {2018}
}
@article{DeWilde2019,
author = {de Wilde, Pieter},
doi = {10.1016/j.buildenv.2019.02.019},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Wilde - 2019 - Ten questions concerning building performance analysis.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
month = {feb},
publisher = {Elsevier Ltd},
title = {{Ten questions concerning building performance analysis}},
url = {https://doi.org/10.1016/j.buildenv.2019.02.019 https://linkinghub.elsevier.com/retrieve/pii/S0360132319301222},
year = {2019}
}
@article{Houssineau2019,
abstract = {Learning the model parameters of a multiobject dynamical system from partial and perturbed observations is a challenging task. Despite recent numerical advancements in learning these parameters, theoretical guarantees are extremely scarce. In this article we aim to help fill this gap and study the identifiability of the model parameters and the consistency of the corresponding maximum likelihood estimate (MLE) under assumptions on the different components of the underlying multi-object system. In order to understand the impact of the various sources of observation noise on the ability to learn the model parameters, we study the asymptotic variance of the MLE through the associated Fisher information matrix. For example, we show that specific aspects of the multitarget tracking (MTT) problem such as detection failures and unknown data association lead to a loss of information which is quantified in special cases of interest. To the best of the authors' knowledge, these are new theoretically backed insights on the subtleties of MTT parameter learning.},
author = {Houssineau, Jeremie and Singh, Sumeetpal S and Jasra, Ajay},
doi = {10.1137/17m113873x},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Houssineau, Singh, Jasra - Unknown - IDENTIFICATION OF MULTI-OBJECT DYNAMICAL SYSTEMS CONSISTENCY AND FISHER INFORMATION.pdf:pdf},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
keywords = {62B10,Consistency,Identifiability},
number = {4},
pages = {2603--2627},
title = {{Identification of MultiObject Dynamical Systems: Consistency and Fisher Information}},
url = {https://arxiv.org/pdf/1707.04371.pdf},
volume = {57},
year = {2019}
}
@article{Mbalawata2013,
author = {Mbalawata and S{\"{a}}rkk{\"{a}}, Simo and Haario, Heikki},
journal = {Computational Statistics},
title = {{Parameter estimation in stochas- tic differential equations with Markov chain Monte Carlo and non-linear Kalman filtering}},
year = {2013}
}
@article{Royapoor2015,
abstract = {A large number of randomly interacting variables combine to dictate the energy performance of a building. Building energy simulation models attempt to capture these perturbations as accurately as possible. The prediction accuracy of building energy models can now be better examined given the widespread availability of environmental and energy monitoring equipment and reduced data storage costs. In this paper a set of two calibrated environmental sensors together with a weather station are deployed in a 5-storey office building to examine the accuracy of an EnergyPlus virtual building model. Using American Society of Heating, Refrigerating and Air-Conditioning Engineers (ASHRAE) Guide 14 indices the model was calibrated to achieve Mean Bias Error (MBE) values within ±5{\%} and Cumulative Variation of Root Mean Square Error (CV(RMSE)) values below 10{\%}. The calibrated EnergyPlus model was able to predict annual hourly space air temperatures with an accuracy of ±1.5 °C for 99.5{\%} and an accuracy of ±1 °C for 93.2{\%} of the time.},
author = {Royapoor, Mohammad and Roskilly, Tony},
doi = {10.1016/j.enbuild.2015.02.050},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778815001553-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building performance simulation,Case study building,Energy,Hourly data,Local weather data,Measured energy data,Model calibration,Plus,Sensor deployment},
pages = {109--120},
publisher = {Elsevier B.V.},
title = {{Building model calibration using energy and environmental data}},
url = {http://dx.doi.org/10.1016/j.enbuild.2015.02.050},
volume = {94},
year = {2015}
}
@book{Idier,
author = {Idier, J{\'{e}}r{\^{o}}me and Demoment, Guy and Goussard, Yves and {Le Besnerais}, Guy and Giovannelli, Jean-Fran{\c{c}}ois and Champagnat, Fr{\'{e}}d{\'{e}}ric and Gautier, St{\'{e}}phane and Blanc-F{\'{e}}raud, Laure and Descombes, Xavier and Mugnier, Laurent and Meimon, Serge and Herment, Alain and Mohammad-Djafari, Ali and Dinten, Jean-Marc and Carfantan, Herv{\'{e}} and Sauer, Ken and Thibault, Jean-Baptiste},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Idier et al. - Unknown - Bayesian Approach to Inverse Problems.pdf:pdf},
isbn = {9781848210325},
title = {{Bayesian Approach to Inverse Problems}}
}
@article{Hengl2007,
author = {Hengl, S and Kreutz, Clemens and Timmer, Jens and Maiwald, T},
doi = {10.1093/bioinformatics/btm382},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hengl et al. - 2007 - Systems biology Data-based identifiability analysis of non-linear dynamical models.pdf:pdf},
number = {19},
pages = {2612--2618},
title = {{Systems biology Data-based identifiability analysis of non-linear dynamical models}},
volume = {23},
year = {2007}
}
@article{Sun2015,
author = {Sun, Yuming and Su, Heng and Wu, C.F. Jeff and Augenbroe, Godfried},
doi = {10.1080/19401493.2014.914247},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2015 - Quantification of model form uncertainty in the calculation of solar diffuse irradiation on inclined surfaces for bu.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
month = {jul},
number = {4},
pages = {253--265},
title = {{Quantification of model form uncertainty in the calculation of solar diffuse irradiation on inclined surfaces for building energy simulation}},
url = {http://www.tandfonline.com/doi/abs/10.1080/19401493.2014.914247},
volume = {8},
year = {2015}
}
@article{Clairon2018,
abstract = {We address the problem of parameter estimation for partially observed linear Ordinary Dif-ferential Equations. Estimation from time series with standard estimators can give misleading results because estimation is often ill-posed, or the models are misspecified. The addition of a forcing function u, that represents uncertainties in the original ODE, can overcome these problems as shown in [Clairon and Brunel, 2017]. A general regularized estimation procedure is derived, that corresponds to an Optimal Control Problem (OCP) solved by the Pontryagin Maximum Principle for nonlinear ODEs. Here, we focus on the linear case and solve the OCP with a computationally fast deterministic Kalman filter which allows weakening of conditions needed for √ n−consistency. A significant improvement is the avoidance of the estimation of initial conditions thanks to a profiling step. Consequently, we can deal with more elaborated penalties and also provide a profiled semiparametric estimation procedure in the case of time-varying parameters. Simulations and real data examples show that our approach is generally more accurate and more reliable than reference methods when the Fisher information matrix is badly-conditioned, with noticeable improvement in the case of model misspecification.},
author = {Clairon, Quentin and Brunel, Nicolas J-B},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clairon, Brunel - 2018 - Tracking for Parameter and State Estimation in Possibly Misspecified Partially Observed Linear Ordinary Diff(2).pdf:pdf},
keywords = {Filtering,M-estimation,Optimal Control,Profiling,Riccati Equation},
title = {{Tracking for Parameter and State Estimation in Possibly Misspecified Partially Observed Linear Ordinary Differential Equations Optimal control for statistical inference in ordinary differential equations View project Mathematical models in running science}},
url = {https://www.researchgate.net/publication/324780530},
year = {2018}
}
@article{Tarvainen2010,
abstract = {See, stats, and : https : // www . researchgate . net / publication/ 231099302 Approximation compensating radiative. . . Article DOI : 10 . 1088 / 0266 - 5611 / 26 / 1 / 015005 CITATIONS 42 READS 44 7 , including : Some : Structure - From - Motion Electrical Tanja University 71 , 024 SEE Ville University 117 , 583 SEE Marko University 155 , 844 SEE Jari University 277 , 017 SEE All . The . All - text and , letting . Abstract In this paper , we investigate the applicability of the Bayesian approximation error approach to compensate for the discrepancy of the diffusion approximation in diffuse optical tomography close to the light sources and in weakly scattering subdomains . While the approximation error approach has earlier been shown to be a feasible approach to compensating for discretization errors , uncertain boundary data and geometry , the ability of the approach to recover from using a qualitatively incorrect physical model has not been contested . In the case of weakly scattering subdomains and close to sources , the radiative transfer equation is commonly considered to be the most accurate model for light scattering in turbid media . In this paper , we construct the approximation error statistics based on predictions of the radiative transfer and diffusion models . In addition , we investigate the combined approximation errors due to using the diffusion approximation and using a very low - dimensional approximation in the forward problem . We show that recovery is feasible in the sense that with the approximation error model the reconstructions with a low - dimensional diffusion approximation are essentially as good as with using a very high - dimensional radiative transfer model .},
author = {Tarvainen, T and Kolehmainen, V and Pulkkinen, A and Vauhkonen, M and Schweiger, M and Arridge, S R and Kaipio, Jari P.},
doi = {10.1088/0266-5611/26/1/015005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarvainen et al. - 2010 - An approximation error approach for compensating for modelling errors between the radiative transfer equation.pdf:pdf},
issn = {0266-5611},
journal = {Inverse Problems},
month = {jan},
number = {1},
pages = {015005},
title = {{An approximation error approach for compensating for modelling errors between the radiative transfer equation and the diffusion approximation in diffuse optical tomography}},
url = {https://www.researchgate.net/profile/Jari{\_}Kaipio/publication/231099302{\_}Approximation{\_}error{\_}approach{\_}for{\_}compensating{\_}modelling{\_}errors{\_}between{\_}the{\_}radiative{\_}transfer{\_}equation{\_}and{\_}the{\_}diffusion{\_}approximation{\_}in{\_}diffuse{\_}optical{\_}tomography/links/55f1bf2508ae1},
volume = {26},
year = {2010}
}
@article{Farmer2017a,
abstract = {The methodology used for measuring the thermal performance of fabric retrofit systems which were applied to a solid wall UK Victorian house situated within an environmental chamber is explored in detail. The work describes how steady-state boundary conditions were approximated, then repeated at the Salford Energy House test facility. How established methods of measuring the fabric thermal performance of buildings in situ were adapted to test the effectiveness of retrofit measures within a steady-state environment. The results presented show that steady-state boundary conditions enable the change in fabric heat loss resulting from the retrofit of a whole house or individual element to be measured to a level of accuracy and precision that is unlikely to be achieved in the field. The test environment enabled identification of heat loss phenomena difficult to detect in the field. However, undertaking tests in an environment devoid of wind underestimates the potential reduction in ventilation heat loss resulting from an improvement in airtightness, and hides the susceptibility of retrofit measures to various heat loss mechanisms, such as wind washing. The strengths and weaknesses of the methods employed, the Energy House test facility, and a steady-state environment, for characterising retrofit building fabric thermal performance are demonstrated.},
author = {Farmer, David and Gorse, Chris and Swan, William and Fitton, Richard and Brooke-Peat, Matthew and Miles-Shenton, Dominic and Johnston, David},
doi = {10.1016/j.enbuild.2017.09.086},
file = {:home/sarah/Dropbox/These/Sources/A classer/Farmer{\%}20et{\%}20al{\%}20{\%}282017{\%}29{\%}20Energy{\%}20House{\%}20Phase{\%}201{\%}20E{\%}26B{\%}20FINALdocx.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/A classer/Farmer{\%}20et{\%}20al{\%}20{\%}282017{\%}29{\%}20Energy{\%}20House{\%}20Phase{\%}201{\%}20E{\%}26B{\%}20FINALdocx.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Airtightness,Building performance evaluation,Full-scale test facility,Heat loss coefficient,Heat transfer coefficient,Insulation,Performance gap,Retrofit,Salford Energy House,Solid-wall,Steady-state,Thermal bypass,Thermal insulation,Thermal performance,Thermal transmittance,U-value,Wind-washing},
month = {dec},
pages = {404--414},
title = {{Measuring thermal performance in steady-state conditions at each stage of a full fabric retrofit to a solid wall dwelling}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778817311581},
volume = {156},
year = {2017}
}
@techreport{ASHRAE2001,
author = {ASHRAE},
institution = {Atlanta: ASHRAE},
title = {{International Weather for Energy Calculations (IWEC Weather Files) Users Manual and CD-ROM}},
year = {2001}
}
@article{Andersen2000,
abstract = {This paper describes the continuous time modelling of the heat dynamics of a building. The considered building is a residential like test house divided into two test rooms with a water based central heating. Each test room is divided into thermal zones in order to describe both short and long term variations. Besides modelling the heat transfer between thermal zones, attention is put on modelling the heat input from radiators and solar radiation. The applied modelling procedure is based on collected building performance data and statistical methods. The statistical methods are used in parameter estimation and model validation, while physical knowledge is used in forming the model structure. The suggested lumped parameter model is thus based on thermodynamics and formulated as a system of stochastic differential equations. Due to the continuous time formulation the parameters of the model are directly physical interpretable. Finally, the prediction and simulation performance of the model is illustrated.},
author = {Andersen, Klaus Kaae and Madsen, Henrik and Hansen, Lars H.},
doi = {10.1016/S0378-7788(98)00069-3},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778898000693-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {heat dynamics,ml method,parameter estimation,stochastic differential equations},
number = {1},
pages = {13--24},
title = {{Modelling the heat dynamics of a building using stochastic differential equations}},
volume = {31},
year = {2000}
}
@article{Rabl1988,
abstract = {Dynamic analysis of energy data can help improve the efficiency of buildings in several ways: evaluation of proposed modifications of a building or its operation (e.g., changes in thermostate setpoints); verification of performance on the basis of short-term measurements (corrected for weather); diagnostics and optimal control of HVAC equipment (real-time comparison of actual and predicted performance can be a powerful diagnostic tool). For this purpose one would like a simple building model whose parameters can readily be adjusted by a statistical fit to the data. This paper reviews the available methods: thermal networks, modal analysis, differential equations, ARMA (autoregressive moving average) models, Fourier series, and calibrated computer simulations. The basic models can be applied in several ways, differing in choice of dependent variable, number of coefficients, statistical criterion, time step, finite differencing scheme, and implementation as linear or nonlinear algorithm. The relation between the various approaches is examined. It is shown how the results of each of these methods can be presented in a standardized format that maximizes their physical interpretation, in terms of time constants and admittances (including heat loss coefficient and solar aperture). A general proof is given that the effective heat capacity equals the heat loss coefficient multiplied by a sum of time constants. The methods are tested with data from an office building. Special attention is focused on difficulties, due to air exchange or solar gains, that are likely to arise in practice.},
author = {Rabl, A.},
doi = {10.1115/1.3268237},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabl - 1988 - Parameter Estimation in Buildings Methods for Dynamic Analysis of Measured Energy Use.pdf:pdf},
issn = {01996231},
journal = {Journal of Solar Energy Engineering},
keywords = {Algorithms,Black-box,Computer simulation,Differential equations,Dynamic analysis,Energy consumption,Fourier series,HVAC equipment,Heat capacity,Heat losses,Measurement,Networks,Optimal control,Parameter estimation,Solar energy,Structures},
mendeley-tags = {Black-box},
number = {1},
pages = {52},
publisher = {American Society of Mechanical Engineers},
title = {{Parameter Estimation in Buildings: Methods for Dynamic Analysis of Measured Energy Use}},
url = {http://solarenergyengineering.asmedigitalcollection.asme.org/article.aspx?articleid=1454756},
volume = {110},
year = {1988}
}
@article{Kreutz2019,
abstract = {Insufficient performance of optimization approaches for fitting of mathematical models is still a major bottleneck in systems biology. In this manuscript, the reasons and methodological challenges are summarized as well as their impact in benchmark studies. Important aspects for increasing evidence of outcomes of benchmark analyses are discussed. Based on general guidelines for benchmarking in computational biology, a collection of tailored guidelines is presented for performing informative and unbiased benchmarking of optimization-based fitting approaches. Comprehensive benchmark studies based on these recommendations are urgently required for establishing of a robust and reliable methodology for the systems biology community.},
archivePrefix = {arXiv},
arxivId = {1907.03427},
author = {Kreutz, Clemens},
eprint = {1907.03427},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1907.03427.pdf:pdf},
journal = {arXiv preprint},
month = {jul},
pages = {1--13},
title = {{Guidelines for benchmarking of optimization approaches for fitting mathematical models}},
url = {http://arxiv.org/abs/1907.03427},
year = {2019}
}
@article{Herman2017,
author = {Herman, Jon and Usher, Will},
doi = {10.21105/joss.00097},
issn = {2475-9066},
journal = {The Journal of Open Source Software},
month = {jan},
number = {9},
pages = {97},
title = {{SALib: An open-source Python library for Sensitivity Analysis}},
url = {http://joss.theoj.org/papers/10.21105/joss.00097},
volume = {2},
year = {2017}
}
@phdthesis{Thebault2017a,
abstract = {Dans un contexte d'{\'{e}}conomie d'{\'{e}}nergie et de r{\'{e}}duction des {\'{e}}missions de gaz {\`{a}} effet de serre, de nombreux efforts ont {\'{e}}t{\'{e}} r{\'{e}}alis{\'{e}}s en France pour renforcer l'isolation de l'enveloppe des b{\^{a}}timents afin de contribuer {\`{a}} r{\'{e}}duire les consommations de chauffage. Toutefois, il arrive souvent que pour diverses raisons la performance thermique calcul{\'{e}}e avant construction ou r{\'{e}}novation ne soit pas atteinte sur le terrain (erreur de calcul, d{\'{e}}fauts de mise en {\oe}uvre, isolant non conforme, etc.). Or, pour pouvoir g{\'{e}}n{\'{e}}raliser la construction de b{\^{a}}timents {\`{a}} basse consommation et la r{\'{e}}novation, il faut pouvoir garantir aux ma{\^{i}}tres d'ouvrage une performance r{\'{e}}elle de leur b{\^{a}}timent apr{\`{e}}s travaux. Le fait de mesurer in situ la performance intrins{\`{e}}que d'isolation thermique de l'enveloppe permet de contribuer {\`{a}} cette garantie. Il existe {\`{a}} l'{\'{e}}chelle internationale de nombreuses m{\'{e}}thodes bas{\'{e}}es sur le suivi des consom- mations et des conditions thermiques int{\'{e}}rieures et ext{\'{e}}rieures. Certaines ont d{\'{e}}j{\`{a}} fait leurs preuves sur le terrain, mais sont souvent soit contraignantes, soit peu pr{\'{e}}cises. Et surtout, les calculs d'incertitude associ{\'{e}}s sont souvent rudimentaires. L'objectif de ce travail financ{\'{e}} par le CSTB est de consolider scientifiquement une nou- velle m{\'{e}}thode de mesure de la qualit{\'{e}} d'isolation globale d'un b{\^{a}}timent {\`{a}} r{\'{e}}ception des travaux (m{\'{e}}thode ISABELE). Dans le premier chapitre, un {\'{e}}tat de l'art sur les m{\'{e}}thodes existantes a {\'{e}}t{\'{e}} r{\'{e}}alis{\'{e}} afin de d{\'{e}}gager des pistes d'am{\'{e}}lioration sur la base d'une synth{\`{e}}se comparative. La piste prioritaire identifi{\'{e}}e porte sur le calcul d'incertitude (qui est un point central du probl{\`{e}}me). La propagation des erreurs al{\'{e}}atoires par un approche bay{\'{e}}sienne ainsi que la propagation des erreurs syst{\'{e}}matiques par une approche plus classique feront l'objet de la m{\'{e}}thodologie globale propos{\'{e}}e dans le second chapitre. L'une des importantes sources d'incertitude porte sur l'{\'{e}}valuation du d{\'{e}}bit d'infiltra- tion au cours du test. La caract{\'{e}}risation de cette incertitude et de l'impact sur le r{\'{e}}sultat de mesure fera l'objet du troisi{\`{e}}me chapitre, avec un comparatif de diff{\'{e}}rentes approches exp{\'{e}}rimentales (r{\`{e}}gle du pouce, mod{\`{e}}les a{\'{e}}rauliques, gaz traceur). Enfin, une am{\'{e}}lioration de la prise en compte de la dynamique thermique du b{\^{a}}timent au cours du test sera propos{\'{e}}e dans le dernier chapitre. Son fondement repose sur l'adapta- tion du mod{\`{e}}le thermique inverse en fonction du b{\^{a}}timent et des conditions du test. Pour cela, une s{\'{e}}lection parmi une banque de mod{\`{e}}les simplifi{\'{e}}s est r{\'{e}}alis{\'{e}}e sur la base de crit{\`{e}}res statistiques et du principe de parcimonie. Ces diff{\'{e}}rentes dispositions ont {\'{e}}t{\'{e}} test{\'{e}}s sur une large s{\'{e}}rie de mesures men{\'{e}}es sur un m{\^{e}}me b{\^{a}}timent {\`{a}} ossature bois (chalet OPTIMOB). La robustesse et la pr{\'{e}}cision du r{\'{e}}sultat de mesure ont ainsi pu {\^{e}}tre l{\'{e}}g{\`{e}}rement am{\'{e}}lior{\'{e}}es. La m{\'{e}}thode de calcul du d{\'{e}}bit d'infiltration, ni trop simple ni trop complexe, a pu {\'{e}}galement {\^{e}}tre valid{\'{e}}e. Enfin, un ordre d'id{\'{e}}e plus pr{\'{e}}cis du temps de mesure minimal n{\'{e}}cessaire a pu {\^{e}}tre d{\'{e}}termin{\'{e}} en fonction de la classe d'inertie du b{\^{a}}timent.},
author = {Th{\'{e}}bault, Simon},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thebault - 2017 - Contribution {\`{a}} l'{\'{e}}valuation in situ des performances d'isolation thermique de l'enveloppe des b{\^{a}}timents.pdf:pdf},
pages = {236--237},
school = {Universit{\'{e}} de Lyon},
title = {{Contribution {\`{a}} l'{\'{e}}valuation in situ des performances d'isolation thermique de l'enveloppe des b{\^{a}}timents}},
year = {2017}
}
@article{Gori2018a,
abstract = {Robust characterisation of the thermal performance of buildings from in-situ measurements requires error analysis to evaluate the certainty of estimates. A method for the quantification of systematic errors on the thermophysical properties of buildings obtained using dynamic grey-box methods is presented, and compared to error estimates from the average method. Different error propagation methods (accounting for equipment uncertainties) were introduced to reflect the different mathematical description of heat transfer in the static and dynamic approaches. Thermophysical properties and their associated errors were investigated using two case studies monitored long term. The analysis showed that the dynamic method (and in particular a three thermal resistance and two thermal mass model) reduced the systematic error compared to the static method, even for periods of low internal-to-external average temperature difference. It was also shown that the use of a uniform error as suggested in the ISO 9869-1:2014 Standard would generally be misrepresentative. The study highlighted that dynamic methods for the analysis of in-situ measurements may provide robust characterisation of the thermophysical behaviour of buildings and extend their application beyond the winter season in temperate climates (e.g., for quality assurance and informed decision making purposes) in support of closing the performance gap.},
author = {Gori, Virginia and Elwell, Clifford A.},
doi = {10.1016/j.enbuild.2018.02.048},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gori, Elwell - 2018 - Estimation of thermophysical properties from in-situ measurements in all seasons quantifying and reducing error(2).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian statistics,Error quantification,Grey-box methods,Heat transfer,In-situ measurements,Inverse modelling,U-value,Uncertainty analysis},
pages = {290--300},
publisher = {Elsevier B.V.},
title = {{Estimation of thermophysical properties from in-situ measurements in all seasons: Quantifying and reducing errors using dynamic grey-box methods}},
url = {https://doi.org/10.1016/j.enbuild.2018.02.048 https://ac.els-cdn.com/S0378778817334990/1-s2.0-S0378778817334990-main.pdf?{\_}tid=85fa72ce-054f-4901-befa-2d0ad99bd84f{\&}acdnat=1522761832{\_}8b39bf0abaad1b8534972d461f54644f http://linkinghub.elsevier.com/retrieve/p},
volume = {167},
year = {2018}
}
@techreport{Butler2013,
author = {Butler, David and Dengel, Andy},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Butler, Dengel - 2013 - Review of co-heating test methodologies.pdf:pdf},
institution = {NHBC Foundation},
isbn = {9781848063518},
keywords = {Co-heating},
mendeley-tags = {Co-heating},
pages = {56},
title = {{Review of co-heating test methodologies}},
year = {2013}
}
@incollection{Sedoglavic2007a,
address = {Berlin, Heidelberg},
annote = {Pour {\'{e}}tudier les sym{\'{e}}tries dans le mod{\`{e}}le et travailler sur le mod{\`{e}}le.},
author = {Sedoglavic, Alexandre},
booktitle = {Algebraic Biology},
doi = {10.1007/978-3-540-73433-8_20},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedoglavic - 2007 - Reduction of Algebraic Parametric Systems by Rectification of Their Affine Expanded Lie Symmetries.pdf:pdf},
pages = {277--291},
publisher = {Springer Berlin Heidelberg},
title = {{Reduction of Algebraic Parametric Systems by Rectification of Their Affine Expanded Lie Symmetries}},
url = {https://hal.inria.fr/inria-00120991 http://link.springer.com/10.1007/978-3-540-73433-8{\_}20},
volume = {4545},
year = {2007}
}
@article{Bauwens2017,
abstract = {Worldwide, the building sector represents the largest energy using sector, and it is still expanding. To reduce energy use of buildings, policy makers are increasingly demanding with regard to energy efficiency of buildings. Despite best planning effort, in practice some of these demands are not met: studies reveal that a building's energy performance on the design table might differ substantially from its performance when actually built. Typically, an important reason for this difference lies in the delivered quality of a building's insulating envelope. In this paper, we investigate the characterisation of the overall heat loss coefficient, H, in WK-1, of whole building envelopes on the basis of dedicated heating experiments performed on vacant houses. We focus on steady-state heating experiments performed on buildings that are either terraced or semi-detached and have a floor on ground or unventilated basement. We depart from an extended stationary heat balance, that in addition to heat exchanges between indoor and outdoor environments, also explicitly includes heat exchanges between indoor environment and conditioned neighbouring zones. The first is of interest as it characterizes H, the latter is of interest as it constitutes a phenomenon that is often ignored, but might corrupt the estimate of H significantly. We show that, for the test buildings considered in this paper, it is advisable to additionally measure heat flows towards neighbouring properties. On the basis of three test cases, we investigate the significance of such heat flows, as well as their influence on the accuracy and robustness of the estimated heat transfer coefficient, H.},
author = {Bauwens, Geert and Roels, Staf},
doi = {10.1016/j.egypro.2017.09.744},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauwens, Roels - 2017 - On site thermal performance characterization of building envelopes How important are heat exchanges with neighbo.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Heat transfer coefficient,co-heating test,heat flux,thermal performance},
month = {oct},
pages = {339--344},
publisher = {Elsevier B.V.},
title = {{On site thermal performance characterization of building envelopes: How important are heat exchanges with neighbouring zones}},
url = {https://doi.org/10.1016/j.egypro.2017.09.744 https://linkinghub.elsevier.com/retrieve/pii/S1876610217348956},
volume = {132},
year = {2017}
}
@article{Arendt2012,
abstract = {To use predictive models in engineering design of physical systems, one should first quantify the model uncertainty via model updating techniques employing both simulation and experimental data. While calibration is often used to tune unknown calibration parameters of the computer model, the addition of a discrepancy function has been used to capture model discrepancy due to underlying missing physics, numerical approximations, and other inaccuracies of the computer model that would exist even if all calibration parameters are known. One of the main challenges in model updating is the difficulty in distinguishing between the effects of calibration parameters versus model discrepancy. We illustrate this identifiability problem with several examples, explain the mechanisms behind it, and attempt to shed light on when a system may or may not be identifiable. In some instances, identifiability is achievable under mild assumptions, whereas in other instances it is virtually impossible. In a companion paper, we demonstrate that using page 2 multiple responses, each of which depends on a common set of calibration parameters, can substantially enhance identifiability.},
author = {Arendt, Paul D and Apley, Daniel W and Chen, Wei and Lamb, David and Gorsich, David},
doi = {10.1115/1.4007573},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arendt et al. - 2012 - Quantification of Model Uncertainty Calibration, Model Discrepancy and Identifiability.pdf:pdf},
issn = {10500472},
journal = {Journal of Mechanical Design},
keywords = {Gaussian processes,Kriging,calibration,identifiability,model updating,uncertainty quantification},
number = {10},
pages = {40},
title = {{Quantification of Model Uncertainty : Calibration, Model Discrepancy and Identifiability}},
url = {http://ai2-s2-pdfs.s3.amazonaws.com/85c1/2fd992a8028b6a69410ef49490624e27aba4.pdf http://mechanicaldesign.asmedigitalcollection.asme.org/article.aspx?articleid=1484831},
volume = {134},
year = {2012}
}
@article{Gelman2017a,
abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeffreys' priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
archivePrefix = {arXiv},
arxivId = {1708.07487},
author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
doi = {10.3390/e19100555},
eprint = {1708.07487},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman, Simpson, Betancourt - 2017 - The prior can generally only be understood in the context of the likelihood.pdf:pdf},
issn = {10994300},
journal = {Entropy},
keywords = {Bayesian inference,Default priors,Prior distribution},
month = {aug},
number = {10},
title = {{The prior can often only be understood in the context of the likelihood}},
url = {https://arxiv.org/pdf/1708.07487.pdf http://arxiv.org/abs/1708.07487},
volume = {19},
year = {2017}
}
@article{Rouchier2015a,
abstract = {This paper proposes the application of the covariance matrix adaptation (CMA) evolution strategy for the identification of building envelope materials hygrothermal properties. All material properties are estimated on the basis of local temperature and relative humidity measurements, by solving the inverse heat and moisture transfer problem. The applicability of the identification procedure is demonstrated in two stages: first, a numerical benchmark is developed and used as to show the potential identification accuracy, justify the choice for a Tikhonov regularization term in the fitness evaluation, and propose a method for its appropriate tuning. Then, the procedure is applied on the basis of experimental measurements from an instrumented test cell, and compared to the experimental characterization of the observed material. Results show that an accurate estimation of all hygrothermal properties of a building material is feasible, if the objective function of the inverse problem is carefully defined.},
annote = {L'objectif est de d{\'{e}}terminer les caract{\'{e}}ristiques hygrothermiques de mat{\'{e}}riaux in situ.
Les {\'{e}}quations physiques de transferts hygro-thermiques ont {\'{e}}t{\'{e}} explicit{\'{e}}es et r{\'{e}}solues par m{\'{e}}thode des {\'{e}}l{\'{e}}ments finis, discr{\'{e}}tis{\'{e}}s par la m{\'{e}}thode Galerkin (MWR). Pour acc{\'{e}}lerer la convergence de la r{\'{e}}solution, utilisation de la m{\'{e}}thode Newton-Raphson. Pour r{\'{e}}gulariser l'estimation des caract{\'{e}}ristiques hygro-t, on utilise le principe de Tikhonov ({\'{e}}q 3)
Dans ce probl{\`{e}}me, on ne peut pas exprimer la matrice jacobienne (de la m{\'{e}}thode de Newton) de mani{\`{e}}re analytique. On pourrait utiliser parall{\`{e}}lement l'algo de Levenberg-Macquardt, mais on opte plut{\^{o}}t pour uen r{\'{e}}solution m{\'{e}}taheuristique.
Covariance Matrix Adaptation Evolution Strategy (CMA-ES) : c'est un algorithme g{\'{e}}n{\'{e}}tique dont les param{\`{e}}tres intrins{\`{e}}ques peuvent varier pendant l'{\'{e}}volution
En CMA-ES, on cr{\'{e}}e une population lambda suivant une distribution normale dont la moyenne et la covariance ont {\'{e}}t{\'{e}} r{\'{e}}{\'{e}}valu{\'{e}}es {\`{a}} l'issue de l'it{\'{e}}ration pr{\'{e}}c{\'{e}}dente. On arr{\^{e}}te l'algo d{\`{e}}s que la covariance est tr{\`{e}}s inf{\'{e}}rieure {\`{a}} la moyenne.


L'algo a d'abord {\'{e}}t{\'{e}} test{\'{e}} sur un mod{\`{e}}le de r{\'{e}}f{\'{e}}rence num{\'{e}}rique (dont les donn{\'{e}}es sont obtenues par simulation sur des propri{\'{e}}t{\'{e}}s connues et recherch{\'{e}}es ensuite par l'algo).
Le mod{\`{e}}le de r{\'{e}}f{\'{e}}rence cr{\'{e}}e un set de donn{\'{e}}es virtuelles, auxquelles a {\'{e}}t{\'{e}} ajout{\'{e}} du bruit (gaussien).
L'algo de recherche essaie de retrouver les ppt{\'{e}}s du mat{\'{e}}riau, avec plusieurs valeurs de r{\'{e}}gularisation de Tikhonov alpha. Chaque r{\'{e}}sultat donne une estimation des ppt{\'{e}}s du mat{\'{e}}riau. On calcule l'erreur pour chaque alpha.
On trouve que dans ce probl{\`{e}}me-ci, alpha = 1 minimise l'erreur. On rel{\`{e}}ve que une ppt{\'{e}} sera d'autant plus facilement identifi{\'{e}} qu'elle a une grande influence sur la solution.
On observe (sans d{\'{e}}mo) d'apr{\`{e}}s le graphique qu'il y a une probable corr{\'{e}}lation n{\'{e}}g entre l'indice de sensibilit{\'{e}} des param{\`{e}}tres et l'erreur d'estimation.


L'application exp{\'{e}}rimentale se fait sur la cellule Passys (HYGROBAT).
Instrumentation intrusive sur une paroi connue (mat{\'{e}}riau unique)
Sur le cas exp{\'{e}}rimental, alpha = 100 (il faut donc chercher ce param de Tikhonov {\`{a}} chaque cas)
La m{\'{e}}thode permet de d{\'{e}}terminer une valeur des param{\`{e}}tres. Les simulations obtenues par ces estimations des param{\`{e}}tres est moins bonne qu'avec les param obtenus sans la r{\'{e}}gularisation. (c-{\`{a}}-d on va vers un mod{\`{e}}le bo{\^{i}}te noire, qui pourra servir {\`{a}} la pr{\'{e}}diction, mais pas {\`{a}} l'identifiabilit{\'{e}})
Mais la pr{\'{e}}cision obtenue sur les valeurs des param{\`{e}}tres individuellement est bien meilleure.
M{\^{e}}me des param{\`{e}}tres ayant une grande influence ont {\'{e}}t{\'{e}} mal identifi{\'{e}}s sans la r{\'{e}}gularisation.
Les ppt{\'{e}}s de sorption sont compl{\`{e}}tement mal identifi{\'{e}}es (valeurs n{\'{e}}gatives). Donc certes les simulations donnent des r{\'{e}}sultats probants mais l'identifiabilit{\'{e}} est nulle.
Derni{\`{e}}re partie : robustesse des r{\'{e}}sultats : on a relanc{\'{e}} l'algo sur diff{\'{e}}rentes quantit{\'{e}} de mesures. La r{\'{e}}p{\'{e}}tabilit{\'{e}} est satisfaisante. La position des capteurs a peu d'importance, leur nombre {\'{e}}galement (pourvu qu'on connaisse pr{\'{e}}cis{\'{e}}ment leur localisation).


Pour aller plus loin : pas de test sur des p{\'{e}}riodes de mesure moins longue ou plus longues.
Voir si on obtient de bons r{\'{e}}sultats sur parois multi-couches.
Pas de calcul rigoureux des intervalles de confiance des esimations. Pour cela il faudrait faire une {\'{e}}tude de la sensibilit{\'{e}}, fonction des incertitudes de mesures. L'algo g{\'{e}}n{\'{e}}tique oblige {\`{a}} faire ce calcul {\`{a}} part.
Solution, utiliser l'approche bay{\'{e}}sienne ({\'{e}}galement non gradiante) et comparer les deux r{\'{e}}sultats.},
author = {Rouchier, Simon and Woloszyn, Monika and Kedowide, Y and B{\'{e}}jat, T},
doi = {10.1080/19401493.2014.996608},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier et al. - 2015 - Identification of the hygrothermal properties of a building envelope material by the covariance matrix adaptati.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
number = {July 2015},
pages = {1--14},
title = {{Identification of the hygrothermal properties of a building envelope material by the covariance matrix adaptation evolution strategy}},
url = {http://www.tandfonline.com/doi/abs/10.1080/19401493.2014.996608},
year = {2015}
}
@article{Lin2012,
abstract = {There is significant recent interest in applying model-based control techniques to improve the energy efficiency of buildings. This requires a predictive model of the building's thermal dynamics. Due to the complexity of the underlying physical processes, usually system identification techniques are used to identify parameters of a physics-based model. We investigate the effect of various model structures and identification techniques on the parameter estimates through a combination of analysis and experiments conducted in a commercial building. We observe that a second order model can reproduce the input-output behavior of a full-scale model (with 13 states). Even a single state model has enough predictive ability that it may be sufficient for control purposes. We also show that the application of conventional techniques to closed-loop data from buildings (that are collected during usual operation) leads to poor estimates; their inaccuracy becomes apparent only when forced-response data is used for validation where there is sufficient difference among various inputs and outputs. The results of this investigation are expected to provide guidelines on do's and don'ts in modeling and identification of buildings for control.},
author = {Lin, Yashen and Middelkoop, Timothy and Barooah, Prabir},
doi = {10.1109/CDC.2012.6425958},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Middelkoop, Barooah - 2012 - Issues in identification of control-oriented thermal models of zones in multi-zone buildings.pdf:pdf},
isbn = {978-1-4673-2066-5},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
keywords = {Emerging control applications,Estimation,Identification for control},
pages = {6932--6937},
title = {{Issues in identification of control-oriented thermal models of zones in multi-zone buildings}},
year = {2012}
}
@article{Naveros2012,
abstract = {a b s t r a c t This work analyses the capabilities and limitations of the regression method based in averages applied to the thermal performance analysis of real size building components tested in dynamic outdoors weather conditions. This study aims to distinguish which of the problems observed in these methods are specifi-cally related to the regression average method such as the minimum integration period, and which are related to general aspects such as the minimum terms necessary in the energy balance equation which should also be solved in dynamic approaches. Integration periods from one to ten days have been con-sidered. A noticeable improvement was observed as the integration period was increased from one to five days. Larger integration periods did not show significant improvements. The influence on the energy balance equation of global solar radiation, longwave radiation and wind speed has been analysed. Sig-nificant improvements have been observed including wind speed. To isolate and highlight the effects of the different analysed aspects from the effects of other assumptions about the test component and its boundaries, a well-known fairly simple opaque wall was analysed to find its U value. Experimental data recorded in the south east of Spain for a total of one year have been used.},
author = {Naveros, I and Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Heras, M R},
doi = {10.1016/j.enbuild.2012.09.028},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naveros, Jim{\'{e}}nez, Heras - 2012 - Analysis of capabilities and limitations of the regression method based in averages, applied to the es.pdf:pdf},
journal = {Energy and Buildings},
keywords = {Building energy,Model selection,Outdoor testing,Performance indicators,System identification,Thermal parameters},
mendeley-tags = {Model selection},
pages = {854--872},
title = {{Analysis of capabilities and limitations of the regression method based in averages, applied to the estimation of the U value of building component tested in Mediterranean weather}},
url = {http://ac.els-cdn.com.camphrier-2.grenet.fr/S0378778812004811/1-s2.0-S0378778812004811-main.pdf?{\_}tid=53df9ee0-15f4-11e7-8976-00000aab0f6b{\&}acdnat=1490952658{\_}219a2c057b8317c7d99b421e6f213b32},
volume = {55},
year = {2012}
}
@misc{Gilks1996a,
abstract = {convince readers it is simple and has potential},
author = {Gilks, Walter R. and Richardson, Sylvia and Spiegelhalter, David J.},
booktitle = {Markov Chain Monte Carlo in Practice},
doi = {10.1007/978-1-4899-4485-6_1},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilks, Richardson, Spiegelhalter - 1996 - Introducing Markov Chain Monte Carlo.pdf:pdf},
isbn = {0412055511},
issn = {0849-6757},
pages = {512},
title = {{Introducing Markov Chain Monte Carlo}},
url = {http://link.springer.com/chapter/10.1007/978-1-4899-4485-6{\_}1},
year = {1996}
}
@article{Fennell2012,
abstract = {Building-Stock Energy Models (BSEMs) are emerging as a powerful tool for cities and regions seeking to reduce greenhouse gas emissions and mitigate the effects of changing climates for their populations. The potential influence of such model results coupled with the scale and complexity of the environments they aim to represent means it is essential to understand their limitations. This study undertakes a systematic review of the literature relating to such models and finds that in only a very small proportion of studies are model uncertainties even considered. This fundamental flaw is due to the computational demands of exploring the output space of such complex models. A more detailed assessment was then undertaken of the identified studies in which uncertainty analysis (UA) and sensitivity analysis (SA) had been applied to BSEMs. The adequacy of the applied methods is discussed, and recommendations proposed for the application of best practice techniques based on the underlying form of the model.},
author = {Fennell, Pamela J and Ruyssevelt, Paul A and Mata, {\'{E}}rika and Jakob, Martin},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/BS2019{\_}219{\_}1{\_}210478{\_}Fennell{\_}2019-07-15{\_}09-03{\_}a.pdf:pdf},
title = {{A Review of the Status of Uncertainty and Sensitivity Analysis in Building-stock Energy Models}},
year = {2012}
}
@article{Gevers2018,
author = {Gevers, Michel and Sanfelice, Alexandre},
doi = {10.1016/j.ifacol.2018.09.115},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevers, Sanfelice - 2018 - A practical method for the consistent identification of a module in a dynamical network.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
number = {15},
pages = {862--867},
publisher = {Elsevier B.V.},
title = {{A practical method for the consistent identification of a module in a dynamical network}},
url = {https://doi.org/10.1016/j.ifacol.2018.09.115},
volume = {51},
year = {2018}
}
@article{Menberg2016,
abstract = {a b s t r a c t Though sensitivity analysis has been widely applied in the context of building energy models (BEMs), there are few studies that investigate the performance of different sensitivity analysis methods in rela-tion to dynamic, high-order, non-linear behaviour and the level of uncertainty in building energy models. We scrutinise three distinctive sensitivity analysis methods: (a) the computationally efficient Morris method for parameter screening, (b) linear regression analysis (medium computational costs) and (c) Sobol method (high computational costs). It is revealed that the results from Morris method taking the commonly used measure for parameter influence can be unstable, while using the median value yields robust results for evaluations with small sample sizes. For the dominant parameters the results from all three sensitivity analysis methods are in very good agreement. Regarding the evaluation of parameter ranking or the differentiation of influential and negligible parameters, the computationally costly quan-titative methods provide the same information for the model in this study as the computational efficient Morris method using the median value. Exploring different methods to investigate higher-order effects and parameter interactions, reveals that correlation of elementary effects and parameter values in Morris method can also provide basic information about parameter interactions.},
author = {Menberg, Kathrin and Heo, Yeonsook and Choudhary, Ruchi},
doi = {10.1016/j.enbuild.2016.10.005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Menberg, Heo, Choudhary - 2016 - Sensitivity analysis methods for building energy models Comparing computational costs and extractable i.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building energy model,Morris method,Regression analysis,Sensitivity analysis,Sobol method},
month = {dec},
pages = {433--445},
title = {{Sensitivity analysis methods for building energy models: Comparing computational costs and extractable information}},
url = {http://ac.els-cdn.com/S0378778816311112/1-s2.0-S0378778816311112-main.pdf?{\_}tid=1e129770-8d65-11e7-a104-00000aab0f02{\&}acdnat=1504085289{\_}68c483945a478e422836b0319ee6f990 https://linkinghub.elsevier.com/retrieve/pii/S0378778816311112},
volume = {133},
year = {2016}
}
@article{Tuo2016,
abstract = {Calibration parameters in deterministic computer experiments are those attributes that cannot be measured or available in physical experiments. Kennedy and O'Hagan $\backslash$cite{\{}kennedy2001bayesian{\}} suggested an approach to estimate them by using data from physical experiments and computer simulations. A theoretical framework is given which allows us to study the issues of parameter identifiability and estimation. We define the {\$}L{\_}2{\$}-consistency for calibration as a justification for calibration methods. It is shown that a simplified version of the original KO method leads to asymptotically {\$}L{\_}2{\$}-inconsistent calibration. This {\$}L{\_}2{\$}-inconsistency can be remedied by modifying the original estimation procedure. A novel calibration method, called the {\$}L{\_}2{\$} calibration, is proposed and proven to be {\$}L{\_}2{\$}-consistent and enjoys optimal convergence rate. A numerical example and some mathematical analysis are used to illustrate the source of the {\$}L{\_}2{\$}-inconsistency problem.},
author = {Tuo, Rui and Wu, C. F.Jeff},
doi = {10.1137/151005841},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuo, Wu - Unknown - A THEORETICAL FRAMEWORK FOR CALIBRATION IN COMPUTER MODELS PARAMETRIZATION, ESTIMATION AND CONVERGENCE PROPERTIES.pdf:pdf},
issn = {21662525},
journal = {SIAM-ASA Journal on Uncertainty Quantification},
keywords = {Computer experiments,Gaussian process,Reproducing kernel Hilbert space,Uncertainty quantification},
number = {1},
pages = {767--795},
title = {{A theoretical framework for calibration in computer models: Parametrization, estimation and convergence properties}},
url = {http://www2.isye.gatech.edu/{~}jeffwu/publications/calibration-may1.pdf},
volume = {4},
year = {2016}
}
@article{Asadi2019,
abstract = {Multiple numbers of Building Energy Simulation (BES) programs have been improved and implemented during the last decades. BES models play a crucial role in understanding building energy demands and accelerating the malfunction diagnosis. However, due to the very high number of interacting parameters, most of the developed energy simulation programs do not accurately predict building energy performance under a known condition. Even the energy models which are developed with the very precise assignment of parameters, there is always significant discrepancies between the simulation results and the real-time data measurements. Current study develops an optimization-based framework to calibrate the whole building energy model. The optimization algorithm attempts to set the identified parameters to minimize the error between the simulation results and the real-time measurements. Due to the high number of parameters, the developed optimization algorithm utilizes a Harmony Search algorithm as its search engine coupled with the energy simulation model to accelerate the calibration process. Moreover, to illustrate the efficiency of using the developed framework, a case study of the office building is modeled and calibrated and the statistical analysis was conducted to assess the accuracy of the results. The results of the calibration process show the reliability of the framework.},
author = {Asadi, Somayeh and Mostavi, Ehsan and Boussaa, Djamel and Indaganti, Madhavi},
doi = {10.1016/j.enbuild.2019.06.001},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778819303330-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building energy performance,Energy model calibration,Harmony search optimization,Occupants' behavior,Optimization algorithm},
month = {jun},
publisher = {Elsevier B.V.},
title = {{Building Energy Model Calibration Using Automated Optimization-Based Algorithm}},
url = {https://www-sciencedirect-com.camphrier-1.grenet.fr/science/article/pii/S0378778819303330 https://linkinghub.elsevier.com/retrieve/pii/S0378778819303330 https://doi.org/10.1016/j.enbuild.2019.06.001},
year = {2019}
}
@misc{InternationalOrganizationforStandardization2017a,
author = {{International Organization for Standardization}},
title = {{Thermal performance of buildings - Heat transfer via the ground - Calculation methods}},
year = {2017}
}
@article{Schetelat2014,
annote = {Aller voir :
Boisson, P., {\&} Bouchi{\'{e}}, R. (2014). ISABELE method: In-Situ Assessment of the Building EnveLope pErformances. In 9th international conference on system simulation in buildings.
Bouchi{\'{e}}, R., Derouineau, S., Abele, C., {\&} Millet, J. R. (2014). Conception et validation d'un capteur de mesurage de la temperature exterieure equivalente d'une paroi opaque d'un batiment. In Conf{\'{e}}rence IBPSA France, Arras.


Deux notions dans la pr{\'{e}}cision de mesure : measurement trueness {\&} measurement precision
--{\textgreater} voir Joint committee for guides in metrology 212


Dans le cadre d'un probl{\`{e}}me inverse, les techniques habituelles de propagation de l'erreur ne sont pas applicables (ni erreur dans measurement trueness, ni dans precision)


Coackley et al 2012 : Il y a actuellement peu d'{\'{e}}tudes qui prennent en compte l'incertitude dans leurs entr{\'{e}}es de mod{\`{e}}les et pr{\'{e}}dictions, d'o{\`{u}} un manque de confiance dans leurs r{\'{e}}sultats.
L'auteur cite Heo et al 2012, incertitude analys{\'{e}}e par l'approche bay{\'{e}}sienne (utilisation des conso {\'{e}}nerg{\'{e}}tique mensuelle)


Efficacit{\'{e}} de l'approche bay{\'{e}}sienne voir : Forbes, A. B., {\&} Sousa, J. A. (2011). The GUM, Bayesian inference and the observation and measurement equations. Measurement, 44(8), 1422-1435.


MCMC sampling avec le Metropolis-Hastings algorithm

Mod{\`{e}}le RC utilis{\'{e}} : inspir{\'{e}} de la RT2012 --{\textgreater} 5R1C
Mesure de la temp{\'{e}}rature de masse {\'{e}}quivalente soit mesur{\'{e}}e soit extim{\'{e}}e. La temp{\'{e}}rature mesur{\'{e}}e est une mesure intrusive. Voir article Bouchi{\'{e}} 2014
air infiltration estim{\'{e}} par ThBCE


Ils ont l'air d'appliquer la m{\'{e}}thode inverse {\`{a}} une consigne en temp{\'{e}}rature {\`{a}} 24°C pendant 3 jours puis sans consigne pendant 4 jours.


Probl{\`{e}}me inverse ont la particularit{\'{e}} d'{\^{e}}tre tr{\`{e}}s d{\'{e}}pendant du choix du mod{\`{e}}le (confer identifiabilit{\'{e}})},
author = {Schetelat, Pascal and Bouchi{\'{e}}, R{\'{e}}mi},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schetelat, Bouchi{\'{e}} - 2014 - ISABELE a Method for Performance Assessment at Acceptance Stage using Bayesian Calibration.pdf:pdf},
journal = {9th International Conference on System Simulation in Buildings},
keywords = {bayesian},
number = {1},
pages = {1--16},
title = {{ISABELE : a Method for Performance Assessment at Acceptance Stage using Bayesian Calibration}},
volume = {1},
year = {2014}
}
@phdthesis{Richalet1991,
abstract = {L'etude des performances energetiques d'un batiment sur site peut etre envisagee par l'analyse de son comportement entrees/sorties, grace aux techniques d'identification. Une methode parametrique est retenue. Des travaux anterieurs conduisent a plusieurs formes mathematiques de representation dynamique (modale, arma ou rc) que nous comparons. Sous certaines hypotheses, il est possible egalement d'adopter un modele stationnaire, dit de signature energetique, dont l'interet est la reduction des moyens experimentaux. Une analyse, effectuee a partir d'un echantillon de donnees simulees et reelles, nous conduit a privilegier les methodes dynamiques pour lesquelles on peut envisager des durees de suivi courtes (de l'ordre de la semaine). Nous retenons pour la suite un modele d'etat modal, directement issu de la reduction de modele, qui permet de donner une signification physique a tous les parametres. Les risques de minimums locaux lies a l'utilisation d'une methode locale de calcul des parametres s'en trouvent diminues. Par une analyse de la surface d'erreur, nous calculons des intervalles de confiance sur les parametres, qui s'averent des outils efficaces pour deceler certains problemes relatifs aux donnees de la non stationnarite du modele liee au renouvellement d'air, et celui d'une configuration multizone du batiment. Avant de conclure, nous rappelons que la reussite de l'identification impose un minimum de contraintes au niveau de l'experimentation. La methodologie elaboree ici, par sa robustesse et sa simplicite d'utilisation, permet d'envisager des applications dans le domaine professionnel du batiment Consulter en biblioth{\`{e}}que},
annote = {BU Sciences
GRENOBLE
Magasin
TS91/INPG/0101/D


Pr{\^{e}}t {\`{a}} domicile
En rayon},
author = {Richalet, V{\'{e}}ronique},
title = {{Caract{\'{e}}risation {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents sur site : identification de mod{\`{e}}les dynamiques ; m{\'{e}}thodes de signature {\'{e}}neg{\'{e}}tique [i.e. {\'{e}}nerg{\'{e}}tique]}},
url = {http://rugbis.grenet.fr/F/56RRLC7M5L8ADESMCICA6N3C9JY6LEA5J3GX6C87F614TIQRTS-01472?func=item-global{\&}doc{\_}library=GRE01{\&}doc{\_}number=000036790{\&}year={\&}volume={\&}sub{\_}library=BUS},
year = {1991}
}
@article{Schoukens1994,
abstract = {Time domain identification of linear dynamic systems using discrete time models relies heavily on the use of piecewise constant excitation signals (ZOH-assumption). If this assumption is not met, severe errors can be generated and the results can be useless. In this article we study the implications of the ZOH-assumption and an alternative is formulated. This leads to frequency domain identification methods based on the band limited assumption (that the signals obey the Shannon sampling theory). The theory and practical aspects of both approaches are compared. Finally, it will be shown that periodic excitations (or perturbation signals) can offer significant advantages in both approaches. {\textcopyright} 1994.},
author = {Schoukens, J. and Pintelon, R. and {Van Hamme}, H.},
doi = {10.1016/0005-1098(94)90211-9},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/1-s2.0-0005109894902119-main.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {System identification,frequency domain,perturbation techniques,time domain},
number = {7},
pages = {1153--1169},
title = {{Identification of linear dynamic systems using piecewise constant excitations: Use, misuse and alternatives}},
volume = {30},
year = {1994}
}
@article{Sclove1987,
abstract = {A review of model-selection criteria is presented, with a view toward showing their similarities. It is suggested that some problems treated by sequences of hypothesis tests may be more expeditiously treated by the application of model-selection criteria. Consideration is given to application of model-selection criteria to some problems of multivariate analysis, especially the clustering of variables, factor analysis and, more generally, describing a complex of variables. {\textcopyright} 1987 The Psychometric Society.},
author = {Sclove, Stanley L.},
doi = {10.1007/BF02294360},
file = {:home/sarah/OneDrive/Travail/Sources/Sclove1987{\_}Article{\_}ApplicationOfModel-selectionCr.pdf:pdf},
issn = {00333123},
journal = {Psychometrika},
keywords = {AIC,Akaike's information criterion,Schwarz's,cluster analysis,clustering variables,criterion,factor analysis,model evaluation,model selection},
number = {3},
pages = {333--343},
title = {{Application of model-selection criteria to some problems in multivariate analysis}},
volume = {52},
year = {1987}
}
@article{Uriarte2019,
author = {Uriarte, Irati and Erkoreka, Aitor and Giraldo-Soto, Catalina and Martin, Koldo and Uriarte, Amaia and Eguia, Pablo},
doi = {10.1016/j.enbuild.2019.03.006},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Uriarte et al. - 2019 - PT US CR.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Average method,Building envelope energy performance,Energy monitoring,Heat Loss Coefficient (HLC)},
month = {jun},
pages = {101--122},
publisher = {Elsevier B.V.},
title = {{Mathematical development of an average method for estimating the reduction of the Heat Loss Coefficient of an energetically retrofitted occupied office building}},
url = {https://doi.org/10.1016/j.enbuild.2019.03.006 https://linkinghub.elsevier.com/retrieve/pii/S0378778818337587},
volume = {192},
year = {2019}
}
@article{Senave2019,
annote = {one at a time (DoE 2 parameters 2 positions)
4 scenarii, 4 ARX test{\'{e}}s},
author = {Senave, Marieline and Reynders, Glenn and Bacher, Peder and Roels, Staf and Verbeke, Stijn and Saelens, Dirk},
doi = {10.1016/j.enbuild.2019.05.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senave et al. - 2019 - Towards the Characterization of the Heat Loss Coefficient via On-Board Monitoring Physical Interpretation of ARX.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {ARX Modelling,Characterization,Heat Loss Coefficient,Physical Parameter Identification,Synthetic Monitoring Data},
month = {may},
publisher = {Elsevier B.V.},
title = {{Towards the Characterization of the Heat Loss Coefficient via On-Board Monitoring: Physical Interpretation of ARX Model Coefficients}},
url = {https://doi.org/10.1016/j.enbuild.2019.05.001 https://linkinghub.elsevier.com/retrieve/pii/S0378778819306565},
year = {2019}
}
@article{Andrade-Cabrera2017,
abstract = {a b s t r a c t Simulation-based building retrofit analysis tools and electricity grid expansion planning tools are not readily compatible. Their integration is required for the combined study of building retrofit measures and electrified heating technologies using low-carbon electricity generation. The direct coupling of these modelling frameworks requires the explicit mathematical representation of Energy Conservation Mea-sures (ECMs) in building-to-grid energy system models. The current paper introduces an automated calibration methodology which describes retrofitted buildings as parametric functions of ECMs. The buildings are represented using a lumped parameter modelling framework. A baseline model, repre-sentative of the building prior to retrofit, and the retrofit functions are calibrated using Particle Swarm Optimization. Synthetic temperature and heating load time-series data were generated using an Ener-gyPlus semi-detached house archetype model. The model is representative of this residential building category in Ireland. It is shown that the proposed methodology calibrates retrofitted building models to an acceptable level of accuracy (MAE below 0.5 • C). The methodologies introduced in the current paper are capable of generating lumped parameter building models with similar dynamics for different ECMs for any archetype building energy model. The identified building retrofit models have the potential to be integrated with electricity grid models in a computationally-efficient manner.},
author = {Andrade-Cabrera, Carlos and Burke, Daniel and Turner, William J.N. and Finn, Donal P},
doi = {10.1016/j.enbuild.2017.09.035},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrade-Cabrera et al. - 2017 - Ensemble Calibration of lumped parameter retrofit building models using Particle Swarm Optimization.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building model calibration,Building retrofit,Integrated analysis,Lumped parameter models,Particle Swarm Optimization},
month = {nov},
pages = {513--532},
title = {{Ensemble Calibration of lumped parameter retrofit building models using Particle Swarm Optimization}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0378778817302530/1-s2.0-S0378778817302530-main.pdf?{\_}tid=cae15ecc-b804-11e7-b93f-00000aab0f27{\&}acdnat=1508771818{\_}4df067867015cf89f30bf33ae821bb0c https://linkinghub.elsevier.com/retrieve/pii/S0378778817302530},
volume = {155},
year = {2017}
}
@article{Bellman,
abstract = {In this article we introduce a new concept, structural identifiability, which plays a central role in identification problems. The concept is useful when answering questions such as: To what extent is it possible to get insight into the internal structure of a system from input-output measurements? What experiments are necessary in order to determine the internal couplings uniquely? The definition of the concept of an identifiable structure is given. Criteria as well as certain identifiable structures are discussed. Particular emphasis is given to compartmental models. ?? 1970.},
annote = {From Duplicate 1 (On structural identifiability - Bellman, R.; {\AA}str{\"{o}}m, K.J.)

Premiers {\`{a}} parler de
Identifiability Structural},
author = {Bellman, R. and {\AA}str{\"{o}}m, K.J.},
doi = {10.1016/0025-5564(70)90132-X},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellman, {\AA}str{\"{o}}m - 1970 - On structural identifiability.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellman, Astr{\"{o}}m - Unknown - Bellman On structural identifiability.pdf.pdf:pdf},
isbn = {9781479956692},
issn = {00255564},
journal = {Mathematical Biosciences},
month = {apr},
number = {3-4},
pages = {329--339},
title = {{On structural identifiability}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002555647090132X https://linkinghub.elsevier.com/retrieve/pii/002555647090132X},
volume = {7},
year = {1970}
}
@article{Rouchier2017,
abstract = {Highlights • The paper is a review of the steps for solving and validating inverse problems in building physics. • Formulation and solving methodologies in a deterministic or stochastic etting • Parameter identifability analysis • Validation and diagnosis of the results of inverse problems • Model selection and optimal experiment design • A simple RC model is used as a running example to illustrate each chapter 1 ACCEPTED MANUSCRIPT Abstract Building physics researchers have benefitted from elements of statistical learning and time series analysis to improve their ability to construct knowledge from data. What is referred to here as inverse problems are actually a very broad field that encompasses any study where data is gathered and mined for information. The purpose of the present article is twofold. First, it is a tutorial on the formalism of inverse problems in building physics and the most common ways to solve them. Then, it provides an overview of tools and methods that can either be used to assess or the reliability of inverse problem results, prevent erroneous interpretation of data, and optimise information gained by experiments. It provides an introduction, along with useful references, to the topics of estimation error assessment, regularisation, identifiability analysis, residual analysis, model selection and optimal experiment design. These concepts are presented in the context of building simulation and energy performance assessment: a simple RC model is used as a running example to illustrate each chapter.},
author = {Rouchier, Simon},
doi = {10.1016/j.enbuild.2018.02.009},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier - 2017 - Solving inverse problems in building physics an overview of guidelines for a careful and optimal use of data.pdf:pdf},
journal = {Energy {\&} Buildings},
keywords = {Identifiability,Inverse problems,Likelihood,Model selection,Optimal experiment design,Validation,identifiability,inverse problems,likelihood,model selection,optimal experiment design,validation},
pages = {1--30},
title = {{Solving inverse problems in building physics : an overview of guidelines for a careful and optimal use of data}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0378778817317942/1-s2.0-S0378778817317942-main.pdf?{\_}tid=dd828440-1225-11e8-a36d-00000aacb361{\&}acdnat=1518681628{\_}8c351a954ad7da220d79e7410ede5253},
year = {2017}
}
@article{Fels1986,
author = {Fels, Margaret F},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fels - 1986 - PRISM An Introduction.pdf:pdf},
journal = {Energy and Buildings},
keywords = {PRISM},
mendeley-tags = {PRISM},
pages = {5--18},
title = {{PRISM: An Introduction}},
url = {http://marean.mycpanel.princeton.edu/{~}marean/images/prism{\_}intro.pdf},
volume = {9},
year = {1986}
}
@inproceedings{Juricic2018,
abstract = {Thermal diagnosis of an existing building requires among other things estimating the thermal properties of the building's envelope. To do so, the calibration of an adequate model from in situ measurements delivers estimation of the model's parameters which may be identified to the sought thermal properties. However, parameter estimation might be highly influenced by the weather boundary conditions which the building is subjected to. This major identifiability issue prevents any physical interpretation of the parameters estimated values. This paper presents a methodology to quantify the influence of natural weather variability on parameter estimation of a model, notably through a stochastic weather data generation method that allows Sobol sensitivity indices calculation. Application of the methodology on a 2R2C lumped model shows that the most influencing weather variable on the overall thermal resistance Req is outdoor temperature and that calibration from overall colder data sets tend to significantly over-estimate Req.},
address = {Bordeaux},
author = {Juricic, Sarah and Goffart, Jeanne and Rouchier, Simon and Foucquier, Aur{\'{e}}lie and Fraisse, Gilles},
booktitle = {Conf{\'{e}}rence Francophone de l'International Building Performance Simulation Association},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Juricic et al. - 2018 - Impact de la variabilit{\'{e}} naturelle des conditions m{\'{e}}t{\'{e}}orologiques sur l'estimation des param{\`{e}}tres applic.pdf:pdf},
keywords = {calibration,identifiability,lumped models,sensitivity analysis},
pages = {1--8},
title = {{Impact de la variabilit{\'{e}} naturelle des conditions m{\'{e}}t{\'{e}}orologiques sur l'estimation des param{\`{e}}tres : application aux mod{\`{e}}les RC}},
year = {2018}
}
@phdthesis{Mora2003,
annote = {Chap 2 : Diff{\'{e}}rents niveaux de mod{\'{e}}lisation
Approche nodale = approche multizone. Chaque zone est caract{\'{e}}ris{\'{e}}e par une pression, une temp{\'{e}}rature (hypoth{\`{e}}se du m{\'{e}}lange parfait).
Bilan des transferts de masse ou de chaleur.
--{\textgreater} description du comportement thermo a{\'{e}}raulique d'un b{\^{a}}timent sur des p{\'{e}}riodes longues
Mise en {\'{e}}quation par bilan massique.
Mod{\`{e}}le de transfert condutif 3R2C d'une paroi : Rumianovski et al 1989 ou Cron Inard et Belarbi 2003
M{\'{e}}thode de prise en compte du rayonnement (temp rayonnante moyenne) en approche nodale voir CRON et al 2003

Mod{\`{e}}le zonal = mod{\`{e}}le de plusieurs ocuches par pi{\`{e}}ce








BIBLIO : Kusuda 1976 Feustel {\&} Dieris 1992 (revue biblio)},
author = {Mora, Laurent},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mora - 2003 - Pr{\'{e}}diction des performances thermo-a{\'{e}}rauliques des b{\^{a}}timents par association de mod{\`{e}}les de diff{\'{e}}rents niveaux de fin.pdf:pdf},
keywords = {B{\^{a}}timent,CFD,Mod{\'{e}}lisation nodale,Mod{\'{e}}lisation zonale,SPARK,Simulation,Thermo-a{\'{e}}raulique,nodal,zonal},
mendeley-tags = {B{\^{a}}timent,Mod{\'{e}}lisation nodale,Mod{\'{e}}lisation zonale},
pages = {182},
school = {Universit{\'{e}} de La Rochelle},
title = {{Pr{\'{e}}diction des performances thermo-a{\'{e}}rauliques des b{\^{a}}timents par association de mod{\`{e}}les de diff{\'{e}}rents niveaux de finesse au sein d'un environnement orient{\'{e}} objet}},
url = {https://tel.archives-ouvertes.fr/tel-00003984/document},
year = {2003}
}
@article{Wang2009,
abstract = {A new universal estimator of divergence is presented for multidimensional continuous densities based on $\kappa$-nearest-neighbor ($\kappa$-NN) distances. Assuming independent and identically distributed (i.i.d.) samples, the new estimator is proved to be asymptotically unbiased and mean-square consistent. In experiments with high-dimensional data, the $\kappa$-NN approach generally exhibits faster convergence than previous algorithms. It is also shown that the speed of convergence of the $\kappa$-NN method can be further improved by an adaptive choice of $\kappa$. {\textcopyright} 2009 IEEE.},
author = {Wang, Qing and Kulkarni, Sanjeev R. and Verd{\'{u}}, Sergio},
doi = {10.1109/TIT.2009.2016060},
file = {:home/sarah/OneDrive/Travail/Sources/10.1.1.160.2548.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Divergence,Information measure,Kullback,Leibler,Nearest-neighbor,Partition,Random vector,Universal estimation},
number = {5},
pages = {2392--2405},
title = {{Divergence estimation for multidimensional densities via $\kappa$-nearest-neighbor distances}},
volume = {55},
year = {2009}
}
@techreport{Orlande2011,
author = {Orlande, Helcio R. B.},
booktitle = {Heat Transfer Engineering},
doi = {10.1080/01457632.2011.525128},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Orlande - 2011 - Inverse Heat Transfer Problems.pdf:pdf},
isbn = {3540536795},
issn = {0145-7632},
number = {9},
pages = {715--717},
title = {{Inverse Heat Transfer Problems}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01457632.2011.525128},
volume = {32},
year = {2011}
}
@article{Pronzato1993,
author = {Pronzato, Luc and Walter, Eric},
doi = {10.1007/BF00995494},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pronzato, Walter - 1993 - Experimental design for estimating the optimum point in a response surface.pdf:pdf},
issn = {01678019},
journal = {Acta Applicandae Mathematicae},
keywords = {Bayes.,Experimental design,Mathematics Subject Classifications (1991): 60F05,,estimator,loss function,optimization},
number = {1},
pages = {45--68},
title = {{Experimental design for estimating the optimum point in a response surface}},
volume = {33},
year = {1993}
}
@article{Denis-Vidal2001,
abstract = {The problem of identifiability of parameters has hardly ever been considered in the case of uncontrolled systems whereas many efficient methods have been developed for controlled systems. In this paper, we are pointing out two procedures to get global identifiability results of uncontrolled nonlinear systems. The first one derives from an algorithm proposed by Ljung and Glad. It is based on differential algebra and its complexity, due to the system size, does not increase as fast as the complexity of their algorithm. The second one is a heuristic approach. It builds a new model from various input datasets which expresses an experimental reality. Therefore, we will analyze the identifiability of this new model. Indeed, this procedure has been tested on an intricate system for which the other methods failed and it has given global identifiability results. {\textcopyright} 2001 IMACS. Published by Elsevier Science B.V. All rights reserved.},
author = {Denis-Vidal, Lilianne and Joly-Blanchard, Ghislaine and Noiret, C{\'{e}}line},
doi = {10.1016/S0378-4754(01)00274-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Denis-Vidal, Joly-Blanchard, Noiret - 2001 - Some effective approaches to check the identifiability of uncontrolled nonlinear systems(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Denis-Vidal, Joly-Blanchard, Noiret - 2001 - Some effective approaches to check the identifiability of uncontrolled nonlinear systems.pdf:pdf},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
keywords = {Biological applications,Differential algebra,Power series expansion,Structural (global and local) identifiability,Uncontrolled nonlinear system},
month = {aug},
number = {1-2},
pages = {35--44},
title = {{Some effective approaches to check the identifiability of uncontrolled nonlinear systems}},
url = {http://ac.els-cdn.com.camphrier-1.grenet.fr/S0378475401002749/1-s2.0-S0378475401002749-main.pdf?{\_}tid=6e697232-1acb-11e7-aa25-00000aab0f26{\&}acdnat=1491484849{\_}d205a53034e8a863b4ff4c3d42c47157 http://linkinghub.elsevier.com/retrieve/pii/S0378475401002749},
volume = {57},
year = {2001}
}
@article{Rezaee2019,
abstract = {Despite the development of a large number of building performance simulation tools, designers still need a systematic framework appropriate for energy-oriented decision-making in the early stages of design. While the current workflow follows a “forward” modelling procedure in which simulation tools predict the performance of a design, this study proposes an “inverse” procedure that entails a performance objective that estimates design parameters. Using linear inverse modelling, this approach generates plausible ranges for design parameters given a preferred thermal performance. The paper begins by demonstrating that thermal demand in a particular building operation-and-climate condition can be expressed as a linear regression model and then, in two case-studies, uses the regression model to develop an inverse algorithm. After defining energy performance targets as input, users obtain a probabilistic estimate of design parameters as output that represents a large “menu” of feasible design solutions, provides confidence, and embodies the iterative nature of design.},
author = {Rezaee, Roya and Brown, Jason and Haymaker, John and Augenbroe, Godfried},
doi = {10.1080/19401493.2018.1507046},
file = {:home/sarah/OneDrive/Travail/Sources/A new approach to performance based building design exploration using linear inverse modeling.pdf:pdf},
issn = {19401507},
journal = {Journal of Building Performance Simulation},
keywords = {design exploration,early stage of design,energy assessment,inverse modelling,uncertainty analysis},
number = {3},
pages = {246--271},
title = {{A new approach to performance-based building design exploration using linear inverse modeling}},
url = {https://doi.org/10.1080/19401493.2018.1507046},
volume = {12},
year = {2019}
}
@article{MacCallum2015,
abstract = {Wu and Browne (Psychometrika, 79, 2015) have proposed an innovative approach to modeling dis-crepancy between a covariance structure model and the population that the model is intended to represent. Their contribution is related to ongoing developments in the field of Uncertainty Quantification (UQ) on modeling and quantifying effects of model discrepancy. We provide an overview of basic principles of UQ and some relevant developments and we examine the Wu–Browne work in that context. We view the Wu–Browne contribution as a seminal development providing a foundation for further work on the critical problem of model discrepancy in statistical modeling in psychological research. Although both applied and methodological researchers in psychology are generally aware that statistical models are always wrong to some degree, there has been relatively little research in our field directed toward explicit incorporation of this fact into techniques for specifying and estimating models. Wu and Browne (2015) have achieved a significant advancement on this front by developing a creative framework and method for modeling of model discrepancy in structural equation modeling (SEM). Their approach provides a foundation for further development of such methods in SEM as well as other modeling frameworks, and for enhancement of our understanding of the utility and limitations of our models through more explicit representation and quantification of the nature of model discrepancy. We anticipate that the Wu–Browne paper will be widely recognized and frequently cited as a seminal contribution to essential research on this issue. Although the Wu–Browne contribution was developed and presented within the context of SEM, it is of central relevance to recognize that there is a strong link between their work and the statistical field of Uncertainty Quantification (UQ). We will review some fundamental principles of UQ in order to provide a larger frame and context for our comments on the Wu–Browne article.},
author = {MacCallum, Robert C. and O'Hagan, Anthony},
doi = {10.1007/s11336-015-9452-2},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maccallum, O 'hagan - 2015 - ADVANCES IN MODELING MODEL DISCREPANCY COMMENT ON WU AND BROWNE (2015).pdf:pdf},
issn = {0033-3123},
journal = {Psychometrika},
keywords = {Uncertainty Quantification,covariance structure modeling,model discrepancy,model error,structural equation modeling},
month = {sep},
number = {3},
pages = {601--607},
title = {{Advances in Modeling Model Discrepancy: Comment on Wu and Browne (2015)}},
url = {https://link-springer-com.camphrier-1.grenet.fr/content/pdf/10.1007{\%}2Fs11336-015-9452-2.pdf http://link.springer.com/10.1007/s11336-015-9452-2},
volume = {80},
year = {2015}
}
@article{Barker1999,
abstract = {Multi-level periodic perturbation signals for system identification in the frequency domain are defined. The design and properties of these signals, and the output signal processing methods used with them to reduce or eliminate the effects of noise and nonlinearity, are developed. Both pseudo-random and multi-frequency perturbation signals are considered, and an application in which these signals were used to identify the dynamics of steel strip in an industrial process is described. It is concluded that the use of these signals leads to considerable benefits, and that they are to be preferred for identification schemes of this kind. {\textcopyright} 1999 Elsevier Science Ltd. All rights reserved.},
author = {Barker, H. Anthony and Godfrey, Keith Richard},
doi = {10.1016/S0967-0661(99)00033-7},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/1-s2.0-S0967066199000337-main.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Multi-frequency signals,Multi-level signals,Nonlinear distortion,Nonlinear systems,Perturbation signals,Pseudo-random signals,System identification},
number = {6},
pages = {717--726},
title = {{System identification with multi-level periodic perturbation signals}},
volume = {7},
year = {1999}
}
@article{Ando2007c,
abstract = {The problem of evaluating the goodness of the predictive distributions of hierarchical Bayesian and empirical Bayes models is investigated. A Bayesian predictive information criterion is proposed as an estimator of the posterior mean of the expected loglikelihood of the predictive distribution when the specified family of probability distributions does not contain the true distribution. The proposed criterion is developed by correcting the asymptotic bias of the posterior mean of the loglikelihood as an estimator of its expected loglikelihood. In the evaluation of hierarchical Bayesian models with random effects, regardless of our parametric focus, the proposed criterion considers the bias correction of the posterior mean of the marginal loglikelihood because it requires a consistent parameter estimator. The use of the bootstrap in model evaluation is also discussed.},
author = {Ando, Tomohiro},
doi = {10.1093/biomet/asm017},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ando - 2007 - Bayesian predictive information criterion for the evaluation of hierarchical Bayesian and empirical Bayes models(2).pdf:pdf},
isbn = {0006-3444},
issn = {00063444},
journal = {Biometrika},
keywords = {Empirical Bayes model,Hierarchical Bayesian model,Markov chain Monte Carlo,Model misspecification},
number = {2},
pages = {443--458},
pmid = {4154661},
title = {{Bayesian predictive information criterion for the evaluation of hierarchical Bayesian and empirical Bayes models}},
volume = {94},
year = {2007}
}
@article{Munoz-Tamayo2018,
abstract = {What is a good (useful) mathematical model in animal science? For models constructed for prediction purposes, the question of model adequacy (usefulness) has been traditionally tackled by statistical analysis applied to observed experimental data relative to model-predicted variables. However, little attention has been paid to analytic tools that exploit the mathematical properties of the model equations. For example, in the context of model calibration, before attempting a numerical estimation of the model parameters, we might want to know if we have any chance of success in estimating a unique best value of the model parameters from available measurements. This question of uniqueness is referred to as structural identifiability; a mathematical property that is defined on the sole basis of the model structure within a hypothetical ideal experiment determined by a setting of model inputs (stimuli) and observable variables (measurements). Structural identifiability analysis applied to dynamic models described by ordinary differential equations (ODEs) is a common practice in control engineering and system identification. This analysis demands mathematical technicalities that are beyond the academic background of animal science, which might explain the lack of pervasiveness of identifiability analysis in animal science modelling. To fill this gap, in this paper we address the analysis of structural identifiability from a practitioner perspective by capitalizing on the use of dedicated software tools. Our objectives are (i) to provide a comprehensive explanation of the structural identifiability notion for the community of animal science modelling, (ii) to assess the relevance of identifiability analysis in animal science modelling and (iii) to motivate the community to use identifiability analysis in the modelling practice (when the identifiability question is relevant). We focus our study on ODE models. By using illustrative examples that include published mathematical models describing lactation in cattle, we show how structural identifiability analysis can contribute to advancing mathematical modelling in animal science towards the production of useful models and, moreover, highly informative experiments via optimal experiment design. Rather than attempting to impose a systematic identifiability analysis to the modelling community during model developments, we wish to open a window towards the discovery of a powerful tool for model construction and experiment design.},
author = {Mu{\~{n}}oz-Tamayo, R. and Puillet, L. and Daniel, J. B. and Sauvant, D. and Martin, O. and Taghipoor, M. and Blavy, P.},
doi = {10.1017/S1751731117002774},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/To be an identifiable model{\_}Munoz-Tamayo{\_}v1.pdf:pdf},
issn = {1751-7311},
journal = {animal},
keywords = {dynamic modelling,identifiability,model calibration,optimal experiment design,parameter identification},
month = {apr},
number = {4},
pages = {701--712},
title = {{Review: To be or not to be an identifiable model. Is this a relevant question in animal science modelling?}},
url = {https://www.cambridge.org/core/product/identifier/S1751731117002774/type/journal{\_}article},
volume = {12},
year = {2018}
}
@book{Gelman2014,
abstract = {Third edition. "Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"-- Part I: Fundamentals of Bayesian inference. Probability and inference -- Single-parameter models -- Introduction to multiparameter models -- Asymptotics and connections to non-Bayesian approaches -- Hierarchical models -- Part II: Fundamentals of Bayesian data analysis. Model checking -- Evaluating, comparing, and expanding models -- Modeling accounting for data collection -- Decision analysis -- Part III: Advanced computation. Introduction to Bayesian computation -- Basics of Markov chain simulation -- Computationally efficient Markov chain simulation -- Modal and distributional approximations -- Part IV: Regression models. Introduction to regression models -- Hierarchical linear models -- Generalized linear models -- Models for robust inference -- Models for missing data -- Part V: Nonlinear and nonparametric models. Parametric nonlinear models -- Basis function models -- Gaussian process models -- Finite mixture models -- Dirichlet process models -- A. Standard probability distributions -- B. Outline of proofs of limit theorems -- Computation in R and Stan.},
author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
doi = {10.1201/b16018},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/[Chapman {\&} Hall{\_}CRC Texts in Statistical Science] Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, Donald B. Rubin - Bayesian Data Analysis (2014, Chapman and Hall{\_}CRC).pdf:pdf},
isbn = {9781439898208},
month = {nov},
pages = {656},
publisher = {Chapman and Hall/CRC},
title = {{Bayesian Data Analysis, Third Edition}},
url = {https://www.taylorfrancis.com/books/9781439898208},
year = {2013}
}
@article{Han2018,
abstract = {The thermal properties of soil are vital in designing the length of buried heat exchangers. Based on a matured experimental technique commonly used for thermal response test in situ, a simulation model was built in this paper to determine the thermal properties of soil. Several sets of thermal response tests were carried out using the simulation model under different experimental conditions. The line heat source model (LHSM) and the column heat source model (CHSM) were applied to identify the thermal properties of soil. In order to analyze the variation of the identification error of the thermal properties under different experimental conditions, the identification results were then compared with the original setting values. The results showed that both identification methods could produce some errors in the identification of soil thermal and physical parameters under different experimental parameters. However, the accuracy of identification could be improved by selecting an appropriate test time. The best test time was duration to determine the thermal properties of soil was defined as an optimum length of time when the identification error was minimized. The best test time duration varied with different experimental parameters and different identification models. It is found that the best test time duration of the column heat source model was shorter than the one of the line source model. Giving longer lead time before counting the test time duration, increasing the thermal conductivity of the backfill material and heat injection, or reducing the circulating fluid flow rate, could effectively shorten the best test time duration.},
author = {Han, Zongwei and Li, Biao and Ma, Changming and Hu, Honghao and Bai, Chenguang},
doi = {10.1016/j.enbuild.2017.12.067},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2017 - Study on Accurate Identification of Soil Thermal Properties under Different Experimental Parameters(2).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Best test time duration,Parameter identification,Simulation test,Thermal properties,Thermal response test (TRT)},
month = {apr},
pages = {21--32},
title = {{Study on accurate identification of soil thermal properties under different experimental parameters}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S037877881733284X/1-s2.0-S037877881733284X-main.pdf?{\_}tid=a7275d56-f9cc-11e7-9fbb-00000aab0f26{\&}acdnat=1516004483{\_}7a83caa6666adb110f997f1a2961aa64 https://linkinghub.elsevier.com/retrieve/pii/S037877881733284X},
volume = {164},
year = {2018}
}
@article{Kircher2015,
abstract = {Thermal resistor-capacitor networks are a popular method for control-oriented building modeling. A basic assumption underlying this method is that the continuous temperature distribution in a wall or window is well-approximated by a small number of lumped capacitances. In this paper, we explore the accuracy of this approximation when a single capacitance is used. We derive conditions on the dimensionless parameters that characterize the problem, called Biot numbers, that lead to small errors in approximating a wall or window's surface heat fluxes and internal energy. The lumped capacitance approximation can be surprisingly accurate for Biot numbers much larger than the conventional upper bound of 0.1. In particular, the approximation is nearly exact for window panes, and is often acceptable for uniform walls. A large Biot number at an indoor wall surface, however, leads to large lumped capacitance approximation errors.},
author = {Kircher, Kevin J. and Zhang, K. Max},
doi = {10.1016/j.enbuild.2015.09.053},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kircher, Zhang - 2015 - On the lumped capacitance approximation accuracy in RC network building models.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {HVAC,Lumped capacitance approximation,MPC,RC networks},
pages = {454--462},
publisher = {Elsevier B.V.},
title = {{On the lumped capacitance approximation accuracy in RC network building models}},
url = {http://dx.doi.org/10.1016/j.enbuild.2015.09.053},
volume = {108},
year = {2015}
}
@article{Goupy2006,
author = {Goupy, Jacques},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goupy - 2006 - Tutoriel LES PLANS D'EXPERIENCES LES PLANS D'EXPERIENCES(2).pdf:pdf},
pages = {74--116},
title = {{Tutoriel LES PLANS D'EXPERIENCES LES PLANS D'EXPERIENCES}},
year = {2006}
}
@article{Kirkpatrick2012,
abstract = {Some methods aim to correct or test for relationships or to reconstruct the pedigree, or family tree. We show that these methods cannot resolve ties for correct relationships due to identifiability of the pedigree likelihood which is the probability of inheriting the data under the pedigree model. This means that no likelihood-based method can produce a correct pedigree inference with high probability. This lack of reliability is critical both for health and forensics applications. Pedigree inference methods use a structured machine learning approach where the objective is to find the pedigree graph that maximizes the likelihood. Known pedigrees are useful for both association and linkage analysis which aim to find the regions of the genome that are associated with the presence and absence of a particular disease. This means that errors in pedigree prediction have dramatic effects on downstream analysis. In this paper we present the first discussion of multiple typed individuals in non-isomorphic pedigrees, and , where the likelihoods are non-identifiable, , for all input data G and all recombination rate parameters $\theta$. While there were previously known non-identifiable pairs, we give an example having data for multiple individuals. Additionally, deeper understanding of the general discrete structures driving these non-identifiability examples has been provided, as well as results to guide algorithms that wish to examine only identifiable pedigrees. This paper introduces a general criteria for establishing whether a pair of pedigrees is non-identifiable and two easy-to-compute criteria guaranteeing identifiability. Finally, we suggest a method for dealing with non-identifiable likelihoods: use Bayes rule to obtain the posterior from the likelihood and prior. We propose a prior guaranteeing that the posterior distinguishes all pairs of pedigrees. {\textcopyright} 2012 Springer-Verlag.},
archivePrefix = {arXiv},
arxivId = {1602.08183},
author = {Kirkpatrick, Bonnie},
doi = {10.1007/978-3-642-30191-9_14},
eprint = {1602.08183},
file = {:home/sarah/OneDrive/Travail/Sources/1602.08183.pdf:pdf},
isbn = {9783642301902},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Pedigree genetics,discrete probability,identifiability},
pages = {139--152},
title = {{Non-identifiable pedigrees and a Bayesian solution}},
volume = {7292 LNBI},
year = {2012}
}
@article{Jimenez2015,
abstract = {This document describes guidelines for using time series analysis methods and tools for estimating the thermal performance of buildings and building components. This is integrated in a more comprehensive work. This first part is mainly dealing with physical aspects. A second part focused on statistical aspects has been also elaborated. Both documents must be considered as complementary. Minimum steps to carry out data analysis are reported and different alternative analysis approaches are outlined. This document is mainly focused on the most critical aspects particularly regarding energy performance assessment of buildings and building components. More general techniques also required to carry out data analysis are briefly presented in this document including references for more comprehensive information. Case studies that help to understand the different aspects discussed are included along this text and references are given for further information.},
author = {Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Bloem, Hans},
doi = {10.1016/j.egypro.2015.11.741},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jim{\'{e}}nez, Bloem - 2015 - Energy performance assessment of buildings and building components. Guidelines for data analysis from dynami(2).pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Building energy,Outdoor testing,Performance indicators,System identification,Thermal parameters},
month = {nov},
pages = {3306--3311},
title = {{Energy Performance Assessment of Buildings and Building Components. Guidelines for Data Analysis from Dynamic Experimental Campaigns Part 1: Physical Aspects}},
url = {https://ac.els-cdn.com/S187661021502473X/1-s2.0-S187661021502473X-main.pdf?{\_}tid=e5ac0fbe-8096-4f05-9535-3dcc68876fc0{\&}acdnat=1522758237{\_}ee4c0116068448b555b9b77d6519289d https://linkinghub.elsevier.com/retrieve/pii/S187661021502473X},
volume = {78},
year = {2015}
}
@article{Zhu2018,
author = {Zhu, Shousheng and Verdi{\`{e}}re, Nathalie and Denis-Vidal, Lilianne and Kateb, Djalil},
doi = {10.1016/j.ecocom.2017.12.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2018 - Identifiability analysis and parameter estimation of a chikungunya model in a spatially continuous domain.pdf:pdf},
issn = {1476945X},
journal = {Ecological Complexity},
month = {may},
number = {2017},
pages = {80--88},
publisher = {Elsevier B.V.},
title = {{Identifiability analysis and parameter estimation of a chikungunya model in a spatially continuous domain}},
url = {http://dx.doi.org/10.1016/j.ecocom.2017.12.004 https://linkinghub.elsevier.com/retrieve/pii/S1476945X17301381},
volume = {34},
year = {2018}
}
@article{Bastogne2007b,
author = {Bastogne, Thierry},
doi = {10.1080/00207720601159803},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastogne - 2007 - Behavioral interpretation of the object-oriented paradigm for interconnected dynamic system modeling.pdf:pdf},
issn = {0020-7721},
journal = {International Journal of Systems Science},
keywords = {complex systems,dynamic systems,mathematical models,object-modeling techniques},
number = {4},
pages = {319--326},
title = {{Behavioral interpretation of the object-oriented paradigm for interconnected dynamic system modeling}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.1080/00207720601159803{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {38},
year = {2007}
}
@article{Berger2017,
author = {Berger, Julien and Orlande, Helcio R. B. and Mendes, Nathan},
doi = {10.1080/17415977.2016.1160395},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger, Orlande, Mendes - 2017 - Proper Generalized Decomposition model reduction in the Bayesian framework for solving inverse heat tra.pdf:pdf},
issn = {1741-5977},
journal = {Inverse Problems in Science and Engineering},
month = {feb},
number = {2},
pages = {260--278},
title = {{Proper Generalized Decomposition model reduction in the Bayesian framework for solving inverse heat transfer problems}},
url = {http://www.tandfonline.com/doi/full/10.1080/17415977.2016.1160395 https://www.tandfonline.com/doi/full/10.1080/17415977.2016.1160395},
volume = {25},
year = {2017}
}
@techreport{Lalanne2012,
author = {Lalanne, Christophe},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lalanne - 2012 - Introduction Aux Statistiques Inf{\'{e}}rentielles.pdf:pdf},
pages = {1--54},
title = {{Introduction Aux Statistiques Inf{\'{e}}rentielles}},
year = {2012}
}
@article{Bohlin1995,
author = {Bohlin, Torsten and Graebe, Stefan F.},
doi = {10.1002/acs.4480090603},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bohlin, Graebe - 1995 - Issues in nonlinear stochastic grey box identification.pdf:pdf},
issn = {10991115},
journal = {International Journal of Adaptive Control and Signal Processing},
keywords = {CAD,grey box identification,modelling,multivariable systems,nonlinear systems,parameter estimation,software tools,stochastic systems,system identification},
number = {6},
pages = {465--490},
title = {{Issues in nonlinear stochastic grey box identification}},
volume = {9},
year = {1995}
}
@inproceedings{Stamp2013,
abstract = {To successfully meet emissions targets and reduce energy demand in the built environment, high targets have been set for building fabric performance. However, field measurements to date have indicated that the measured as-built fabric heat loss of tested UK buildings is consistently and sometimes considerably higher than design values. Many of these results stem from co-heating tests – an in situ measurement of the heat loss across the entire building envelope. Widespread implementation of the co-heating method is however restricted due to its invasive nature, long testing duration and uncertainty in the result. The test's reliability and accuracy are embedded in the available mix of weather and in the tested building's characteristics. This paper presents the results of both simulated and field co-heating tests, showing how changing external temperatures and high incident solar radiation interact with the thermal mass and glazing characteristics of a dwelling and can reduce the accuracy of the test and often lead to systematic underestimation of heat loss.},
address = {Chamb{\'{e}}ry},
author = {Stamp, Samuel and Lowe, Robert and Altamirano-Medina, Hector},
booktitle = {13th Conference of International Building Performance Simulation Association},
file = {:home/sarah/Dropbox/These/Sources/Mod{\`{e}}les - Mod{\'{e}}lisation/p{\_}1384.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Mod{\`{e}}les - Mod{\'{e}}lisation/p{\_}1384.pdf:pdf},
pages = {39--46},
title = {{An investigation into the role of thermal mass on the accuracy of co-heating tests through simulations and field results}},
year = {2013}
}
@article{Tissot2012,
abstract = {This paper deals with the random balance design method (RBD) and its hybrid approach, RBD-FAST. Both these global sensitivity analysis methods originate from Fourier amplitude sensitivity test (FAST) and consequently face the main problems inherent to discrete harmonic analysis. We present here a general way to correct a bias which occurs when estimating sensitivity indices (SIs) of any order - except total SI of single factor or group of factors - by the random balance design method (RBD) and its hybrid version, RBD-FAST. In the RBD case, this positive bias has been recently identified in a paper by Xu and Gertner [1]. Following their work, we propose a bias correction method for first-order SIs estimates in RBD. We then extend the correction method to the SIs of any order in RBD-FAST. At last, we suggest an efficient strategy to estimate all the first- and second-order SIs using RBD-FAST. {\textcopyright} 2012 Elsevier Ltd.},
author = {Tissot, Jean Yves and Prieur, Cl{\'{e}}mentine},
doi = {10.1016/j.ress.2012.06.010},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-S0951832012001159-main.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Bias correction,Global sensitivity analysis,RBD-FAST,Random balance design,Sensitivity indices},
pages = {205--213},
title = {{Bias correction for the estimation of sensitivity indices based on random balance designs}},
volume = {107},
year = {2012}
}
@article{Alzetto2018a,
abstract = {The Quick U-Building (QUB) method is a dynamic method developed to estimate the heat loss coefficient of a building in one night without occupancy. Feasibility measurements and comparisons with various references have been done in earlier studies whatever numerically, experimentally in an ideal case, or experimentally in real cases. This article presents a review of various perturbation methods developed to assess building thermal performance, details of theoretical understanding of the QUB method, and gathers experimental results obtained in many different configurations. The heat loss coefficients estimated with the QUB method are in good agreement with experimental references and are reproducible. This demonstrates that the QUB method has a real potential to estimate the heat loss coefficient of a building in a short duration and with a reasonable accuracy.},
author = {Alzetto, Florent and Meulemans, Johann and Pandraud, Guillaume and Roux, Didier},
doi = {10.1016/j.crci.2018.09.003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alzetto et al. - 2018 - A perturbation method to estimate building thermal performance.pdf:pdf},
issn = {16310748},
journal = {Comptes Rendus Chimie},
keywords = {Heat loss coefficient,In situ,Perturbation method,QUB method,Thermal performance},
month = {oct},
number = {10},
pages = {938--942},
title = {{A perturbation method to estimate building thermal performance}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1631074818302017},
volume = {21},
year = {2018}
}
@article{Beaud2006,
abstract = {920},
author = {Beaud, Michel and Gravier, Magali and {Toledo (de)}, Alain},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beaud, Gravier, Toledo (de) - 2006 - L'art de la th{\`{e}}se Comment pr{\'{e}}parer et r{\'{e}}diger un m{\'{e}}moire de master, une th{\`{e}}se de doctorat o.pdf:pdf},
isbn = {2-7071-4794-X},
journal = {Rep{\`{e}}res},
keywords = {SUJETS = m{\'{e}}thodologie,bibliographie,r{\'{e}}daction},
pages = {202},
title = {{L'art de la th{\`{e}}se : Comment pr{\'{e}}parer et r{\'{e}}diger un m{\'{e}}moire de master, une th{\`{e}}se de doctorat ou tout autre travail universitaire {\`{a}} l'{\`{e}}re du Net}},
year = {2006}
}
@article{Shi2019,
abstract = {This article introduces a parameter estimation and state prediction technique called constrained dual Extended Kalman Filter (EKF) that can be used in model prediction controls (MPC) and fault detection and diagnostics (FDD) in building systems. The proposed method is an improvement over the existing nonlinear filter-based methods such as the joint EKF or Unscented Kalman Filter, which is widely adopted in previous building controls research. Case studies using both simulation and real measurements are conducted to demonstrate the proposed algorithm when used for a building thermal zone. Data from parametric simulations are used to test the thermal model's ability to capture parameter variations. Measured data from five identical offices is collected to test the performance of parameter estimates and state predictions under real-life operation. Overall, the proposed algorithm is 25{\%} faster than a conventional EKF with improved numerical stability. It can also help mitigate numerical instabilities seen in previous EKF research. The reduced thermal model used in this paper is also capable of detecting most of the parametric changes to the thermal zone and providing reliable temperature predictions.},
author = {Shi, Zixiao and O'Brien, William},
doi = {10.1016/j.enbuild.2018.11.024},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778817316821-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
month = {jan},
pages = {538--546},
publisher = {Elsevier B.V.},
title = {{Sequential state prediction and parameter estimation with constrained dual extended Kalman filter for building zone thermal responses}},
url = {https://doi.org/10.1016/j.enbuild.2018.11.024 https://linkinghub.elsevier.com/retrieve/pii/S0378778817316821},
volume = {183},
year = {2019}
}
@article{Pang2020,
abstract = {A building system is highly nonlinear and commonly includes a variety of parameters ranging from the architectural design to the building mechanical and energy system. Serving as a powerful tool to understand the complicated building system, sensitivity analysis (SA) has been receiving increasing attention in the recent decade. This review paper focused on the application of SA in the building performance analysis (BPA). First, the existing review papers on the application of SA for BPA were briefly reviewed and summarized. Then, a large amount of recent SA case studies in BPA were reviewed. The critical information regarding the implementation of a SA, such as the sampling method, the SA method, etc., were extracted and summarized. Next, an extensive analysis was performed to evaluate the role of the SA in the BPA. This includes: 1) The typical selection of the input and output parameters for the SA were visualized; 2) The uncertainty level and sampling strategies for the input parameters were investigated; 3) The principles, benefits, and drawbacks of the SA methods were analyzed and summarized; and 4) The various tools used in the SA, including the simulation software, sampling tools, and SA tools were introduced to facilitate the practitioners. Lastly, several conclusions were summarized on the role of the SA in the BPA. Suggestions were also provided to offer practical solutions to the current challenges.},
author = {Pang, Zhihong and O'Neill, Zheng and Li, Yanfei and Niu, Fuxin},
doi = {10.1016/j.enbuild.2019.109659},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-S0378778819319164-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building energy efficiency,Building energy simulation,Building performance analysis,Sensitivity analysis},
pages = {109659},
publisher = {Elsevier B.V.},
title = {{The role of sensitivity analysis in the building performance analysis: A critical review}},
url = {https://doi.org/10.1016/j.enbuild.2019.109659},
volume = {209},
year = {2020}
}
@techreport{Metropolis1953,
address = {U.S. Atomic Energy Commission},
author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
doi = {10.2172/4390578},
institution = {Division of Technical Information Extension},
month = {mar},
title = {{Equation of state calculations by fast computing machines}},
url = {http://www.osti.gov/servlets/purl/4390578/},
year = {1953}
}
@article{Chis2011,
abstract = {Abstract Model parametric identification is a critical yet often overlooked step for the modelling of biosystems. Modern experimental techniques can be used to obtain time-series data which may then be used to estimate model parameters. However, in many cases, a subset of model parameters may not be uniquely estimated, independently of the quantity and quality of data available or the numerical techniques used for estimation. This lack of identifiability is related to the structure of the model. This work presents a review and a critical comparison of methods to analyze the structural identifiability of non-linear models. Three examples, of increasing level of complexity, related to the modelling of biochemical networks, will be used to illustrate advantages and disadvantages of the available techniques. Results reveal that the generating series approach combined with the identifiability tableau is the most promising to analyze large scale highly nonlinear models.},
author = {Chis, Oana and Banga, Julio R and Balsa-Canto, Eva},
doi = {10.3182/20110828-6-IT-1002.00800},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chis, Banga, Balsa-Canto - 2011 - Methods for checking structural identifiability of nonlinear biosystems A critical comparison(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chis, Banga, Balsa-Canto - 2011 - Methods for checking structural identifiability of nonlinear biosystems A critical comparison(3).pdf:pdf},
isbn = {9783902661937},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {(Structural) identifiability,(structural) identifiability,Biological models,Controllability,Observability,biological models,controllability,observability},
month = {jan},
number = {1},
pages = {10585--10590},
publisher = {IFAC},
title = {{Methods for checking structural identifiability of nonlinear biosystems: A critical comparison.}},
url = {http://dx.doi.org/10.3182/20110828-6-IT-1002.00800 http://ac.els-cdn.com.camphrier-1.grenet.fr/S1474667016453139/1-s2.0-S1474667016453139-main.pdf?{\_}tid=7a625306-1acb-11e7-93f3-00000aacb35f{\&}acdnat=1491484869{\_}befc7592c6f6d50ca7acf5f3d9180ca3 http://linkingh},
volume = {44},
year = {2011}
}
@article{Kim2014,
abstract = {In the statistical modeling of a biological or ecological phenomenon, selecting an optimal model among a collection of candidates is a critical issue. To identify an optimal candidate model, a number of model selection criteria have been developed and investigated based on estimating Kullback's (Information theory and statistics. Dover, Mineola, 1968) directed or symmetric divergence. Criteria that target the directed divergence include the Akaike (2nd international symposium on information theory. Akad{\'{e}}mia Kiad{\'{o}}, Budapest, Hungary, pp 267-281, 1973, IEEE Trans Autom Control AC 19:716-723, 1974) information criterion, AIC, and the "corrected" Akaike information criterion (Hurvich and Tsai in Biometrika 76:297-307, 1989), AICc; criteria that target the symmetric divergence include the Kullback information criterion, KIC, and the "corrected" Kullback information criterion, KICc (Cavanaugh in Stat Probab Lett 42:333-343, 1999; Aust N Z J Stat 46:257-274, 2004). For overdispersed count data, simple modifications of AIC and AICc have been increasingly utilized: specifically, the quasi Akaike information criterion, QAIC, and its corrected version, QAICc (Lebreton et al. in Ecol Monogr 62(1):67-118 1992). In this paper, we propose analogues of QAIC and QAICc based on estimating the symmetric as opposed to the directed divergence: QKIC and QKICc. We evaluate the selection performance of AIC, AICc, QAIC, QAICc, KIC, KICc, QKIC, and QKICc in a simulation study, and illustrate their practical utility in an ecological application. In our application, we use the criteria to formulate statistical models of the tick (Dermacentor variabilis) load on a white-footed mouse (Peromyscus leucopus) in northern Missouri. {\textcopyright} 2013 Springer Science+Business Media New York.},
author = {Kim, Hyun Joo and Cavanaugh, Joseph E. and Dallas, Tad A. and For{\'{e}}, Stephanie A.},
doi = {10.1007/s10651-013-0257-0},
file = {:home/sarah/OneDrive/Travail/Sources/modselect.pdf:pdf},
issn = {13528505},
journal = {Environmental and Ecological Statistics},
keywords = {AIC,KIC,Model selection criterion,Overdispersion,QAIC,Quasi likelihood},
number = {2},
pages = {329--350},
title = {{Model selection criteria for overdispersed data and their application to the characterization of a host-parasite relationship}},
volume = {21},
year = {2014}
}
@article{Plischke2010,
abstract = {We present an algorithm named EASI that estimates first order sensitivity indices from given data using Fast Fourier Transformations. Hence it can be used as a post-processing module for pre-computed model evaluations. Ideas for the estimation of higher order sensitivity indices are also discussed. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Plischke, Elmar},
doi = {10.1016/j.ress.2009.11.005},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-S0951832009002579-main.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Correlation ratio,FAST method,Global sensitivity analysis,Post-processing algorithm,Sobol' sensitivity indices,Space filling curves},
number = {4},
pages = {354--360},
publisher = {Elsevier},
title = {{An effective algorithm for computing global sensitivity indices (EASI)}},
url = {http://dx.doi.org/10.1016/j.ress.2009.11.005},
volume = {95},
year = {2010}
}
@article{Evans2013,
abstract = {Binding affinities are useful measures of target interaction and have an important role in understanding biochemical reactions that involve binding mechanisms. Surface plasmon resonance (SPR) provides convenient real-time measurement of the reaction that enables subsequent estimation of the reaction constants necessary to determine binding affinity. Three models are considered for application to SPR experiments—the well mixed Langmuir model and two models that represent the binding reaction in the presence of transport effects. One of these models, the effective rate constant approximation, can be derived from the other by applying a quasi-steady state assumption. Uniqueness of the reaction constants with respect to SPR measurements is considered via a structural identifiability analysis. It is shown that the models are structurally unidentifiable unless the sample concentration is known. The models are also considered for analytes with heterogeneity in the binding kinetics. This heterogeneity further confounds the identifiability of key parameters necessary for reliable estimation of the binding affinity.},
annote = {Explication sur l'identif structurelle en alg diff

M{\'{e}}thode utilis{\'{e}}e : similaire {\`{a}} Denis-Vidal (2001)},
author = {Evans, N.D. and Moyse, H.A.J. and Lowe, D and Briggs, D and Higgins, R and Mitchell, D and Zehnder, D and Chappell, Mike J},
doi = {10.1016/j.automatica.2012.09.015},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Evans et al. - 2013 - Structural identifiability of surface binding reactions involving heterogeneous analyte Application to surface pla.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Biomedical systems,binding affinity,structural identifiability,surface plasmon resonance,surface-volume reactions,system identification},
month = {jan},
number = {1},
pages = {48--57},
title = {{Structural identifiability of surface binding reactions involving heterogeneous analyte: Application to surface plasmon resonance experiments}},
url = {http://wrap.warwick.ac.uk/49183 http://linkinghub.elsevier.com/retrieve/pii/S0005109812004785},
volume = {49},
year = {2013}
}
@techreport{Janssens2016,
abstract = {Reliable building energy performance characterisation based on full scale dynamic measurements in Buildings Background : Renewed interest in full scale testing Interest},
author = {Janssens, Arnold},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Janssens - 2016 - Reliable building energy performance characterisation based on full scale dynamic measurements ST b Overview of metho.pdf:pdf},
institution = {IEA EBC},
isbn = {9789460189906},
title = {{IEA EBC Annex 58 Reliable building energy performance characterisation based on full scale dynamic measurements : ST b Overview of methods to analyse dynamic data}},
year = {2016}
}
@article{Stoffel2000,
author = {Stoffel, T L and Reda, I and Myers, D R and Renne, D and Wilcox, S and Treadwell, J},
doi = {10.1088/0026-1394/37/5/11},
file = {:home/sarah/OneDrive/Travail/Sources/Mesurage/Current{\_}issues{\_}in{\_}terrestrial{\_}solar{\_}radiation{\_}inst.pdf:pdf},
issn = {0026-1394},
journal = {Metrologia},
month = {oct},
number = {5},
pages = {399--402},
title = {{Current issues in terrestrial solar radiation instrumentation for energy, climate, and space applications}},
url = {http://stacks.iop.org/0026-1394/37/i=5/a=11?key=crossref.586ce80d4f3d654d8f8f935085dd5c45},
volume = {37},
year = {2000}
}
@article{Liu2009,
abstract = {Bayesian analysis incorporates different sources of information into a single analysis through Bayes theorem. When one or more of the sources of information are suspect (e.g., if the model assumed for the information is viewed as quite possibly being significantly flawed), there can be a concern that Bayes theorem allows this suspect information to overly influence the other sources of information. We consider a variety of situations in which this arises, and give methodological suggestions for dealing with the problem. After consideration of some pedagogical examples of the phenomenon, we focus on the interface of statistics and the development of complex computer models of processes. Three testbed computer models are considered, in which this type of issue arises.},
author = {Liu, F and Bayarri, M. J. and Berger, J O},
doi = {10.1214/09-BA404},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Bayarri, Berger - 2009 - Modularization in Bayesian Analysis, with Emphasis on Analysis of Computer Models.pdf:pdf},
issn = {1936-0975},
journal = {Bayesian Analysis},
keywords = {Complex computer models,Confounding,Emulators,Identifiability,MCMC mixing,Partial likelihood,Random effects},
month = {mar},
number = {1},
pages = {119--150},
title = {{Modularization in Bayesian analysis, with emphasis on analysis of computer models}},
url = {https://projecteuclid.org/download/pdf{\_}1/euclid.ba/1340370392 http://projecteuclid.org/euclid.ba/1340370392},
volume = {4},
year = {2009}
}
@article{Park2013,
abstract = {– This study proposes a low order dynamic model of a building system in order to predict thermal behavior within a building and its energy consumption. The building system includes a thermally well-insulated room and an electric heater. It is modeled by a second order lumped RC thermal network based on the thermal-electrical analogy. In order to identify unknown parameters of the model, an experimental procedure is firstly detailed. Then, the different linear parametric models (ARMA, ARX, ARMAX, BJ, and OE models) are recalled. The parameters of the parametric models are obtained by the least square approach. The obtained parameters are interpreted to the parameters of the physically based model in accordance with their relationship. Afterwards, the obtained models are implemented in Matlab/Simulink{\textregistered} and are evaluated by the mean of the sum of absolute error (MAE) and the mean of the sum of square error (MSE) with the variable of indoor temperature of the room. Quantities of electrical energy and converted thermal energy are also compared. This study will permit a further study on Model Predictive Control adapting to the proposed model in order to reduce energy consumption of the building.},
author = {Park, Herie and Martaj, Nadia and Ruellan, Marie and Bennacer, Rachid and Monmasson, Eric},
doi = {10.5370/JEET.2013.8.5.975},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park et al. - 2013 - Modeling of a Building System and its Parameter Identification.pdf:pdf},
journal = {J Electr Eng Technol},
keywords = {Dynamic model,Low energy building,Parameter identification,Thermal network},
number = {5},
pages = {975--983},
title = {{Modeling of a Building System and its Parameter Identification}},
url = {http://dx.doi.org/10.5370/JEET.2013.8.5.975},
volume = {8},
year = {2013}
}
@article{Danafar2015,
abstract = {This paper introduces Kernel-based Information Criterion (KIC) for model selection in regression analysis. The novel kernel-based complexity measure in KIC efficiently computes the interdependency between parameters of the model using a variable-wise variance and yields selection of better, more robust regressors. Experimental results show superior performance on both simulated and real data sets compared to Leave-One-Out Cross-Validation (LOOCV), kernel-based Information Complexity (ICOMP), and maximum log of marginal likelihood in Gaussian Process Regression (GPR).},
archivePrefix = {arXiv},
arxivId = {1408.5810},
author = {Danafar, Somayeh and Fukumizu, Kenji and Gomez, Faustino},
doi = {10.5539/cis.v8n1p10},
eprint = {1408.5810},
file = {:home/sarah/OneDrive/Travail/Sources/1408.5810.pdf:pdf},
issn = {1913-8989},
journal = {Computer and Information Science},
number = {1},
pages = {1--15},
title = {{Kernel-Based Information Criterion}},
volume = {8},
year = {2015}
}
@article{Raue2011,
abstract = {Mathematical description of biological processes such as gene regulatory networks or signalling pathways by dynamic models utilising ordinary differential equations faces challenges if the model parameters like rate constants are estimated from incomplete and noisy experimental data. Typically, biological networks are only partially observed. Only a fraction of the modelled molecular species is measurable directly. This can result in structurally non-identifiable model parameters. Furthermore, practical non-identifiability can arise from limited amount and quality of experimental data. In the challenge of growing model complexity on one side, and experimental limitations on the other side, both types of non-identifiability arise frequently in systems biological applications often prohibiting reliable prediction of system dynamics. On theoretical grounds this article summarises how and why both types of non-identifiability arise. It exemplifies pitfalls where models do not yield reliable predictions of system dynamics because of non-identifiabilities. Subsequently, several approaches for identifiability analysis proposed in the literature are discussed. The aim is to provide an overview of applicable methods for detecting parameter identifiability issues. Once non-identifiability is detected, it can be resolved either by experimental design, measuring additional data under suitable conditions; or by model reduction, tailoring the size of the model to the information content provided by the experimental data. Both strategies enhance model predictability and will be elucidated by an example application. [Includes supplementary material].},
annote = {From Duplicate 1 (Addressing parameter identifiability by model-based experimentation - Maiwald, T.; Timmer, Jens; Kreutz, C.; Klingm{\"{u}}ller, U.; Raue, Andreas)

From Duplicate 3 (Addressing parameter identifiability by model-based experimentation. - Raue, Andreas; Kreutz, C.; Maiwald, T.; Klingmuller, U; Timmer, Jens; Kreutz, C.; Klingm{\"{u}}ller, U.; Raue, Andreas; Kreutz, C.; Maiwald, T.; Klingmuller, U; Timmer, Jens)

From Duplicate 2 (Addressing parameter identifiability by model-based experimentation - Maiwald, T.; Timmer, Jens; Kreutz, C.; Klingm{\"{u}}ller, U.; Raue, Andreas)

Non-observability : if internal states are determined by non identifiable parameters (which might have been calibrated but have no whatsoever physical meaning), cannot be observed : their trajectory might not be determined.

Data-based approach do not insure global identifiability of the system. Since it depends on the available data, we have identifiability of the parameter space defined by the data, which is a local identifiability. That region is however precisely relevant, and usually sufficient for some applications, like building inverse problems.

Cons{\'{e}}quence de la non-identifiabilit{\'{e}} de certains param{\`{e}}tres :
- soit on a besoin de ces param{\`{e}}tres pour l'analyse du probl{\`{e}}me auquel cas il faut absolument reproc{\'{e}}der {\`{a}} la calibration avec des donn{\'{e}}es plus informatives (utiliser optimal experiment design)
- soit on n'en avait pas besoin (param{\`{e}}tres {\`{a}} la marge), et en ce cas, on peut se m{\^{e}}me se permettre d'essayer de simplifier le syst{\`{e}}me pour diminuer les temps de calcul et la complexit{\'{e}}},
author = {Maiwald, T. and Timmer, Jens and Kreutz, Clemens and Klingm{\"{u}}ller, U. and Raue, Andreas},
doi = {10.1049/iet-syb.2010.0061},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raue et al. - 2011 - Addressing parameter identifiability by model-based experimentation.pdf:pdf},
isbn = {1751-8849},
issn = {1751-8849},
journal = {IET Systems Biology},
keywords = {Algorithms,Biological,Chi-Square Distribution,Gene Regulatory Networks,Models,Research Design,Signal Transduction,Systems Biology},
month = {mar},
number = {2},
pages = {120--130},
pmid = {21405200},
title = {{Addressing parameter identifiability by model-based experimentation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21405200 http://digital-library.theiet.org/content/journals/10.1049/iet-syb.2010.0061 https://digital-library.theiet.org/content/journals/10.1049/iet-syb.2010.0061},
volume = {5},
year = {2011}
}
@article{Latyshenko2017,
abstract = {The paper focuses on sensitivity-based identifiability analysis of parameters for mathematical models described by systems of nonlinear ordinary differential equations. This analysis is carried out using eigenvalue method and orthogonal method. Both methods allow one to globally evaluate and compare the influence of parameter values on measurement data. The sensitivity analysis and numerical experiments for mathematical model of the spread of TB and HIV co-infection are demonstrated. The numerical results show that 4 parameters (from 15 available) are identifiable uniquely by the given data only about 3 measured time-point functions during 5 years.},
author = {LATYSHENKO, Varvara and KRIVOROTKO, Olga and KABANIKHIN, Sergey and ZHANG, Shuhua and KASHTANOVA, Victoriya and YERMOLENKO, Dariya},
doi = {10.12783/dtcse/cmsam2017/16435},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latyshenko et al. - 2017 - Identifiability Analysis of Inverse Problems in Biology.pdf:pdf},
isbn = {978-1-60595-499-8},
journal = {DEStech Transactions on Computer Science and Engineering},
keywords = {Eigenvalue method,Epidemiology,HIV,Identifiability,Inverse problem,ODE,Orthogonal method,Sensitivity-based analysis,Tuberculosis},
number = {cmsam},
title = {{Identifiability Analysis of Inverse Problems in Biology}},
url = {http://dpi-proceedings.com/index.php/dtcse/article/viewFile/16435/15942},
year = {2017}
}
@article{Kathryn1995,
author = {Kathryn, Chaloner and Isabella, Verdinelli},
doi = {10.2307/2246015},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kathryn, Isabella - 1995 - Bayesian Experimental Design A Review.pdf:pdf},
isbn = {0444820612},
issn = {08834237},
journal = {Statistical Science},
keywords = {Decision theory,hierarchical linear models,logistic regression,nonlinear design,nonlinear models,optimal design,optimality criteria,utility functions},
number = {3},
pages = {273--304},
title = {{Bayesian Experimental Design: A Review}},
url = {http://www.jstor.org/stable/2246015},
volume = {10},
year = {1995}
}
@article{Myung2003,
abstract = {In this paper, I provide a tutorial exposition on maximum likelihood estimation (MLE). The intended audience of this tutorial are researchers who practice mathematical modeling of cognition but are unfamiliar with the estimation method. Unlike least-squares estimation which is primarily a descriptive tool, MLE is a preferred method of parameter estimation in statistics and is an indispensable tool for many statistical modeling techniques, in particular in non-linear modeling with non-normal data. The purpose of this paper is to provide a good conceptual explanation of the method with illustrative examples so the reader can have a grasp of some of the basic principles. ?? 2003 Elsevier Science (USA). All rights reserved.},
author = {Myung, In Jae},
doi = {10.1016/S0022-2496(02)00028-7},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Myung - 2003 - Tutorial on maximum likelihood estimation.pdf:pdf},
isbn = {0022-2496},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
number = {1},
pages = {90--100},
pmid = {238},
title = {{Tutorial on maximum likelihood estimation}},
volume = {47},
year = {2003}
}
@book{Madsen2007,
author = {Madsen, Henrik},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madsen - 2007 - Time series analysis.pdf:pdf},
isbn = {1584883170},
pages = {1 -- 345},
publisher = {Chapman {\&} Hall / CRC},
title = {{Time series analysis}},
year = {2008}
}
@article{Spitz2012a,
abstract = {Nowadays, simulation tools are widely used to design buildings since their energy performance is increasing. Simulation is used to predict building energy performance and to improve thermal comfort of occupants, but also to reduce the environmental impact of the building over its whole life cycle and the cost of construction and operation. Simulation becomes an essential decision support tool, but its reliability should not be ignored. Hypothesis, made 10 years ago for buildings conception, are often not adapted to the new constructions because of physical phenomena which until now were overlooked. At the same time, guarantees of energy efficiency, which aims to check if actual energy performances are matching the conception goals, are becoming important. But there are usually differences between measured and simulation data. They may be the result of mistakes and unknowns on input parameters, on schedule occupation or on weather data. Today it's important to evaluate simulation and measurement reliability and uncertainties to improve design building. This PhD work aimed to evaluate and order simulation results uncertainties during the design building process. A methodology in three steps was developed to determine influential parameters on building energy performance and to identify the influence of these parameters uncertainty on the building performance. The first step uses the local sensitivity analysis and identifies the most influential parameters on the outputs among all parameters. This step enables to reduce the number of parameters which is necessary to proceed the following steps The second step is an uncertainty analysis focuses on quantifying uncertainty in model outputs. This step is conducted with the Monte Carlo probabilistic approach. The last step uses global sensitivity analysis which is the study of how uncertainty in the output of a model can be apportioned to different sources of uncertainty in the model input. This methodology was applied to the INCAS experimental platform of the French National Institute of Solar Energy (INES) in Le-Bourget-du-Lac to identify measure uncertainties and uncertainties on simulation hypothesis.},
annote = {Evaluation et hi{\'{e}}rarchisation des incertitudes sur les r{\'{e}}sultats de simulation. D{\'{e}}veloppement d'une m{\'{e}}thodo ad hoc : identifier les param{\`{e}}tres du mod{\`{e}}le qui ont une influence sur le r{\'{e}}sultat (analyse de sensibilit{\'{e}} locale), {\'{e}}valuer les incertitudes de ces param{\`{e}}tres les plus influents et calculer la propagation de cette incertitude (Monte Carlo), {\'{e}}valuer la responsabilit{\'{e}} de chacun des param{\`{e}}tres influents sur l'incertitude du r{\'{e}}sultat (analyse de sensiblit{\'{e}} globale)},
author = {Spitz, Clara},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spitz - 2012 - Analyse de la fiabilit{\'{e}} des outils de simulation et des incertitudes de m{\'{e}}trologie appliqu{\'{e}}e {\`{a}} l'efficacit{\'{e}} {\'{e}}ne.pdf:pdf},
journal = {PhD Thesis},
keywords = {Sensitivity analysis,influential parameter,low energy building,reliability,simulation,uncertainty},
pages = {169},
title = {{Analyse de la fiabilit{\'{e}} des outils de simulation et des incertitudes de m{\'{e}}trologie appliqu{\'{e}}e {\`{a}} l'efficacit{\'{e}} {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents}},
year = {2012}
}
@article{Dawid1979,
author = {Dawid, A. P.},
doi = {10.1111/j.2517-6161.1979.tb01052.x},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/2984718.pdf:pdf},
issn = {00359246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {adequacy,ancillarity,bayesian,condmiional independence,data,identification,independence,inference,invariance,markov chains,prediction,s paradox,simpson,sufficiency,total sufficiency,transvityi},
month = {sep},
number = {1},
pages = {1--15},
title = {{Conditional Independence in Statistical Theory}},
url = {http://doi.wiley.com/10.1111/j.2517-6161.1979.tb01052.x},
volume = {41},
year = {1979}
}
@article{Li2014a,
abstract = {Model based control has become a promising solution for building operation optimization and energy saving. Accuracy and computationally efficiency are two of the most important requirements for building energy models. Existing studies in this area have mostly been focusing on reducing computation burden using simplified physics based modeling approach. However, creating even the simplified physics based model is often challenging and time consuming. Pure date-driven statistical models have also been adopted in a lot of studies. Such models, unfortunately, often require long training period and are bounded to building operating conditions that they are trained for. Therefore, this study proposes a novel methodology to develop building energy estimation models for on-line building control and optimization using a system identification approach. Frequency domain spectral density analysis is implemented in this on-line modeling approach to capture the dynamics of building energy system and forecast the energy consumption with more than 90{\%} accuracy and less than 2 min computational speed. A systematic analysis of system structure, system order and system excitation selection are also demonstrated. The forecasting results from this proposed model are validated against detailed physics based simulation results using a mid-size commercial building EnergyPlus model. ?? 2014 Elsevier B.V.},
author = {Li, Xiwang and Wen, Jin},
doi = {10.1016/j.enbuild.2014.07.021},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Wen - 2014 - Building energy consumption on-line forecasting using physics based system identification.pdf:pdf},
isbn = {9780791846186},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building control and operation,Building energy efficiency,Building energy modeling,System identification},
pages = {1--12},
publisher = {Elsevier B.V.},
title = {{Building energy consumption on-line forecasting using physics based system identification}},
url = {http://dx.doi.org/10.1016/j.enbuild.2014.07.021},
volume = {82},
year = {2014}
}
@article{Lee2017,
author = {Lee, Sang Hoon and Hong, Tianzhen},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Hong - 2017 - Leveraging Zone Air Temperature Data to Improve Physics-Based Energy Simulation of Existing Buildings Lawrence Berkel.pdf:pdf},
pages = {1223--1230},
title = {{Leveraging Zone Air Temperature Data to Improve Physics-Based Energy Simulation of Existing Buildings Lawrence Berkeley National Laboratory , Berkeley , United States}},
year = {2017}
}
@article{JEDIDI2015,
author = {Jedidi, Safa and Bourdais, Romain and Buisson, Jean and Lefebvre, Marie-Anne},
doi = {10.1016/j.ifacol.2015.12.331},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/JEDIDI et al. - 2015 - Structural identifiability and identification of systems under output couplings.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
number = {28},
pages = {1415--1420},
title = {{Structural identifiability and identification of systems under output couplings}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2405896315029559},
volume = {48},
year = {2015}
}
@article{BellM;StaffordA;Gorse2012a,
abstract = {The term ‘performance gap' is often used to refer to the difference between the design thermal performance, and the measured thermal performance of buildings, treated as a whole system. Reducing the performance gap is important to ensure we achieve real and significant energy savings from the built environment: critical if we are to reach the UK's 2050 target of an 80{\%} reduction in carbon emissions. The purpose of this paper is to offer an analysis of the accumulated Leeds Metropolitan University data around as-built thermal performance for new build and retrofitted homes. What are the key factors that determine the performance gap? The analysis enables stakeholders to consider targeted processes or standards which can improve performance, helping the industry to move towards minimising, and eventually eliminating, the performance gap.},
author = {Bell, Malcolm and Stafford, A and Gorse, Chris},
file = {:home/sarah/OneDrive/Travail/Sources/Mod{\`{e}}les - Mod{\'{e}}lisation/building-confidence.pdf:pdf},
institution = {Leeds Metropolitan University},
pages = {29},
title = {{Building Confidence – A working paper}},
url = {https://www.leedsbeckett.ac.uk/as/cebe/projects/building-confidence.pdf},
year = {2012}
}
@article{Tian2014,
abstract = {In regression analysis, there are two main aims: interpretation and prediction, which can be also applied in building performance analysis. Interpretation is used to understand the relationship between input parameters and building energy performance (also called sensitivity analysis), whereas prediction is used to create a reliable energy model to estimate building energy consumption. This article explores the implementation of a distribution-free bootstrap method for these two purposes. The bootstrap is a resampling method that enables assessment of the accuracy of an estimator by random sampling with replacement from an original dataset. An office building is used as a case study to demonstrate the application of this method in assessing building thermal performance. The results indicate that the probabilistic sensitivity analysis incorporating the bootstrap approach provides valuable insights into the variations in sensitivity indicators, which are not available from typical deterministic sensitivity analysis. The single point values from deterministic methods may lead to misleading prioritization of energy saving measures because they do not provide the distributions of sensitivity indicators. Information on prediction errors obtained from the bootstrap method can facilitate the selection of an appropriate building energy metamodel to more accurately predict the energy consumption of buildings, compared with the traditional one-time data splitting method (also called holdout cross-validation method), which partitions the data into a training set and a test set.},
author = {Tian, Wei and Song, Jitian and Li, Zhanyong and de Wilde, Pieter},
doi = {10.1016/j.apenergy.2014.08.110},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261914009337-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Bootstrap method,Building thermal performance,Model selection,Sensitivity analysis},
pages = {320--328},
publisher = {Elsevier Ltd},
title = {{Bootstrap techniques for sensitivity analysis and model selection in building thermal performance analysis}},
url = {http://dx.doi.org/10.1016/j.apenergy.2014.08.110},
volume = {135},
year = {2014}
}
@article{Casella1992,
abstract = {Presented is the synthesis and characterization of a series of luminescent heteroleptic bis-cyclometalated platinum(IV) complexes. An oxidation-facilitated cyclometalation is employed to convert platinum(II) pendant species into bis-cyclometalated platinum(IV) dichlorides, which are transformed into the tris-chelated diimine complexes through ligand substitution. The structure-property relationship is probed by judiciously varying substituents on both the C(∧)N and the N(∧)N ligands resulting in a family of complexes exhibiting blue emission, long excited-state lifetimes, and highly efficient oxygen quenching. Excited-state properties are corroborated by static and time-dependent density-functional theory calculations of both the singlet and the triplet state.},
author = {Casella, George and George, Edward I},
doi = {10.1080/00031305.1992.10475878},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, George - 1992 - Explaining the Gibbs Sampler.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
keywords = {Data augmentation,Markov chains,Monte Carlo methods,Resampling techniques},
number = {3},
pages = {167--174},
title = {{Explaining the gibbs sampler}},
url = {http://www.jstor.org/stable/2685208 http://www.jstor.org/stable/2685208?seq=1{\&}cid=pdf-reference{\#}references{\_}tab{\_}contents http://about.jstor.org/terms},
volume = {46},
year = {1992}
}
@inproceedings{Raillon2019,
address = {Nantes},
author = {Raillon, Lo{\"{i}}c and Rouchier, Simon and Juricic, Sarah},
booktitle = {Congr{\`{e}}s fran{\c{c}}ais de thermique},
file = {:home/sarah/OneDrive/Travail/Sources/SFT article v3.pdf:pdf},
title = {{pySIP : an open-source tool for Bayesian inference and prediction of heat transfer in buildings}},
year = {2019}
}
@article{Soares2019,
abstract = {The experimental characterization of the overall thermal transmittance of homogeneous, moderately- and non-homogeneous walls, windows, and construction elements with innovative materials is very important to predict their thermal performance. It is also important to evaluate if the standard calculation methods to estimate the U-value of new and existing walls can be applied to more complex configurations, since the correct estimation of this value is a critical requirement when performing building energy simulations or energy audit. This paper provides a survey on the main methods to measure the thermal transmittance and thermal behavior of construction elements, considering laboratory conditions and in-situ non-destructive measurements. Five methods are described: the heat flow meter (HFM); the guarded hot plate (GHP); the hot box (HB), considering the guarded HB (GHB) and the calibrated HB (CHB); and the infrared thermography (IRT). Then, previous studies dedicated to the assessment of the thermal performance of different heavy- and light-weight walls are discussed. Particular attention is devoted to the measurement of the U-value of non-homogeneous walls, including the effect of thermal bridging caused by steel framing or mortar joints, and the presence of PCMs or new insulation materials in the configuration of the walls.},
author = {Soares, Nelson and Martins, Cl{\'{a}}udio and Gon{\c{c}}alves, Margarida and Santos, Paulo and da Silva, Lu{\'{i}}s Sim{\~{o}}es and Costa, Jos{\'{e}} J.},
doi = {10.1016/j.enbuild.2018.10.021},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S037877881831836X-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Calibrated hot box,Guarded hot box,Guarded hot plate,Heat flow meter,Infrared thermography,Thermal transmittance,U-value},
month = {jan},
pages = {88--110},
publisher = {Elsevier B.V.},
title = {{Laboratory and in-situ non-destructive methods to evaluate the thermal transmittance and behavior of walls, windows, and construction elements with innovative materials: A review}},
url = {https://doi.org/10.1016/j.enbuild.2018.10.021 https://linkinghub.elsevier.com/retrieve/pii/S037877881831836X},
volume = {182},
year = {2019}
}
@article{Jacquez1985,
abstract = {We define two levels of parameters. The basic parameters are associated with the model and experiment(s). However, the observations define a set of identifiable observational parameters that are functions of the basic parameters. Starting with this formulation, we show that an implicit function approach provides a common basis for examining local identifiability and estimability and gives a lead-in to the problem of optimal sampling design. A least squares approach based on a large but finite set of observations generated at initial parameter estimates then gives a uniform approach to local identifiability, estimability, and the generation of an optimal sampling schedule. ?? 1985.},
author = {Jacquez, John A. and Greif, Peter},
doi = {10.1016/0025-5564(85)90098-7},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacquez, Greif - 1985 - Numerical parameter identifiability and estimability Integrating identifiability, estimability, and optimal samp.pdf:pdf},
isbn = {0025-5564},
issn = {00255564},
journal = {Mathematical Biosciences},
keywords = {Identifiability},
mendeley-tags = {Identifiability},
number = {1-2},
pages = {201--227},
title = {{Numerical parameter identifiability and estimability: Integrating identifiability, estimability, and optimal sampling design}},
volume = {77},
year = {1985}
}
@article{Cai2016,
abstract = {— Poorly designed excitation signals could lead to in-accurate or, even worse, highly correlated parameter estimates in a data-driven model, so it is critical to have an informative training data set in order to obtain an accurate model in a cost effective manner. This paper investigates a sequential optimal design of experiments (DOE) approach to generate an optimal training data set for varying zone temperature setpoints that maximizes the accuracy of parameter estimates for an intended building model structure. This method was applied to a whole building case study in which a simplified thermal network modeling approach was adopted and the thermal parameters were estimated. The obtained optimal trajectory was always under a bang-bang type which enables an exhaustive search scheme to start the sequential design procedure. The designed excitation signals led to significant improvements in model accuracy compared to night-setup/back control strategies that are typically used to vary setpoints.},
annote = {Ref de litt [1-5] extensive research focusing on application of lumped models
Dans le cadre de mod{\`{e}}le pr{\'{e}}dictifs, l'utilisation de mod{\`{e}}les dynamiques calibr{\'{e}}s sur des donn{\'{e}}es en condition normale d'utilisation peut mener {\`{a}} une non identifiabilit{\'{e}} dans la pratique.
"Optimal experimental design" est une mani{\`{e}}re de concevoir une excitation d'entr{\'{e}}e optimale pour favoriser l'identifiabilit{\'{e}}.
Les auteurs maximisent "functional scalar of the Fisher Information Matrix" (KESAKO?)
Avant de lancer la proc{\'{e}}dure, analyse de sensibilit{\'{e}} pour {\'{e}}carter les param{\`{e}}tres sans influence --{\textgreater} Ce sont en effet des param{\`{e}}tres non-identifiable! (e qui voudrait aussi dire que le mod{\`{e}}le n'a pas {\'{e}}t{\'{e}} adapt{\'{e}} au probl{\`{e}}me...??) permet aussi de diminuer les temps de calcul (pour du MPO c'est important)


On suppose que l'estimateur n'est pas biais{\'{e}} (?) "assuming the estimator is unbiased" : ???
Matrice d'information de Fisher est donn{\'{e}}e par l'in{\'{e}}galit{\'{e}} de Cramer-Rao
La matrice de Fisher est normalis{\'{e}}e pour g{\'{e}}rer un syst{\`{e}}me {\`{a}} plusieurs {\'{e}}chelles (et {\'{e}}viter une matrice mal conditionn{\'{e}}e du fait de ces {\'{e}}chelles)


Les param{\`{e}}tres sans influence doivent {\^{e}}tre {\'{e}}cart{\'{e}}s du processus de calibration parce que le r{\'{e}}sultat serait fortement corr{\'{e}}l{\'{e}}s {\`{a}} d'autres param{\`{e}}tres, et les intervalles de confiance exploseraient. Pour analyser les param{\`{e}}tres sans influence, l'auteur utilise une analyse des composantes principales, {\`{a}} partir d'un jeu de donn{\'{e}}es pr{\'{e}}liminaire (si ce jeu de donn{\'{e}}es n'est pas assez riche, risque d'{\'{e}}carter un param{\`{e}}tres qui a une influence non n{\'{e}}gligeable...)
Pour {\'{e}}viter cela, l'auteur introduit  un indice d'identifiabilit{\'{e}} structurelle
(Voir Van Doren et al 2008)


Quand on utilise le crit{\`{e}}re d'optimisation de la trace de la matrice d'information (T-optimization), on est sur un input optimal "bang-bang" c{\`{a}}d qui alterne en format hyst{\'{e}}r{\'{e}}sis entre deux {\'{e}}tats (pas de continuit{\'{e}} de la variable d'entr{\'{e}}e d'une valeur {\`{a}} l'autre).},
author = {Cai, Jie and Kim, Donghun and Braun, James E. and Hu, Jianghai},
doi = {10.1109/ACC.2016.7525125},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2016 - Optimizing zone temperature setpoint excitation to minimize training data for data-driven dynamic building models.pdf:pdf},
isbn = {9781467386821},
issn = {07431619},
journal = {Proceedings of the American Control Conference},
pages = {1478--1484},
title = {{Optimizing zone temperature setpoint excitation to minimize training data for data-driven dynamic building models}},
volume = {2016-July},
year = {2016}
}
@misc{NREL,
author = {NREL},
title = {{Energy Plus - Testing and Validation reports on https://energyplus.net/testing}},
url = {https://energyplus.net/testing},
year = {2016}
}
@article{Goffart2017,
abstract = {Uncertainty and risk analyses are important tools for building designs and performance assessment of renewable energy systems. This task requires to account for the variability of the weather data. In this work, we develop a methodology to characterize and simulate stochastic weather data. The stochastic features of each weather input, such as auto-correlation and hourly cumulative distribution functions, are extracted from the dataset at hand. Then, the procedure of Iman and Conover is used to generate stochastic weather inputs. The approach is applied to a sequence of 1 month extracted from the typical meteorological year of the city of Lyon, France. The simulated stochastic weather data are employed to perform the uncertainty and sensitivity analysis of a real passive, low-energy house. The results show that the uncertainty on the predicted energy needs is roughly 20{\%} and is essential due to the stochastic variability of the outdoor air temperature.},
author = {Goffart, Jeanne and Mara, Thierry and Wurtz, Etienne},
doi = {10.1177/1744259116668598},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goffart, Mara, Wurtz - 2017 - Generation of stochastic weather data for uncertainty and sensitivity analysis of a low-energy building(2).pdf:pdf},
issn = {17442583},
journal = {Journal of Building Physics},
keywords = {Iman and Conover's procedure,Stochastic weather generation,building performance simulation,uncertainty and sensitivity analysis},
number = {1},
pages = {41--57},
title = {{Generation of stochastic weather data for uncertainty and sensitivity analysis of a low-energy building}},
volume = {41},
year = {2017}
}
@article{Chambers2019,
abstract = {Dwellings in the UK account for about 25{\%} of global energy demand, of which 60{\%} is space heating making this a key area for efficiency improvement. Dwelling UK Energy Performance Certificates (EPC) are currently based on surveyed data, rather than energy use monitoring. The installation of smart meters provides an opportunity to develop an EPC based on in situ dwelling thermal performance. This paper presents ‘Deconstruct' – a method of estimating the as-built Heat Power Loss Coefficient (HPLC) of occupied dwellings as a measure of thermal performance, using just smart-meter and meteorological data. Deconstruct is a steady-state grey box building model combined with a data processing pipeline and a model fitting method that limits the effects of confounding factors. Smart meter data from 780 UK dwellings from the UK Energy Demand Research Project (EDRP), was used to calculate a median HPLC of 0.28 kW/°C (±15{\%}). The stability of the estimate across multiple years of data with different weather and energy use was demonstrated. Deconstruct was found to be suitable for large scale inference of dwelling thermal properties using the UK's new smart metering data infrastructure.},
author = {Chambers, Jonathan and Oreszczyn, Tadj},
doi = {10.1016/j.enbuild.2018.11.016},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chambers, Oreszczyn - 2019 - Deconstruct A scalable method of as-built heat power loss coefficient inference for UK dwellings using smar.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building assessment methods,Building energy models,Energy demand,Residential sector,Smart meter},
pages = {443--453},
publisher = {Elsevier B.V.},
title = {{Deconstruct: A scalable method of as-built heat power loss coefficient inference for UK dwellings using smart meter data}},
url = {https://doi.org/10.1016/j.enbuild.2018.11.016},
volume = {183},
year = {2019}
}
@article{Gori2017,
abstract = {The estimation of the thermophysical characteristics of building elements based on in situ monitoring enables their performance to be assessed for quality assurance and successful decision making in pol-icy making, building design, construction and refurbishment. Two physically-informed lumped thermal mass models, together with Bayesian statistical analysis of temperature and heat flow measurements, are presented to derive estimates of the thermophysical properties of a wall. The development of a two thermal mass, three thermal resistance model (2TM) enabled the thermal structure of the wall to be inves-tigated and related to the known physical structure of two heavy-weight walls of different construction: a solid brick wall and an aerated clay, plaster, woodfibre insulation and gypsum fibreboard wall. The 2TM model produced good match to the measured heat flux at both interior and exterior surfaces for both walls, unlike a one thermal mass model (1TM); Bayesian model comparison strongly supported the 2TM over the 1TM model to accurately describe the observed data. Characterisation of the thermal structure and performance of building elements prior to decision making in interventions will support the devel-opment of tailored solutions to maximise thermal comfort and minimise energy use through insulation, heating and cooling strategies.},
author = {Gori, Virginia and Marincioni, Valentina and Biddulph, Phillip and Elwell, Clifford A},
doi = {10.1016/j.enbuild.2016.10.043},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gori et al. - 2017 - Inferring the thermal resistance and effective thermal mass distribution of a wall from in situ measurements to cha.pdf:pdf},
journal = {Energy {\&} Buildings},
keywords = {Bay{\'{e}}sien,Building component,RC,inverse problem},
mendeley-tags = {Bay{\'{e}}sien,Building component,RC,inverse problem},
pages = {398--409},
title = {{Inferring the thermal resistance and effective thermal mass distribution of a wall from in situ measurements to characterise heat transfer at both the interior and exterior surfaces}},
url = {http://ac.els-cdn.com/S0378778816313056/1-s2.0-S0378778816313056-main.pdf?{\_}tid=e47e4e00-5b37-11e7-bd06-00000aacb360{\&}acdnat=1498568307{\_}663e3986038644ca0ed34bdeec180aa7},
volume = {135},
year = {2017}
}
@article{Icard2018,
abstract = {While Bayesian models have been applied to an impressive range of high-level cognitive phenomena in recent years, methodological challenges have been leveled concerning their particular use in cognitive science, and specifically their role in the program of rational analysis. The focus of the present article is on one strand of these criticisms, namely, computational impediments to probabilis-tic inference, and related puzzles about empirical confirmation of these models. The proposal is to rethink the role of Bayesian methods in rational analysis, and specifically to adopt an independently motivated notion of rationality appropriate for computationally bounded agents, and then to explore broad conditions under which (approximately) Bayesian agents would in fact be rational. The proposal is illustrated with a characterization of computational costs in an abstract manner inspired by ideas in thermodynamics and information theory.},
author = {Icard, Thomas F},
doi = {10.1086/694837},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Icard - 2017 - Bayes, Bounds, and Rational Analysis.pdf:pdf},
issn = {00318248},
journal = {Philosophy of Science},
number = {1},
pages = {79--101},
title = {{Bayes, bounds, and rational analysis}},
url = {https://web.stanford.edu/{~}icard/BBRA.pdf},
volume = {85},
year = {2018}
}
@book{Tarantola2004,
abstract = {"The book is directed to all scientists, including applied mathematicians, facing the problem of quantitative interpretation of experimental data in fields such as physics, chemistry, biology, image processing, and information sciences. Considerable effort has been made so that this book can serve either as a reference manual for researchers or as a textbook in a course for undergraduate or graduate students."--Jacket. General discrete inverse problem -- Monte Carlo methods -- Least-squares criterion -- Least-absolute-values criterion and minimax criterion -- Functional inverse problems -- Appendices -- Problems.},
annote = {From Duplicate 2 (Inverse problem theory and methods for model parameter estimation - Tarantola, Albert)

Livre BU Grenoble - Math{\'{e}}matiques RDC Sud - 519.24 TAR

Chap 1 :
"Concept of 'State of information', described by a probability density over the parameter space." The general inverse problem may be set as a problem of combining all different probability densities."
Let S be a physical system :
- parametrization of the system = determine a minimal set of parameters that completely characterise the system from a given point of view.
- forward modeling : physical laws that allow us to make predictions on the results of measurements of some observable variables
- inverse problem : sue the actual measurements of the observable variables to infer actual values of model parameters
--{\textgreater} A model fit for forward modelling might be not fit for solving the inverse problem !

Metropolis Hastings algortihm :
" It is a Markov Chain Monte Carlo, i.e. it is random (monte carlo) and has no memory (markov chain). basic idea is o perform a random walk (sort of brownian motion), that, if unmodified, would sample the initial probability distribution, then using a probabilistic rule to modify the walk (some moves are accepted, some are rejected), in such way that the walk samples the target distribution. There exists many prob rules, but the most efficient is the Metropolis rule.

Genetic algorithms do not sample the posteriori distribution, thus are not interesting for our problem. (chap 2.3.6)

Gibbs sampler : no rejection of candidates (chap 2.3.4) Tarentalo says to be not convinced of its superiority in cas of solving inverse problems.

On the difficulties of random walks (chap 2.4)
- problem 1 : if the samples of the priori distribution presented to the metropolis algo are not independent, the samples of the posterior will not be independent. It is necessary to not take all the samples produced by the algorithm in consideration. Instead, it is wise to "wait" until a sufficient number of moves has been made to hope that the algorithm has forgotten the sample. IE not take every candidate of the trace.
- problem 2 : compromise between need to move rapidly in the model space and the need of the metropolis algorithm to accept some of the candidates. The size of the perturbations has to be such that the acceptance rate is 30-50{\%}. If larger, we are not moving fast enough. If lower, waste of computer resources to test models not accepted. Balance between extensive exploration of the space (large steps but low acceptance) and careful sampling of located probability maxima (small steps, few rejects, but slow walk).
- problem 3 : when to stop the walk (ie when have we sufficiently sampled the posterior?). Easy part : rules of thumb to decide if a given maximum has been sufficiently sampled. Difficult part : if maximum not known the algorithm might completely miss some isolated region of significant probability. Very acute in highly non linear problems (decide for every case if the risk is high).
- comment : computational cost might be high

Chap 3 : On least squares criterion
easiest computations, lack of robustness (sensitivity to a small numbers of large errors ina data set)

Chap 7.8
The condition number : it gives less information than the covariance operator because it only gives information about the ratio between the largest and the shortest diameters of the ellipsoid of uncertainties in the model space.
!!! A careful analysis of the a posteriori cov operator mus always be made when solving least-squares inverse problems.},
author = {Tarantola, Albert},
doi = {10.1137/1.9780898717921},
file = {:home/sarah/OneDrive/Travail/Sources/Probl{\`{e}}mes inverses/Inverse Problem Theory and Methods for Model Parameter Estimation by Albert Tarantola (z-lib.org).pdf:pdf},
isbn = {978-0-89871-572-9},
month = {jan},
pages = {1--358},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Inverse Problem Theory and Methods for Model Parameter Estimation}},
url = {http://www.ipgp.fr/{~}tarantola/Files/Professional/SIAM/InverseProblemTheory.pdf{\%}0Apapers2://publication/uuid/62A7A164-F0E3-4298-AA2B-222FF673BF4E http://epubs.siam.org/doi/book/10.1137/1.9780898717921},
year = {2005}
}
@article{Baldwin1990,
author = {Baldwin, R L and Hanigan, M D},
doi = {10.1016/j.cmpb.2007.07.002.DAISY},
keywords = {Systems theory,agriculture,agroecosystems,animal feeding,animal management,animal metabolism,animal nutrition,dairy,energetics,farming systems,food,livestock,models,nutrients,protein,ruminants},
number = {1},
pages = {1--21},
title = {{Biological and physiological systems: animal sciences}},
volume = {88},
year = {1990}
}
@article{Schoups2010,
abstract = {[1] Estimation of parameter and predictive uncertainty of hydrologic models has traditionally relied on several simplifying assumptions. Residual errors are often assumed to be independent and to be adequately described by a Gaussian probability distribution with a mean of zero and a constant variance. Here we investigate to what extent estimates of parameter and predictive uncertainty are affected when these assumptions are relaxed. A formal generalized likelihood function is presented, which extends the applicability of previously used likelihood functions to situations where residual errors are correlated, heteroscedastic, and non‐Gaussian with varying degrees of kurtosis and skewness. The approach focuses on a correct statistical description of the data and the total model residuals, without separating out various error sources. Application to Bayesian uncertainty analysis of a conceptual rainfall‐runoff model simultaneously identifies the hydrologic model parameters and the appropriate statistical distribution of the residual errors. When applied to daily rainfall‐runoff data from a humid basin we find that (1) residual errors are much better described by a heteroscedastic, first‐order, auto‐correlated error model with a Laplacian distribution function characterized by heavier tails than a Gaussian distribution; and (2) compared to a standard least‐squares approach, proper representation of the statistical distribution of residual errors yields tighter predictive uncertainty bands and different parameter uncertainty estimates that are less sensitive to the particular time period used for inference. Application to daily rainfall‐runoff data from a semiarid basin with more significant residual errors and systematic underprediction of peak flows shows that (1) multiplicative bias factors can be used to compensate for some of the largest errors and (2) a skewed error distribution yields improved estimates of predictive uncertainty in this semiarid basin with near‐zero flows. We conclude that the presented methodology provides improved estimates of parameter and total prediction uncertainty and should be useful for handling complex residual errors in other hydrologic regression models as well. Citation: Schoups, G., and J. A. Vrugt (2010), A formal likelihood function for parameter and predictive inference of hydrologic models with correlated, heteroscedastic, and non‐Gaussian errors, Water Resour. Res., 46, W10531,},
author = {Schoups, Gerrit and Vrugt, Jasper A},
doi = {10.1029/2009WR008933},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schoups, Vrugt - 2010 - A formal likelihood function for parameter and predictive inference of hydrologic models with correlated, hetero.pdf:pdf},
issn = {00431397},
journal = {Water Resources Research},
month = {oct},
number = {10},
title = {{A formal likelihood function for parameter and predictive inference of hydrologic models with correlated, heteroscedastic, and non-Gaussian errors}},
url = {http://faculty.sites.uci.edu/jasper/files/2016/04/61.pdf http://doi.wiley.com/10.1029/2009WR008933},
volume = {46},
year = {2010}
}
@article{Jiang2015,
abstract = {In physics-based engineering modeling and uncertainty quantification, distinguishing the effects of two main sources of uncertainty — calibration parameter uncertainty and model discrepancy — is challenging. Previous research has shown that identifiability, which is quantified by the posterior covariance of the calibration parameters, can sometimes be improved by experimentally measuring multiple responses of the system that share a mutual dependence on a com-mon set of calibration parameters. In this paper, we address the issue of how to select the most appropriate subset of responses to measure experimentally, to best enhance identifiability. We use a preposterior analysis approach that, prior to conducting physical experiments but after conducting computer simulations, can predict the degree of identifiability that will result using different subsets of responses to measure experimentally. It predicts identifiability via the pre-posterior covariance from a modular Bayesian Monte Carlo analysis of a multi-response spatial random process (SRP) model. Furthermore, to handle the computational challenge in preposterior analysis, we propose a surrogate preposte-rior analysis based on Fisher information of the calibration parameters. The proposed methods are applied to a simply supported beam example to select two out of six responses to best improve identifiability. The estimated preposterior covariance is compared to the actual posterior covariance to demonstrate the effectiveness of the methods.},
author = {Jiang, Zhen and Apley, Daniel W and Chen, Wei},
doi = {10.1615/Int.J.UncertaintyQuantification.2015012627},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Apley, Chen - 2015 - SURROGATE PREPOSTERIOR ANALYSES FOR PREDICTING AND ENHANCING IDENTIFIABILITY IN MODEL CALIBRATION.pdf:pdf},
issn = {21525099},
journal = {International Journal for Uncertainty Quantification},
keywords = {Bayesian inference,Model calibration,Parameter estimation,Uncertainty quantification},
number = {4},
pages = {341--359},
title = {{Surrogate preposterior analyses for predicting and enhancing identifiability in model calibration}},
url = {http://ideal.mech.northwestern.edu/},
volume = {5},
year = {2015}
}
@article{Ljung1994,
author = {Ljung, Lennart and Glad, Torkel},
doi = {10.1016/0005-1098(94)90029-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ljung, Glad - 1994 - On global identifiability for arbitrary model parametrizations.pdf:pdf},
issn = {00051098},
journal = {Automatica},
month = {feb},
number = {2},
pages = {265--276},
title = {{On global identifiability for arbitrary model parametrizations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0005109894900299},
volume = {30},
year = {1994}
}
@unpublished{Kennedy,
abstract = {We provide more detail of the mathematical development involved in the Bayesian calibration methods of Kennedy and O'Hagan (2000), and we present a further example using data from a simulated accident assessment exercise. 1. Introduction We assume the reader is already familiar with the concepts and notation of Kennedy and O'Hagan (2000). We begin by deriving the posterior distribution of the calibration param-eters in Section 2. In Section 3 we discuss the estimation of hyperparameters involved in the model. Section 4 deals with details on calibration, calibrated prediction and calibrated uncertainty analysis. In Section 5 we investigate the sensitivity of our results to some of the model assumptions. Computational issues are discussed in Section 6, and in Section 7 we describe an example.},
author = {Kennedy, Marc C and {O 'hagan}, Anthony},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy, O 'hagan - Unknown - Supplementary details on Bayesian Calibration of Computer Models.pdf:pdf},
pages = {2000},
title = {{Supplementary details on Bayesian Calibration of Computer Models}},
url = {https://pdfs.semanticscholar.org/e23b/ccc73c010bc473b5c22b041388830f937280.pdf}
}
@article{Antonopoulos1999,
abstract = {The real or effective thermal capacitance of buildings quantifies the energy stored within and differs considerably from the apparent thermal capacitance, which results by adding distributed specific heats of building elements into a lumped value. In the present study, a method is developed for analyzing the total effective capacitance into components concerning the building envelope or parts of it (e.g. ceiling, floor, etc.), the interior partitions, the furnishings, etc. The developed procedure is based on a finite-difference solution of a set of differential equations describing the transient heat conduction in all elements of a building. Applications are made to 21 types of buildings with 15 and 10 wall and roof compositions, respectively, and floor area from 50 m 2 to 2500 m 2. For example, it is found that for typical fully-insulated, one-storey, detached houses, the envelope, interior partitions and furnishings effective heat capacitances are 78.1{\%}, 14.5{\%} and 7.4{\%}, respectively, of the total effective thermal capacitance. Also, a correlation is developed, which links the effective to the easily-calculated apparent thermal capacitance of buildings.},
author = {Antonopoulos, K A and Koronaki, E},
doi = {10.1016/S1359-4311(98)00080-5},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antonopoulos, Koronaki - 1999 - Envelope and indoor thermal capacitance of buildings.pdf:pdf},
isbn = {13594311 (ISSN)},
issn = {13594311},
journal = {Applied Thermal Engineering},
keywords = {building envelope,building interior partitions,capacitance,components of thermal capacitance,e,ective and apparent thermal,thermal capacitance},
number = {7},
pages = {743--756},
title = {{Envelope and indoor thermal capacitance of buildings}},
volume = {19},
year = {1999}
}
@article{Buttitta2019,
abstract = {Building stock modelling usually deploys representative building archetypes to obtain reliable results of annual energy heating demand and to minimise the associated computational cost. Available methodologies define archetypes considering only the physical characteristics of buildings. Uniform occupancy schedules, which correspond to national averages, are generally used in archetype energy simulations, despite evidence of occupancy schedules which can vary considerably for each building. This paper presents a new methodology to define occupancy-integrated archetypes. The novel feature of these archetype models is the integration of different occupancy schedules within the archetype itself. This allows building stock energy simulations of national population subgroups characterised by specific occupancy profiles to be undertaken. The importance of including occupant-related data in residential archetypes, which is different than the national average, is demonstrated by applying the methodology to the UK national building stock. The resultant occupancy-integrated archetypes are then modelled to obtain the annual final heating energy demand. It is shown that the relative difference between the heating demand of occupancy-integrated archetypes and uniform occupancy archetypes can be up to 30{\%}.},
author = {Buttitta, Giuseppina and Turner, William J.N. and Neu, Olivier and Finn, Donal P.},
doi = {10.1016/j.enbuild.2019.05.056},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S037877881833559X-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Archetypes,K-mode clustering,Occupancy profiles,Residential buildings,Stock modelling},
month = {sep},
pages = {84--99},
publisher = {Elsevier B.V.},
title = {{Development of occupancy-integrated archetypes: Use of data mining clustering techniques to embed occupant behaviour profiles in archetypes}},
url = {https://www-sciencedirect-com.camphrier-1.grenet.fr/science/article/pii/S037877881833559X https://doi.org/10.1016/j.enbuild.2019.05.056 https://linkinghub.elsevier.com/retrieve/pii/S037877881833559X},
volume = {198},
year = {2019}
}
@article{Jia2018,
abstract = {a b s t r a c t An efficient Bayesian analytical framework was developed to address the challenges of uncertainty analysis and assess the parameter identification problems of complex water quality models with high-dimensional parameter space. The inclusion of a multi-chain Markov Chain Monte Carlo method and comprehensive global sensitive analysis (GSA) guarantees the results to be robust. A high-frequency synthetic data case study was conducted in the EFDC water quality module including 54 parameters. The comprehensive GSA identified 39 completely or partially sensitive parameters for reducing dimensionality, among which only nine were identifiable without significant bias. The fundamental causes of the parameter identification problem could be traced to the cognitive limitations of the real water quality assessment process instead of data scarcity. The framework is powerful for exploring these limitations, generating reminders for model users to use Bayesian estimates in future forecasts, and providing directions for model developers to perfect a model in future work.},
author = {Jia, Haifeng and Xu, Te and Liang, Shidong and Zhao, Pei and Xu, Changqing},
doi = {10.1016/j.envsoft.2018.03.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2018 - Bayesian framework of parameter sensitivity, uncertainty, and identifiability analysis in complex water quality m(2).pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling {\&} Software},
keywords = {High dimension,Identifiability,Parameter,Sensitivity,Uncertainty,Water quality model},
month = {jun},
pages = {13--26},
title = {{Bayesian framework of parameter sensitivity, uncertainty, and identifiability analysis in complex water quality models}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S1364815217305947/1-s2.0-S1364815217305947-main.pdf?{\_}tid=433b5e7a-337f-467d-8a46-562ae2151c46{\&}acdnat=1522045074{\_}ed0d7fce455eb16c4479d915352d44bf https://linkinghub.elsevier.com/retrieve/pii/S1364815217305947},
volume = {104},
year = {2018}
}
@article{Thebault2018a,
abstract = {In the construction sector, strong efforts are being made to reduce energy consumption in buildings, particularly regarding thermal insulation in northern countries. However, the objectives set for the thermal insulation performance of the building envelopes are rarely achieved in practice. For this reason, there is increasing interest in taking onsite measurements. This paper presents the new achievements obtained by the ISABELE (In Situ Assessment of the Building EnveLope pErformances) method for data treatment to evaluate the global transmission heat transfer coefficient of a building with a consolidated uncertainty and within a short unoccupied period. Most of the work relates to the quantification and propagation of systematic errors and to the adaptation of the thermal model used for the inverse method. Practical applications on a test cell and a demonstration on a low-energy house in real outdoor conditions are presented, as are comparisons with other measurement methods (coheating, Quick U-Value of Buildings (QUB)) and the resulting calculated parameters, which show coherent outcomes. The test cell results reveal that a stabilized, repeatable measure with an acceptable uncertainty range (± 10 {\%} in average) can be obtained within 2 days. The house results are slightly less precise (± 15-20 {\%}) but can be obtained just as quickly, assuming that both configurations are insulated from the inside.},
author = {Th{\'{e}}bault, Simon and Bouchi{\'{e}}, R{\'{e}}mi},
doi = {10.1016/j.enbuild.2018.08.047},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Th{\'{e}}bault, Bouchi{\'{e}} - 2018 - Refinement of the ISABELE method regarding uncertainty quantification and thermal dynamics modelling.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778818307722-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building envelope,Construction diagnostics,Heat transfer coefficient,In situ measurement,Thermal insulation,Uncertainty},
month = {nov},
pages = {182--205},
title = {{Refinement of the ISABELE method regarding uncertainty quantification and thermal dynamics modelling}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818307722},
volume = {178},
year = {2018}
}
@article{Sobol1999,
abstract = {First report of an attempt to apply variance reducing multipliers in Monte Carlo estimations of global sensitivity indices.},
author = {Sobol', I.M. and Levitan, Yu.L.},
doi = {10.1016/S0010-4655(98)00156-8},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sobol', Levitan - 1999 - On the use of variance reducing multipliers in Monte Carlo computations of a global sensitivity index.pdf:pdf},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {Ishigami},
mendeley-tags = {Ishigami},
month = {mar},
number = {1-2},
pages = {52--61},
title = {{On the use of variance reducing multipliers in Monte Carlo computations of a global sensitivity index}},
url = {http://www.andreasaltelli.eu/file/repository/Sobol{\_}Levitan{\_}1999.pdf http://linkinghub.elsevier.com/retrieve/pii/S0010465598001568},
volume = {117},
year = {1999}
}
@article{Gelfand1992,
abstract = {Constrained parameter problems arise in a wide variety of applications, including bioassay, actuarial graduation, ordinal categoric data, response surfaces, reliability development testing, and variance component models. Truncated data problems arise naturally in survival and failure time studies, ordinal data models, and categorical data studies aimed at uncovering underlying continuous distributions. In many applications both parameter constraints and data truncation are present. The statistical literature on such problems is very extensive, reflecting both the problems' widespread occurrence in applications and the methodological challenges that they pose. However, it is striking that so little of this applied and theoretical literature involves a parametric Bayesian perspective. From a technical viewpoint, this perhaps is not difficult to understand. The fundamental tool for Bayesian calculations in typical realistic models is (multidimensional) numerical integration, which often is problematic in unconstrained contexts and can be well-nigh impossible for the kinds of constrained problems we consider. In this article we show that Bayesian calculations can be implemented routinely for constrained parameter and truncated data problems by means of the Gibbs sampler. Specific models discussed include constrained multinormal parameters, constrained linear model parameters, ordered parameters in experimental family models, data and order restricted parameters from exponential distributions, straight line regression with censoring and bivariate grouped data models. Analysis of data sets illustrating the first two of these settings is provided. Constrained parameter problems arise in a wide variety of applications, including bioassay, actuarial graduation, or-dinal categorical data, response surfaces, reliability devel-opment testing, and variance component models. Truncated data problems-to be understood as encompassing both censoring and scoring or grouping mechanisms-arise nat-urally in survival and failure time studies, ordinal data mod-els, and categorical data studies aimed at uncovering under-lying continuous distributions. In many applications both parameter constraints and data truncation occur. The parametric Bayes perspective is attractive for exam-ining such models. For example, consider ordered parameter (slippage) models, which in a classical setting might employ isotonic regression of maximum likelihood estimates to ob-tain point estimates. A more satisfying analysis would de-velop and compare posterior distributions arising from priors (possibly vague) that reflect the order restrictions. However, analytic approaches (exact or approximate) for carrying out required multi dimensional integrations in this case (and in fact for all the aforementioned problems) will be well-nigh impossible. This article aims to show that Bayesian calculations can be implemented routinely for constrained parameter and truncated data problems by means of the Gibbs sampler. The Gibbs sampler was introduced by Geman and Geman (1984) in the context of image processing, see also Hastings (1970) for an early recognition. Later, it was proposed as a general method for Bayesian calculations by Gelfand and Smith (1990). In general we shall assume that the desired outcome of a Bayesian analysis is the calculation and display of marginal posterior (predictive) densities of parameters (unobserved},
author = {Gelfand, Alan E and Smith, Adrian F M and Lee, Tai-Ming},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelfand, Smith, Lee - 1992 - Bayesian Analysis of Constrained Parameter and Truncated Data Problems Using Gibbs Bayesian Analysis of Con.pdf:pdf},
journal = {Source Journal of the American Statistical Association},
keywords = {Bayesian inference,Constrained parameters,Gibbs sampler,Gibbs sampling,Truncated data},
mendeley-tags = {Gibbs sampling},
number = {418},
pages = {523--532},
title = {{Bayesian Analysis of Constrained Parameter and Truncated Data Problems Using Gibbs Bayesian Analysis of Constrained Parameter and Truncated Data Problems Using Gibbs Sampling}},
url = {http://www.jstor.org/stable/2290286 http://about.jstor.org/terms},
volume = {87},
year = {1992}
}
@article{Kennedy2001,
abstract = {We consider prediction and uncertainty analysis for systems which are approximated using complex mathematical models. Such models, implemented as computer codes, are often generic in the sense that by a suitable choice of some of the model's input parameters the code can be used to predict the behaviour of the system in a variety of specific applications. However, in any specific application the values of necessary parameters may be unknown. In this case, physical observations of the system in the specific context are used to learn about the unknown parameters. The process of fitting the model to the observed data by adjusting the parameters is known as calibration. Calibration is typically effected by ad hoc fitting, and after calibration the model is used, with the fitted input values, to predict the future behaviour of the system. We present a Bayesian calibration technique which improves on this traditional approach in two respects. First, the predictions allow for all sources of uncertainty, including the remaining uncertainty over the fitted parameters. Second, they attempt to correct for any inadequacy of the model which is revealed by a discrepancy between the observed data and the model predictions from even the best-fitting parameter values. The method is illustrated by using data from a nuclear radiation release at Tomsk, and from a more complex simulated nuclear accident exercise.},
annote = {From Duplicate 1 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

From Duplicate 3 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

From Duplicate 2 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

Uncertainties in computer models:
- parameter uncertainty : 
- model inadequacy (model-form error?!) no model is perfect
- residual variability
- observation error
- parametric variability
- code uncertainty
-----------------
Incertitudes dans les mod{\`{e}}les :
- incertitudes sur les param{\`{e}}tres : toutes les entr{\'{e}}es du mod{\`{e}}le
- mod{\`{e}}le : aucun mod{\`{e}}le ne traduit fid{\`{e}}lement la r{\'{e}}alit{\'{e}}. Ces simplifications le rendent imparfait
- variabilit{\'{e}} du r{\'{e}}siduel
- variabilit{\'{e}} param{\'{e}}trique
- incertitude sur les mesures
- incertitude du codage


Article traite uniquement la calibration du code {\`{a}} partir d'observations.
Le code a {\'{e}}t{\'{e}} consid{\'{e}}r{\'{e}} comme bo{\^{i}}te noire, 




formulation math{\'{e}}matiques de calibration bay{\'{e}}sienne
Ref trouv{\'{e}}e dans Heo et al (2012)

From Duplicate 4 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

From Duplicate 1 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

Uncertainties in computer models:
- parameter uncertainty : 
- model inadequacy (model-form error?!) no model is perfect
- residual variability
- observation error
- parametric variability
- code uncertainty

From Duplicate 2 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

From Duplicate 2 (Bayesian Calibration of Computer Models - Kennedy, Marc C; O'Hagan, Anthony)

Uncertainties in computer models:
- parameter uncertainty : 
- model inadequacy (model-form error?!) no model is perfect
- residual variability
- observation error
- parametric variability
- code uncertainty
-----------------
Incertitudes dans les mod{\`{e}}les :
- incertitudes sur les param{\`{e}}tres : toutes les entr{\'{e}}es du mod{\`{e}}le
- mod{\`{e}}le : aucun mod{\`{e}}le ne traduit fid{\`{e}}lement la r{\'{e}}alit{\'{e}}. Ces simplifications le rendent imparfait
- variabilit{\'{e}} du r{\'{e}}siduel
- variabilit{\'{e}} param{\'{e}}trique
- incertitude sur les mesures
- incertitude du codage


Article traite uniquement la calibration du code {\`{a}} partir d'observations.
Le code a {\'{e}}t{\'{e}} consid{\'{e}}r{\'{e}} comme bo{\^{i}}te noire, 




formulation math{\'{e}}matiques de calibration bay{\'{e}}sienne
Ref trouv{\'{e}}e dans Heo et al (2012)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Kennedy, Marc C and O'Hagan, Anthony},
doi = {10.1111/1467-9868.00294},
eprint = {arXiv:1011.1669v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy, O'Hagan - 2001 - Bayesian Calibration of Computer Models(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy, O'Hagan - 2001 - Bayesian Calibration of Computer Models.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennedy, O'Hagan - 2001 - Bayesian Calibration of Computer Models(3).pdf:pdf},
isbn = {1369-7412},
issn = {13697412, 14679868},
journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
keywords = {calibration,computer experiments,deterministic models,gaussian process,interpolation,model inadequacy,sensitivity analysis,uncertainty analysis},
number = {3},
pages = {425--464},
pmid = {3290900},
title = {{Bayesian Calibration of Computer Models}},
url = {http://www.jstor.org/stable/2680584},
volume = {63},
year = {2001}
}
@unpublished{Rouchier2016,
author = {Rouchier, Simon},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier - 2016 - Caract{\'{e}}risation de param{\`{e}}tres et analyse d'identifiabilit{\'{e}} par m{\'{e}}thode Bay{\'{e}}sienne appliqu{\'{e}}e au b{\^{a}}timent.pdf:pdf},
pages = {1--15},
title = {{Caract{\'{e}}risation de param{\`{e}}tres et analyse d'identifiabilit{\'{e}} par m{\'{e}}thode Bay{\'{e}}sienne appliqu{\'{e}}e au b{\^{a}}timent}},
year = {2016}
}
@article{InternationalOrganizationforStandardization1987,
author = {{International Organization for Standardization}},
title = {{Isolation thermique : Grandeurs physiques et d{\'{e}}finitions}},
url = {https://www.iso.org/fr/standard/14024.html},
volume = {ISO 7345:1},
year = {1987}
}
@article{Walter2008,
abstract = {Identification is more an art form than an exact science, and it is based on intuition just as much as on a large variety of techniques. Tradition is a major factor, and customs that may only have history as a justification should be questioned. Examples are the confidence bestowed on classical mathematical formulas even when they turn out not to be suited for com- puter implementation, the quasi-exclusive role played by the minimization of quadratic cost functions, the use of finite-difference approximations for the computation of gradients, the al- most exclusive resort to local, non-guaranteed techniques for the identification and simulation of nonlinear models. For all of these topics, alternative approaches are suggested.},
author = {Walter, Eric and Kieffer, Michel and Walter, Eric and Kieffer, Michel and Walter, Eric and Kieffer, Michel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter et al. - 2008 - Sur quelques id{\'{e}}es fausses ayant des cons{\'{e}}quences en identification.pdf:pdf},
journal = {Journal europ{\'{e}}en des syst{\`{e}}mes automatis{\'{e}}s},
keywords = {adjoint code,automatic differentiation,global optimisation,interval analysis,least squares,outliers,robust estimation},
mendeley-tags = {adjoint code,automatic differentiation,global optimisation,interval analysis,least squares,outliers,robust estimation},
number = {2-3},
pages = {181--210},
title = {{Sur quelques id{\'{e}}es fausses ayant des cons{\'{e}}quences en identification}},
volume = {42},
year = {2008}
}
@article{Bastogne2007a,
abstract = {This paper deals with parameter selection and estimation of large and complex simulation models. This estimation problem is addressed in the case of passive observation, i.e. when no controlled experiment is possible. Given the lack of information in the data, an appropriate methodology is proposed to select and estimate some physical parameters of the model. Its implementation is based on a new software: Diffedge?? which makes it possible to symbolically determine model output sensitivity functions of block diagrams. An application to a winding prototype is developed to illustrate the effectiveness of such an approach in practice. ?? 2007 Elsevier Ltd. All rights reserved.},
annote = {Question de l'estimation de param{\`{e}}tres dans le cadre d'une exp{\'{e}}rience dont on ne ma{\^{i}}trise pas les entr{\'{e}}es.

Le terme "Calibration" est g{\'{e}}n{\'{e}}ralement abusivement utilis{\'{e}} : calibration signifie ajustement de param{\`{e}}tres en comparaison {\`{a}} une norme, un standard, sous-entendu norme non bruit{\'{e}}e.

Trois parties {\`{a}} la contribution de l'article :
- relation entre l'identifiabilit{\'{e}} pratique et la discernabilit{\'{e}} des sorties
- nouvelle m{\'{e}}thode de s{\'{e}}lection pour d{\'{e}}signer les param{\`{e}}tres les plus identifiables
- solution trouv{\'{e}}e par le logiciel DiffEdge (d{\'{e}}termine symboliquement les fonctions de sensibilit{\'{e}} des sorties de diagrammes en bloc)

Dans la m{\'{e}}thodo d'identification
- analyse a priori : attribuer des valeur aux param{\`{e}}tres, avec une incertitude associ{\'{e}}e. Pour l'incertitude, les auteurs citent Brun et al (2002) deux classes d'incertitude relative : param{\`{e}}tres connus pr{\'{e}}cis{\'{e}}ment (classe 1) et param{\`{e}}tres vaguement connus (classe 2).
- impl{\'{e}}mentation dans Simulink (orient{\'{e}} objet de MatLab)
- outil DiffEdge pour analyse d'identifiabilit{\'{e}} pratique
- diff{\'{e}}rencier les param{\`{e}}tres d'influence n{\'{e}}gligeable et corr{\'{e}}l{\'{e}}s entre eux.

Conclusion, dans le cas de conditions exp{\'{e}}rimentales non contr{\^{o}}l{\'{e}}es, il faut v{\'{e}}rifier l'unicit{\'{e}} de la solution {\'{e}}tant donn{\'{e}}es les donn{\'{e}}es de mesure (examiner l'identifiabilit{\'{e}} pratique) et s{\'{e}}lectionner les param{\`{e}}tres les plus identifiables avant de proc{\'{e}}der {\`{a}} l'estimation des param{\`{e}}tres.},
author = {Bastogne, Thierry and Thomassin, Magalie and Masse, J.},
doi = {10.1016/j.conengprac.2006.12.006},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastogne, Thomassin, Masse - 2007 - Selection and identification of physical parameters from passive observation. Application to a windi.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Identifiability,Limited experimentation,Parameter identification,Parameter selection,Sensitivity analysis,Winding system},
number = {9},
pages = {1051--1061},
title = {{Selection and identification of physical parameters from passive observation. Application to a winding process}},
volume = {15},
year = {2007}
}
@article{Asiri2015,
abstract = {{\textcopyright} 2015 Sharefa Asiri et al.Observers are well known in control theory. Originally designed to estimate the hidden states of dynamical systems given some measurements, the observers scope has been recently extended to the estimation of some unknowns, for systems governed by partial differential equations. In this paper, observers are used to solve inverse source problem for a one-dimensional wave equation. An adaptive observer is designed to estimate the state and source components for a fully discretized system. The effectiveness of the algorithm is emphasized in noise-free and noisy cases and an insight on the impact of measurements' size and location is provided.},
author = {Asiri, Sharefa and Zayane, Chadia and Laleg-Kirati, Taous Meriem},
doi = {10.1155/2015/796539},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asiri, Zayane, Laleg-Kirati - 2015 - An Adaptive Observer-Based Algorithm for Solving Inverse Source Problem for the Wave Equation.pdf:pdf},
issn = {15635147},
journal = {Mathematical Problems in Engineering},
title = {{An Adaptive Observer-Based Algorithm for Solving Inverse Source Problem for the Wave Equation}},
volume = {2015},
year = {2015}
}
@article{Vajda1989,
abstract = {Through use of the local state isomorphism theorem instead of the algebraic equiva-lence theorem of linear systems theory, the similarity transformation approach is extended to nonlinear models, resulting in finitely verifiable sufficient and necessary conditions for global and local identifiability. The approach requires testing of certain controllability and observability conditions, but in many practical examples these conditions prove very easy to verify. In principle the method also involves nonlinear state variable transformations, but in all of the examples presented in the paper the transformations turn out to be linear. The method is applied to an unidentifiable nonlinear model and a locally identifiable nonlinear model, and these are the first nonlinear models other than bilinear models where the reason for lack of global identifiability is nontrivial. The method is also applied to two models with Michaelis-Menten elimination kinetics, both of considerable importance in pharmacokinetics, and for both of which the complicated nature of the algebraic equations arising from the Taylor series approach has hitherto defeated attempts to establish identifiability results for specific input functions.},
author = {Vajda, Sandor and Godfrey, Keith Richard and Rabitz, Herschel},
doi = {10.1016/0025-5564(89)90024-2},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vajda, Godfrey, Rabitz - 1989 - Similarity transformation approach to identifiability analysis of nonlinear compartmental models.pdf:pdf},
issn = {00255564},
journal = {Mathematical Biosciences},
month = {apr},
number = {2},
pages = {217--248},
title = {{Similarity transformation approach to identifiability analysis of nonlinear compartmental models}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0025556489900242},
volume = {93},
year = {1989}
}
@book{Box1992,
author = {Box, George E.P. and Tiao, George C.},
booktitle = {A Wiley-Interscience Publication},
doi = {10.1002/9781118033197},
editor = {{John Wiley and sons inc}},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Box, Tiao - 1992 - Bayesian Inference in Statistical Analysis.pdf:pdf},
isbn = {9781118033197},
keywords = {Jeffrey's prior,bayesian},
mendeley-tags = {Jeffrey's prior,bayesian},
pages = {608},
title = {{Bayesian Inference in Statistical Analysis}},
url = {http://doi.wiley.com/10.1002/9781118033197},
year = {1992}
}
@article{Day2004,
abstract = {The use of degree-days in building energy monitoring and targeting has often given rise to misinterpretation of results, which has in turn undermined confidence in such techniques. Anecdotal reporting has, by turns, suggested the use of degree-days either works very well, or does not work at all. This ambiguous position is not helpful to energy managers who need robust tools and clear guidance on their use. This paper presents evidence to show how energy/degree-day correlations i.e., building performance lines, can be properly identified, while taking account of the correct (and practical) energy balance of the building. In doing so it shows how the correct building base temperature can be identified from reduced data sets, while demonstrating that such a practice is desirable. Performance lines constructed in this way, where appropriate, give rise to greater accuracy and reliability of results, while forming the basis for improved diagnostics.},
author = {Day, A. R. and Knight, I. and Dunn, G. and Gaddas, R.},
doi = {10.1191/0143624403bt073oa},
file = {:home/sarah/OneDrive/Travail/Sources/0143624403bt073oa.pdf:pdf},
issn = {01436244},
journal = {Building Services Engineering Research and Technology},
number = {4},
pages = {221--228},
title = {{Improved methods for evaluating base temperature for use in building energy performance lines}},
volume = {24},
year = {2004}
}
@article{Goffart2015,
abstract = {This paper presents a statistical approach for uncertainty and sensitivity analyses applied to 14 inputs whose 10 properties associated with brick material, using the four different EnergyPlus wall models. The variability of inputs has been extracted from several characterization works presented in IEA Annexes 14, 24 and 55, being coherent to the lack of knowledge in the early design stage. Besides the methodology, this paper presents the moisture effects on cooling energy demand and indoor air conditions, using a simple building geometry and the humid climate of Singapore. Results are presented in terms of uncertainty quantification, most uncertain parameters and sensitivity indices for all models, illustrating the impact of moisture and the importance of the need to well define moisture-dependent functions. The methodology is well adapted for use in complex interactive models with a low-cost simulation and can be used to reduce uncertainties in the design stage and promote reliability of retrofitting assessment.},
author = {Goffart, Jeanne and Rabouille, Mickael and Mendes, Nathan},
doi = {10.1080/19401493.2015.1112430},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goffart, Rabouille, Mendes - 2015 - Uncertainty and sensitivity analysis applied to hygrothermal simulation of a brick building in a hot.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {brick properties,building performance,enegyplus ou energyplus,hygrothermal performance,moisture effects on,reliability assessment,uncertainty and sensitivity analysis},
month = {jan},
number = {1},
pages = {37--57},
title = {{Uncertainty and sensitivity analysis applied to hygrothermal simulation of a brick building in a hot and humid climate}},
url = {https://www.tandfonline.com/doi/full/10.1080/19401493.2015.1112430},
volume = {10},
year = {2017}
}
@unpublished{Birchall,
author = {Birchall, Sarah},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Birchall - Unknown - Co-heating Tests.pdf:pdf},
title = {{Co-heating Tests}}
}
@article{Harish2016,
abstract = {Buildings consume about 40{\%} of the overall energy consumption, worldwide and correspondingly are also responsible for carbon emissions. Since, last decade efforts have been made to reduce this share of CO2 emissions by energy conservation and efficient measures. Scientist across the world is working on energy modeling and control in order to develop strategies that would result in an overall reduction of a building's energy consumption. Development of control strategies asks for a computationally efficient energy model of a building under study. This paper presents a review of all the significant modeling methodologies which have been developed and adopted to model the energy systems of buildings. Attention is majorly focused on the works which involved development of the control strategies by modeling the building energy systems. Models reviewed are presented categorically as per the modeling approach adopted by the researchers. Simulation programs and softwares available for building energy modeling are also presented.},
author = {Harish, V. S.K.V. and Kumar, Arun},
doi = {10.1016/j.rser.2015.12.040},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S1364032115014239-main.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Building energy simulation,Building energy systems,Comfort,Energy model,Occupancy},
pages = {1272--1292},
publisher = {Elsevier Ltd},
title = {{A review on modeling and simulation of building energy systems}},
url = {http://dx.doi.org/10.1016/j.rser.2015.12.040},
volume = {56},
year = {2016}
}
@article{Sclove2012,
abstract = {Some model-selection criteria for choosing among a set of alternative models are reviewed. Particular model-selection problems considered here include choice of a regression equation for prediction, the number of bins for a histogram, and the number of component p.d.f.s in a finite mixture model. Several general methods of scoring the choices in such problems are considered. Minimum description length and penalized likelihood criteria are discussed, in particular AIC (Akaike's Information Criterion), BIC (Bayesian Information Criterion) and KIC (Kashyap's Information Criterion). Interpretation of BIC and KIC in terms of posterior probabilities of alternative models is given. Averaging a prediction or classification over models is considered.},
author = {Sclove, Stanley L.},
doi = {10.2139/ssrn.1910768},
file = {:home/sarah/OneDrive/Travail/Sources/SSRN-id1910768.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
title = {{A Review of Statistical Model Selection Criteria: Application to Prediction in Regression, Histograms, and Finite Mixture Models}},
url = {http://www.ssrn.com/abstract=1910768},
year = {2011}
}
@book{Shumway2011,
address = {New York, NY},
author = {Shumway, Robert H. and Stoffer, David S.},
doi = {10.1007/978-1-4419-7865-3},
edition = {Third edit},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shumway, Stoffer - 2011 - Time Series Analysis and Its Applications.pdf:pdf},
isbn = {978-1-4419-7864-6},
pages = {605},
publisher = {Springer New York},
series = {Springer Texts in Statistics},
title = {{Time Series Analysis and Its Applications}},
url = {www.springer.com/series/417 http://link.springer.com/10.1007/978-1-4419-7865-3},
year = {2011}
}
@book{Boashash,
abstract = {Time-Frequency Signal Analysis and Processing (TFSAP) is a collection of theory, techniques and algorithms used for the analysis and processing of non-stationary signals, as found in a wide range of applications including telecommunications, radar, and biomedical engineering. This book gives the university researcher and R{\&}D engineer insights into how to use TFSAP methods to develop and implement the engineering application systems they require. New to this edition: New sections on Efficient and Fast Algorithms; a "Getting Started" chapter enabling readers to start using the algorithms on simulated and real examples with the TFSAP toolbox, compare the results with the ones presented in the book and then insert the algorithms in their own applications and adapt them as needed. Two new chapters and twenty three new sections, including updated references. New topics including: efficient algorithms for optimal TFDs (with source code), the enhanced spectrogram, time-frequency modelling, more mathematical foundations, the relationships between QTFDs and Wavelet Transforms, new advanced applications such as cognitive radio, watermarking, noise reduction in the time-frequency domain, algorithms for Time-Frequency Image Processing, and Time-Frequency applications in neuroscience (new chapter). A comprehensive tutorial introduction to Time-Frequency Signal Analysis and Processing (TFSAP), accessible to anyone who has taken a first course in signals. Key advances in theory, methodology and algorithms, are concisely presented by some of the leading authorities on the respective topics. Applications written by leading researchers showing how to use TFSAP methods.},
annote = {Pages 47-48 Bandwidth Duration product is proportionnal to richness of signal},
author = {Boashash, Boualem},
booktitle = {Time-Frequency Signal Analysis and Processing: A Comprehensive Reference},
doi = {10.1016/C2012-0-00024-5},
isbn = {9780123984999},
pages = {1--1020},
title = {{Time-Frequency Signal Analysis and Processing: A Comprehensive Reference}},
url = {https://books.google.dk/books?id=WbYoRC1-lMkC{\&}pg=PA48{\&}lpg=PA48{\&}dq=frequency+signal+richness{\&}source=bl{\&}ots=u4r5a6r9S0{\&}sig=uWUYD3XfgYXCwJz82KV1PKf6i4U{\&}hl=fr{\&}sa=X{\#}v=onepage{\&}q{\&}f=false},
year = {2015}
}
@article{Kaipio2011,
annote = {Les m{\'{e}}thodes d{\'{e}}terministes ne cherchent qu'{\`{a}} trouver une solution unique {\`{a}} probl{\`{e}}me, avec {\'{e}}ventuellement une analyse de sensibilit{\'{e}} pour {\'{e}}valuer les incertitudes.
Les erreurs dues au mod{\`{e}}le ont tendance {\`{a}} dominer les erreurs de mesures.
Le principe m{\^{e}}me du cadre de r{\'{e}}solution bay{\'{e}}sien est d'explorer la distribution post-simulation pour d{\'{e}}terminer les incertitudes li{\'{e}}es aux inconnues sachant les mesures et sachant les incertitudes a priori inh{\'{e}}rentes au mod{\`{e}}le.
Algorithme d'{\'{e}}chantillonnage : Markov Chain Monte Carlo. Permet de tirer un {\'{e}}chantillonnage de la distribution a posteriori. Ces algo g{\'{e}}n{\`{e}}rent des s{\'{e}}quences d'{\'{e}}tats X dont la distribution converge vers la distribution d{\'{e}}sir{\'{e}}e quand on en tire une infinit{\'{e}}.},
author = {Kaipio, Jari P. and Fox, Colin},
doi = {10.1080/01457632.2011.525137},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaipio, Fox - 2011 - The Bayesian Framework for Inverse Problems in Heat Transfer.pdf:pdf},
issn = {0145-7632},
journal = {Heat Transfer Engineering},
month = {aug},
number = {9},
pages = {718--753},
title = {{The Bayesian Framework for Inverse Problems in Heat Transfer}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01457632.2011.525137},
volume = {32},
year = {2011}
}
@article{Brouwer2018,
abstract = {The interactions between parameters, model structure, and outputs can determine what inferences, predictions, and control strategies are possible for a given system. Parameter space reduction and parameter estimation---and, more generally, understanding the shape of the information contained in models with observational structure---are thus essential for many questions in mathematical modeling and uncertainty quantification. As such, different disciplines have developed methods in parallel for approaching the questions in their field. Many of these approaches, including identifiability, sloppiness, and active subspaces, use related ideas to address questions of parameter dimension reduction, parameter estimation, and robustness of inferences and quantities of interest. In this paper, we show that active subspace methods have intrinsic connections to methods from sensitivity analysis and identifiability, and indeed that it is possible to frame each approach in a unified framework. A particular form of the Fisher information matrix (FIM), which we denote the sensitivity FIM, is fundamental to all three approaches---active subspaces, identifiability, and sloppiness. Through a series of examples and case studies, we illustrate the properties of the sensitivity FIM in several contexts. These initial examples show that the interplay between local and global and linear and non-linear strongly impact the insights each approach can generate. These observations underline that one's approach to parameter dimension reduction should be driven by the scientific question and also open the door to using tools from the other approaches to generate useful insights.},
archivePrefix = {arXiv},
arxivId = {1802.05641},
author = {Brouwer, Andrew F and Eisenberg, Marisa C},
eprint = {1802.05641},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brouwer, Eisenberg - 2018 - The underlying connections between identifiability, active subspaces, and parameter space dimension reduc(2).pdf:pdf},
month = {feb},
title = {{The underlying connections between identifiability, active subspaces, and parameter space dimension reduction}},
url = {https://arxiv.org/pdf/1802.05641.pdf http://arxiv.org/abs/1802.05641},
year = {2018}
}
@techreport{ASHRAE2002,
abstract = {(ASHRAE). ASHRAE Guidelines are developed under a review process, identifying a guideline for the design, testing, appli-cation, or evaluation of a specific product, concept, or practice. As a guideline it is not definitive but encompasses areas where there may be a variety of approaches, none of which must be precisely correct. ASHRAE Guidelines are written to assist professionals in the area of concern and expertise of ASHRAE's Technical Committees and Task Groups. ASHRAE Guidelines are prepared by project committees appointed specifically for the purpose of writing Guidelines. The project committee chair and vice-chair must be members of the ASHRAE; while other members of the project committee may or may not be ASHRAE members, all must be technically qualified in the subject area of the Guideline. Development of ASHRAE Guidelines follows procedures similar to those for ASHRAE Standards except that (a) committee balance is desired but not required, (b) an effort is made to achieve consensus but consensus is not required, (c) guidelines are not appealable, and (d) guidelines are not submitted to ANSI for approval. The Manager of Standards of ASHRAE should be contacted for a. interpretation of the contents of this Guideline, b. participation in the next review of the Guideline, c. offering constructive criticism for improving the Guideline, d. permission to reprint portions of the Guideline. ASHRAE INDUSTRIAL ADVERTISING POLICY ON STANDARDS ASHRAE Standards and Guidelines are established to assist industry and the public by offering a uniform method of testing for rating purposes, by suggesting safe practices in designing and installing equipment, by providing proper definitions of this equipment, and by providing other information that may serve to guide the industry. The creation of ASHRAE Standards and Guidelines is determined by the need for them, and conformance to them is completely voluntary. In referring to this Standard or Guideline and in marking of equipment and in advertising, no claim shall be made, either stated or implied, that the product has been approved by ASHRAE. DISCLAIMER ASHRAE publishes Guidelines in order to provide assistance to interested parties on issues that relate to the design, testing, application, and/or evaluation of products, concepts, and practices where there may be more than one acceptable approach. Guidelines are not mandatory and only provide one source of information that may be helpful in any given situation.},
author = {ASHRAE},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/ashrae{\_}guideline{\_}14-2002{\_}measurement{\_}of{\_}energy{\_}and{\_}demand{\_}saving.pdf:pdf},
institution = {ASHRAE},
title = {{ASHRAE Guideline Measurement of Energy and Demand Savings}},
year = {2002}
}
@article{Wong2013,
abstract = {The best linear approximation (BLA) of a nonlinear system minimizes the difference between the actual output of the system and the modeled output in a least square sense. It depends on the power and amplitude distribution of the excitation sequences used to identify it. The theory of the BLA for Gaussian input sequences (including random phased multisines) has been widely studied. It has recently been shown that the BLA when using a binary input sequence is biased with respect to that obtained using a Gaussian input sequence, and expressions for this bias have been obtained. In this paper, it is shown that it is possible to design discrete multilevel input sequences to mimic Gaussianity as closely as possible, thus reducing the bias, by adjusting sequence levels and the probability of the sequence being at these levels. Their performance is compared with true Gaussian sequences in simulation experiments. {\textcopyright} 1963-2012 IEEE.},
author = {Wong, Hin Kwan Roland and Schoukens, Johan and Godfrey, Keith Richard},
doi = {10.1109/TIM.2012.2216471},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/Wongetal2012-DesignofMultilevelSignals-IEEEIM.pdf:pdf},
issn = {00189456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Linear approximation,Multilevel systems,Nonlinear systems,Signal design,System identification},
number = {2},
pages = {519--524},
title = {{Design of multilevel signals for identifying the best linear approximation of nonlinear systems}},
volume = {62},
year = {2013}
}
@phdthesis{Thil2007,
author = {Thil, St{\'{e}}phane},
booktitle = {Traitement du Signal},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thil - 2007 - Contributions {\`{a}} l'identification de mod{\`{e}}les avec des erreurs en les variables.pdf:pdf},
school = {Universit{\'{e}} Henri Poincar{\'{e}}, Nancy 1 Sp{\'{e}}cialit{\'{e}}},
title = {{Contributions {\`{a}} l'identification de mod{\`{e}}les avec des erreurs en les variables}},
year = {2007}
}
@article{Zou2004,
abstract = {The relationship between a response variable and one or more continuous covariates is often curved. Attempts to represent curvature in single-or multiple-regression models are usually made by means of polynomials of the covariates, typically quadratics. However, low order polynomials offer a limited family of shapes, and high order polynomials may fit poorly at the extreme values of the covariates. We propose an extended family of curves, which we call fractional polynomials, whose power terms are restricted to a small predefined set of integer and non-integer values. The powers are selected so that conventional polynomials are a subset of the family. Regression models using fractional polynomials of the covariates have appeared in the literature in an ad hoc fashion over a long period; we provide a unified description and a degree of formalization for them. They are shown to have considerable flexibility and are straightforward to fit using standard methods. We suggest an iterative algorithm for covariate selection and model fitting when several covariates are available. We give six examples of the use of fractional polynomial models in three types of regression analysis: normal errors, logistic and Cox regression. The examples all relate to medical data: fetal measurements, immunoglobulin concentrations in children, diabetes in children, infertility in women, myelomatosis (a type of leukaemia) and leg ulcers.},
author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and van der Linde, Angelika},
doi = {10.1111/1467-9868.00353},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Spiegelhalter{\_}et{\_}al-2002-Journal{\_}of{\_}the{\_}Royal{\_}Statistical{\_}Society{\_}{\_}Series{\_}B{\_}(Statistical....pdf:pdf},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {AIC,BIC,Functional approximation,Model averaging,Model selection,Multimodel inference,Non-linear curves,Polynomials,Regression,Smoothing,bayesian model comparison,chain monte carlo methods,decision theory,deviance information criterion,effective number of parameters,hierarchical models,information theory,lasso,leverage,markov,model dimension},
month = {oct},
number = {4},
pages = {583--639},
title = {{Bayesian measures of model complexity and fit}},
url = {https://www.jstor.org/stable/2986270?origin=crossref http://doi.wiley.com/10.1111/1467-9868.00353},
volume = {64},
year = {2002}
}
@article{Sadegh2018,
abstract = {Hydrological models contain parameters, values of which cannot be directly mea-sured in the field, and hence need to be meaningfully inferred through calibration against historical records. Although much progress has been made in the model inference literature, relatively little is known about the effects of transforming calibration data (or error residual) on the identifiability of model parameters and reliability of model predictions. Such effects are analyzed herein using two hydrological models and three watersheds. Our results depict that calibration data transformations significantly influence parameter and predictive uncertainty estimates. Those transformations that distort the temporal distribution of calibration data, such as flow duration curve, normal quantile transform, and Fourier transform, considerably deteriorate the identifiability of model parameters derived in a formal Bayesian framework with a residual-based likelihood function. Other transformations, such as wavelet, BoxCox and square root, while demonstrating some merits in identifying specific model parameters, would not consistently improve predictive capability of hydrological models in a single objective inverse problem. Multi-objective optimization schemes, however, may present a more rigorous Water Resour Manage https://doi.org/10.1007/s11269-018-1908-6 Highlights • Data transformations are used for accentuating impacts of specific portions of hydrograph in model inference • Transformations which distort temporal distribution of data, might obstruct parameter identifiability and disrupt predictive capability of models • Data transformations are most constructive in a multi-objective inference framework • Data transformations might be more helpful for evaluation and analysis of model behavior than model inference Electronic supplementary material The online version of this article (https://doi.org/10.1007/s11269-018-1908-6) contains supplementary material, which is available to authorized users. basis to extract several independent pieces of information from different data transformations. Finally, data transformations might offer a greater potential to evaluate model performance and assess specific sections of model behavior, rather than to calibrate models in a single objective framework. Findings of this study shed light on the importance and impacts of data transfor-mations in search of hydrological signatures.},
author = {Sadegh, Mojtaba and {Shakeri Majd}, Morteza and Hernandez, Jairo and Haghighi, Ali Torabi},
doi = {10.1007/s11269-018-1908-6},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sadegh et al. - 1908 - The Quest for Hydrological Signatures Effects of Data Transformation on Bayesian Inference of Watershed Models(2).pdf:pdf},
issn = {0920-4741},
journal = {Water Resources Management},
keywords = {Bayesian inference,Data transformation,Hydrological signatures,MCMC,Parameter identifiability,Prediction reliability},
month = {mar},
number = {5},
pages = {1867--1881},
title = {{The Quest for Hydrological Signatures: Effects of Data Transformation on Bayesian Inference of Watershed Models}},
url = {https://link-springer-com.camphrier-1.grenet.fr/content/pdf/10.1007{\%}2Fs11269-018-1908-6.pdf http://link.springer.com/10.1007/s11269-018-1908-6},
volume = {32},
year = {2018}
}
@article{Bianconi2018,
author = {Bianconi, Fortunato and Antonini, Chiara and Tomassoni, Lorenzo and Valigi, Paolo},
doi = {10.1109/TCST.2018.2844362},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bianconi et al. - 2018 - Robust Calibration of High Dimension Nonlinear Dynamical Models for Omics Data An Application in Cancer Systems.pdf:pdf},
issn = {1063-6536},
journal = {IEEE Transactions on Control Systems Technology},
pages = {1--12},
publisher = {IEEE},
title = {{Robust Calibration of High Dimension Nonlinear Dynamical Models for Omics Data: An Application in Cancer Systems Biology}},
url = {https://ieeexplore.ieee.org/document/8392730/},
volume = {PP},
year = {2018}
}
@inproceedings{Agbi2012,
annote = {"model calibration is in fact a system-identification problem"
--{\textgreater} Creuser la terminologie Calibration/Identification/identifiabilit{\'{e}}


Dans les m{\'{e}}thodes de r{\'{e}}solution utilis{\'{e}}es par les auteurs, des donn{\'{e}}es de mesure issues de signaux pauvres ne permettent pas l'identification correcte des param{\`{e}}tres


Les auteurs d{\'{e}}veloppent le concept d'identifiabilit{\'{e}} structurelle locale et pratique locale (appel{\'{e}}e numerical identifiability).
Le syst{\`{e}}me consid{\'{e}}r{\'{e}} est cependant lin{\'{e}}aire (approximation forte)
Les auteurs citent les travaux de Van Doren sur la th{\'{e}}orie de l'identifiabilit{\'{e}} (g{\'{e}}otechnique)
Le mod{\`{e}}le est explicit{\'{e}} sous forme de param{\`{e}}tres de Markov (r{\'{e}}ponse impulsionnelle), ce qui permet de d{\'{e}}terminer une matrice d'information structurelle (sensibilit{\'{e}} suivant chaque param{\`{e}}tre)
Pour l'identifiabilit{\'{e}} pratique, les auteurs calculent la matrice d'information de Fisher.
Les auteurs {\'{e}}voquent la question de l'informativit{\'{e}} des donn{\'{e}}es (mais ils ne l'utilisent pas on dirait)


les auteurs d{\'{e}}veloppent un algorithme  qui calcule une estimation de l'informativit{\'{e}}  pour un mod{\`{e}}le RC arbitraire.


L'estimation des param{\`{e}}tres {\'{e}}tant donn{\'{e}}es des valeurs mesur{\'{e}}es se fait par une m{\'{e}}thode Prediction-Error Identification. Utilise des algo num{\'{e}}rique de gradient, comme la m{\'{e}}thode Gauss-Newton.
--{\textgreater} donc pas de r{\'{e}}gularisation?


Application de l'algo {\`{a}} u, mod{\`{e}}le 13 zones, 52 {\'{e}}tats descrptif (temp{\'{e}}rature) 150 param{\`{e}}tres.
G{\'{e}}n{\'{e}}ration d'une simulation bruit{\'{e}}e d'un b{\^{a}}timent dont les caract{\'{e}}ristiques sont connues. Temp{\'{e}}rature ext{\'{e}}rieure sont bruit blanc aussi. Pas d'approst solaire.


PLusieurs essais avec des signaux d'entr{\'{e}}e de chauffage plus ou moins riche. Les auteurs annoncent une certaine richesse des signaux de chauffage. (--{\textgreater} comment quantifier la richesse de donn{\'{e}}es?)


les auteurs identifient le probl{\`{e}}me que certains des aram{\`{e}}tres qui s'av{\`{e}}rent {\^{e}}tre peu identifiable doient {\^{e}}tre fix{\'{e}}s arbitrairement, ce qui n{\'{e}}cessite des connaissances a priori
--{\textgreater} l'approche bay{\'{e}}sienne a certainement des choses {\`{a}} apporter sur le degr{\'{e}} d'identifiabilit{\'{e}}},
author = {Agbi, Clarence and Song, Zhen and Krogh, Bruce},
booktitle = {2012 IEEE 51st IEEE Conference on Decision and Control (CDC)},
doi = {10.1109/CDC.2012.6425995},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agbi, Song, Krogh - 2012 - Parameter identifiability for multi-zone building models.pdf:pdf},
isbn = {978-1-4673-2066-5},
month = {dec},
pages = {6951--6956},
publisher = {IEEE},
title = {{Parameter identifiability for multi-zone building models}},
url = {http://ieeexplore.ieee.org/document/6425995/},
year = {2012}
}
@article{Finkelstein1971,
abstract = {Two statistics for testing goodness of fit for small sample sizes are provided. The first statistic, S n, can be used to test the fit to any completely specified continuous distribution function and is more powerful than the Kolmogorov-Smirnov statistic in the cases tested. The second statistic, S * n, tests the fit to an exponential distribution with mean unknown. It is more powerful than a Kolmogorov-Smirnov type statistic suggested by Lilliefors (1969) for the cases tested. Critical values for S nand S * n are given for sample size n=1 (1)20(5)30 and $\alpha$=0.20, 0.15, 0.10, 0.05 and 0.01. The critical values and power analyses were obtained by Monte Carlo techniques. These new statistics are closely related to the Kolmogorov-Smirnov statistic and are computationally equival},
author = {Finkelstein, J. M. and Schafer, R. E.},
doi = {10.1093/biomet/58.3.641},
file = {:home/sarah/OneDrive/Travail/Sources/58-3-641.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
number = {3},
pages = {641--645},
title = {{Improved goodness-of-fit tests}},
url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/58.3.641},
volume = {58},
year = {1971}
}
@article{Rissanen1986,
author = {Rissanen, J.},
doi = {3035559},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rissanen - 1986 - Stochastic Complexity and Modeling.pdf:pdf},
journal = {The Annals of Statistics},
pages = {pp. 1080--1100},
title = {{Stochastic Complexity and Modeling}},
url = {http://www.jstor.org/stable/3035559},
volume = {14},
year = {1986}
}
@article{Dobre2012,
abstract = {In systems biology , a common approach to model biological processes is to use large systems of nonlinear differential equations. The associated parameter estimation problem then requires a prior handling of the global identifiability question in a realistic experimental framework . The lack of a method able to solve this issue has indirectly encouraged the use of global sensitivity analysis to select the subset of parameters to estimate . Nevertheless , the links between these two global analyses are not yet fully explored . The present work reveals new bridges between sensitivity analyses and global non - identifiability , through the use of functions derived from the Sobol ' high dimensional representation of the model output . We particularly specify limits of variance - based sensitivity tools to completely conclude on global non - identifiability of parameters in a given experimental context .},
author = {Dobre, Simona and Bastogne, Thierry and Profeta, Christophe and Barberi-Heyob, Muriel and Richard, Alain},
doi = {10.1016/j.automatica.2012.05.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dobre et al. - 2012 - Limits of variance-based sensitivity analysis for non- identifiability testing in high dimensional dynamic models.pdf:pdf},
issn = {00051098},
journal = {Automatica},
month = {nov},
number = {11},
pages = {2740--2749},
title = {{Limits of variance-based sensitivity analysis for non-identifiability testing in high dimensional dynamic models}},
url = {https://hal.archives-ouvertes.fr/hal-00730316/file/Automatica{\_}SD{\_}VF.pdf https://linkinghub.elsevier.com/retrieve/pii/S000510981200177X},
volume = {48},
year = {2012}
}
@article{Raillon2018,
abstract = {a b s t r a c t Experimental calibration of dynamic thermal models is required for model predictive control and characterization of building energy performance. In these applications, the uncertainty assessment of the parameter estimates is decisive; this is why a Bayesian calibration procedure (selection, calibration and validation) is presented. The calibration is based on an improved Metropolis-Hastings algorithm suitable for linear and Gaussian state-space models. The procedure, illustrated on a real house experiment, shows that the algorithm is more robust to initial conditions than a maximum likelihood optimization with a quasi-Newton algorithm. Furthermore, when the data are not informative enough, the use of prior distributions helps to regularize the problem.},
author = {Raillon, Lo{\"{i}}c and Ghiaus, Cristian},
doi = {10.1016/j.energy.2018.03.168},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raillon, Ghiaus - 2018 - An efficient Bayesian experimental calibration of dynamic thermal models(2).pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {Bayesian calibration,Dynamic thermal models,Improved metropolis-Hastings algorithm,Model selection and validation,Real house experiment,Robust gradient and Hessian computation},
month = {jun},
pages = {818--833},
title = {{An efficient Bayesian experimental calibration of dynamic thermal models}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0360544218305772/1-s2.0-S0360544218305772-main.pdf?{\_}tid=0260798d-a503-42ed-8321-61cff4ef2f66{\&}acdnat=1524136043{\_}1c2837ebca20d5cc3dd5218c2a9d2cbc https://linkinghub.elsevier.com/retrieve/pii/S0360544218305772},
volume = {152},
year = {2018}
}
@article{Li2016,
abstract = {a b s t r a c t Calibration of model parameters is an essential step in predicting the response of a complicated system, but the lack of data at the system level makes it impossible to conduct this quantification directly. In such a situation, system model parameters are estimated using tests at lower levels of complexity which share the same model parameters with the system. For such a multi-level problem, this paper proposes a methodology to quantify the uncertainty in the system level prediction by integrating calibration, vali-dation and sensitivity analysis at different levels. The proposed approach considers the validity of the models used for parameter estimation at lower levels, as well as the relevance at the lower level to the prediction at the system level. The model validity is evaluated using a model reliability metric, and models with multivariate output are considered. The relevance is quantified by comparing Sobol indices at the lower level and system level, thus measuring the extent to which a lower level test represents the characteristics of the system so that the calibration results can be reliably used in the system level. Finally the results of calibration, validation and relevance analysis are integrated in a roll-up method to predict the system output.},
author = {Li, Chenzhao and Mahadevan, Sankaran},
doi = {10.1016/j.ress.2015.11.013},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Mahadevan - 2016 - Role of calibration, validation, and relevance in multi-level uncertainty integration.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering {\&} System Safety},
keywords = {Bayesian,Calibration,Model reliability metric,Sobol indices,Uncertainty,Validation},
month = {apr},
pages = {32--43},
title = {{Role of calibration, validation, and relevance in multi-level uncertainty integration}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0951832015003403/1-s2.0-S0951832015003403-main.pdf?{\_}tid=7c2b1726-c850-11e7-82bd-00000aab0f26{\&}acdnat=1510563546{\_}b5c30802071780418ebc687c29318933 https://linkinghub.elsevier.com/retrieve/pii/S0951832015003403},
volume = {148},
year = {2016}
}
@article{Senave2017,
abstract = {Both a well-designed on-board monitoring campaign and an adequate data-driven statistical modeling method are required to accurately characterize the building's overall heat transfer coefficient (HTC). In this paper, we reflect on the latter by means of a theoretical deduction of the heat balance equation and case studies on simulation data. We demonstrate the impact of using air temperatures as a proxy for equivalent temperatures and neglecting the intercept when characterizing the HTC using a linear regression method on measurement data.},
author = {Senave, Marieline and Reynders, Glenn and Verbeke, Stijn and Saelens, Dirk},
doi = {10.1016/j.egypro.2017.09.687},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senave et al. - 2017 - A simulation exercise to improve building energy performance characterization via on-board monitoring.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Building energy simulation,Overall heat transfer coefficient,Sensitivity analysis,System identification},
month = {oct},
pages = {969--974},
publisher = {Elsevier B.V.},
title = {{A simulation exercise to improve building energy performance characterization via on-board monitoring}},
url = {https://doi.org/10.1016/j.egypro.2017.09.687 https://linkinghub.elsevier.com/retrieve/pii/S1876610217348348},
volume = {132},
year = {2017}
}
@article{Rouchier2016a,
abstract = {As building energy modeling becomes more sophisticated, the amount of user input and the number of parame- ters used to define the models continue to grow. There are numerous sources of uncertainty in these parameters, especially when the modeling process is being performed prior to construction and commissioning. Past efforts to perform sensitivity and uncertainty analysis have focused on tens of parameters, while in this work, we increase the size of analysis by two orders of magnitude (by studying the influence of about 1000 parameters). We extend traditional sensitivity analysis in order to decompose the pathway as uncertainty flows through the dynamics, which identifies which internal or intermediate processes transmit the most uncertainty to the final output. We present these results as a method that is applicable to many different modeling tools, and demonstrate its applicability on an example EnergyPlus model. Keywords:},
annote = {Probl{\`{e}}me inverse, plusieurs questions : {\`{a}} quel point les r{\'{e}}sultats sont-ils fiables. Dans le cadre d'une calibration, on doit analyser l'identifiabilit{\'{e}} des param{\`{e}}tres : attention {\`{a}} l'amplification des incertitudes de mesures/mod{\`{e}}le/... attention {\`{a}} l'identifiabilit{\'{e}} tout court. Cela n{\'{e}}cessite un mod{\`{e}}le ad{\'{e}}quat, des mesures ad{\'{e}}quates.


Utiliser inf{\'{e}}rence bay{\'{e}}sienne introduit un biais dans la r{\'{e}}solution du probl{\`{e}}me inverse dans le sens o{\`{u}} la probabilit{\'{e}} a posteriori d{\'{e}}pend de la connaissance a priori du param{\`{e}}tre. donc l'incertitude de l'expert dans sa d{\'{e}}termination des valeurs a priori se r{\'{e}}percute imm{\'{e}}diatement dans la r{\'{e}}solution du probl{\`{e}}me inverse.
Il est possible d'obtenir une distribution a posteriori bien d{\'{e}}finie mais incorrecte si : le mod{\`{e}}le est inappropri{\'{e}} ou si : l'erreur de mesure n'est pas une variable al{\'{e}}atoire distribu{\'{e}}e identiquement et ind{\'{e}}pendente.
Pour d{\'{e}}terminer la non-identifiabilit{\'{e}} des param{\`{e}}tres, on {\'{e}}tudie la corr{\'{e}}lation des param{\`{e}}tres et le likelihood profile dans leur distribution a posteriori.


La m{\'{e}}thodo a ben fonctionn{\'{e}} pour la premi{\`{e}}re partie de l'exp{\'{e}}rimentation en sorption, o{\`{u}} il y a eu deux paliers de sorption (contre un seul en d{\'{e}}sorption). Le fait qu'il y ait eu deux sollicitations donc deux r{\'{e}}ponses a donn{\'{e}} des r{\'{e}}sultats statistiquement mieux probants.


Questions et r{\'{e}}flexions:
Puisque deux sollicitations donnent des r{\'{e}}sultats plus affin{\'{e}}s ({\`{a}} v{\'{e}}rifier qu'il sont r{\'{e}}ellement bien affin{\'{e}} ou si en r{\'{e}}alit{\'{e}} l'identifiabilit{\'{e}} a {\'{e}}t{\'{e}} fauss{\'{e}}e, revoir les causes de faussage d'identifiabilit{\'{e}})
mais donc deux sollicitations donnent ds r{\'{e}}sultats plus affin{\'{e}}s (pourquoi est-ce que math{\'{e}}matiquement cette m{\'{e}}thode donne des r{\'{e}}sultats meilleurs, alors qu'on penserait qu'il faut etre en steady-state pour mieux exploiter de sr{\'{e}}sultats...???) , c'est sans doute beaucoup plus int{\'{e}}ressant en r{\'{e}}no et mesures in situ, de travailler sur des ph{\'{e}}nom{\`{e}}nes changeants (alternance thermique jour-nuit) que sur du co-heating protocol...


Hygric characterization under uncertainty with dynamic measurements and MCMC algorithm},
author = {Rouchier, Simon and Busser, Thomas and Pailha, Micka{\"{e}}l and Piot, Amandine and Woloszyn, Monika},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouchier et al. - 2016 - Hygric characterization under uncertainty with dynamic measurements and MCMC algorithm.pdf:pdf},
isbn = {1940-1493$\backslash$r1940-1507},
issn = {19401493},
journal = {Journal of Building Performance Simulation},
keywords = {HAM,MCMC,characterization,identifiability},
title = {{Hygric characterization under uncertainty with dynamic measurements and MCMC algorithm}},
year = {2016}
}
@article{Virk1995,
abstract = {Mathematical models for describing system behavior are a vital aid in the design, operation, control, and management of buildings. This paper describes the modelling approaches that are currently available and asserts that, for buildings, stochastic multivariable modelling is the most suitable. In this respect, the application of stochastic multivariable identification to this field is described in detail, and practical advice is offered based on experience gained from applying the technique to an experimental office zone/air-conditioning system. Models are identified that forecast the thermal and moisture behavior of the air in the office zone, and methods are explained for the gathering of input/output data, model construction, and model validation. It is shown that good quality models are obtainable that are capable of accurately forecasting the future psychrometric behavior of the air in the zone, thus demonstrating the suitability of the stochastic identification technique for the modelling of buildings. {\textcopyright} 1995.},
author = {Virk, G. S. and Cheung, J. Y.M. and Loveday, D. L.},
doi = {10.1016/0307-904X(95)00079-Y},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-0307904X9500079Y-main.pdf:pdf},
issn = {0307904X},
journal = {Applied Mathematical Modelling},
keywords = {HVAC systems,PRBS,building automation systems (BAS),buildings,multivariable identification,practical application,stochastic modelling},
mendeley-tags = {PRBS},
number = {10},
pages = {621--636},
title = {{Practical stochastic multivariable identification for buildings}},
volume = {19},
year = {1995}
}
@article{Lundstrom2019,
abstract = {{\textless}p{\textgreater}Reliable energy models are needed to determine building energy performance. Relatively detailed energy models can be auto-generated based on 3D shape representations of existing buildings. However, parameters describing thermal performance of the building fabric, the technical systems, and occupant behavior are usually not readily available. Calibration with on-site measurements is needed to obtain reliable energy models that can offer insight into buildings' actual energy performances. Here, we present an energy model that is suitable for district-heated multifamily buildings, based on a 14-node thermal network implementation of the ISO 52016-1:2017 standard. To better account for modeling approximations and noisy inputs, the model is converted to a stochastic state-space model and augmented with four additional disturbance state variables. Uncertainty models are developed for the inputs solar heat gains, internal heat gains, and domestic hot water use. An iterated extended Kalman filtering algorithm is employed to enable nonlinear state estimation. A Bayesian calibration procedure is employed to enable assessment of parameter uncertainty and incorporation of regulating prior knowledge. A case study is presented to evaluate the performance of the developed framework: parameter estimation with both dynamic Hamiltonian Monte Carlo sampling and penalized maximum likelihood estimation, the behavior of the filtering algorithm, the impact of different commonly occurring data sources for domestic hot water use, and the impact of indoor air temperature readings.{\textless}/p{\textgreater}},
author = {Lundstr{\"{o}}m, Lukas and Akander, Jan},
doi = {10.3390/en13010076},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/energies-13-00076.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
number = {1},
pages = {76},
title = {{Bayesian Calibration with Augmented Stochastic State-Space Models of District-Heated Multifamily Buildings}},
url = {https://www.mdpi.com/1996-1073/13/1/76},
volume = {13},
year = {2019}
}
@techreport{Subbarao1988,
abstract = {This report summarizes a longer report entitled PSTAR - Primary and Secondary Terms Analysis and Renormalization: A Unified Approach to Building Energy Simulations and Short-term Monitoring, SERI/TR-254-3175. These reports highlight short-term testing for predicting long-term performance of residential buildings. Our efforts resulted in developing a test procedure and analytic tools.},
author = {Subbarao, Kris},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subbarao - 1988 - PSTAR -- Primary and Secondary Terms Analysis and Renormalization A Unified Approach to Building and Energy Simulation.pdf:pdf},
institution = {Solar Energy Research Institude},
keywords = {PSTAR,STEM},
mendeley-tags = {PSTAR,STEM},
title = {{PSTAR -- Primary and Secondary Terms Analysis and Renormalization: A Unified Approach to Building and Energy Simulations and Short-Term Testing; A Summary}},
url = {http://www.nrel.gov/docs/legosti/old/3347.pdf},
year = {1988}
}
@article{Akbari1995,
abstract = {We have developed an algorithm to disaggregate short-interval (hourly) whole-building electrical load into major end uses. Hourly load data, hourly load-temperature regression coefficients and simulation end-use results comprise the algorithm input. The algorithm produces hourly load profiles for air conditioning, lighting, fans and pumps, and miscellaneous loads. Measured data from two end-use metered buildings (an office and a retail store) have been used to validate the algorithm. For the retail store, the algorithm estimates of hourly end use compare remarkably well with the monitored end-use data (average error of less than 5{\%} during daytime operation). For the office building, the algorithm gives a consistent bias of about 12 and 27{\%} in overestimating the HVAC and lighting electric loads, respectively, at the expense of underestimating the miscellaenous load by 35{\%}. Results may be attributed to the presence of inconsistencies between office audit information and measured end-use data. A three-fold difference between the auditor's estimate for miscellaneous energy use and the metered amount has been found. The validation, however, indicates great promise for application of the algorithm to whole-building load data for obtaining reliable end-use data. ?? 1995.},
author = {Akbari, H.},
doi = {10.1016/0360-5442(95)00033-D},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Akbari - 1995 - Validation of an algorithm to disaggregate whole-building hourly electrical load into end uses.pdf:pdf},
issn = {03605442},
journal = {Energy},
number = {12},
pages = {1291--1301},
title = {{Validation of an algorithm to disaggregate whole-building hourly electrical load into end uses}},
volume = {20},
year = {1995}
}
@article{Thomassin2009,
author = {Thomassin, Magalie and Bastogne, Thierry and Richard, Alain},
doi = {10.1109/TCST.2008.2000982},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomassin, Bastogne, Richard - 2009 - Identification of a managed river reach by a Bayesian approach.pdf:pdf},
issn = {10636536},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Bayesian identification,Degeneracy,Delay estimation,Impulse response,Open-channel system},
number = {2},
pages = {353--365},
title = {{Identification of a managed river reach by a Bayesian approach}},
volume = {17},
year = {2009}
}
@article{Hapsari2018,
author = {Hapsari, G and Richard, F and {Ben Hmida}, R. and Mal{\'{e}}cot, P and Thibaud, S{\'{e}}bastien},
doi = {10.1016/j.matdes.2017.12.002},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hapsari et al. - 2017 - Instrumented Incremental Sheet Testing for material behavior extraction under very large strain Information rich.pdf:pdf},
issn = {02641275},
journal = {Materials {\&} Design},
keywords = {Damage,Finite element method,Identifiability,Inverse method,Micro incremental deformation test},
month = {feb},
number = {17},
pages = {317--331},
title = {{Instrumented Incremental Sheet Testing for material behavior extraction under very large strain: Information richness of continuous force measurement}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0264127517311073/1-s2.0-S0264127517311073-main.pdf?{\_}tid=b6e1da84-dcdd-11e7-90bc-00000aab0f27{\&}acdnat=1512823227{\_}4e7aaa2f92e96abcb066ad44b2b6c583 https://linkinghub.elsevier.com/retrieve/pii/S0264127517311073},
volume = {140},
year = {2018}
}
@article{Virtanen2020,
author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, St{\'{e}}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^{o}}nio H. and Pedregosa, Fabian and van Mulbregt, Paul},
doi = {10.1038/s41592-019-0686-2},
issn = {1548-7091},
journal = {Nature Methods},
month = {mar},
number = {3},
pages = {261--272},
title = {{SciPy 1.0: fundamental algorithms for scientific computing in Python}},
url = {http://www.nature.com/articles/s41592-019-0686-2},
volume = {17},
year = {2020}
}
@article{Meulemans2017,
abstract = {{\textcopyright} Springer International Publishing AG 2017. This paper presents a novel transient experimental method developed in order to perform in situ measurements of the thermal performance of building fabrics: the QUB/e method. In one night, a QUB/e test yields the whole house heat loss coefficient (HLC) and the local in situ U-values. A comprehensive set of in situ measurements were carried out in a circa 1900 solid wall end-terrace house located in an environmental chamber to evaluate the thermal performance of the building fabric and to validate the QUB/e method. The accuracy of the QUB/e method was assessed against steady-state measurements before and after a deep retrofit, both the HLC and U-values were used in the comparison. The measurement of the HLC using the QUB/e method for heating durations down to one hour yielded accurate results (i.e. the relative differences from the value estimated with the steady-state method were smaller than 10{\%}) provided the a-criterion lay within the recommended range (i.e. between approximately 0.4 and 0.7). The U-values measured in situ with the QUB/e method were in good agreement with the steady-state (ISO 9869-1) values (i.e. the relative differences were within the uncertainty bound of the measurement methods). The QUB/e method was thus deemed validated by comparison with reference U-values measured in accordance with ISO 9869-1.},
author = {Meulemans, Johann and Alzetto, Florent and Farmer, David and Gorse, Chris},
doi = {10.1007/978-3-319-50346-2_9},
file = {:home/sarah/OneDrive/Travail/Sources/Meulemans et al. (2016) - SEEDS.pdf:pdf},
isbn = {9783319503462},
journal = {Building Information Modelling, Building Performance, Design and Smart Construction},
keywords = {Heat loss coefficient,QUB/e,U-value in situ measurements},
pages = {115--127},
title = {{QUB/e: A novel transient experimental method for in situ measurements of the thermal performance of building fabrics}},
year = {2017}
}
@article{Chi,
author = {Chi, Tran Viet},
pages = {1--5},
title = {{Comment comprendre l ' information de Fisher ?}}
}
@article{Matajira-Rueda2018a,
abstract = {This article presents a comparative study using two global optimization algorithms, Electromagnetic Field Optimization (EFO) and Heat Transfer Search (HTS). These techniques are efficient alternatives when classical methods find limitations to solve real problems. To verify methods performance, the rectangular microchannel heat sink design was implemented formulating the respective Inverse Heat Transfer Problem (IHTP). Experimental results were competitively compared with the traditional Levenberg-Marquardt (LM) outcomes. Moreover, global algorithms achieved estimations with errors lower than 5{\%}, and they converged at least three times faster than LM.},
author = {Matajira-Rueda, David and {Cruz Duarte}, Jorge and {Avi{\~{n}}a Cervantes}, Juan and {Correa Cely}, Carlos},
doi = {10.18273/revuin.v17n1-2018023},
file = {:home/sarah/OneDrive/Travail/Sources/7891-Texto del art{\'{i}}culo-37346-2-10-20180212.pdf:pdf},
issn = {16574583},
journal = {Revista UIS Ingenier{\'{i}}as},
keywords = {efo,egm,electromagnetic field optimization,entropy generation minimization,heat transfer,hts,ihtp,inverse heat transfer problem,levenberg-marquardt method,lm,ordinary least squares norm,search},
number = {1},
pages = {233--242},
title = {{Global optimization algorithms applied in a parameter estimation strategy}},
volume = {13},
year = {2018}
}
@article{Budaiwi2002,
abstract = {The thermal and energy performance of buildings depends on the thermal characteristics of the building envelope, and particularly on the thermal resistance of the insulation material used. The performance of the thermal insulation material is mainly determined by its thermal conductivity, which describes the ability of heat to flow across the material in the presence of a differential temperature. The value of the thermal conductivity of a particular material is subject to variation, due to changes in both moisture content and temperature. In reality, thermal insulation in buildings is exposed to significant and continuous temperature variations, due to varying outdoor air temperature and solar radiation. However, when calculating cooling loads or performing energy analyses for buildings, most designers, if not all, use published or manufacturer-supplied values of thermal conductivity, which are normally evaluated at 24°C according to theASTM standards. Currently, many types of insulation materials are produced in Saudi Arabia, but not enough information is available to evaluate their performance under the prevailing climatic conditions. The objective of this paper is to present the results of a study that investigates the relationship between the temperature and thermal conductivity of various types of locally produced insulation materials. Additionally, the impact of thermal conductivity variation with temperature on the envelope-induced cooling load for a theoretically modeled building is quantified and discussed. Results are expected to clarify the issue of thermal conductivity dependence on temperature and lead to a more accurate assessment of the thermal and energy performance of buildings.},
author = {Budaiwi, I and Abdou, A and Al-Homoud, M},
doi = {10.1061/(ASCE)1076-0431(2002)8:4(125)},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budaiwi, Abdou, Al-Homoud - 2002 - Variations of thermal conductivity of insulation materials under different operating temperatures (2).pdf:pdf},
issn = {1076-0431},
journal = {Journal of Architectural Engineering},
number = {December},
pages = {125--132},
title = {{Variations of thermal conductivity of insulation materials under different operating temperatures : Impact on envelope-induced cooling load}},
volume = {8},
year = {2002}
}
@incollection{Jaulina,
annote = {Kalman et matrices de covariance},
author = {Jaulin, L},
booktitle = {Robotique mobile},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaulin - Unknown - Filtre de Kalman.pdf:pdf},
keywords = {Filtre de Kalman,Matrice de covariance},
mendeley-tags = {Filtre de Kalman,Matrice de covariance},
title = {{Filtre de Kalman}},
url = {https://www.ensta-bretagne.fr/jaulin/poly{\_}kalman.pdf}
}
@article{Betancourt2016,
abstract = {When properly tuned, Hamiltonian Monte Carlo scales to some of the most challenging high-dimensional problems at the frontiers of applied statistics, but when that tuning is suboptimal the performance leaves much to be desired. In this paper I show how suboptimal choices of one critical degree of freedom, the cotangent disintegration, manifest in readily observed diagnostics that facilitate the robust application of the algorithm.},
archivePrefix = {arXiv},
arxivId = {1604.00695},
author = {Betancourt, Michael},
eprint = {1604.00695},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/1604.00695.pdf:pdf},
journal = {arXiv},
keywords = {a probability distribution,and phrases,applied statistics,carlo,diagnostics,distribution,hamiltonian monte,has been specified as,markov chain monte carlo,microcanonical disintegration,of expectations with respect,once a statistical model,reduces to the evaluation,to the that target},
month = {apr},
title = {{Diagnosing Suboptimal Cotangent Disintegrations in Hamiltonian Monte Carlo}},
url = {http://arxiv.org/abs/1604.00695},
year = {2016}
}
@article{VandenHof1998,
author = {van den Hof, J.M.},
doi = {10.1109/9.679020},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van den Hof - 1998 - Structural identifiability of linear compartmental systems.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
month = {jun},
number = {6},
pages = {800--818},
title = {{Structural identifiability of linear compartmental systems}},
url = {http://ieeexplore.ieee.org/document/679020/},
volume = {43},
year = {1998}
}
@misc{CSTB2012,
author = {CSTB},
booktitle = {Journal officiel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/CSTB - 2012 - Arr{\^{e}}t{\'{e}} du 30 avril 2013 portant approbation de la m{\'{e}}thode de calcul Th-BCE 2012 pr{\'{e}}vue aux articles 4, 5 et 6 de.pdf:pdf},
title = {{Arr{\^{e}}t{\'{e}} du 30 avril 2013 portant approbation de la m{\'{e}}thode de calcul Th-BCE 2012 pr{\'{e}}vue aux articles 4, 5 et 6 de l'arr{\^{e}}t{\'{e}} du 26 octobre 2010 relatif aux caract{\'{e}}ristiques thermiques et aux exigences de performance {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents nouveaux et des}},
volume = {n°0106: 77},
year = {2012}
}
@article{Knochel2018,
abstract = {A growing understanding of complex processes in biology has led to large-scale mechanistic models of pharmacologically relevant processes. These models are increasingly used to study the response of the system to a given input or stimulus, e.g., after drug administration. Understanding the input–response relationship, however, is often a challenging task due to the complexity of the interactions between its constituents as well as the size of the models. An approach that quantifies the importance of the different constituents for a given input–output relationship and allows to reduce the dynamics to its essential features is therefore highly desirable. In this article, we present a novel state-and time-dependent quantity called the input–response index that quantifies the importance of state variables for a given input–response relationship at a particular time. It is based on the concept of time-bounded controllability and observability, and defined with respect to a reference dynamics. In application to the brown snake venom–fibrinogen (Fg) network, the input–response indices give insight into the coordinated action of specific coagulation factors and about those factors that contribute only little to the response. We demonstrate how the indices can be used to reduce large-scale models in a two-step procedure: (i) elimi-nation of states whose dynamics have only minor impact on the input–response relationship, and (ii) proper lumping of the remaining (lower order) model. In application to the brown snake venom–fibrinogen network, this resulted in a reduction from 62 to 8 state variables in the first step, and a further reduction to 5 state variables in the second step. We further illustrate that the sequence, in which a recursive algorithm eliminates and/or lumps state variables, has an impact on the final reduced model. The input–response indices are particularly suited to determine an informed sequence, since they are based on the dynamics of the original system. In summary, the novel measure of importance provides a powerful tool for analysing the complex dynamics of large-scale systems and a means for very efficient model order reduction of nonlinear systems.},
author = {Kn{\"{o}}chel, Jane and Kloft, Charlotte and Huisinga, Wilhelm},
doi = {10.1007/s10928-017-9561-x},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kn{\"{o}} chel, Charlotte Kloft, Wilhelm Huisinga - Unknown - Understanding and reducing complex systems pharmacology models based on a no(2).pdf:pdf},
issn = {1567-567X},
journal = {Journal of Pharmacokinetics and Pharmacodynamics},
keywords = {Blood coagulation network,Control theory,Model order reduction,Nonlinear systems,coagulation network {\'{a}} nonlinear,control theory {\'{a}} model,order reduction {\'{a}} blood,systems},
month = {feb},
number = {1},
pages = {139--157},
title = {{Understanding and reducing complex systems pharmacology models based on a novel input–response index}},
url = {http://link.springer.com/10.1007/s10928-017-9561-x https://link-springer-com.camphrier-2.grenet.fr/content/pdf/10.1007{\%}2Fs10928-017-9561-x.pdf},
volume = {45},
year = {2018}
}
@article{Lema-Perez2019,
author = {Lema-Perez, Laura and Mu{\~{n}}oz-Tamayo, Rafael and Garcia-Tirado, Jose and Alvarez, Hernan},
doi = {10.1016/j.imu.2019.02.002},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S2352914818302181-main.pdf:pdf},
issn = {23529148},
journal = {Informatics in Medicine Unlocked},
keywords = {Biological systems,Identifiability,Mechanistic models,Parameter interpretability,Phenomenological based semi-physical model (PBSM)},
number = {February},
pages = {100158},
publisher = {Elsevier Ltd},
title = {{On parameter interpretability of phenomenological-based semiphysical models in biology}},
url = {https://doi.org/10.1016/j.imu.2019.02.002 https://linkinghub.elsevier.com/retrieve/pii/S2352914818302181},
volume = {15},
year = {2019}
}
@misc{BigLadderSoftware2020,
author = {BigLadderSoftware},
title = {https://bigladdersoftware.com/epx/docs/8-6/engineering-reference/conduction-through-the-walls.html{\#}conduction-through-the-walls},
year = {2020}
}
@article{Xie2006,
abstract = {Identifiability has long been an important concept in classical statistical estimation. Historically, Bayesians have been less interested in the concept since, strictly speaking, any parameter having a proper prior distribution also has a proper posterior, and is thus estimable. However, the larger statistical community's recent move toward more Bayesian thinking is largely fueled by an interest in Markov chain Monte Carlo-based analyses using vague or even improper priors. As such, Bayesians have been forced to think more carefully about what has been learned about the parameters of interest (given the data so far), or what could possibly be learned (given an infinite amount of data). In this paper, we propose measures of Bayesian learning based on differences in precision and Kullback-Leibler divergence. After investigating them in the context of some familiar Gaussian linear hierarchical models, we consider their use in a more challenging setting involving two sets of random effects (traditional and spatially arranged), only the sum of which is identified by the data. We illustrate this latter model with an example from periodontal data analysis, where the spatial aspect arises from the proximity of various measurements taken in the mouth. Our results suggest our measures behave sensibly and may be useful in even more complicated (e.g., non-Gaussian) model settings. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Xie, Yang and Carlin, Bradley P.},
doi = {10.1016/j.jspi.2005.04.003},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378375805001278-main.pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Conditionally autoregressive (CAR) model,Markov chain Monte Carlo (MCMC),Nonidentifiability,Noninformativity,Spatial statistics},
number = {10},
pages = {3458--3477},
title = {{Measures of Bayesian learning and identifiability in hierarchical models}},
volume = {136},
year = {2006}
}
@article{Ratto2001,
abstract = {A new approach is presented applicable in framework of model calibration to observed data. The approach consists of a combination of the Generalized Likelihood Uncertainty Estimation technique (GLUE) and Global Sensitivity Analysis (GSA). The method is based on multiple model evaluations. The GSA is a quantitative, model independent approach and is based on estimating the fractional contribution of each input factor to the variance of the model output, also accounting for interaction terms. In GLUE, the model runs are classified according to a likelihood measure, conditioning each run to observations. In calibration procedures, strong interaction is observed between model parameters, due to model over-parameterization. The use of likelihood measures allows an estimate of the posterior joint pdf of parameters. By performing a GSA to the likelihood measure, input factors mainly driving model runs with good fit to data are identified. Moreover GSA allows highlighting the basic features of the interaction structure. Any other tool subsequently adopted to represent in more detail the interaction structure, from correlation coefficients to Principal Component Analysis to Bayesian networks to tree-structured density estimation, confirms the general features identified by GSA.  2001 Published by Elsevier Science B.V.},
author = {Ratto, M and Tarantola, Stefano and Saltelli, Andrea},
doi = {10.1016/S0010-4655(01)00159-X},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratto, Tarantola, Saltelli - 2091 - Sensitivity analysis in model calibration GSA-GLUE approach.pdf:pdf},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {0270-c,0270Lq,0705Tp Keywords,Global Sensitivity Analysis,Likelihood measures,Model calibration,Model uncertainty,PACS,Parameter Interaction,Uncertainty analysis},
month = {may},
number = {3},
pages = {212--224},
title = {{Sensitivity analysis in model calibration: GSA-GLUE approach}},
url = {www.elsevier.nl/locate/cpc https://linkinghub.elsevier.com/retrieve/pii/S001046550100159X},
volume = {136},
year = {2001}
}
@article{Boersch-Supan2018,
abstract = {1 Mechanistic representations of individual life-history trajectories are powerful tools for the pre-2 diction of organismal growth, reproduction and survival under novel environmental conditions. 3 Dynamic energy budget (DEB) theory provides compact models to describe the acquisition and 4 allocation of organisms over their full life cycle of bioenergetics. However, estimating DEB model 5 parameters, and their associated uncertainties and covariances, is not trivial. Bayesian inference 6 provides a coherent way to estimate parameter uncertainty, and propagate it through the model, 7 while also making use of prior information to constrain the parameter space. We outline a Bayesian 8 inference approach for energy budget models and provide two case studies-based on a simplified 9 DEBkiss model, and the standard DEB model-detailing the implementation of such inference pro-10 cedures using the open-source software package deBInfer. We demonstrate how DEB and DEBkiss 11 parameters can be estimated in a Bayesian framework, but our results also highlight the difficulty 12 of identifying DEB model parameters which serves as a reminder that fitting these models requires 13 statistical caution. 14},
author = {Boersch-Supan, Philipp H and Johnson, Leah R},
doi = {10.1101/259705},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boersch-Supan, Johnson - 2018 - A tutorial on Bayesian parameter inference for dynamic energy budget models(2).pdf:pdf},
journal = {bioRxiv},
keywords = {dynamic energy budget theory,informative priors 15,parameter identifiability},
number = {February 3},
title = {{A tutorial on Bayesian parameter inference for dynamic energy budget models}},
url = {https://www.biorxiv.org/content/biorxiv/early/2018/02/05/259705.full.pdf http://dx.doi.org/10.1101/259705},
year = {2018}
}
@book{Wit2006,
author = {Wit, Martin De},
booktitle = {Bouwstenen},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wit - 2006 - Heat air and moisture model for building and systems evaluation.pdf:pdf},
isbn = {9068146017},
title = {{Heat air and moisture model for building and systems evaluation}},
url = {http://sts.bwk.tue.nl/bps/onderwijs/readers/HambaseV2{\_}2008.pdf},
year = {2006}
}
@article{Senave2020,
abstract = {The past decade has seen the rapid development of sensor technologies. Monitoring data of the interior climate and energy consumption of in-use buildings, so-called on-board monitoring (OBM) data, offers the opportunity to identify as-built energy performance indicators, such as the heat loss coefficient (HLC) of the building envelope. To this end, it is important to advance the understanding of the impact of the OBM set-up and the applied data analysis method. This paper uses synthetic OBM data sets, generated from building energy simulations. The level of accuracy achieved with four data analysis methods for characterizing the HLC is investigated. The considered methods are the Average Method, the Energy Signature Method, Linear Regression and ARX modeling. Different cases, representing different building types, are considered in order to gain thorough insight into the physical interpretation of the results. By taking subsets of the original data sets, the sensitivity of the data analysis methods to the availability of specific data is assessed. This theoretical exercise illustrates how, under idealized monitoring circumstances, both linear regression and ARX models can accurately determine the HLC. The latter is able to assess the performance indicator within 5{\%}. However, when subjected to practical limitations regarding the measurement of system inputs, such as unavailable solar or internal heat gains, the characterization results show large variations in accuracy and uncertainty.},
author = {Senave, Marieline and Roels, Staf and Reynders, Glenn and Verbeke, Stijn and Saelens, Dirk},
doi = {10.1016/j.enbuild.2019.109706},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778819319747-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Characterization,Data Analysis Methods,Heat loss coefficient,Physical parameter identification,Synthetic Monitoring Data},
pages = {109706},
publisher = {Elsevier B.V.},
title = {{Assessment of data analysis methods to identify the heat loss coefficient from on-board monitoring data}},
url = {https://doi.org/10.1016/j.enbuild.2019.109706},
volume = {209},
year = {2020}
}
@inproceedings{Martincevic2015,
abstract = {{\textcopyright} 2014 IEEE. The improvement of the building sector energy efficiency becomes crucially important to attain a balance in many sectors. Reduction of the energy consumption in buildings by using model predictive control strategies is recognized as one of the essential solutions to achieve considerable energy savings. Due to the nature of thermodynamic processes in buildings the underlying models are mostly nonlinear and of high order. In this work Constrained Unscented Kalman Filter is employed to obtain a linear low order model of a large public building applicable for the predictive control. Through the comparison of results with the data generated by highly accurate building simulation software IDA Indoor Climate and Energy (IDA-ICE), it has been shown that the first order linear model for each zone, with separated nonlinearities related to the solar radiation effects, is sufficient to capture the main dynamics of the observed building.},
author = {Martincevic, Anita and Starcic, Antonio and Vasak, Mario},
booktitle = {IEEE PES Innovative Smart Grid Technologies Conference Europe},
doi = {10.1109/ISGTEurope.2014.7028767},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin{\v{c}}evi, Star{\v{c}}i, Va{\v{s}}ak - Unknown - Parameter estimation for low-order models of complex buildings.pdf:pdf},
isbn = {978-1-4799-7720-8},
keywords = {Building temperature prediction,Constrained Unscented Kalman Filter (UKF),Model Predictive Control (MPC),Online parameter identification,Parameter-Adaptive building model},
month = {oct},
number = {January},
pages = {1--6},
publisher = {IEEE},
title = {{Parameter estimation for low-order models of complex buildings}},
url = {http://bib.irb.hr/datoteka/719796.Martincevic{\_}Starcic{\_}Vasak.pdf http://ieeexplore.ieee.org/document/7028767/},
volume = {2015-Janua},
year = {2015}
}
@article{Ouf2019,
abstract = {Most existing and new buildings adapt poorly to variable occupancy, in part due to technical constraints and common operational practice. Although building automation systems and advanced control strategies aim to address this issue by improving adaptability to partial occupancy, no holistic metrics exist to quantify this aspect of building performance. To this end, we present a technology-independent approach to define adaptability as a building performance attribute and introduce metrics to quantify it. These metrics can be used to evaluate how different building technologies and control strategies influence building operations' adaptability to variable occupancy or estimate their associated energy savings. To demonstrate these metrics, a case study based on simulating a single-story office building was used to compare several control strategies with regards to their effect on improving adaptability. Results showed how the proposed metrics highlighted the additional benefits of these control strategies, especially under low-occupancy scenarios. Performance-based compliance with building energy codes and standards typically assumes full or near full occupancy, which may underestimate the benefits of adaptable building technologies or controls. Therefore, incorporating adaptability metrics in energy codes and operational guidelines would quantify the benefits of adaptable systems, especially under variable occupancy.},
author = {Ouf, Mohamed M. and O'Brien, William and Gunay, Burak},
doi = {10.1016/J.BUILDENV.2019.03.048},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ouf, O'Brien, Gunay - 2019 - On quantifying building performance adaptability to variable occupancy.pdf:pdf},
issn = {0360-1323},
journal = {Building and Environment},
publisher = {Elsevier Ltd},
title = {{On quantifying building performance adaptability to variable occupancy}},
url = {https://www.sciencedirect.com/science/article/pii/S0360132319302100},
year = {2019}
}
@article{Robinson2009,
author = {Robinson, Darren},
doi = {10.1016/j.buildenv.2009.03.025},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robinson - 2009 - Interactions with window openings by office occupants.pdf:pdf},
issn = {0360-1323},
journal = {Building and Environment},
number = {12},
pages = {2378--2395},
publisher = {Elsevier Ltd},
title = {{Interactions with window openings by office occupants}},
url = {http://dx.doi.org/10.1016/j.buildenv.2009.03.025},
volume = {44},
year = {2009}
}
@article{Rabl1992,
abstract = {The purpose of this paper is twofold: to see if the application of the energy signature model PRISM to commercial buildings can be improved by adding occupancy as a variable, and to examine what one can learn from the individual parameters that have been identified. Using occupancy rate as proxy for the operating mode of the building and its HVAC system, the model is generalized by doubling the number of parameters and distinguishing two types of day, occupied and unoccupied. This approach is tested with measured consumption data for some fifty commercial buildings. The results show that occupancy data can bring appreciable improvement in the accuracy of the model. However, the interpretation of the individual parameters, such as slope and balance point temperature, should be undertaken with great caution. Due to various biases the discrepancy between the parameters identified by an energy signature model and the true values can differ by far more than the standard errors indicated by the regression. Such biases are particularly important in commercial buildings, as we demonstrate with several examples. {\textcopyright} 1992.},
author = {Rabl, A. and Rialhe, A.},
doi = {10.1016/0378-7788(92)90008-5},
file = {:home/sarah/OneDrive/Travail/Sources/Diagnostic/1-s2.0-0378778892900085-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {commercial buildings,energy audits,energy consumption data,energy management,energy signature,parameter identification},
number = {2},
pages = {143--154},
title = {{Energy signature models for commercial buildings: test with measured data and interpretation}},
volume = {19},
year = {1992}
}
@article{Gustafson2010,
abstract = {Identification can be a major issue in causal modeling contexts, and in contexts where observational studies have various limitations. Partially identified models can arise, whereby the identification region for a target parameter - the set of values consistent with the law of the observable data - is strictly contained in the set of a priori plausible values, but strictly contains the single true value. The first part of this paper reviews the use of Bayesian inference in partially identified models, and describes the large-sample limit of the posterior distribution over the target parameter. This limiting distribution will have the identification region as its support. The second part of the paper focuses on the informativeness of the shape of the limiting distribution. This provides a point of departure with non-Bayesian approaches, since they focus on inferring the identification region without attempting to speak to relative plausibilities of values inside the identification region. The utility of the shape is investigated in several partially identified models. {\textcopyright} 2010 The Berkeley Electronic Press. All rights reserved.},
author = {Gustafson, Paul},
doi = {10.2202/1557-4679.1206},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/[The International Journal of Biostatistics] Bayesian Inference for Partially Identified Models.pdf:pdf},
issn = {15574679},
journal = {International Journal of Biostatistics},
keywords = {Asymptotics,Bayesian inference,Nonidentified models},
number = {2},
title = {{Bayesian inference for partially identified models}},
volume = {6},
year = {2010}
}
@article{Alzetto2018,
abstract = {The accurate assessment of buildings to assess their performance across a range of parameters is an essential part of understanding both new and retrofit buildings. The growing understanding of the performance gap in terms of its assessment and characterisation relies on effective methods of analysis. Here, we evaluate an experimental whole house method, known as QUB. As with many whole building approaches the method establishes heat loss through transmission and ventilation losses. This study compares QUB against an alternative, established, whole house test known as coheating. It was applied in a whole house test facility under controlled conditions. The test property, a solid wall pre-1919 UK archetype, was retrofit using a set of commercially available products and then the retrofit was removed in stages. At each of these stages a QUB test, which commonly takes one night, and coheating test, which can take few weeks, were applied. The objective of the study was to provide a comparison between the new method and more established method in terms of accuracy. The two methods showed close agreement in terms of results, suggesting that the quicker test has great potential as a more practical and economic test. There were higher levels of uncertainty with the QUB method due to shorter measurement periods. The lack of full boundary conditions within the test facility should be considered a limitation in applying the findings directly to the field. However, this study indicates the potential for QUB in validating performance, warranting further investigation.},
author = {Alzetto, Florent and Farmer, David and Fitton, Richard and Hughes, Tara and Swan, Will},
doi = {10.1016/j.enbuild.2018.03.024},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alzetto et al. - 2018 - Comparison of whole house heat loss test methods under controlled conditions in six distinct retrofit scenarios.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building thermal performance,Coheating,HLC,Performance gap,QUB,Retrofit,Thermal performance methods},
month = {jun},
pages = {35--41},
publisher = {Elsevier B.V.},
title = {{Comparison of whole house heat loss test methods under controlled conditions in six distinct retrofit scenarios}},
url = {https://doi.org/10.1016/j.enbuild.2018.03.024 https://linkinghub.elsevier.com/retrieve/pii/S0378778818307412},
volume = {168},
year = {2018}
}
@phdthesis{Jedidi2016,
abstract = {With the increasing complexity of dynamical systems that appear in engineering and other fields of science, the study of large systems consisting of a set of interconnected subsystems has become an important subject of attention in various areas such as ro- botics, transport networks, large spacial structures (solar panels, antennas, telescopes, . . . ), buildings, . . . and led to interesting problems of parametric identification analysis, distributed control and optimization. The lack of a universal definition of systems called ”large systems”, ”complex systems”, ”interconnected systems”, . . . , demonstrates the confusion between these concepts and the difficulty of defining clear boundaries for such systems. The analysis of the identifiability and identification of these systems requires processing digital models of large scale, the management of diverse dynamics within the same system and the consideration of structural constraints (interconnections, . . . ) . This is very complicated and very difficult to handle. Thus, these analyzes are rarely taken into consideration globally. Simplifying the problem by decomposing the large system to sub-problems is often the only possible solution. This thesis presents a decentralized approach for the identification of ”large scale sys- tems” composed of a set of interconnected subsystems. This approach is based on the structural properties (controllability, observability and identifiability) of the global system. This methodological approach is implemented on thermal applications of buildings. The advantage of this approach is demonstrated through comparisons with a global approach},
author = {Jedidi, Safa},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jedidi - 2016 - Identification d{\'{e}}centralis{\'{e}}e des syst{\`{e}}mes de grande taille. Approches appliqu{\'{e}}es {\`{a}} la thermique des b{\^{a}}timents.pdf:pdf},
keywords = {Decentralized identification,Identifiabilit{\'{e}} structurelle,Identification d{\'{e}}centralis{\'{e}}e,Large scale systems,buildings,structural identifiability},
mendeley-tags = {Identifiabilit{\'{e}} structurelle,Identification d{\'{e}}centralis{\'{e}}e},
school = {Universit{\'{e}} de Rennes},
title = {{Identification d{\'{e}}centralis{\'{e}}e des syst{\`{e}}mes de grande taille. Approches appliqu{\'{e}}es {\`{a}} la thermique des b{\^{a}}timents}},
year = {2016}
}
@inproceedings{Bou-Saada,
abstract = {In order to improve upon previous calibration techniques, this paper presents new calibration methods including a temperature bin analysis to improve hourly x-y scatter plots, a 24-hour weather-daytype bin analysis to allow for the evaluation of hourly temperature and schedule dependent comparisons, and a 52-week bin analysis to facilitate the evaluation of long-term trends. In addition, architectural rendering is suggested as a means of verifying the building envelope dimensions and external shading placement. Several statistical methods are also reviewed to evaluate the goodness-of-fit including percent difference calculations, mean bias error (MBE), and the coefficient of variation of the root mean squared error (CV(RMSE)). The procedures are applied to a case study building located in Washington, D.C. Nine months of hourly whole-building electricity data and site-specific weather data were measured and used with the DOE-2. ID building simulation program to test the new techniques. Use of the new calibration procedures were able to produce an hourly MBE of -0.7{\%} and a CV(RMSE) of 23.1{\%} which compare favorably with the most accurate hourly neural network models.},
author = {Bou-Saada, Tarek E and Haberl, Jeff S},
booktitle = {IBPSA},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bou-Saada, Haberl - Unknown - AN IMPROVED PROCEDURE FOR DEVELOPING CALIBRATED HOURLY SIMULATION MODELS.pdf:pdf},
keywords = {Model calibration,Model fit assessment},
mendeley-tags = {Model calibration,Model fit assessment},
title = {{AN IMPROVED PROCEDURE FOR DEVELOPING CALIBRATED HOURLY SIMULATION MODELS}},
url = {http://oaktrust.library.tamu.edu/bitstream/handle/1969.1/94780/ESL-PA-95-08-01.pdf?sequence=1{\&}isAllowed=y}
}
@article{Akaike1981,
author = {Akaike, Hirotugu},
doi = {10.1016/0304-4076(81)90071-3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Akaike - 1981 - Likelihood of a model and information criteria.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
month = {may},
number = {1},
pages = {3--14},
title = {{Likelihood of a model and information criteria}},
url = {http://paper.blog.bbiq.jp/Akaike{\_}1981.pdf http://linkinghub.elsevier.com/retrieve/pii/0304407681900713},
volume = {16},
year = {1981}
}
@article{Bauwens2014,
author = {Bauwens, Geert and Roels, Staf},
doi = {10.1016/j.enbuild.2014.04.039},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauwens, Roels - 2014 - Co-heating test A state-of-the-art.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Co-heating},
mendeley-tags = {Co-heating},
pages = {163--172},
title = {{Co-heating test: A state-of-the-art}},
url = {https://www.researchgate.net/profile/Staf{\_}Roels/publication/264426836{\_}Co-heating{\_}test{\_}A{\_}state-of-the-art/links/54df6df00cf29666378a4ccd.pdf http://linkinghub.elsevier.com/retrieve/pii/S0378778814003648},
volume = {82},
year = {2014}
}
@article{Karlsson2012,
abstract = {Ordinary differential equation models often contain a large number of parameters that must be determined from measurements by parameter estimation. For a parameter estimation procedure to be successful, there must be a unique set of parameters that can have produced the measured data. This is not the case if a model is not structurally identifiable with the given set of outputs selected as measurements. We describe the implementation of a recent probabilistic semi-numerical method for testing local structural identifiability based on computing the rank of a numerically instantiated Jacobian matrix (observability/identifiability matrix). To obtain this, matrix parameters and initial conditions are specialized to random integer numbers, inputs are specialized to truncated random integer coefficient power series, and the corresponding output of the state space system is computed in terms of a truncated power series, which then is utilized to calculate the elements of a Jacobian matrix. To reduce the memory requirements and increase the speed of the computations all operations are done modulo a large prime number. The method has been extended to handle parametrized initial conditions and is demonstrated to be capable of handling systems in the order of a hundred state variables and equally many parameters on a standard desktop computer. {\textcopyright} 2012 IFAC.},
address = {Brussels},
author = {Karlsson, Johan and Anguelova, Milena and Jirstrand, Mats},
doi = {10.3182/20120711-3-BE-2027.00381},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/local{\_}170841.pdf:pdf},
isbn = {9783902823069},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Dynamic systems,Identifiability,Parameter estimation,Systems identification},
month = {jul},
number = {16},
pages = {941--946},
title = {{An Efficient Method for Structural Identifiability Analysis of Large Dynamic Systems*}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667015380745},
volume = {45},
year = {2012}
}
@article{Lomas1992,
abstract = {Three sensitivity analysis techniques, differential sensitivity analysis (DSA), Monte Carlo analysis (MCA), and stochastic sensitivity analysis (SSA), are appraised using three detailed finite difference simulation programs, ESP, HTB2, and SERI-RES. The applicability of the methods to simpler programs is considered. Domestic-scale, passive solar buildings are used as vehichles for testing the methods. The sensitivities, in both hourly and daily average predictions, due to the uncertainties in over 70 input parameters, are compared for DSA and MCA. The sensitivities of the predictions to changes in a reduced set of inputs are compared for DSA and SSA. It was found that in this case SSA had drawbacks. It is suggested that, at present, DSA is used to obtain the sensitivities of predictions to individual input parameter uncertainties and that MCA is used to obtain the total sensitivities in the predictions. With further work, it may be possible to extract individual sensitivities from MCA, which would make this the preferred technique. ?? 1992.},
author = {Lomas, Kevin J. and Eppel, Herbert},
doi = {10.1016/0378-7788(92)90033-D},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lomas, Eppel - 1992 - Sensitivity analysis techniques for building thermal simulation programs.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
number = {1},
pages = {21--44},
title = {{Sensitivity analysis techniques for building thermal simulation programs}},
volume = {19},
year = {1992}
}
@misc{BigLadderSoftware2016a,
author = {{Big Ladder Software}},
title = {{Input Output Reference - Weather Data Hourly Interpolation}},
url = {https://bigladdersoftware.com/epx/docs/8-5/input-output-reference/weather-data-hourly-interpolation.html},
urldate = {2019-10-10},
year = {2016}
}
@article{Maillet2010,
author = {Maillet, Denis and Sablier, Michel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillet, Sablier - 2010 - Probl{\`{e}}mes inverses en diffusion thermique Mod{\`{e}}les diffusifs, mesures, sensibilit{\'{e}}s.pdf:pdf},
isbn = {7200103624},
title = {{Probl{\`{e}}mes inverses en diffusion thermique : Mod{\`{e}}les diffusifs, mesures, sensibilit{\'{e}}s}},
year = {2010}
}
@article{Balan2011,
author = {Balan, R. and Cooper, J. and Chao, K. and Stan, S. and Donca, R.},
journal = {Energy and Buildings},
pages = {748--758},
title = {{Parameter identification and model based predictive control of temperature inside a house}},
volume = {43},
year = {2011}
}
@phdthesis{Andersen2013,
author = {Andersen, Philip Delff},
file = {:home/sarah/OneDrive/Travail/Sources/Ph.D.{\_}thesis{\_}-{\_}2013{\_}-{\_}Models{\_}for{\_}the{\_}energy{\_}performance{\_}of{\_}low-energy{\_}houses.pdf:pdf},
keywords = {Statistical modeling,Stochastic differential equa},
school = {Technical University of Danmark},
title = {{Models for the energy performance of low-energy houses}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Models+for+the+energy+performance+of+low-energy+houses{\#}0},
year = {2013}
}
@article{DeSimon2018,
author = {{De Simon}, Lia and Iglesias, Marco and Jones, Benjamin and Wood, Christopher},
doi = {10.1016/j.enbuild.2018.06.045},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Simon et al. - 2018 - Quantifying uncertainty in thermophysical properties of walls by means of Bayesian inversion.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian framework,Heat transfer,Inverse p,U-value},
month = {oct},
pages = {220--245},
publisher = {Elsevier B.V.},
title = {{Quantifying uncertainty in thermophysical properties of walls by means of Bayesian inversion}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778817334035},
volume = {177},
year = {2018}
}
@article{Watanabe2013,
abstract = {A statistical model or a learning machine is called regular if the map taking a parameter to a probability distribution is one-to-one and if its Fisher information matrix is always positive definite. If otherwise, it is called singular. In regular statistical models, the Bayes free energy, which is defined by the minus logarithm of Bayes marginal likelihood, can be asymptotically approximated by the Schwarz Bayes information criterion (BIC), whereas in singular models such approximation does not hold. Recently, it was proved that the Bayes free energy of a singular model is asymptotically given by a generalized formula using a birational invariant, the real log canonical threshold (RLCT), instead of half the number of parameters in BIC. Theoretical values of RLCTs in several statistical models are now being discovered based on algebraic geometrical methodology. However, it has been difficult to estimate the Bayes free energy using only training samples, because an RLCT depends on an unknown true distribution. In the present paper, we define a widely applicable Bayesian information criterion (WBIC) by the average log likelihood function over the posterior distribution with the inverse temperature 1/logn, where n is the number of training samples. We mathematically prove that WBIC has the same asymptotic expansion as the Bayes free energy, even if a statistical model is singular for or unrealizable by a statistical model. Since WBIC can be numerically calculated without any information about a true distribution, it is a generalized version of BIC onto singular statistical models. ?? 2013 Sumio Watanabe.},
archivePrefix = {arXiv},
arxivId = {1208.6338},
author = {Watanabe, Sumio},
eprint = {1208.6338},
file = {:home/sarah/OneDrive/Travail/Sources/watanabe13a.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Bayes marginal likelihood,Widely applicable Bayes information criterion},
number = {1},
pages = {867--897},
title = {{A widely applicable bayesian information criterion}},
volume = {14},
year = {2013}
}
@book{IEA2014a,
abstract = {Reliable building energy performance characterisation based on full scale dynamic measurements in Buildings Background : Renewed interest in full scale testing Interest},
author = {IEA},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/IEA - 2014 - Annex 58 Final Report ST 3a.pdf:pdf},
isbn = {9789460189906},
number = {May},
pages = {1--11},
title = {{Annex 58 Final Report ST 3a}},
year = {2014}
}
@article{Ham2015,
abstract = {The ability to import building geometric and construction thermal data from building information models (BIM) has significant potential to reduce the time and uncertainty in building energy modeling process. In today's BIM-based energy modeling practice, thermal properties are mainly derived from generic building construction types in BIM. However, for energy modeling of existing buildings, such assumptions are often inaccurate as they do not account for diminishing thermal resistances of building materials instigated by their deteriorations. To improve the reliability of BIM-based energy modeling, we present a system, together with new methods for automated association and updating of actual thermal property measurements with BIM elements in gbXML schema. By leveraging collections of digital and thermal images and based on environmental measurements, our system first produces a 3D thermal model for the building under inspection and then derives the actual thermal resistances of the building assemblies at the level of 3D vertexes. By associating these measurements with their corresponding elements in gbXML, thermal properties of the BIM elements are automatically updated. Our experiments in real-world residential and instructional buildings show how actual thermal properties can be automatically associated with BIM elements and updated in gbXML. The proposed method shortens the gap between architectural information in BIM and the actual data needed for energy performance simulation, and enables reliable BIM-based energy analysis for retro-commissioning, continuous commissioning, and retrofit.},
author = {Ham, Youngjib and Golparvar-Fard, Mani},
doi = {10.1016/j.autcon.2014.07.009},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0926580514001605-main.pdf:pdf},
issn = {09265805},
journal = {Automation in Construction},
keywords = {Building energy performance modeling,Building information models (BIM),Building retrofits,Green building XML (gbXML),Image-based 3D reconstruction,Thermal resistances,Thermography},
pages = {214--224},
publisher = {Elsevier B.V.},
title = {{Mapping actual thermal properties to building elements in gbXML-based BIM for reliable building energy performance modeling}},
url = {http://dx.doi.org/10.1016/j.autcon.2014.07.009},
volume = {49},
year = {2015}
}
@article{Afram2015,
abstract = {In this article, black-box models of the residential heating, ventilation and air conditioning (HVAC) system are developed. The data of the input and output of the system is measured and the models of the energy recovery ventilator (ERV), air handling unit (AHU), buffer tank (BT), radiant floor heating (RFH) and ground source heat pump (GSHP) are developed using the system identification techniques in Matlab{\textregistered}. The developed models include models based on multiple-input and multiple-output (MIMO) artificial neural network (ANN), transfer function (TF), process, state-space (SS) and autoregressive exogenous (ARX) ones of each HVAC subsystem (ERV, AHU, BT and RFH). The gray-box models of the same HVAC subsystems were developed in [1] which are also compared with the black-box models developed in this article. The models were compared visually and analytically. Ranks of the models were calculated based on their relative performance. It was found that the ANN outperforms the other modeling methods followed by the ARX, TF, SS, process and gray-box models respectively.},
author = {Afram, Abdul and Janabi-Sharifi, Farrokh},
doi = {10.1016/j.enbuild.2015.02.045},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778815001504-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Black-box models,Gray-box models,HVAC models,Modeling comparison,System identification},
pages = {121--149},
publisher = {Elsevier B.V.},
title = {{Black-box modeling of residential HVAC system and comparison of gray-box and black-box modeling methods}},
url = {http://dx.doi.org/10.1016/j.enbuild.2015.02.045},
volume = {94},
year = {2015}
}
@article{Godfrey1980,
author = {Godfrey, Keith Richard},
doi = {10.1016/S1474-6670(17)53974-9},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S1474667017539749-main.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {--computational methods,Computational methods,abstract,correlation methods,correlation theory,crosscorrelation to determine,dynamic response,emphasising the use of,identification,random processes,the paper discusses the,theory of correlation me-,thods},
month = {sep},
number = {8},
pages = {527--534},
publisher = {Elsevier},
title = {{Correlation Methods}},
url = {http://dx.doi.org/10.1016/S1474-6670(17)53974-9 https://linkinghub.elsevier.com/retrieve/pii/S1474667017539749},
volume = {12},
year = {1979}
}
@book{Ritt1950,
author = {Ritt, Joseph Fels},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ritt - 1950 - Differential Algebra.pdf:pdf},
keywords = {Alg{\`{e}}bre diff{\'{e}}rentielle},
mendeley-tags = {Alg{\`{e}}bre diff{\'{e}}rentielle},
publisher = {American Mathematical Soc.},
title = {{Differential Algebra}},
volume = {33},
year = {1950}
}
@phdthesis{Perasso2009,
author = {Perasso, Antoine},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perasso - 2009 - Pr{\'{e}}sent{\'{e}}e pour obtenir par Identifiabilit{\'{e}} de param{\`{e}}tres pour des syst{\`{e}}mes d{\'{e}}crits par des {\'{e}}quations aux d{\'{e}}ri.pdf:pdf},
pages = {166},
school = {Universit{\'{e}} Paris-Sud 11},
title = {{Identifiabilit{\'{e}} de param{\`{e}}tres pour des syst{\`{e}}mes d{\'{e}}crits par des {\'{e}}quations aux d{\'{e}}riv{\'{e}}es partielles . Application {\`{a}} la dynamique des populations}},
year = {2009}
}
@article{Gelman2013,
abstract = {A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics. We argue that the most successful forms of Bayesian statistics do not actually support that particular philosophy but rather accord much better with sophisticated forms of hypothetico-deductivism. We examine the actual role played by prior distributions in Bayesian models, and the crucial aspects of model checking and model revision, which fall outside the scope of Bayesian confirmation theory. We draw on the literature on the consistency of Bayesian updating and also on our experience of applied work in social science. Clarity about these matters should benefit not just philosophy of science, but also statistical practice. At best, the inductivist view has encouraged researchers to fit and compare models without checking them; at worst, theorists have actively discouraged practitioners from performing model checking because it does not fit into their framework.},
annote = {From Duplicate 2 (Philosophy and the practice of Bayesian statistics - Gelman, Andrew; Shalizi, Cosma Rohilla)

Article qui {\'{e}}tudie les priors et leur impact sur le r{\'{e}}sultat final.
Les prior uniformes et larges sont les plus efficaces.},
author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
doi = {10.1111/j.2044-8317.2011.02037.x},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman, Shalizi - Unknown - Philosophy and the practice of Bayesian statistics.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman, Shalizi - 2013 - Philosophy and the practice of Bayesian statistics.pdf:pdf},
issn = {00071102},
journal = {British Journal of Mathematical and Statistical Psychology},
month = {feb},
number = {1},
pages = {8--38},
publisher = {Blackwell Publishing Ltd},
title = {{Philosophy and the practice of Bayesian statistics}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4476974/pdf/nihms697619.pdf http://doi.wiley.com/10.1111/j.2044-8317.2011.02037.x},
volume = {66},
year = {2013}
}
@phdthesis{Dobre2010,
annote = {Lien entre analyse de sensibilit�� et identifiabilit��?},
author = {Dobre, Simona},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dobre - 2010 - Analyses de sensibilit{\'{e}} et d ' identifiabilit{\'{e}} globales . Application {\`{a}} l ' estimation de param{\`{e}}tres photophysiq.pdf:pdf},
keywords = {A lire},
mendeley-tags = {A lire},
school = {Universit{\'{e}} Henri Poincar{\'{e}}, Nancy 1},
title = {{Analyses de sensibilit{\'{e}} et d ' identifiabilit{\'{e}} globales . Application {\`{a}} l ' estimation de param{\`{e}}tres photophysiques en th{\'{e}}rapie photodynamique}},
year = {2010}
}
@article{Conti2005,
abstract = {In many fields of science, sophisticated mathematical models are devised and implemented within large computer codes in order to simulate and predict complex real-world phenomena. These models are known for being exposed to various sources of uncertainty taking place at their building and validation steps, so that they are routinely subject to reliability tests by means of uncertainty and/or sensitivity analysis. Since such diagnostics typically require a large number of training code runs, for CPU-intensive models an approach based around preliminary emulation of a code's response, followed by application of the aforementioned techniques to the emulator, can be more practical and efficient. This paper extends results already established within a Bayesian set-up for deterministic models (see e.g. [1]) to dynamic multi-response computer codes, for which some of the outputs at one stage of a simulation become inputs to the subsequent stage. Advantages and difficulties in the implementation are here discussed, and a test- bed application to the Sheffield Dynamic Global Vegetation Model, developed within the UK Centre for Terrestrial Carbon Dynamics, is also presented.},
author = {Conti, Stefano and Anderson, Clive W and Kennedy, Marc C and Hagan, Anthony O},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Conti et al. - Unknown - A Bayesian Analysis of Complex Dynamic Computer Models.pdf:pdf},
journal = {Computer},
keywords = {analysis,bayesian inference,computer experiments,hierarchical models,sensitivity,uncertainty analysis},
number = {June 2014},
pages = {147--156},
title = {{A Bayesian Analysis of Complex Dynamic Computer Models}},
url = {https://www.researchgate.net/profile/Marc{\_}Kennedy/publication/228738723{\_}A{\_}Bayesian{\_}analysis{\_}of{\_}complex{\_}dynamic{\_}computer{\_}models/links/09e41507ed0b37c273000000.pdf},
year = {2005}
}
@article{Plumlee2017,
author = {Plumlee, Matthew},
doi = {10.1080/01621459.2016.1211016},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = {jul},
number = {519},
pages = {1274--1285},
title = {{Bayesian Calibration of Inexact Computer Models}},
url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1211016},
volume = {112},
year = {2017}
}
@article{Kramer2012,
abstract = {This paper provides a systematic literature review on simplified building models. Questions are answered like: What kind of modelling approaches are applied? What are their (dis)advantages? What are important modelling aspects? The review showed that simplified building models can be classified into neural network models (black box), linear parametric models (black box or grey box) and lumped capacitance models (white box). Research has mainly dealt with network topology, but more research is needed on the influence of input parameters. The review showed that particularly the modelling of the influence of sun irradiation and thermal capacitance is not performed consistently amongst researchers. Furthermore, a model with physical meaning, dealing with both temperature and relative humidity, is still lacking. Inverse modelling has been widely applied to determine models parameters. Different optimization algorithms have been used, but mainly the conventional Gaus-Newton and the newer genetic algorithms. However, the combination of algorithms to combine their strengths has not been researched. Despite all the attention for state of the art building performance simulation tools, simplified building models should not be forgotten since they have many useful applications. Further research is needed to develop a simplified hygric and thermal building model with physical meaning.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0402594v3},
author = {Kramer, Rick and van Schijndel, Jos and Schellen, Henk},
doi = {10.1016/j.foar.2012.09.001},
eprint = {0402594v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kramer, van Schijndel, Schellen - 2012 - Simplified thermal and hygric building models A literature review(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kramer, van Schijndel, Schellen - 2012 - Simplified thermal and hygric building models A literature review.pdf:pdf},
isbn = {03787788},
issn = {20952635},
journal = {Frontiers of Architectural Research},
keywords = {Building performance simulation,Climate change,Inverse modelling,Literature review,Simplified building models},
number = {4},
pages = {318--325},
pmid = {21489910},
primaryClass = {arXiv:cond-mat},
publisher = {Elsevier},
title = {{Simplified thermal and hygric building models: A literature review}},
url = {http://dx.doi.org/10.1016/j.foar.2012.09.001},
volume = {1},
year = {2012}
}
@article{Antonopoulos1998,
author = {Antonopoulos, K A and Koronaki, E},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antonopoulos, Koronaki - 1998 - Apparent and Effective Thermal Capacitance of.pdf:pdf},
number = {3},
pages = {183--192},
title = {{Apparent and Effective Thermal Capacitance of}},
volume = {23},
year = {1998}
}
@article{Evins2013,
abstract = {This paper presents a comprehensive review of all significant research applying computational optimisation to sustainable building design problems. A summary of common heuristic optimisation algorithms is given, covering direct search, evolutionary methods and other bio-inspired algorithms. The main summary table covers 74 works that focus on the application of these methods to different fields of sustainable building design. Key fields are reviewed in detail: envelope design, including constructions and form; configuration and control of building systems; renewable energy generation; and holistic optimisations of several areas simultaneously, with particular focus on residential and retrofit. Improvements to the way optimisation is applied are also covered, including platforms and frameworks, algorithmic comparisons and developments, use of meta-models and incorporation of uncertainty. Trends, including the rise of multi-objective optimisation, are analysed graphically. Likely future developments are discussed.},
author = {Evins, Ralph},
doi = {10.1016/j.rser.2013.02.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Evins - 2013 - A review of computational optimisation methods applied to sustainable building design.pdf:pdf},
isbn = {1364-0321},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Building,Design,Multi-objective,Optimisation,Review,Sustainable},
pages = {230--245},
publisher = {Elsevier},
title = {{A review of computational optimisation methods applied to sustainable building design}},
url = {http://dx.doi.org/10.1016/j.rser.2013.02.004},
volume = {22},
year = {2013}
}
@article{Varghese2018,
author = {Varghese, Arun and Narasimhan, Sridharakumar and Bhatt, Nirav},
doi = {10.1016/j.ifacol.2018.09.162},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Varghese, Narasimhan, Bhatt - 2018 - A Priori Parameter Identifiability in Complex Reaction Networks.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Complex Reaction Networks,Extent Domain,Parameter Identifiability,Ritts Pseudo–Division Algorithm,Systems Biology},
number = {15},
pages = {760--765},
publisher = {Elsevier B.V.},
title = {{A Priori Parameter Identifiability in Complex Reaction Networks}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896318318238},
volume = {51},
year = {2018}
}
@article{Pant2018,
abstract = {A new class of functions, called the `Information sensitivity functions' (ISFs), which quantify the information gain about the parameters through the measurements/observables of a dynamical system are presented. These functions can be easily computed through classical sensitivity functions alone and are based on Bayesian and information-theoretic approaches. While marginal information gain is quantified by decrease in differential entropy, correlations between arbitrary sets of parameters are assessed through mutual information. For individual parameters these information gains are also presented as marginal posterior variances, and, to assess the effect of correlations, as conditional variances when other parameters are given. The easy to interpret ISFs can be used to a) identify time-intervals or regions in dynamical system behaviour where information about the parameters is concentrated; b) assess the effect of measurement noise on the information gain for the parameters; c) assess whether sufficient information in an experimental protocol (input, measurements, and their frequency) is available to identify the parameters; d) assess correlation in the posterior distribution of the parameters to identify the sets of parameters that are likely to be indistinguishable; and e) assess identifiability problems for particular sets of parameters.},
archivePrefix = {arXiv},
arxivId = {1711.08360},
author = {Pant, Sanjay},
doi = {10.1098/rsif.2017.0871},
eprint = {1711.08360},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pant - 2017 - Information sensitivity functions to assess parameter information gain and identifiability of dynamical systems.pdf:pdf},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
month = {may},
number = {142},
pages = {20170871},
title = {{Information sensitivity functions to assess parameter information gain and identifiability of dynamical systems}},
url = {https://arxiv.org/pdf/1711.08360.pdf http://arxiv.org/abs/1711.08360 http://www.royalsocietypublishing.org/doi/10.1098/rsif.2017.0871},
volume = {15},
year = {2018}
}
@article{Kreutz2013,
abstract = {Inferring knowledge about biological processes by a mathematical description is a major characteristic of Systems Biology. To understand and predict system's behavior the available experimental information is translated into a mathematical model. Since the availability of experimental data is often limited and measurements contain noise, it is essential to appropriately translate experimental uncertainty to model parameters as well as to model predictions. This is especially important in Systems Biology because typically large and complex models are applied and therefore the limited experimental knowledge might yield weakly specified model components. Likelihood profiles have been recently suggested and applied in the Systems Biology for assessing parameter and prediction uncertainty. In this article, the profile likelihood concept is reviewed and the potential of the approach is demonstrated for a model of the erythropoietin (EPO) receptor. To understand and predict system's behavior, it is essential to appropriately translate experimental uncertainty to model parameters as well as to model predictions. Likelihood profiles have been recently suggested and applied in the Systems Biology for this purpose. We review the concept and demonstrate the potential of the approach for a model of the EPO receptor. {\textcopyright} 2013 FEBS.},
author = {Kreutz, Clemens and Raue, Andreas and Kaschek, Daniel and Timmer, Jens},
doi = {10.1111/febs.12276},
file = {:home/sarah/OneDrive/Travail/Sources/febs12276.pdf:pdf},
issn = {1742464X},
journal = {FEBS Journal},
keywords = {parameter estimation,prediction,profile likelihood,propagation of errors,uncertainty},
number = {11},
pages = {2564--2571},
title = {{Profile likelihood in systems biology}},
volume = {280},
year = {2013}
}
@phdthesis{Arendt2012a,
abstract = {Simulation based design under uncertainty has played a critical role in designing high quality and low cost products. On a parallel front, complex and computationally expensive computer simulations have become commonplace in engineering design. However, challenges arise when utilizing these complex computer simulations within the design under uncertainty framework. Specifically, two of the main challenges are to account for the different sources of uncertainty present in the engineering system (a.k.a. model uncertainty) and to mitigate the effect on the response of both the variations of the input variables and the uncertainty due to a lack of observations from the computer simulator. In physics-based models, the two primary sources of model uncertainty, which account for the differences between computer models and physical experiments, are parameter uncertainty and model discrepancy. Distinguishing the effects of the two sources of uncertainty can be challenging using a single response. We illustrate this identifiability problem and attempt to shed light on when a system may or may not be identifiable. For situations in which identifiability cannot be achieved using only a single response, we propose to improve identifiability by using multiple responses that share a mutual dependence on a common set of calibration parameters. We demonstrate that including multiple responses can improve identifiability by an amount that ranges from minimal to substantial, depending on the characteristics of the specific responses that are combined. Since physical experiments can be costly, one would like to determine the physical experiment input settings that would result in the most improvement of identifiability. Thus, to estimate the improved identifiability prior to conducting physical experiments, we develop a preposterior approach. On the other hand, when there are variations in the input variables, it can be difficult to obtain enough observations from the computationally expensive computer simulator to accurately identify a robust design. Therefore, we develop a systematic objective-oriented sequential sampling approach for robust design that considers both the input variable uncertainty and the interpolation uncertainty. We show that the sequential algorithm is more efficient in finding the robust design than a one-shot space filling design.},
author = {Arendt, Paul},
booktitle = {ProQuest Dissertations and Theses},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arendt Evanston - 2012 - Quantification and Mitigation of Multiple Sources of Uncertainty in Simulation Based Design.pdf:pdf},
isbn = {9781267618917},
keywords = {0463:Statistics,0537:Engineering,0548:Mechanical engineering,Applied sciences,Bayesian calibration,Engineering,Gaussian process model,Identifiability,Mechanical engineering,Metamodeling,Pure sciences,Robust design,Sequential sampling,Sources of uncertainty,Statistics},
pages = {226},
title = {{Quantification and Mitigation of Multiple Sources of Uncertainty in Simulation Based Design}},
url = {https://search.proquest.com/openview/18ea592f3e929a600e713dcf93cf139b/1?pq-origsite=gscholar{\&}cbl=18750{\&}diss=y http://ezphost.dur.ac.uk/login?url=https://search.proquest.com/docview/1095130465?accountid=14533{\%}0Ahttp://openurl.ac.uk/ukfed:dur.ac.uk?genre=di},
year = {2012}
}
@article{Wu2018a,
abstract = {Forward Uncertainty Quantification (UQ) provides Quantity-of-Interest (QoI) pre- dictions with uncertainties. It requires knowledge in the computer model input uncertainties. Historically, “expert opinion” or “user self-evaluation” have been widely used to specify such information, which are subjective and not rigorous mathematically. Inverse UQ, or Bayesian calibration, is the process to quantify the uncertainties in random input parameters that are consistent with relevant exper- imental data. Within the Bayesian framework it seeks the posterior distributions rather than point estimates of “best-fit” values of the uncertain input parameters. In this paper, we introduced a Bayesian formulation for inverse UQ which accounts for the model discrepancy term to avoid “over-fitting” (biased parameter estimates). We also proposed an improved modular Bayesian approach for inverse UQ that does not require priors for the model discrepancy. The developed framework was applied to the inverse UQ ofTRACE uncertain physical model parameters based on the NU- PEC BWR Full-size Fine-Mesh Bundle Tests (BFBT) benchmark steady-state void fraction data. It has been demonstrated that the inclusion of model discrepancy is capable of avoiding “over-fitting” for inverse UQ. The inversely quantified uncer- tainties can be used to replace ad-hoc expert judgment in future forward UQ and validation studies.},
author = {Wu, Xu and Kozlowski, Tomasz and Shirvan, Koroush},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Kozlowski, Shirvan - 2018 - Inverse Uncertainty Quantification using the Modular Bayesian Approach in the Presence of Model Discrepa.pdf:pdf},
journal = {Proceedings of ANS Best Estimate Plus Uncertainty International Conference (BEPU 2018)},
number = {May},
pages = {BEPU2018--133},
title = {{Inverse Uncertainty Quantification using the Modular Bayesian Approach in the Presence of Model Discrepancy}},
year = {2018}
}
@article{XiMeng,
author = {{Xi Meng} and {Tao Luo} and {Yanna Gao} and {Qiong Shen} and {Enshen Long}},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xi Meng et al. - Unknown - A new simple method to measure wall thermal transmittance in situ and its adaptability analysis.pdf:pdf},
title = {{A new simple method to measure wall thermal transmittance in situ and its adaptability analysis}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S1359431116326199/1-s2.0-S1359431116326199-main.pdf?{\_}tid=4c4ccc9e-d0f1-11e7-8d4c-00000aab0f6c{\&}acdnat=1511512224{\_}c81bf1b1844bf4d3d525d0f9cf306ba7}
}
@article{Tan2015,
abstract = {This study describes how sets of spectrally independent and uncorrelated pseudorandom perturbation signals created by a freely available MATLAB program may be used to simultaneously perturb the inputs of multi-input systems to facilitate their identification. It is shown that with appropriate choices of signals with periods N, N/2, N/4 and so on, the signals in a set have no common harmonics over the common period N, and that a very large number of sets are available in the program. The ways in which these signals may be applied is described and illustrated by two application examples.},
author = {Tan, Ai Hui and Barker, H. Anthony and Godfrey, Keith Richard},
doi = {10.1049/iet-cta.2014.0795},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/tan2015.pdf:pdf},
issn = {17518652},
journal = {IET Control Theory and Applications},
number = {15},
pages = {2283--2292},
title = {{Identification of multi-input systems using simultaneous perturbation by pseudorandom input signals}},
volume = {9},
year = {2015}
}
@misc{MathieuFenniak,
author = {{Mathieu Fenniak}},
title = {{Latin Hypercube Sampling}},
url = {https://mathieu.fenniak.net/latin-hypercube-sampling/},
urldate = {2017-12-07}
}
@article{Deconinck2015,
abstract = {The thermal resistances of a building's components are main parameters in assessing the overall thermal performance of the building envelope. In order to assess the actual, as-built thermal performance of building components, a reliable thermal characterization of building elements from on-site measurements is required. In this paper, the thermal resistance of a cavity wall is estimated by means of maximum likelihood estimation (MLE) from on-site measurements. To evaluate the performance of MLE the method is applied on various data sets of the outdoor test wall. Based on the results for all data sets, the potentials of the dynamic estimation technique are considered. Special attention is paid to the accuracy of the estimation results in function of the measurement length and the measurement period throughout the year.},
author = {Deconinck, An-Heleen and Roels, Staf},
doi = {10.1016/j.egypro.2015.11.723},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deconinck, Roels - 2015 - A maximum likelihood estimation of the thermal resistance of a cavity wall from on-site measurements.pdf:pdf},
isbn = {0000000000},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Building component,Building components,Identification,In situ,In-situ measurements,MLE,Maximum likelihood estimation,Thermal performance},
mendeley-tags = {Building component,Identification,In situ,MLE},
pages = {3276--3281},
publisher = {Elsevier B.V.},
title = {{A maximum likelihood estimation of the thermal resistance of a cavity wall from on-site measurements}},
url = {http://dx.doi.org/10.1016/j.egypro.2015.11.723},
volume = {78},
year = {2015}
}
@inproceedings{Delff2010,
address = {Brussels},
author = {Delff, Philip and Madsen, Henrik and Bacher, Peder},
booktitle = {DYNASTEE international workshop : Dynamic Methods for Building Energy Assessment},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delff, Madsen, Bacher - 2010 - Nonlinear phenomena in greybox-modeling of heat dynamics of buildings.pdf:pdf},
pages = {1--8},
title = {{Nonlinear phenomena in greybox-modeling of heat dynamics of buildings}},
year = {2010}
}
@article{Rao2001,
author = {Rao, B. L S Prakasa},
doi = {10.1016/S0169-7161(01)19021-8},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rao - 2001 - Characterization and identifiability for stochastic processes.pdf:pdf},
issn = {01697161},
journal = {Handbook of Statistics},
number = {1992},
pages = {643--691},
title = {{Characterization and identifiability for stochastic processes}},
volume = {19},
year = {2001}
}
@article{Calvi,
author = {Calvi, Jean-paul},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calvi - Unknown - Calcul diff{\'{e}}rentiel.pdf:pdf},
keywords = {calcul diff{\'{e}}rentiel,th{\'{e}}or{\`{e}}me des accroissement fi},
title = {{Calcul diff{\'{e}}rentiel}}
}
@article{Anstett-Collin2015,
abstract = {In this paper, we address the issue of conducting a sensitivity analysis of complex models with both static and dynamic uncertain inputs. While several approaches have been proposed to compute the sensitivity indices of the static inputs (i.e. parameters), the one of the dynamic inputs (i.e. stochastic fields) have been rarely addressed. For this purpose, we first treat each dynamic as a Gaussian process. Then, the truncated Karhunen-Lo{\`{e}}ve expansion of each dynamic input is performed. Such an expansion allows to generate independent Gaussian processes from a finite number of independent random variables. Given that a dynamic input is represented by a finite number of random variables, its variance-based sensitivity index is defined by the sensitivity index of this group of variables. Besides, an efficient sampling-based strategy is described to estimate the first-order indices of all the input factors by only using two input samples. The approach is applied to a building energy model, in order to assess the impact of the uncertainties of the material properties (static inputs) and the weather data (dynamic inputs) on the energy performance of a real low energy consumption house.},
author = {Anstett-Collin, F. and Goffart, Jeanne and Mara, Thierry and Denis-Vidal, L.},
doi = {10.1016/j.ress.2014.08.010},
file = {:home/sarah/OneDrive/Travail/Sources/AS{\_}SamoR2TM.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Building energy model,Dynamic and static inputs,Global sensitivity analysis,Karhunen-Lo{\`{e}}ve expansion},
pages = {268--275},
title = {{Sensitivity analysis of complex models: Coping with dynamic and static inputs}},
volume = {134},
year = {2015}
}
@inproceedings{Rendu2019,
address = {Rome},
author = {Rendu, Manon and Dr{\'{e}}au, J{\'{e}}r{\^{o}}me Le and Salagnac, Patrick and Doya, Maxime and Da{\^{a}}ge, Mathilde Colmet},
booktitle = {Proceedings of the 16th IBPSA Building Simulation Conference},
file = {:home/sarah/OneDrive/Travail/Sources/IBPSA2019/BS2019{\_}113{\_}2{\_}211229{\_}Rendu{\_}2019-06-27{\_}16-52{\_}a.pdf:pdf},
title = {{Comparison of models to identify thermal characteristics of multi-layer building walls using inverse methods}},
year = {2019}
}
@inproceedings{Li2017,
abstract = {This paper proposes an empirical validation framework to validate building performance simulation tools under uncertainty. It presents a case study of a future experiment in a controlled environment with detailed measurement. At this stage synthetic measurement data were generated to demonstrate the framework and preliminarily assess the experiment. The simulation and analysis result highlights the importance of explicit uncertainty quantification especially by means of detailed measurements. It also demonstrates the benefit of probabilistic agreement criteria. Future work on actual experiment is expected to extend this framework for practical use.},
author = {Li, Qi and Augenbroe, Godfried and Muehleisen, Ralph},
booktitle = {Proceedings of Building Simulation 2017: the 15th conference of International Building Performance Simulation Association},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Augenbroe, Muehleisen - 2017 - A Framework for Empirical Validation of Building Performance Simulation under Uncertainty.pdf:pdf},
pages = {631--640},
title = {{A Framework for empirical validation of building performance simulation under uncertainty}},
year = {2017}
}
@article{Xia2003,
abstract = {In this note, we investigate different concepts of nonlinear identifiability in the generic sense. We work in the linear algebraic framework. Necessary and sufficient conditions are found for geometrical identifiability, algebraic identifiability and identifiability with known initial conditions. Relationships between different concepts are characterized. Constructive procedures are worked out for both generic geometrical and algebraic identifiability of nonlinear systems. As an application of the theory developed, we study the identifiability properties of a four dimensional model of HIV/AIDS. The questions answered in this study include the minimal number of measurement of the variables for a complete determination of all parameters and the best period of time to make such measurements. This information will be useful in formulating guidelines for clinical practice.},
author = {Xia, X. and Moog, C.H.},
doi = {10.1109/TAC.2002.808494},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia, Moog - 2003 - Identifiability of nonlinear systems with application to HIVAIDS models.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
keywords = {AIDS,Algebraic framework,HIV,Identifiability,Nonlinear systems},
month = {feb},
number = {2},
pages = {330--336},
title = {{Identifiability of nonlinear systems with application to HIV/AIDS models}},
url = {http://ieeexplore.ieee.org/document/1178922/},
volume = {48},
year = {2003}
}
@article{Mansell2017,
abstract = {Effective mathematical modelling of continuous subcutaneous infusion pharmacokinetics should aid understanding and control in insulin therapy. Thorough analysis of candidate model performance is important for selecting the appropriate models. Eight candidate models for insulin pharmacokinetics included a range of modelled behaviours, parameters and complexity. The models were compared using clinical data from subjects with type 1 diabetes with continuous subcutaneous insulin infusion. Performance of the models was compared through several analyses: R 2 for goodness of fit; the Akaike Information Criterion; a bootstrap analysis for practical identifiability; a simulation exercise for predictability. The simplest model fit poorly to the data (R 2 = 0.53), had the highest Akaike score, and worst prediction. Goodness of fit improved with increasing model complexity (R 2 = 0.85–0.92) but Akaike scores were similar for these models. Complexity increased practical non-identifiability, where small changes in the dataset caused large variation (CV [ 10{\%}) in identified parameters in the most complex models. Best prediction was achieved in a relatively simple model. Some model complexity was necessary to achieve good data fit but further complexity introduced practical non-identifiability and worsened prediction capability. The best model used two linear subcutaneous compartments, an interstitial and plasma compartment, and two identified variables for interstitial clearance and subcutaneous transfer rate. This model had optimal performance trade-off with reasonable fit (R 2 = 0.85) and parameterisation, and best prediction and practical identifiability (CV $\backslash$ 2{\%}).},
author = {Mansell, Erin J and Schmidt, Signe and Docherty, Paul D. and N{\o}rgaard, Kirsten and J{\o}rgensen, John B. and Madsen, Henrik},
doi = {10.1007/s10928-017-9535-z},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mansell et al. - 2017 - Evaluation of pharmacokinetic model designs for subcutaneous infusion of insulin aspart.pdf:pdf},
issn = {1567-567X},
journal = {Journal of Pharmacokinetics and Pharmacodynamics},
keywords = {Bootstrap,Continuous subcutaneous insulin infusion,Goodness of fit,Parameter identification,Pharmacokinetic modelling,Practical identifiability,Robustness,Type 1 diabetes},
mendeley-tags = {Bootstrap,Practical identifiability,Robustness},
month = {aug},
title = {{Evaluation of pharmacokinetic model designs for subcutaneous infusion of insulin aspart}},
url = {https://link-springer-com.camphrier-2.grenet.fr/content/pdf/10.1007{\%}2Fs10928-017-9535-z.pdf http://link.springer.com/10.1007/s10928-017-9535-z},
year = {2017}
}
@article{Marzouk2009,
abstract = {We present an efficient numerical strategy for the Bayesian solution of inverse problems. Stochastic collocation methods, based on generalized polynomial chaos (gPC), are used to construct a polynomial approximation of the forward solution over the support of the prior distribution. This approximation then defines a surrogate posterior probability density that can be evaluated repeatedly at minimal computational cost. The ability to simulate a large number of samples from the posterior distribution results in very accurate estimates of the inverse solution and its associated uncertainty. Combined with high accuracy of the gPC-based forward solver, the new algorithm can provide great efficiency in practical applications. A rigorous error analysis of the algorithm is conducted, where we establish convergence of the approximate posterior to the true posterior and obtain an estimate of the convergence rate. It is proved that fast (exponential) convergence of the gPC forward solution yields similarly fast (exponential) convergence of the posterior. The numerical strategy and the predicted convergence rates are then demonstrated on nonlinear inverse problems of varying smoothness and dimension. {\textcopyright} 2009 Global-Science Press.},
annote = {NULL},
author = {Marzouk, Youssef and Xiu, Dongbin},
doi = {10.4208/cicp.2009.v6.p826},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marzouk, Xiu - 2009 - A stochastic collocation approach to Bayesian inference in inverse problems.pdf:pdf},
isbn = {18152406 (ISSN)},
issn = {18152406},
journal = {Communications in Computational Physics},
keywords = {Bayesian inference,Generalized polynomial chaos,Inverse problems,Stochastic collocation,Uncertainty quantification},
number = {4},
pages = {826--847},
title = {{A stochastic collocation approach to Bayesian inference in inverse problems}},
volume = {6},
year = {2009}
}
@phdthesis{Laret1980,
author = {Laret, Louis},
file = {:home/sarah/OneDrive/Travail/Sources/Analogie RC/TheseLaret1.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Analogie RC/TheseLaret2.pdf:pdf},
school = {Universite de Liege},
title = {{Contribution au d{\'{e}}veloppement de mod{\`{e}}les math{\'{e}}matiques du comportement thermique transitoire de structures d'habitation}},
year = {1980}
}
@article{Wetter2014,
abstract = {This article describes the Buildings library, a free open-source library that is implemented in Modelica, an equation-based object-oriented modelling language. The library supports rapid prototyping, as well as design and operation of building energy and control systems. First, we describe the scope of the library, which covers heating, ventilation and air-conditioning systems, multi-zone heat transfer and multi-zone airflow and contaminant transport. Next, we describe differentiability requirements and address how we implemented them. We describe the class hierarchy that allows implementing component models by extending partial implementations of base models of heat and mass exchangers, and by instantiating basic models for conservation equations and flow resistances. We also describe associated tools for pre- and post-processing, regression tests, co-simulation and real-time data exchange with building automation systems. The article closes with an example of a chilled water plant, with and without water-side economizer, in which we analysed the system-level efficiency for different control setpoints.},
author = {Wetter, Michael and Zuo, Wangda and Nouidui, Thierry S. and Pang, Xiufeng},
doi = {10.1080/19401493.2013.765506},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wetter et al. - 2014 - Modelica Buildings library.pdf:pdf},
isbn = {1940-1493},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {building simulation,co-simulation,equation-based,modular modelling,object-oriented},
number = {4},
pages = {253--270},
title = {{Modelica Buildings library}},
url = {http://www.tandfonline.com/doi/abs/10.1080/19401493.2013.765506},
volume = {7},
year = {2014}
}
@article{Hammarsten1987,
abstract = {The use of different energy-signature (ES) models for energy consumption predictions and building parameter estimations is reviewed. For predictions using time-steps of one day or longer, static ES models are found to be useful. Recommendations for the choice of model are given. The use of ES models for the estimation of building parameters, e.g. for an energy audit, should only be done with great caution, as there can be considerable errors. The development of more sophisticated dynamic models may solve some of the problems encountered with the static models discussed here. {\textcopyright} 1987.},
author = {Hammarsten, Stig},
doi = {10.1016/0306-2619(87)90012-2},
file = {:home/sarah/OneDrive/Travail/Sources/hammarsten1987.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
number = {2},
pages = {97--110},
title = {{A critical appraisal of energy-signature models}},
volume = {26},
year = {1987}
}
@article{Tan2009,
abstract = {There are now many types of perturbation signal that can be used for system identification. These include signals with fixed power spectra, computer-optimized signals for which the user specifies the required harmonics, and hybrids of the two. With so many types now available, it is often difficult for the user to know how to select a signal that will be most appropriate for a particular application. In this paper, the authors provide a general guideline to this selection in a number of different experimental situations, giving the reasons for the particular selection. {\textcopyright}2009 IEEE.},
author = {Tan, Ai Hui and Godfrey, Keith Richard},
doi = {10.1109/CDC.2009.5400077},
file = {:home/sarah/OneDrive/Travail/Sources/Sereine/A{\_}Guide{\_}to{\_}the{\_}Design{\_}and{\_}Selection{\_}of{\_}Perturbatio.pdf:pdf},
isbn = {9781424438716},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
keywords = {Identification for control,NL system identification,System identification},
number = {January 2010},
pages = {464--469},
title = {{A guide to the design and selection of perturbation signals}},
year = {2009}
}
@article{Iooss2015,
abstract = {This chapter makes a review, in a complete methodological framework, of various global sensitivity analysis methods of model output. Numerous statistical and probabilistic tools (regression, smoothing, tests, statistical learning, Monte Carlo, $\backslash$ldots) aim at determining the model input variables which mostly contribute to an interest quantity depending on model output. This quantity can be for instance the variance of an output variable. Three kinds of methods are distinguished: the screening (coarse sorting of the most influential inputs among a large number), the measures of importance (quantitative sensitivity indices) and the deep exploration of the model behaviour (measuring the effects of inputs on their all variation range). A progressive application methodology is illustrated on a scholar application. A synthesis is given to place every method according to several axes, mainly the cost in number of model evaluations, the model complexity and the nature of brought information.},
archivePrefix = {arXiv},
arxivId = {1404.2405},
author = {Iooss, Bertrand and Lema{\^{i}}tre, Paul},
doi = {10.1007/978-1-4899-7547-8_5},
eprint = {1404.2405},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/10.1.1.751.6687.pdf:pdf},
issn = {1387666X},
journal = {Operations Research/ Computer Science Interfaces Series},
keywords = {computer code,design of experiment,meta-,model,numerical experiment,uncertainty},
number = {around 30},
pages = {101--122},
title = {{A review on global sensitivity analysis methods}},
volume = {59},
year = {2015}
}
@article{Pant2015,
author = {Pant, Sanjay and Lombardi, Damiano and Pant, Sanjay and Lombardi, Damiano},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pant et al. - 2015 - An information-theoretic approach to assess practical identifiability of parametric dynamical systems To cite this.pdf:pdf},
title = {{An information-theoretic approach to assess practical identifiability of parametric dynamical systems To cite this version : An information-theoretic approach to assess practical identifiability of parametric dynamical}},
year = {2015}
}
@article{LoPiano2019,
author = {{Lo Piano}, S. and Ferretti, F. and Puy, A. and Albrecht, D. and Tarantola, Stefano and Saltelli, Andrea},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1703.05799.pdf:pdf},
number = {May},
title = {{Is it possible to improve existing sample-based algorithm to compute the total sensitivity index?}},
year = {2019}
}
@phdthesis{Rabouille2014,
annote = {RBD Fast
Bootstrap method},
author = {Rabouille, Mickael},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabouille - 2014 - Recherche de la performance en simulation thermique dynamique applicatio a la r{\'{e}}habilitation des b{\^{a}}timents.pdf:pdf},
keywords = {Analyse de sensibilit{\'{e}}},
mendeley-tags = {Analyse de sensibilit{\'{e}}},
title = {{Recherche de la performance en simulation thermique dynamique : applicatio a la r{\'{e}}habilitation des b{\^{a}}timents}},
url = {https://tel.archives-ouvertes.fr/tel-01142344/document},
year = {2014}
}
@article{Team2015,
abstract = {RSTAN package Stan Development Team (2013). Stan: A C++ Library for Probability and Sampling, Version 2.2.0. URL http://mc-stan.org/. Stan Development Team (2013). Stan Modeling Language User's Guide and Reference Manual, Version 2.2.0. URL http://mc-stan.org/. Hoffman, Matthew D. and Andrew Gelman. In press. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research.},
author = {Team, Stan Development},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Team - 2015 - Stan Modeling Language.pdf:pdf},
isbn = {9780128001080},
journal = {User's Guide and Reference Manual},
pages = {1--488},
title = {{Stan Modeling Language}},
url = {http://mc-stan.org/manual.html{\%}5Cnpapers2://publication/uuid/C0937B19-1CC1-423C-B569-3FDB66090102},
year = {2015}
}
@phdthesis{Ngendakumana1988,
abstract = {The buildings reference models (among others those based on the transfer functions of the walls) aimed to simulate the thermal behaviour are too complex and computer time consuming compared to the accuracy of the needed data they require and the assumptions generally made. By an electrical analogy, a model whose order is lower than 4 is first proposed to model the walls. Then, a proposal for a two second order model is made for a one zone building and how to connect the different rooms in a multi-zone building. The way to take into account the solar gains is also proposed. The model thus proposed has been validated experimentally on a small scale of a one zone building in laboratory and in "situ". In an occupied dwelling in a residential building, the occupation gains seemed to be one of the main uncertainty of the modelling. In that thesis, a simplified model for the inside heat transfer coefficients is also proposed and validated experimentally in a climatic chamber in order to predict the gradient temperature which occurs in a room.},
author = {Ngendakumana, Philippe},
issn = {0075-9333},
keywords = {B{\^{a}}timents,Mod{\'{e}}lisation,Thermique},
publisher = {[Université de Liège, Faculté des sciences appliquées]},
school = {Universit{\'{e}} de Li{\`{e}}ge},
title = {{Mod{\'{e}}lisation simplifi{\'{e}}e du comportement thermique d'un b{\^{a}}timent et v{\'{e}}rification exp{\'{e}}riementale}},
url = {http://orbi.ulg.be/handle/2268/36295},
year = {1988}
}
@inproceedings{Bouchie2014,
abstract = {Les conditions aux limites ext{\'{e}}rieures au niveau des parois opaques d'un b{\^{a}}timent font intervenir des ph{\'{e}}nom{\`{e}}nes coupl{\'{e}}s dont la mesure ou la mod{\'{e}}lisation peuvent s'av{\'{e}}rer d{\'{e}}licates (rayonnement vers l'environnement {\ldots}). Certains mod{\`{e}}les de transfert thermique du b{\^{a}}timent permettent de d{\'{e}}finir une temp{\'{e}}rature ext{\'{e}}rieure {\'{e}}quivalente tenant compte du couplage de ces ph{\'{e}}nom{\`{e}}nes. Un capteur permettant un mesurage direct de cette temp{\'{e}}rature ext{\'{e}}rieure {\'{e}}quivalente a {\'{e}}t{\'{e}} d{\'{e}}velopp{\'{e}} et valid{\'{e}} exp{\'{e}}rimentalement. Mis en {\oe}uvre sur les parois ext{\'{e}}rieures d'un b{\^{a}}timent, son utilisation permettrait de r{\'{e}}aliser un mesurage direct de l'effet des sollicitations ext{\'{e}}rieures pour fiabiliser les m{\'{e}}thodes d'identification des performances thermiques intrins{\`{e}}ques des enveloppes de b{\^{a}}timent.},
address = {Arras},
author = {Bouchi{\'{e}}, R{\'{e}}mi and Abele, Charlotte and Derouineau, St{\'{e}}phanie and Millet, Jean-Robert},
booktitle = {IBPSA France},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouchi{\'{e}} et al. - 2014 - Conception et validation d'un capteur de mesurage de la temp{\'{e}}rature ext{\'{e}}rieure {\'{e}}quivalente d'une paro.pdf:pdf},
keywords = {boundary conditions,envelope,thermal performance of the,thermal transfer},
title = {{Conception et validation d'un capteur de mesurage de la temp{\'{e}}rature ext{\'{e}}rieure {\'{e}}quivalente d'une paroi opaque d'un b{\^{a}}timent}},
year = {2014}
}
@article{Naveros2015,
abstract = {Experimental identification of the dynamic models of heat transfer in walls is needed for optimal control and characterization of building energy performance. These models use the heat equation in time domain which can be put in matrix form and then, through state-space representation, transformed in a transfer function which is of infinite order. However, the model acts as a low-pass filter and needs to respond only to the frequency spectrum present in the measured inputs. Then, the order of the transfer function can be determined by using the frequency spectrum of the measured inputs and the accuracy of the sensors. The main idea is that from two models of different orders, the one with a lower order can be used in building parameter identification, when the difference between the outputs is negligible or lower than the output measurement error. A homogeneous light wall is used as an example for a detailed study and examples of homogeneous building elements with very high and very low time constants are given. The first order model is compared with a very high order model (hundreds of states) which can be considered almost continuous in space.},
annote = {Diag de Bode des ent{\'{e}}es sur les sorties
Analyse fr{\'{e}}quentielle des diff{\'{e}}rents signaux

choix de mod{\`{e}}le bas{\'{e}} sur les r{\'{e}}ponses fr{\'{e}}quentielles

Le choix du mod{\`{e}}le doit se porter sur le mod{\`{e}}le qui v{\'{e}}rifie les effets suivants :
- il y une fr{\'{e}}quence pour laquelle l'amplitude du gain est max, au regard des performances limit{\'{e}}es des appareils de mesure
- cette fqce est la frqce max pour laquelle le mod{\`{e}}le complet et le mod{\`{e}}le approch{\'{e}} doivent avoir le m{\^{e}}me comportement

Utilisation des diagrammes pour conna{\^{i}}tre les amplitudes minimales des sollcitations pour avoir une r{\'{e}}ponse dans la sortie mesur{\'{e}}e, {\`{a}} une fqce donn{\'{e}}e. En fonction de l'ordre du mod{\`{e}}le, certaines r{\'{e}}ponses rapides n{\'{e}}cessitent une amplitude {\'{e}}norme (non r{\'{e}}alisable) pour avoir une sortie visible mesurable.},
author = {Naveros, I and Ghiaus, Cristian},
doi = {10.1016/j.apenergy.2014.11.033},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naveros, Ghiaus - 2015 - Order selection of thermal models by frequency analysis of measurements for building energy efficiency estimati.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Calibration,Frequency analysis,Heat transfer,Parameter identification,State-space,Thermal networks,s{\'{e}}lection de mod{\`{e}}les},
mendeley-tags = {Calibration,s{\'{e}}lection de mod{\`{e}}les},
pages = {230--244},
publisher = {Elsevier Ltd},
title = {{Order selection of thermal models by frequency analysis of measurements for building energy efficiency estimation}},
url = {http://dx.doi.org/10.1016/j.apenergy.2014.11.033},
volume = {139},
year = {2015}
}
@techreport{Everett1985,
author = {Everett, R.},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Everett - 1985 - The Rapid Thermal Calibration of Houses.pdf:pdf},
institution = {Energy Research Group Open University ERG 055},
title = {{The Rapid Thermal Calibration of Houses}},
year = {1985}
}
@article{Salvatier2016,
abstract = {Probabilistic programming allows for automatic Bayesian inference on user-defined probabilistic models. Recent advances in Markov chain Monte Carlo (MCMC) sampling allow inference on increasingly complex models. This class of MCMC, known as Hamiltonian Monte Carlo, requires gradient information which is often not readily available. PyMC3 is a new open source probabilistic programming framework written in Python that uses Theano to compute gradients via automatic differentiation as well as compile probabilistic programs on-the-fly to C for increased speed. Contrary to other probabilistic programming languages, PyMC3 allows model specification directly in Python code. The lack of a domain specific language allows for great flexibility and direct interaction with the model. This paper is a tutorial-style introduction to this software package.},
author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
doi = {10.7717/peerj-cs.55},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salvatier, Wiecki, Fonnesbeck - 2015 - Probabilistic Programming in Python using PyMC(2).pdf:pdf},
issn = {2376-5992},
journal = {PeerJ Computer Science},
month = {apr},
pages = {e55},
title = {{Probabilistic programming in Python using PyMC3}},
url = {https://peerj.com/articles/cs-55 https://arxiv.org/pdf/1507.08050.pdf},
volume = {2},
year = {2016}
}
@article{Viot2015a,
author = {Viot, Hugo and Sempey, Alain and Mora, Laurent and Batsale, Jean-Christophe},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viot et al. - 2015 - Campagnes de mesures rapides pour l'identification de mod{\`{e}}les l{\'{e}}gers de b{\^{a}}timents en vue de contr{\^{o}}le.pdf:pdf},
journal = {Sft 2015},
number = {May},
title = {{Campagnes de mesures rapides pour l'identification de mod{\`{e}}les l{\'{e}}gers de b{\^{a}}timents en vue de contr{\^{o}}le}},
year = {2015}
}
@article{Leccese2018,
abstract = {In contemporary architecture, the opaque building envelope is usually realised by multi-layered walls; that is, a sequence of homogeneous layers of different materials. The layer sequence and distribution affect the wall behaviour in terms of its overall thermal inertia, or heat storage capability; hence, analysis of the thermal performance of a multi-layered wall becomes very important under dynamic heat transfer conditions, as usually occurs during summer. In this study, the authors employ analytical models based on the heat transfer matrix method, with the aim of predicting the dynamic thermal behaviour of external and internal building walls. Although numerous studies have been devoted to investigating the dynamic thermal behaviour of walls, the approach followed and results obtained by the authors are original and have significant implications that are of practical interest. By using the analytical models, the effects of continuous variations in the positioning and thickness distribution of the insulation material on the dynamic thermal performance (dynamic thermal transmittance, decrement factor and time lag) are demonstrated with reference to different constructive solutions (from a light-weight wall with a surface mass of 85 kg/m2 to a massive wall with a surface mass of 294 kg/m2). Moreover, a simplified correlation is proposed, which allows for correction of the dynamic thermal transmittance and time lag of external walls to take consider the effect of the internal walls (partition walls and slabs) on the dynamic thermal behaviour of a room. The results presented in the paper can be used during the building envelope design stage as a guideline for the improvement of the dynamic thermal performance of multi-layered walls. Furthermore, the insight provided into the building envelope thermal behaviour could prove useful for understanding how to maximise the effectiveness of possible retrofit interventions.},
author = {Leccese, Francesco and Salvadori, Giacomo and Asdrubali, Francesco and Gori, Paola},
doi = {10.1016/j.apenergy.2018.05.090},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261918308079-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Building envelope,Decrement factor,Dynamic thermal behaviour,Internal walls,Multi-layered walls,Time lag},
number = {January},
pages = {1078--1089},
publisher = {Elsevier},
title = {{Passive thermal behaviour of buildings: Performance of external multi-layered walls and influence of internal walls}},
url = {https://doi.org/10.1016/j.apenergy.2018.05.090},
volume = {225},
year = {2018}
}
@book{Geometry,
address = {Boca Raton : CRC Press, Taylor {\&} Francis Group, 2019.},
author = {Broemeling, Lyle D.},
booktitle = {Society},
doi = {10.1201/9780429488443},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Broemeling, Lyle D - Bayesian analysis of time series (2019, Chapman {\&} Hall{\_}CRC).pdf:pdf},
isbn = {9780429488443},
month = {apr},
publisher = {Chapman and Hall/CRC},
title = {{Bayesian Analysis of Time Series}},
url = {https://www.taylorfrancis.com/books/9780429948923},
year = {2019}
}
@article{Wu2018c,
abstract = {In nuclear reactor system design and safety analysis, the Best Estimate plus Uncertainty (BEPU) methodology requires that computer model output uncertainties must be quantified in order to prove that the investigated design stays within acceptance criteria. “Expert opinion” and “user self-evaluation” have been widely used to specify computer model input uncertainties in previous uncertainty, sensitivity and validation studies. Inverse Uncertainty Quantification (UQ) is the process to inversely quantify input uncertainties based on experimental data in order to more precisely quantify such ad-hoc specifications of the input uncertainty information. In this paper, we used Bayesian analysis to establish the inverse UQ formulation, with systematic and rigorously derived metamodels constructed by Gaussian Process (GP). Due to incomplete or inaccurate underlying physics, as well as numerical approximation errors, computer models always have discrepancy/bias in representing the realities, which can cause over-fitting if neglected in the inverse UQ process. The model discrepancy term is accounted for in our formulation through the “model updating equation”. We provided a detailed introduction and comparison of the full and modular Bayesian approaches for inverse UQ, as well as pointed out their limitations when extrapolated to the validation/prediction domain. Finally, we proposed an improved modular Bayesian approach that can avoid extrapolating the model discrepancy that is learnt from the inverse UQ domain to the validation/prediction domain.},
author = {Wu, Xu and Kozlowski, Tomasz and Meidani, Hadi and Shirvan, Koroush},
doi = {10.1016/j.nucengdes.2018.06.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - Unknown - Inverse Uncertainty Quantification using the Modular Bayesian Approach based on Gaussian Process, Part 1 Theory(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - Unknown - Inverse Uncertainty Quantification using the Modular Bayesian Approach based on Gaussian Process, Part 2 Applic(2).pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1-s2.0-S0029549318306423-main.pdf:pdf},
issn = {00295493},
journal = {Nuclear Engineering and Design},
keywords = {Bayesian calibration,Gaussian Process,Gaussian process,Inverse uncertainty quantification,Model discrepancy,Modular Bayesian},
number = {June},
pages = {339--355},
title = {{Inverse uncertainty quantification using the modular Bayesian approach based on Gaussian process, Part 1: Theory}},
url = {https://arxiv.org/pdf/1801.01782.pdf https://arxiv.org/pdf/1801.09261.pdf},
volume = {335},
year = {2018}
}
@unpublished{Bronken,
author = {Bronken, Vidar},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bronken - Unknown - MATLAB commands in numerical Python ( NumPy ).pdf:pdf},
pages = {1--17},
title = {{MATLAB commands in numerical Python ( NumPy )}},
volume = {0}
}
@article{Gori2018b,
abstract = {The performance gap between the expected and actual energy performance of buildings and elements has stimulated interest in in-situ measurements. Most research has employed quasi-static analysis methods that estimate heat loss metrics such as U-values, without taking advantage of the rich time series data that is often recorded. This paper presents a dynamic Bayesian-based method to estimate the thermophysical properties of building elements from in-situ measurements. The analysis includes Markov chain Monte Carlo (MCMC) estimation, priors, uncertainty analysis, and model comparison to select the most appropriate model. Data from two case study dwellings is used to illustrate model performance; U-value estimates from the dynamic and static methods are within error estimates, with the dynamic model generally requiring much shorter time series than the static model. The dynamic model produced robust results at all times of year, including when the average indoor-to-outdoor temperature difference was low, when external temperatures had large daily variation, and measurements were subjected to direct solar radiation. Further, the probability distributions of parameters may provide insights into the thermal performance of elements. Dynamic methods such as that presented herein may enable wider characterisation of the performance of building elements as built, supporting work to reduce the performance gap.},
author = {Gori, Virginia and Biddulph, Phillip and Elwell, Clifford A.},
doi = {10.3390/en11040802},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gori, Biddulph, Elwell - 2018 - A Bayesian dynamic method to estimate the thermophysical properties of building elements in all seasons,.pdf:pdf},
issn = {19961073},
journal = {Energies},
keywords = {Bayesian statistics,Dynamic modelling,Heat transfer,In-situ measurements,Inverse modelling,U-value,Uncertainty analysis},
number = {4},
title = {{A Bayesian dynamic method to estimate the thermophysical properties of building elements in all seasons, orientations and with reduced error}},
volume = {11},
year = {2018}
}
@article{Nissinen2008,
abstract = {Inverse problems can be characterized as problems that tolerate measurement and modelling errors poorly . While the measurement error issue has been widely considered as a solved problem , the modelling errors have remained largely untreated . The approximation and modelling errors can , however , be argued to dominate the measurement errors in most applications . There are several applications in which the temporal and memory requirements dictate that the computational complexity of the forward solver be radically reduced . For example , in process tomography the reconstructions have to be carried out typically in a few tens of milliseconds . Recently , a Bayesian approach for the treatment of approximation and modelling errors for inverse problems has been proposed . This approach has proven to work well in several classes of problems but the approach has not been verified in any problem with real data . In this paper we study two different types of modelling errors in the case of electrical impedance tomography , one related to model reduction and one concerning partially unknown geometry . We show that the approach is also feasible in practice and may facilitate the reduction of the computational complexity of the nonlinear EIT problem at least by an order of magnitude .},
author = {Nissinen, A and Heikkinen, L M and Kaipio, Jari P.},
doi = {10.1088/0957-0233/19/1/015501},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nissinen, Heikkinen, Kaipio - Unknown - The Bayesian approximation error approach for electrical impedance tomography – experimental r.pdf:pdf},
issn = {0957-0233},
journal = {Measurement Science and Technology},
month = {jan},
number = {1},
pages = {015501},
title = {{The Bayesian approximation error approach for electrical impedance tomography—experimental results}},
url = {https://www.researchgate.net/profile/Antti{\_}Nissinen2/publication/230577005{\_}The{\_}Bayesian{\_}approximation{\_}error{\_}approach{\_}for{\_}electrical{\_}impedance{\_}tomography{\_}-{\_}Experimental{\_}results/links/004635315fb8cef77f000000.pdf http://stacks.iop.org/0957-0233/19/i=1/a=015},
volume = {19},
year = {2008}
}
@article{Ghiaus2019a,
abstract = {Quick U-building (QUB) is a method for short time measurement of energy performance of buildings, typically one night. It uses the indoor air temperature response to the power delivered to the indoor air by electric heaters. This paper introduces a method for estimating the expected measurement error as a function of the amplitude and the time duration of the input signal based on the decomposition of the time response of a state-space model into a sum of exponentials by using the eigenvalues of the state matrix. It is shown that the buildings have a group of dominant time constants, which gives an exponential response, and many very short and very large time constants, which have a small influence on the response. The analysis of the eigenvalues demonstrates that the QUB experiment may be done in a rather short time as compared with the largest time constant of the building.},
author = {Ghiaus, Christian and Alzetto, Florent},
doi = {10.1080/19401493.2018.1561753},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiaus, Alzetto - 2019 - Design of experiments for Quick U-building method for building energy performance measurement.pdf:pdf},
issn = {19401507},
journal = {Journal of Building Performance Simulation},
keywords = {QUB method,eigenvalues and eigenvectors,exponential matrix,global thermal conductance,model identification,modelling and measurement error,time constants},
number = {4},
pages = {465--479},
publisher = {Taylor {\&} Francis},
title = {{Design of experiments for Quick U-building method for building energy performance measurement}},
url = {https://doi.org/19401493.2018.1561753},
volume = {12},
year = {2019}
}
@article{Privara2013,
abstract = {Recent results show that a predictive building automation can be used to operate buildings in an energy and cost effective manner with only a small retrofitting requirements. In this approach, the dynamic models are of crucial importance. As industrial experience has shown, modeling is the most time-demanding and costly part of the automation process. Many papers devoted to this topic actually deal with modeling of building subsystems. Although some papers identify a building as a complex system, the provided models are usually simple two-zones models, or extremely detailed models resulting from the use of building simulation software packages. These are, however, not suitable for predictive control. The objective of this paper is to share the years-long experience of the authors in building modeling intended for predictive control of the building's climate. We provide an overview of identification methods for buildings and analyze their applicability for subsequent predictive control. Moreover, we propose a new methodology to obtain a model suitable for the use in a predictive control framework combining the building energy performance simulation tools and statistical identification. The procedure is based on the so-called co-simulation that has appeared recently as a feature of various building simulation software packages.},
author = {Pr{\'{i}}vara, Samuel and Cigler, Jiř{\'{i}} and V{\'{a}}ňa, Zden{\v{e}}k and Oldewurtel, Frauke and Sagerschnig, Carina and {\v{Z}}{\'{a}}{\v{c}}ekov{\'{a}}, Eva},
doi = {10.1016/j.enbuild.2012.10.024},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
month = {jan},
pages = {8--22},
title = {{Building modeling as a crucial part for building predictive control}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778812005336},
volume = {56},
year = {2013}
}
@article{Rasooli2018,
author = {Rasooli, Arash and Itard, Laure},
doi = {10.1016/j.enbuild.2018.09.004},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1{\_}s2.0{\_}S0378778818314282{\_}main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Heat flux sensor,Heat transfer simulation,ISO 9869 standard,In-situ measurement,Thermal resistance},
month = {nov},
pages = {374--383},
publisher = {Elsevier B.V.},
title = {{In-situ characterization of walls' thermal resistance: An extension to the ISO 9869 standard method}},
url = {https://doi.org/10.1016/j.enbuild.2018.09.004 https://linkinghub.elsevier.com/retrieve/pii/S0378778818314282},
volume = {179},
year = {2018}
}
@article{Grewal1976,
abstract = {This short paper considers the identification of dynamical systems from input-output data. The problem of parameter identifiability for such systems is approached by considering whether system outputs obtained with different parameter values can be distinguished one from another. The results are stated formally by defining the notion of "output distinguishability." Parameter identifiability is then defined precisely in terms of output distinguishability. Relationships have been developed with the other definitions such as least square identifiability and identifiability from the transfer function. Several results for linear and nonlinear systems are presented with examples.},
author = {Grewal, M. and Glover, Keith},
doi = {10.1109/TAC.1976.1101375},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grewal, Glover - 1976 - Identifiability of linear and nonlinear dynamical systems(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grewal, Glover - 1976 - Identifiability of linear and nonlinear dynamical systems.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
number = {6},
pages = {833--837},
title = {{Identifiability of linear and nonlinear dynamical systems}},
volume = {21},
year = {1976}
}
@phdthesis{Gori2017b,
author = {Gori, Virginia},
file = {:home/sarah/OneDrive/Travail/Sources/Gori{\_}1568418{\_}PhDThesis-Revised-title.pdf:pdf},
school = {University College London},
title = {{A novel method for the estimation of thermophysical properties of walls from short and seasonally independent in-situ surveys}},
year = {2017}
}
@book{MacKay2005,
abstract = {This book is aimed at senior undergraduates and graduate students in Engineering, Science, Mathematics, and Computing. It expects familiarity with calculus, probability theory, and linear algebra as taught in a rst- or secondyear undergraduate course on mathematics for scientists and engineers. Conventional courses on information theory cover not only the beautiful theoretical ideas of Shannon, but also practical solutions to communication problems. This book goes further, bringing in Bayesian data modelling, Monte Carlo methods, variational methods, clustering algorithms, and neural networks. Why unify information theory and machine learning? Because they are two sides of the same coin. In the 1960s, a single eld, cybernetics, was populated by information theorists, computer scientists, and neuroscientists, all studying common problems. Information theory and machine learning still belong together. Brains are the ultimate compression and communication systems. And the state-of-the-art algorithms for both data compression and error-correcting codes use the same tools as machine learning.},
author = {MacKay, David},
booktitle = {Learning},
doi = {10.1198/jasa.2005.s54},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MacKay - 2005 - Information Theory, Inference, and Learning Algorithms David J.C. MacKay.pdf:pdf},
isbn = {9780521642989},
issn = {01621459},
pmid = {13217055},
publisher = {Cambridge University Press},
title = {{Information Theory, Inference, and Learning Algorithms}},
url = {http://pubs.amstat.org/doi/abs/10.1198/jasa.2005.s54{\%}5Cnhttp://www.cambridge.org/0521642981},
year = {2005}
}
@article{Villemonteix2009,
author = {Villemonteix, Julien and Vazquez, Emmanuel and Walter, Eric},
doi = {10.3182/20090706-3-FR-2004.0189},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Villemonteix, Vazquez, Walter - 2009 - Bayesian optimization for parameter identification on a small simulation budget.pdf:pdf},
isbn = {9783902661470},
issn = {14746670},
journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
keywords = {Gaussian processes,Global optimization,Kriging},
number = {PART 1},
pages = {1603--1608},
title = {{Bayesian optimization for parameter identification on a small simulation budget}},
volume = {15},
year = {2009}
}
@inproceedings{Arendt,
abstract = {In physics-based engineering modeling, the two primary sources of model uncertainty,$\backslash$nwhich account for the differences between computer models and physical experiments,$\backslash$nare parameter uncertainty and model discrepancy. Distinguishing the effects of the two$\backslash$nsources of uncertainty can be challenging. For situations in which identifiability cannot$\backslash$nbe achieved using only a single response, we propose to improve identifiability by using$\backslash$nmultiple responses that share a mutual dependence on a common set of calibration$\backslash$nparameters. To that end, we extend the single response modular Bayesian approach for$\backslash$ncalculating posterior distributions of the calibration parameters and the discrepancy$\backslash$nfunction to multiple responses. Using an engineering example, we demonstrate that$\backslash$nincluding multiple responses can improve identifiability (as measured by posterior standard$\backslash$ndeviations) by an amount that ranges from minimal to substantial, depending on the$\backslash$ncharacteristics of the specific responses that are combined. [DOI: 10.1115/1.4007573]},
author = {Arendt, Paul D and Chen, Wei and Apley, Daniel W},
booktitle = {Proceedings of the ASME Design Engineering Technical Conference},
doi = {10.1115/DETC2011-48623},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arendt et al. - Unknown - Improving Identifiability in Model Calibration Using Multiple Responses.pdf:pdf},
isbn = {9780791854822},
keywords = {Gaussian process,calibration,identifiability,model updating,multi-output emulator,multiple responses,uncertainty quantification},
number = {PARTS A AND B},
pages = {1213--1222},
title = {{Improving identifiability in model calibration using multiple responses}},
url = {http://users.iems.northwestern.edu/{~}apley/papers/2012, Improving Identifiability Using Multiple Responses.pdf},
volume = {5},
year = {2011}
}
@article{Jedidi2018,
abstract = {a b s t r a c t The main result presented by this paper is that the structural identifiability of an original continues-linear time invariant (LTI) dynamic system can be preserved in expanded systems within the inclusion principle when using block structured complementary matrices. This preservation is ensured only for some selections of specific complementary matrices. Overlapping expansions of these systems are then discussed. An original system composed of two overlapped subsystems is used as a general prototype case. An illustrative example is given.},
author = {Jedidi, Safa and Bourdais, Romain and Lefebvre, Marie Anne},
doi = {10.1016/j.ejcon.2017.11.003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jedidi, Bourdais, Lefebvre - 2017 - ARTICLE IN PRESS Preservation of structural identifiability in expanded systems.pdf:pdf},
issn = {09473580},
journal = {European Journal of Control},
keywords = {Inclusion principle,Large-scale-systems,Overlapping decomposition,Structural identifiability},
month = {mar},
number = {0},
pages = {48--52},
title = {{Preservation of structural identifiability in expanded systems}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0947358016301856/1-s2.0-S0947358016301856-main.pdf?{\_}tid=eaa4fdb4-db53-11e7-9e17-00000aab0f6c{\&}acdnat=1512654092{\_}92df9567f0d1d90cbd8109ed471427da https://linkinghub.elsevier.com/retrieve/pii/S0947358016301856},
volume = {40},
year = {2018}
}
@book{Bertsekas2008,
abstract = {Assuming one semester of calculus, this textbook introduces probability to undergraduate students who want to learn statistics. It clearly explains the importance of widely used distributions in statistics, such as normal, binomial, and Poisson, and explores how they are all connected. The book makes the distributions easier to remember, understand, and work with by illustrating natural applications where they arise, including applications of MCMC. R is used to perform statistical calculations.},
author = {Bertsekas, Dimitri and Tsitsiklis, John},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blitzstein, Hwang - 2015 - Introduction to Probability.pdf:pdf},
isbn = {978-1-886529-23-6},
keywords = {Probability,Probability theory},
pages = {589},
publisher = {Athena Scientific},
title = {{Introduction to Probability}},
year = {2008}
}
@article{Coakley2014,
abstract = {Whole building energy simulation (BES) models play a significant role in the design and optimisation of buildings. Simulation models may be used to compare the cost-effectiveness of energy-conservation measures (ECMs) in the design stage as well as assessing various performance optimisation measures during the operational stage. However, due to the complexity of the built environment and prevalence of large numbers of independent interacting variables, it is difficult to achieve an accurate representation of real-world building operation. Therefore, by reconciling model outputs with measured data, we can achieve more accurate and reliable results. This reconciliation of model outputs with measured data is known as calibration. This paper presents a detailed review of current approaches to model development and calibration, highlighting the importance of uncertainty in the calibration process. This is accompanied by a detailed assessment of the various analytical and mathematical/statistical tools employed by practitioners to date, as well as a discussion on both the problems and the merits of the presented approaches. {\textcopyright} 2014 Elsevier Ltd.},
annote = {Methods for assessing calibration performance :
- mean bias error
- root mean square error
- coef of variation of RMSE},
archivePrefix = {arXiv},
arxivId = {10.1016/j.rser.2014.05.007},
author = {Coakley, Daniel and Raftery, Paul and Keane, Marcus},
doi = {10.1016/j.rser.2014.05.007},
eprint = {j.rser.2014.05.007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coakley, Raftery, Keane - 2014 - A review of methods to match building energy simulation models to measured data.pdf:pdf},
isbn = {1364-0321},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Calibration,EnergyPlus,Optimisation,Review,Simulation,Uncertainty},
pages = {123--141},
primaryClass = {10.1016},
publisher = {Elsevier},
title = {{A review of methods to match building energy simulation models to measured data}},
url = {http://dx.doi.org/10.1016/j.rser.2014.05.007},
volume = {37},
year = {2014}
}
@article{Senave2020a,
author = {Senave, Marieline and Roels, Staf and Verbeke, Stijn and Saelens, Dirk},
doi = {10.1016/j.enbuild.2020.109860},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778819331020-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Characterization,Data Analysis,Heat Loss Coefficient,Interior Temperature,Physical Parameter Identification,Sensitivity Analysis,Single-Zone Approach,Synthetic Monitoring Data},
month = {feb},
pages = {109860},
publisher = {Elsevier B.V.},
title = {{Analysis of the Influence of the Definition of the Interior Dwelling Temperature on the Characterization of the Heat Loss Coefficient via On-Board Monitoring}},
url = {https://doi.org/10.1016/j.enbuild.2020.109860 https://linkinghub.elsevier.com/retrieve/pii/S0378778819331020},
year = {2020}
}
@article{Chatzis2015,
annote = {Diop {\&} Fliess (1991) a parameter being identifiable is equivalent to it being observable.},
author = {Chatzis, Manolis N. and Chatzi, Eleni N. and Smyth, Andrew W.},
doi = {10.1002/stc.1690},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatzis, Chatzi, Smyth - 2015 - On the observability and identifiability of nonlinear structural and mechanical systems.pdf:pdf},
issn = {15452255},
journal = {Structural Control and Health Monitoring},
keywords = {Identifiability,Observability,geometric ‐ algebraic observability,non analytic systems,nonlinear dynamics,system identification},
month = {mar},
number = {3},
pages = {574--593},
title = {{On the observability and identifiability of nonlinear structural and mechanical systems}},
url = {http://doi.wiley.com/10.1002/stc.1690},
volume = {22},
year = {2015}
}
@article{Bastogne2007,
abstract = {A unified description of networked dynamical systems, entitled multiport diagram, is proposed in this paper. The multiport diagram is an object-oriented model structure described into a general mathematical framework, independently from any computer language. It is shown that usual diagrammatic representations of networks, e.g. block diagrams, signal flow graphs, compartmental networks and bond graphs, are subclasses of the multiport diagram. By bridging the gap between these four network representations, this unified diagram should contribute to facilitate education of networked system modelling in systems and control theories. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Bastogne, Thierry},
doi = {10.1016/j.simpat.2007.04.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastogne - 2007 - A unified representation for networked dynamical system modelling.pdf:pdf},
issn = {1569190X},
journal = {Simulation Modelling Practice and Theory},
keywords = {Block diagrams,Bond graphs,Compartmental networks,Mathematical models,Networked dynamical systems,Object-modelling techniques,Signal flow graphs,System modelling},
number = {7},
pages = {747--763},
title = {{A unified representation for networked dynamical system modelling}},
volume = {15},
year = {2007}
}
@article{Kristensen2004,
abstract = {A systematic framework for improving the quality of continuous time models of dynamic systems based on experimental data is presented. The framework is based on an interplay between stochastic differential equation modelling, statistical tests and nonparametric modelling and provides features that allow model deficiencies to be pinpointed and their structural origin to be uncovered. More specifically, the proposed framework can be used to obtain estimates of unknown functional relations, in turn allowing unknown or inappropriately modelled phenomena to be uncovered. In this manner the framework permits systematic iterative model improvement. The performance of the proposed framework is illustrated through a case study involving a dynamic model of a fed-batch bioreactor, where it is shown how an inappropriately modelled biomass growth rate can be uncovered and a proper functional relation inferred. A key point illustrated through this case study is that functional relations involving unmeasured variables can also be uncovered.},
author = {Kristensen, Niels Rode and Madsen, Henrik and J{\o}rgensen, Sten Bay},
doi = {10.1016/j.compchemeng.2003.10.003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rode Kristensen, Madsen, J{\o}rgensen - 2004 - A method for systematic improvement of stochastic grey-box models.pdf:pdf},
issn = {00981354},
journal = {Computers {\&} Chemical Engineering},
keywords = {Bioreactor modelling,Model improvement,Nonparametric modelling,Parameter estimation,Statistical tests,Stochastic differential equations},
month = {jul},
number = {8},
pages = {1431--1449},
title = {{A method for systematic improvement of stochastic grey-box models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.8601{\&}rep=rep1{\&}type=pdf http://linkinghub.elsevier.com/retrieve/pii/S0098135403002758},
volume = {28},
year = {2004}
}
@misc{Huang1997,
abstract = {The shape, size, and content of MC carbides in a unidirectional Ni-base superalloy have been studied at different solidification rates using material of normal commercial composition (5 ppm nitrogen) and two melts with additions to produce 22 and 30 ppm nitrogen. M(C,N) was found in nitrogendoped specimens. The increased nitrogen content results in a change in carbide morphology from acicular or Chinese-script type to a blocky one. Carbide size increases from 6.85 to 7.25 $\mu$m at 2.5 $\mu$m/s and from 2.31 to 2.81 $\mu$m at 200 $\mu$m/s as the nitrogen content increases from 5 to 22 ppm; carbide size is reduced to 5.2 $\mu$m at 2.5 $\mu$/s and to 2.1 $\mu$m at 200 $\mu$m/s when nitrogen content is further raised to 30 ppm. There is no evident change in carbide content (area percentage) with increase of nitrogen. Scanning electron microscopy (SEM) and electron probe microanalysis revealed characteristic centers in some of the blocky carbides of TiN, as nuclei of MC or M(C,N) formed in the melt. The influences of nitrogen on carbide at the low solidification rate are stronger than those at the higher rate. With the increase of solidification rate, the carbide turns from bar to Chinese-script type, except for the base alloy at 2.5 $\mu$m/s, and the content and size decrease.},
archivePrefix = {arXiv},
arxivId = {arXiv:physics/0608246v3},
author = {Huang, Xuebing and Zhang, Yun and Liu, Yulin and Hu, Zhuangqi},
booktitle = {Metallurgical and Materials Transactions A: Physical Metallurgy and Materials Science},
doi = {10.1007/s11661-997-0172-9},
eprint = {0608246v3},
file = {:home/sarah/Dropbox/These/Sources/FINAL-IBPC2108-Proceedings.pdf:pdf},
isbn = {0000000154871},
issn = {10735623},
number = {10},
pages = {2143--2147},
pmid = {27935037},
primaryClass = {arXiv:physics},
title = {{Effect of small amount of nitrogen on carbide characteristics in unidirectional Ni-base superalloy}},
volume = {28},
year = {1997}
}
@book{Saltelli2008,
abstract = {Written by the leading names in the field, Global Sensitivity Analysis: The Primer offers an accessible summary of the essential concepts involved in a sound sensitivity analysis. It is a self- contained book allowing the reader to learn about, and practice, sensitivity analysis through the use of many exercises and solved problems. This book brings the methodology and applications described in ‘Sensitivity Analysis' up-to-date. Includes a chapter on experimental design, a topic neglected by the sensitivity analysis literature to date.},
address = {Chichester, UK},
author = {Saltelli, Andrea and Ratto, Marco and Andres, Terry and Campolongo, Francesca and Cariboni, Jessica and Gatelli, Debora and Saisana, Michaela and Tarantola, Stefano},
booktitle = {Global Sensitivity Analysis. The Primer},
doi = {10.1002/9780470725184.ch6},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/GlobalSensitivityAnalysisThePrimer.pdf:pdf},
isbn = {9780470725184},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Sensitivity Analysis: From Theory to Practice}},
url = {http://doi.wiley.com/10.1002/9780470725184.ch6},
year = {2008}
}
@book{Ljung1999,
author = {Ljung, Lennart},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ljung - 1999 - System Identification, Theory for the User.pdf:pdf},
isbn = {0-13-881640-9},
publisher = {Prentice-Hall},
title = {{System Identification, Theory for the User}},
year = {1999}
}
@article{Westermann2019,
author = {Westermann, Paul and Evins, Ralph},
doi = {10.1016/j.enbuild.2019.05.057},
file = {:home/sarah/OneDrive/Travail/Sources/Mod{\`{e}}les - Mod{\'{e}}lisation/1-s2.0-S0378778819302877-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Sustainable building design,building design optimisation,building performance simulation,early design,meta-model,sensitivity analysis,surrogate model,uncertainty analysis},
publisher = {Elsevier B.V.},
title = {{Surrogate modelling for sustainable building design - A review}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778819302877},
year = {2019}
}
@article{Lara2017,
abstract = {Different optimization tools have been developed to find the best trade-off between competitive goals. The optimization problem is typical of the design process, where different design solutions have to be compared to achieve one or more objectives, often in contrast with each other. A quite novel application of optimization is building energy model calibration. The use of well-calibrated energy simulation models is key for successful buildings' retrofit or operation management and the optimization techniques can improve the reliability of the results. The typical optimization method consists in the analysis of all the alternatives' performances, developing a full factorial plan and simulating all the possible options (brute-force approach). However, this process could take unsustainable long time. That is why some optimization tools, based on evolutionary algorithms have been developed to speed up the process. This study compares results obtained through the brute-force approach and the evolutionary optimization methods applied on the calibration of a large educational building model located in the province of Treviso, north of Italy. The total design space consists of about 72 000 EnergyPlus building models. Two optimization-based calibrations have been repeated using a genetic algorithm by means of jEPlus+EA on a local computer and through parametric simulations implemented by jEPlus on a cloud service. The quality of results from the evolutionary optimization tools as compared to a full parametric study applied on calibration have been discussed. Scenarios of applicability are drafted. On a practical level, the research is a contribution for the selection of methods and tools for the preparation of models that can lead to optimized retrofit interventions and rationalization of building management and operation.},
author = {Lara, Rigoberto Arambula and Naboni, Emanuele and Pernigotto, Giovanni and Cappelletti, Francesca and Zhang, Yi and Barzon, Furio and Gasparella, Andrea and Romagnoni, Piercarlo},
doi = {10.1016/j.egypro.2017.03.269},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lara et al. - 2017 - Optimization Tools for Building Energy Model Calibration.pdf:pdf},
isbn = {3904710176},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Genetic Algorithm,Optimization,Parametric analysis,Retrofit},
number = {September 2016},
pages = {1060--1069},
publisher = {Elsevier B.V.},
title = {{Optimization Tools for Building Energy Model Calibration}},
url = {http://dx.doi.org/10.1016/j.egypro.2017.03.269},
volume = {111},
year = {2017}
}
@phdthesis{Ligier2019,
author = {Ligier, Simon},
file = {:home/sarah/OneDrive/Travail/Sources/2018PSLEM083{\_}archivage.pdf:pdf},
school = {PSL Research University},
title = {{D{\'{e}}veloppement d'une m{\'{e}}thodologie pour la garantie de performance {\'{e}}nerg{\'{e}}tique associant la simulation {\`{a}} un protocole de mesure et v{\'{e}}rification}},
year = {2018}
}
@phdthesis{Chambers2017a,
author = {Chambers, Jonathan David},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chambers - 2017 - Developing a rapid , scalable method of thermal characterisation for UK dwellings using smart meter data.pdf:pdf},
number = {June},
pages = {1--254},
school = {UCL},
title = {{Developing a rapid, scalable method of thermal characterisation for UK dwellings using smart meter data}},
year = {2017}
}
@article{Wang2019,
author = {Wang, Zequn and Chen, Yuxiang and Li, Yong},
doi = {10.1016/j.enbuild.2019.04.042},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Chen, Li - 2019 - Development of RC Model for Thermal Dynamic Analysis of Buildings through Model Structure Simplification.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building thermal dynamics,Data-driven models,Model structure simplification,Multi-zone models,RC models},
month = {may},
publisher = {Elsevier B.V.},
title = {{Development of RC Model for Thermal Dynamic Analysis of Buildings through Model Structure Simplification}},
url = {https://doi.org/10.1016/j.enbuild.2019.04.042 https://linkinghub.elsevier.com/retrieve/pii/S0378778818337654},
year = {2019}
}
@article{Tuo2015,
abstract = {Many computer models contain unknown parameters which need to be estimated using physical observations. Kennedy and O'Hagan (2001) shows that the calibration method based on Gaussian process models proposed by Kennedy and O'Hagan (2001) may lead to unreasonable estimate for imperfect computer models. In this work, we extend their study to calibration problems with stochastic physical data. We propose a novel method, called the {\$}L{\_}2{\$} calibration, and show its semiparametric efficiency. The conventional method of the ordinary least squares is also studied. Theoretical analysis shows that it is consistent but not efficient. Numerical examples show that the proposed method outperforms the existing ones.},
archivePrefix = {arXiv},
arxivId = {1507.07280},
author = {Tuo, Rui and Wu, C F Jeff},
eprint = {1507.07280},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuo, Wu - 2015 - EFFICIENT CALIBRATION FOR IMPERFECT COMPUTER MODELS(2).pdf:pdf},
keywords = {Computer Experiments,Reproducing Kernel Hilbert Space,Semiparametric Efficiency,Uncertainty Quantification},
month = {jul},
title = {{Efficient Calibration for Imperfect Computer Models}},
url = {https://arxiv.org/pdf/1507.07280.pdf http://arxiv.org/abs/1507.07280},
year = {2015}
}
@book{Luo2014,
address = {Cham},
author = {Tan, Ai Hui and Godfrey, Keith Richard},
booktitle = {Springer-Verlag},
doi = {10.1007/978-3-030-03661-4},
file = {:home/sarah/OneDrive/Travail/Sources/[Advances in Industrial Control] Ai Hui Tan, Keith Richard Godfrey - Industrial Process Identification{\_} Perturbation Signal Design and Applications (2019, Springer International Publishing).pdf:pdf},
isbn = {978-3-030-03660-7},
issn = {1430-9491},
publisher = {Springer International Publishing},
series = {Advances in Industrial Control},
title = {{Industrial Process Identification}},
url = {http://link.springer.com/10.1007/978-3-030-03661-4},
year = {2019}
}
@article{Moeckel1997,
abstract = {To evaluate models of dynamical systems, researchers have traditionally used quantitative measures of short term prediction errors. However, for chaotic or stochastic systems, comparison of long term, qualitative behaviors may be more relevant. Let x = (x0. . . . , xn) be a sequence of real numbers generated by sampling a dynamical system or stochastic process and suppose y = (y0, . . . . yn) is another sequence, generated by a mathematical model of the process which generated x. In this paper we consider several ways of assigning a distance d(x, y) which measures the difference in long term behavior. {\textcopyright} 1997 Elsevier Science B.V. All rights reserved.},
author = {Moeckel, Richard and Murray, Brad},
doi = {10.1016/S0167-2789(96)00154-6},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moeckel, Murray - 1997 - Measuring the distance between time series.pdf:pdf},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
month = {apr},
number = {3-4},
pages = {187--194},
title = {{Measuring the distance between time series}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0167278996001546/1-s2.0-S0167278996001546-main.pdf?{\_}tid=2a56df2a-a924-11e7-9b3d-00000aab0f6c{\&}acdnat=1507136025{\_}26fc4fc9e74f9e278db80da8b3c43524 https://linkinghub.elsevier.com/retrieve/pii/S0167278996001546},
volume = {102},
year = {1997}
}
@article{Guyon2010,
abstract = {The principle of parsimony also known as "Ockham's razor" has inspired many theories of model selection. Yet such theories, all making arguments in favor of parsimony, are based on very different premises and have developed distinct methodologies to derive algorithms. We have organized challenges and edited a special issue of JMLR and several conference proceedings around the theme of model selection. In this editorial, we revisit the problem of avoiding overfitting in light of the latest results. We note the remarkable convergence of theories as different as Bayesian theory, Minimum Description Length, bias/variance tradeoff, Structural Risk Minimization, and regularization, in some approaches. We also present new and interesting examples of the complementarity of theories leading to hybrid algorithms, neither frequentist, nor Bayesian, or perhaps both frequentist and Bayesian!. {\textcopyright} 2010 Isabelle Guyon, Amir Saffari, Gideon Dror and Gavin Cawley.},
author = {Guyon, Isabelle and Saffari, Amir and Dror, Gideon and Cawley, Gavin},
file = {:home/sarah/OneDrive/Travail/Sources/guyon10a.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian priors,Bias-variance tradeoff,Ensemble methods,Guaranteed risk minimization,Model selection,Multilevel inference,Multilevel optimization,Over-fitting,Performance prediction,Regularization,Structural risk minimization},
pages = {61--87},
title = {{Model selection: Beyond the bayesian/frequentist divide}},
volume = {11},
year = {2010}
}
@article{Gustafson2009,
abstract = {In health research and other fields, the observational data available to researchers often fall short of the data that ideally would be available, due to the inherent limitations of study design and data acquisition. Were they available, these ideal data might be readily analyzed via straightforward statistical models with such desirable properties as parameter identifiability. Conversely, realistic models for the available data that incorporate uncertainty about the link between ideal and available data may be nonidentified. While there is no conceptual difficulty in implementing Bayesian analysis with nonidentified models and proper prior distributions, it is important to know to what extent data can be informative about parameters of interest. Determining the large-sample limit of the posterior distribution is one way to characterize the informativeness of data. In some nonidentified models, it is relatively straightforward to determine the limit via a particular reparameterization of the model; however, in other nonidentified models there is no such obvious approach. Thus we have developed an algorithm for determining the limiting posterior distribution for at least some such more difficult models. The work is motivated by two specific nonidentified models that arise quite naturally, and the algorithm is applied to reveal how informative the data are for these models. This article has supplementary material online {\textcopyright} 2009 American Statistical Association.},
author = {Gustafson, Paul},
doi = {10.1198/jasa.2009.tm08603},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/40592372.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Asymptotics,Bayesian inference,Nonidentified model},
number = {488},
pages = {1682--1695},
title = {{What are the limits of posterior distributions arising from nonidentified models, and why should we care?}},
volume = {104},
year = {2009}
}
@article{Deng2014,
abstract = {This paper proposes an aggregation-based model reduction method for nonlinear models of multi-zone building thermal dynamics. The full-order model, which is already a lumped-parameter approximation, quickly grows in state space dimension as the number of zones increases. An advantage of the proposed method, apart from being applicable to the nonlinear thermal models, is that the reduced model obtained has the same structure and physical intuition as the original model. This makes the reduced model useful not only for control design and analysis but also for building design iterations. The key to the methodology is an analogy between a continuous-time Markov chain and the linear part of the thermal dynamics. A recently developed aggregation-based method of Markov chains is employed to aggregate the large state space of the full-order model into a smaller one. Simulations are provided to illustrate tradeoffs between prediction error and computation time.},
annote = {Utilisation de la divergence de Kullback Leibler pour mesurer la diff{\'{e}}rence de performance entre deux mod{\`{e}}les.
La distribution mesur{\'{e}}e est celle des temp{\'{e}}ratures {\`{a}} un noeud donn{\'{e}}.},
author = {Deng, Kun and Goyal, Siddharth and Barooah, Prabir and Mehta, Prashant G},
doi = {10.1016/j.automatica.2014.02.009},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng et al. - 2014 - Structure-preserving model reduction of nonlinear building thermal models.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Control oriented models,Kullback-Leibler divergence,Markov models,Model reduction,Model-based control,Structure preserving,S{\'{e}}lection de mod{\`{e}}les},
mendeley-tags = {Kullback-Leibler divergence,S{\'{e}}lection de mod{\`{e}}les},
month = {apr},
number = {4},
pages = {1188--1195},
title = {{Structure-preserving model reduction of nonlinear building thermal models}},
url = {http://plaza.ufl.edu/siddgoya/Homepage/Publications{\_}files/12{\_}Automatica{\_}Model{\_}Reduction.pdf http://linkinghub.elsevier.com/retrieve/pii/S0005109814000478},
volume = {50},
year = {2014}
}
@misc{Hartland2018,
abstract = {The KL-divergence is normally defined between two probability distributions. In the case where only samples of the probability distribution are available, the KL-divergence can be estimated in a number of ways. Here I test a few implementations of a KL-divergence estimator based on k-Nearest-Neighbours probability density estimation. The estimator is that of Qing Wang, Sanjeev R. Kulkarni, and Sergio Verd{\'{u}}. "Divergence estimation for multidimensional densities via k-nearest-neighbor distances." Information Theory, IEEE Transactions on 55.5 (2009): 2392-2405. Samples are drawn from various test distributions, and the estimated KL-divergence between them is computed. Uncertainties are assessed by re-sampling the distributions and re-computing divergence estimates 100 times. Uncertainty bands are then given as the interval containing 68{\%} of the re-sampled estimates closest to the median. Timings where provided are the time taken for the computation of all 100 re-samples on a sample size of N=1000 with k=5. This study is far from exhaustive, and timings are sensitive to implementation details. Please take with a pinch of salt.},
author = {Hartland, Nathan},
pages = {Latest commit 5473a23 on 7 Mar 2018},
publisher = {GitHub repository},
title = {{KL-divergence-estimators}},
url = {https://github.com/nhartland/KL-divergence-estimators},
year = {2018}
}
@article{Xu2008,
abstract = {An alternative simplified building model is developed to describe existing building system aiming at providing performance benchmark for performance evaluation and diagnosis at building level and performance prediction for air - conditioning system optimal control . This model combines detailed physical models of building envelopes and a thermal network model of building internal mass . The detailed physical models are the CTF (Conduction Transfer Function) models of building envelopes based on the easily available detailed physical properties of exterior walls and roof . The thermal network model is the 2R2C model , and its parameters are estimated and optimized using genetic algorithm with short - term monitored operation data . The parameter optimization of the simplified building internal mass model (2R2C) and the simplified dynamic building model (i . e . , CTF + 2R2C model) are validated in a high - rising commercial office building under various weather conditions . This CTF + 2R2C model is an alternative modeling approach for simulating the overall building dynamic thermal performance when CTF model is chosen to model the building envelope .},
author = {Xu, Xinhua and Wang, Shengwei},
doi = {10.1016/j.ijthermalsci.2007.10.011},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Wang - 2008 - A simplified dynamic model for existing buildings using CTF and thermal network models.pdf:pdf},
journal = {International Journal of Thermal Sciences},
keywords = {CTF model,Dynamic thermal performance,Existing building,Grey box,Modeling,Parameter optimization,Predictive control,RC model,Thermal network model},
mendeley-tags = {Grey box,Predictive control,RC model},
pages = {1249--1262},
title = {{A simplified dynamic model for existing buildings using CTF and thermal network models}},
url = {https://www.researchgate.net/profile/Shengwei{\_}Wang/publication/245075213{\_}A{\_}simplified{\_}dynamic{\_}model{\_}for{\_}existing{\_}buildings{\_}using{\_}CTF{\_}and{\_}thermal{\_}network{\_}models/links/54f439f90cf299c8d9e6601b.pdf},
volume = {47},
year = {2008}
}
@phdthesis{Alcalde2015,
abstract = {The analysis of time series data is important in fields as disparate as the social sciences, biology, engineering or econometrics. In this dissertation, we present a number of algorithms designed to learn Bayesian nonparametric models of time series. The goal of these kinds of models is twofold. First, they aim at making predictions which quantify the uncertainty due to limitations in the quantity and the quality of the data. Second, they are flexible enough to model highly complex data whilst preventing overfitting when the data does not warrant complex models. We begin with a unifying literature review on time series models based on Gaussian processes. Then, we centre our attention on the Gaussian Process State-Space Model (GP-SSM): a Bayesian nonparametric generalisation of discrete-time nonlinear state-space models. We present a novel formulation of the GP-SSM that offers new insights into its properties. We then proceed to exploit those insights by developing new learning algorithms for the GP-SSM based on particle Markov chain Monte Carlo and variational inference. Finally, we present a filtered nonlinear auto-regressive model with a simple, robust and fast learning algorithm that makes it well suited to its application by non-experts on large datasets. Its main advantage is that it avoids the computationally expensive (and potentially difficult to tune) smoothing step that is a key part of learning nonlinear state-space models.},
author = {Alcalde, Roger},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frigola-Alcalde - 2015 - Bayesian Time Series Learning with Gaussian Processes.pdf:pdf},
number = {August},
pages = {109},
title = {{Bayesian Time Series Learning with Gaussian Processes}},
url = {http://www.rogerfrigola.com/doc/thesis.pdf http://mlg.eng.cam.ac.uk/pub/pdf/Fri15.pdf},
year = {2015}
}
@article{Xiao2017,
author = {Xiao, Sinan and Lu, Zhenzhou},
doi = {10.1016/j.ast.2017.09.009},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao, Lu - 2017 - Structural reliability sensitivity analysis based on classification of model output.pdf:pdf},
issn = {12709638},
journal = {Aerospace Science and Technology},
number = {September},
pages = {52--61},
title = {{Structural reliability sensitivity analysis based on classification of model output}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1270963817312713},
volume = {71},
year = {2017}
}
@incollection{VandenHof2009,
abstract = {When first principles models are used for model-based operations as mon-itoring, control and optimization, the estimation of accurate physical parameters is important in particular when the underlying dynamical model is nonlinear. If the models are the result of partial differential equations being discretized, they are of-ten large-scale in terms of number of states and possibly also number of parameters. Estimating a large number of parameters from measurement data leads to problems of identifiability, and consequently to inaccurate identification results. The question whether a physical model structure is identifiable, is usually considered in a qualita-tive way, i.e. it is answered with a yes/no answer. However since also nearly uniden-tifiable model structures lead to poor parameter estimates, the questions is addressed how the model structure can be approximated so as to achieve local identifiability, while retaining the interpretation of the physical parameters. Appropriate attention is also given to the relevant scaling of parameters. The problem is addressed in a prediction error setting, showing the relation with gradient-type optimization algo-rithms as well as with Bayesian parameter estimation.},
address = {Boston, MA},
author = {{Van den Hof}, Paul M. J. and {Van Doren}, Jorn F M and Douma, Sippe G},
booktitle = {Model-Based Control:},
doi = {10.1007/978-1-4419-0895-7_8},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van den Hof, Van Doren, Douma - 2009 - Identification of Parameters in Large Scale Physical Model Structures, for the Purpose of Model-B.pdf:pdf},
pages = {125--143},
publisher = {Springer US},
title = {{Identification of Parameters in Large Scale Physical Model Structures, for the Purpose of Model-Based Operations}},
url = {http://www.pvandenhof.nl/Paperfiles/VandenHof{\&}etal{\_}OHBook.pdf http://link.springer.com/10.1007/978-1-4419-0895-7{\_}8},
year = {2009}
}
@techreport{Baker2011,
author = {Baker, Paul},
file = {:home/sarah/OneDrive/Travail/Sources/techpaper10-u-value-measurements.pdf:pdf},
institution = {Glasgow Caledonian University},
pages = {70},
title = {{Historic Scotland Technical Paper 10}},
url = {www.historic‐scotland.gov.uk/technicalpapers},
year = {2011}
}
@article{Tokmakian2017,
abstract = {It is common practice to use a simple model to explain the mechanisms or processes that occur in a much more complex, complete, and computationally expensive model. Many such examples can be found in climate change research. This paper uses two illustrative examples to show how we can quantitatively relate the mechanisms or processes observed in a simple climate model to similar mechanisms in a more complex one. The examples are, first, analytic and numerical solutions to the heat equation and, second, the 1948 Stommel model of horizontal ocean circulation and a more complex quasi-geostrophic ocean model. A simple model can only explain a more complex solution's mechanisms if outcomes are tested over a broad range of inputs. By carefully sampling the full set of inputs for both the simple and complex models, we can robustly compare the process or mechanistic outcomes, statistically, between them. Thus, by examining the similarity or differences in the relationship between the inputs and outputs, we can quantitatively state how similar the simple model's mechanisms are to the mechanisms in the more complex representation. The method can reject an incorrect simple model. In addition, when a simple solution may be correct, we show the percentage of the variance of the complex model's outcomes that is explained Published by Oxford University Press 2017. 2 R. Tokmakian and P. Challenor by the simple response along with an uncertainty estimate.},
author = {Tokmakian, Robin and Challenor, Peter},
doi = {10.1093/climsys/dzx003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tokmakian, Challenor - 2017 - Towards the validation of a traceable climate model hierarchies.pdf:pdf},
issn = {2059-6987},
journal = {Dynamics and Statistics of the Climate System},
keywords = {Analyse de sensibilit{\'{e}},Comparaison de mod{\`{e}}les,Variance},
mendeley-tags = {Analyse de sensibilit{\'{e}},Comparaison de mod{\`{e}}les,Variance},
month = {jul},
number = {0},
pages = {1--27},
title = {{Towards the validation of a traceable climate model hierarchies}},
url = {https://oup.silverchair-cdn.com/oup/backfile/Content{\_}public/Journal/climatesystem/PAP/10.1093{\_}climsys{\_}dzx003/1/dzx003.pdf?Expires=1503390242{\&}Signature=bfUBGUU3UiyZ{~}bmJ08QE1Im86wVmaYzAUkMjwTh74qB7kH3fmpuHqm5h{~}rk6wgr9Py{~}fEOf7BIqh6c9Uj5AMnlJRY5L{~}3mD2RkZQtE0J},
volume = {0},
year = {2017}
}
@article{Sicard1985,
abstract = {An analytic method using the integral-transform technique is extended to solve stationary, linear, reciprocal thermal transfer problems with heat transfer by conduction, convection and radiation. To simplify the analysis, the equations are established for the case of a simple cell (room) with one-dimensional conduction through the walls. It is shown that the solution can be achieved requiring very few parameters. Theoretical and practical applications are developed. {\textcopyright} 1985.},
author = {Sicard, J. and Bacot, P. and Neveu, A.},
doi = {10.1016/0017-9310(85)90013-4},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-0017931085900134-main.pdf:pdf},
issn = {00179310},
journal = {International Journal of Heat and Mass Transfer},
number = {1},
pages = {111--123},
title = {{Analyse modale des {\'{e}}changes thermiques dans le b{\^{a}}timent}},
volume = {28},
year = {1985}
}
@article{Ling2014a,
abstract = {a r t i c l e i n f o a b s t r a c t In the Kennedy and O'Hagan framework for Bayesian calibration of physics models, selection of an appropriate prior form for the model discrepancy function is a challenging issue due to the lack of physics knowledge regarding model inadequacy. Aiming to address the uncertainty arising from the selection of a particular prior, this paper first conducts a study on possible formulations of the model discrepancy function. A first-order Taylor series expansion-based method is developed to investigate the potential redundancy caused by adding a discrepancy function to the original physics model. Further, we propose a three-step (calibration, validation, and combination) approach in order to inform the decision on the construction of model discrepancy priors. In the validation step, a reliability-based metric is used to evaluate posterior model predictions in the validation domain. The validation metric serves as a quantitative measure of how well the discrepancy formulation captures the missing physics in the model. In the combination step, the posterior distributions of model parameters and discrepancy corresponding to different priors are combined into a single distribution based on the probabilistic weights derived from the validation step. The combined distribution acknowledges the uncertainty in the prior formulation of model discrepancy function.},
author = {Ling, You and Mullins, Joshua and Mahadevan, Sankaran},
doi = {10.1016/j.jcp.2014.08.005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ling, Mullins, Mahadevan - 2014 - Selection of model discrepancy priors in Bayesian calibration.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Bayesian calibration,Identifiability,Model uncertainty,Validation},
month = {nov},
pages = {665--680},
title = {{Selection of model discrepancy priors in Bayesian calibration}},
url = {www.elsevier.com/locate/jcp https://linkinghub.elsevier.com/retrieve/pii/S0021999114005518},
volume = {276},
year = {2014}
}
@article{Deb2018,
abstract = {a b s t r a c t This study aims to determine key building variables influencing energy consumption in air-conditioned office buildings. The study is based in Singapore which entails tropical climatic conditions. The analysis is based on assessment of several energy audit reports concerning pre-and post-retrofit data from 56 office buildings. A list of 14 building variables, extracted from these reports form the superset. These are systematically analyzed further to derive key variables influencing energy consumption and retrofitting decisions. For this purpose, a robust iterative process is developed utilizing k-means clustering. This process tests all combinations of the 14 variables against change in energy use intensity (EUI, measured as kWh/m 2 .year) for pre-and post-retrofit conditions. The results indicate that the best set of variables consists of: 1) gross floor area (GFA), 2) non-air-conditioning energy consumption, 3) average chiller plant efficiency, and 4) installed capacity of chillers. This information can be utilized to explore energy saving potential of office buildings that need to be retrofitted. The resultant clusters can also be used to benchmark buildings based on pre-retrofit conditions and energy saving potential.},
author = {Deb, Chirag and Lee, Siew Eang},
doi = {10.1016/j.enbuild.2017.11.007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deb, Lee - 2018 - Determining key variables influencing energy consumption in office buildings through cluster analysis of pre- and post.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building energy,Building retrofit,Cluster analysis,Energy efficiency,K-means clustering,Office buildings},
month = {jan},
pages = {228--245},
title = {{Determining key variables influencing energy consumption in office buildings through cluster analysis of pre- and post-retrofit building data}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S0378778817330244/1-s2.0-S0378778817330244-main.pdf?{\_}tid=94ad7abe-c850-11e7-8fe1-00000aacb35e{\&}acdnat=1510563587{\_}8fc2ef52002a046b8de4ee2a751f6e2f https://linkinghub.elsevier.com/retrieve/pii/S0378778817330244},
volume = {159},
year = {2018}
}
@article{Jimenez2008,
abstract = {Outdoor testing of buildings and building components under real weather conditions provides useful information about their dynamic performance. Such knowledge is needed to properly characterize the heat transfer dynamics and provides useful information for implementing energy saving strategies, for example. For the analysis of these tests, dynamic analysis models and methods are required. However, a wide variety of models and methods exists, and the problem of choosing the most appropriate approach for each particular case is a non-trivial and interdisciplinary task. Knowledge of a large family of these approaches may therefore be very useful for selecting a suitable approach for each particular case. This paper presents an overview of models that can be applied for modelling the thermal characteristics of buildings and building components using data from outdoor testing. The choice of approach depends on the purpose of the modelling, existence of prior physical knowledge, the data and the available statistical tools. In this paper, a variety of models are outlined and compared, and a strong relationship among a large number of widely used linear and stationary stochastic models is mathematically demonstrated. The characteristics of each type of model are highlighted. Some available software tools for each of the methods described will be mentioned. A case study also demonstrating the difference between linear and nonlinear models is considered.},
author = {Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Madsen, Henrik},
doi = {10.1016/j.buildenv.2006.10.029},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jim{\'{e}}nez, Madsen - 2008 - Models for describing the thermal characteristics of building components.pdf:pdf},
journal = {Building and Environment},
keywords = {Building energy,Outdoor testing,System identification,Thermal parameters},
pages = {152--162},
title = {{Models for describing the thermal characteristics of building components}},
url = {http://ac.els-cdn.com.camphrier-1.grenet.fr/S0360132306002952/1-s2.0-S0360132306002952-main.pdf?{\_}tid=4edbf6f8-2596-11e7-8a8e-00000aab0f02{\&}acdnat=1492671495{\_}ce5ecd76b78e351659c7437bc7c5b63e},
volume = {43},
year = {2008}
}
@inproceedings{Chong2019a,
abstract = {With the emergence of the Internet of Things (IoT), there is an opportunity to create a digital twin of a building that continuously learns and updates itself using real-time observations. Model calibration is an essential aspect of the overall process to ensure its reliability. However, the calibration of building energy models (BEM) is typically carried out only once and can quickly become outdated. Continuous Bayesian calibration reduces the effort to maintain an energy model while accounting for its uncertainty. Invariably , the model would be up-to-date for use in applications such as retrofit analysis, fault detection, and model predictive control. The present paper aims to present the concept and implementation of a framework for the continuous calibration of BEM with uncertainty. The proposed framework includes instance selection as a pre-processing step to keep the calibration process computationally tractable.},
address = {Rome},
author = {Chong, Adrian and Song, Chao},
booktitle = {16th Conference of IBPSA},
file = {:home/sarah/OneDrive/Travail/Sources/IBPSA2019/BS2019{\_}114{\_}2{\_}210577{\_}Chong{\_}2019-06-25{\_}20-41{\_}a.pdf:pdf},
number = {September},
title = {{A framework for the continuous Bayesian calibration of building energy models}},
url = {https://www.researchgate.net/publication/335680184},
year = {2019}
}
@article{Foucquier2013a,
author = {Foucquier, Aur{\'{e}}lie and Brun, A and Faggianelli, G A and Suard, Fr{\'{e}}d{\'{e}}ric},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foucquier et al. - 2013 - Effect of wall merging on a simplified building energy model accuracy versus number of equations.pdf:pdf},
journal = {13th International Conference of the International Building Performance Simulation Association},
pages = {3161--3168},
title = {{Effect of wall merging on a simplified building energy model: accuracy versus number of equations}},
url = {https://www-publicea.cea.fr/exl-doc/201300003097.pdf},
year = {2013}
}
@article{Chong2018,
abstract = {This paper provides practical guidelines to the Bayesian calibration of building energy models using the probabilistic programming language Stan. While previous studies showed the applicability of the calibration method to building simulation, its practicality is still impeded by its complexity and the need to specify a whole range of information due to its Bayesian nature. We ease the reader into the practical application of Bayesian calibration to building energy models by providing the corresponding code and user guidelines with this paper. Using a case study, we demonstrate the application of Kennedy and O'Hagan's (KOH) [1] Bayesian calibration framework to an EnergyPlus whole building energy model. The case study is used to analyze the sensitivity of the posterior distributions to the number of calibration parameters. The study also looks into the influence of prior specification on the resulting (1) posterior distributions; (2) calibrated predictions; and (3) model inadequacy that is revealed by a discrepancy between the observed data and the model predictions. Results from the case study suggest that over-parameterization can result in a significant loss of posterior precision. Additionally, using strong prior information for the calibration parameters may dominate any influence from the data leading to poor posterior inference of the calibration parameters. Lastly, this study shows that it may be misleading to assume that the posteriors of the calibration parameters are representative of their true values and their associated uncertainty simply because the calibrated predictions matches the measured output well.},
author = {Chong, Adrian and Menberg, Kathrin},
doi = {10.1016/j.enbuild.2018.06.028},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778818307539-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,Building energy modeling,Building simulation,Gaussian process,Hamiltonian Monte Carlo},
pages = {527--547},
publisher = {Elsevier B.V.},
title = {{Guidelines for the Bayesian calibration of building energy models}},
url = {https://doi.org/10.1016/j.enbuild.2018.06.028},
volume = {174},
year = {2018}
}
@article{Ruiz2017,
abstract = {Nowadays, there is growing interest in all the smart technologies that provide us with information and knowledge about the human environment. In the energy field, thanks to the amount of data received from smart meters and devices and the progress made in both energy software and computers, the quality of energy models is gradually improving and, hence, also the suitability of Energy Conservation Measures (ECMs). For this reason, the measurement of the accuracy of building energy models is an important task, because once the model is validated through a calibration procedure, it can be used, for example, to apply and study different strategies to reduce its energy consumption in maintaining human comfort. There are several agencies that have developed guidelines and methodologies to establish a measure of the accuracy of these models, and the most widely recognized are: ASHRAE Guideline 14-2014, the International Performance Measurement and Verification Protocol (IPMVP) and the Federal Energy Management Program (FEMP). This article intends to shed light on these validation measurements (uncertainty indices) by focusing on the typical mistakes made, as these errors could produce a false belief that the models used are calibrated.},
author = {Ruiz, Germ{\'{a}}n and Bandera, Carlos},
doi = {10.3390/en10101587},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruiz, Bandera - 2017 - Validation of Calibrated Energy Models Common Errors.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
month = {oct},
number = {10},
pages = {1587},
title = {{Validation of Calibrated Energy Models: Common Errors}},
url = {http://www.mdpi.com/1996-1073/10/10/1587},
volume = {10},
year = {2017}
}
@article{Chong2017,
author = {Chong, Adrian and Lam, Khee Poh},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chong, Lam - 2017 - A Comparison of MCMC Algorithms for the Bayesian Calibration of Building Energy Models for Building Simulation 2017.pdf:pdf},
pages = {494--503},
title = {{A Comparison of MCMC Algorithms for the Bayesian Calibration of Building Energy Models for Building Simulation 2017 Conference Center for Building Performance and Diagnostics , Carnegie Mellon University , Pittsburgh , USA Abstract EnergyPlus model}},
year = {2017}
}
@article{Foucquier2013,
abstract = {In the European Union, the building sector is one of the largest energy consumer with about 40{\%} of the final energy consumption. Reducing consumption is also a sociological, technological and scientific matter. New methods have to be devised in order to support building professionals in their effort to optimize designs and to enhance energy performances. Indeed, the research field related to building modelling and energy performances prediction is very productive, involving various scientific domains. Among them, one can distinguish physics-related fields, focusing on the resolution of equations simulating building thermal behaviour and mathematics-related ones, consisting in the implementation of prediction model thanks to machine learning techniques. This paper proposes a detailed review and discussion of these works. First, the approaches based on physical (white box) models are reviewed according three-category classification. Then, we present the main machine learning (black box) tools used for prediction of energy consumption, heating/cooling demand, indoor temperature. Eventually, a third approach called hybrid (grey box) method is introduced, which uses both physical and statistical techniques. The paper covers a wide range of research works, giving the base principles of each technique and numerous illustrative examples. {\textcopyright} 2013 Elsevier Ltd.},
author = {Foucquier, Aur{\'{e}}lie and Robert, Sylvain and Suard, Fr{\'{e}}d{\'{e}}ric and St{\'{e}}phan, Louis and Jay, Arnaud},
doi = {10.1016/j.rser.2013.03.004},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foucquier et al. - 2013 - State of the art in building modelling and energy performances prediction A review.pdf:pdf},
isbn = {1364-0321},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Building modelling,Building prediction model,Building thermal models,Energy consumption,Energy performance,Grey box,Machine learning,White box,black box},
mendeley-tags = {Grey box,White box,black box},
pages = {272--288},
pmid = {89217952},
title = {{State of the art in building modelling and energy performances prediction: A review}},
volume = {23},
year = {2013}
}
@article{Reddy2007a,
abstract = {Calibrated simulation is the process of using a building simulation program for an existing building and "tuning" or calibrating the various inputs to the program so that predictions match closely with observed energy use. Historically, the calibration process has been an art form that inevitably relies on user knowledge, past experience, statistical expertise, engineering judgment, and an abundance of trial and error. Unfortunately, despite widespread interest in the professional community, no consensus guidelines have been published on how to perform a calibration using detailed simulation programs. This research project was initiated with the intention to cull the best tools, techniques, approaches, and procedures from the existing body of research and develop a coherent and systematic calibration methodology that includes both parameter estimation and the determination of the uncertainty in the calibrated simulation. A general methodology of calibrating detailed simulation programs to performance data is proposed, which we deem to be methodical, rational, robust, and computationally efficient while being flexible enough to satisfy different users with different personal preferences and biases. The methodology involves various concepts and approaches borrowed from allied scientific disciplines that are also reviewed in this paper. The methodology essentially consists of five parts: (1) identify a building energy program that has the ability to simulate the types of building elements and systems present and set up the simulation input file to be as realistic as possible; (2) depending on the building type, heuristically define a set of influential parameters and schedules that have simple and clear correspondence to specific and easy-to-identify inputs to the simulation program, along with their best-guess estimates and their range of variation; (3) perform a coarse grid search wherein the heuristically defined influential parameters are subject to a Monte Carlo simulation involving thousands of simulation trials from which a small set of promising parameter vector solutions can be identified by filtering, the strong and weak parameters can be identified, and narrower bounds of variability of the strong parameters can be defined; (4) perform a guided grid search to further refine the promising parameter vector solutions; and (5) use this small set of solutions (as opposed to a single calibrated solution) to make predictions about intended changes to the building and its systems, and determine the prediction uncertainty of the entire calibration process. A companion paper (Reddy et al. 2007) will present the results of applying this calibration methodology to two synthetic office buildings and one actual office building.},
author = {Reddy, T A and Maor, I and Panjapornpon, Chanin},
doi = {Article},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reddy, Maor, Panjapornpon - 2007 - Calibrating detailed building energy simulation programs with measured data - Part 1 General methodol.pdf:pdf},
isbn = {1078-9669},
issn = {10789669},
journal = {HvacR Research},
number = {2},
pages = {221--241},
pmid = {24818836},
title = {{Calibrating detailed building energy simulation programs with measured data - Part 1: General methodology (RP-1051)}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=a9h{\&}AN=24818836{\&}site=ehost-live},
volume = {13},
year = {2007}
}
@inproceedings{Wang2017,
author = {Wang, Qinpeng and Augenbroe, Godfried},
booktitle = {Building simulation 2017},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Augenbroe - 2017 - Combined sensitivity ranking of input parameters and model forms of building energy simulation.pdf:pdf},
pages = {8},
title = {{Combined sensitivity ranking of input parameters and model forms of building energy simulation}},
year = {2017}
}
@article{Tian2018,
abstract = {Uncertainty analysis in building energy assessment has become an active research field because a number of factors influencing energy use in buildings are inherently uncertain. This paper provides a systematic review on the latest research progress of uncertainty analysis in building energy assessment from four perspectives: uncertainty data sources, forward and inverse methods, application of uncertainty analysis, and available software. First, this paper describes the data sources of uncertainty in building performance analysis to provide a firm foundation for specifying variations of uncertainty factors affecting building energy. The next two sections focus on the forward and inverse methods. Forward uncertainty analysis propagates input uncertainty through building energy models to obtain variations of energy use, whereas inverse uncertainty analysis infers unknown input factors through building energy models based on energy data and prior information. For forward analysis, three types of approaches (Monte Carlo, non-sampling, and non-probabilistic) are discussed to provide sufficient choices of uncertainty methods depending on the purpose and specific application of a building project. For inverse analysis, recent research has concentrated more on Bayesian computation because Bayesian inverse methods can make full use of prior information on unknown variables. Fourth, several applications of uncertainty analysis in building energy assessment are discussed, including building stock analysis, HVAC system sizing, variations of sensitivity indicators, and optimization under uncertainty. Moreover, the software for uncertainty analysis is described to provide flexible computational environments for implementing uncertainty methods described in this review. This paper concludes with the trends and recommendations for further research to provide more convenient and robust uncertainty analysis of building energy. Uncertainty analysis has been ready to become the mainstream approach in building energy assessment although a number of issues still need to be addressed.},
author = {Tian, Wei and Heo, Yeonsook and de Wilde, Pieter and Li, Zhanyong and Yan, Da and Park, Cheol Soo and Feng, Xiaohang and Augenbroe, Godfried},
doi = {10.1016/j.rser.2018.05.029},
file = {:home/sarah/OneDrive/Travail/Sources/Probl{\`{e}}mes inverses/1-s2.0-S136403211830368X-main.pdf:pdf},
issn = {18790690},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Bayesian computation,Building energy,Inverse problems,Uncertainty analysis,Uncertainty propagation},
number = {May},
pages = {285--301},
publisher = {Elsevier Ltd},
title = {{A review of uncertainty analysis in building energy assessment}},
url = {https://doi.org/10.1016/j.rser.2018.05.029},
volume = {93},
year = {2018}
}
@article{Daly2018b,
abstract = {As systems approaches to the development of biological models become more mature, attention is increasingly focusing on the problem of inferring parameter values within those models from experimental data. However, particularly for nonlinear models, it is not obvious, either from inspection of the model or from the experimental data, that the inverse problem of parameter fitting will have a unique solution, or even a non-unique solution that constrains the parameters to lie within a plausible physiological range. Where parameters cannot be constrained they are termed 'unidentifiable'. We focus on gaining insight into the causes of unidentifiability using inference-based methods, and compare a recently developed measure-theoretic approach to inverse sensitivity analysis to the popular Markov chain Monte Carlo and approximate Bayesian computation techniques for Bayesian inference. All three approaches map the uncertainty in quantities of interest in the output space to the probability of sets of parameters in the input space. The geometry of these sets demonstrates how unidentifiability can be caused by parameter compensation and provides an intuitive approach to inference-based experimental design.},
author = {Daly, Aidan C. and Gavaghan, David and Cooper, Jonathan and Tavener, Simon},
doi = {10.1098/rsif.2018.0318},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daly et al. - 2018 - Inference-based assessment of parameter identifiability in nonlinear biological models.pdf:pdf},
isbn = {0000000294997},
issn = {17425662},
journal = {Journal of The Royal Society Interface},
keywords = {Identifiability,Markov chain Monte Carlo,approximate Bayesian computation,biomathematics,computational biology,experimental design,inverse sensitivity},
month = {jul},
number = {144},
pages = {20180318},
title = {{Inference-based assessment of parameter identifiability in nonlinear biological models}},
url = {http://rsif.royalsocietypublishing.org/lookup/doi/10.1098/rsif.2018.0318},
volume = {15},
year = {2018}
}
@article{Gumussoy2018,
author = {Gumussoy, Suat and Ozdemir, Ahmet Arda and McKelvey, Tomas and Ljung, Lennart and Gibanica, Mladen and Singh, Rajiv},
doi = {10.1016/j.ifacol.2018.09.158},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gumussoy et al. - 2018 - Improving Linear State-Space Models with Additional Iterations.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Maximum Likelihood,Parameter estimation,State-space models,Subspace identification,estimation,state-space},
number = {15},
pages = {341--346},
publisher = {Elsevier B.V.},
title = {{Improving Linear State-Space Models with Additional Iterations}},
url = {https://doi.org/10.1016/j.ifacol.2018.09.158 https://linkinghub.elsevier.com/retrieve/pii/S2405896318318196},
volume = {51},
year = {2018}
}
@article{Weerts,
abstract = {Dynamic networks are interconnected dynamic systems with measured node signals and dynamic modules reflecting the links between the nodes. We address the problem of identifying a dynamic network with known topology, on the basis of measured signals, for the situation of additive process noise on the node signals that is spatially correlated and that is allowed to have a spectral density that is singular. A prediction error approach is followed in which all node signals in the network are jointly predicted. The resulting joint-direct identification method, generalizes the classical direct method for closed-loop identification to handle situations of mutually correlated noise on inputs and outputs. When applied to general dynamic networks with rank-reduced noise, it appears that the natural identification criterion becomes a weighted LS criterion that is subject to a constraint. This constrained criterion is shown to lead to maximum likelihood estimates of the dynamic network and therefore to minimum variance properties, reaching the Cram{\'{e}}r–Rao lower bound in the case of Gaussian noise. In order to reduce technical complexity, the analysis is restricted to dynamic networks with strictly proper modules.},
author = {Weerts, Harm H.M. and {Van den Hof}, Paul M.J. and Dankers, Arne G},
doi = {10.1016/j.automatica.2018.09.033},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weerts, Van Den Hof, Dankers - Unknown - Prediction error identification of linear dynamic networks with rank-reduced noise.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Consistency,Cram{\'{e}}r–Rao lower bound,Dynamic networks,Maximum likelihood,Rank-reduced noise,System identification,Variance},
pages = {256--268},
title = {{Prediction error identification of linear dynamic networks with rank-reduced noise}},
url = {https://arxiv.org/pdf/1711.06369.pdf},
volume = {98},
year = {2018}
}
@article{Korolija2013,
abstract = {This paper described the development of regression models which are able to predict office building annual heating, cooling and auxiliary energy requirements for different HVAC systems as a function of office building heating and cooling demands. In order to represent the office building stock, a large number of building parameters were explored such as built forms, fabrics, glazing levels and orientation. Selected parameters were combined into a large set of office building models (3840 in total). As different HVAC systems have different energy requirements when responding to same building demands, each of the 3840 models were further coupled with five HVAC systems: VAV, CAV, fan-coil system with dedicated air (FC), and two chilled ceiling systems with dedicated air, radiator heating and either embedded pipes (EMB) or exposed aluminium panels (ALU). In total 23,040 possible scenarios were created and simulated using EnergyPlus software. The annual heating and cooling demands and their HVAC system's heating, cooling and auxiliary energy requirements were normalised per floor area and fitted to two groups of statistical models. Outputs from the regression analysis were evaluated by inspecting models best fit parameter values and goodness of fit. Based on the described analysis, the specific regression models were recommended. {\textcopyright} 2012 Elsevier B.V.},
author = {Korolija, Ivan and Zhang, Yi and Marjanovic-Halburd, Ljiljana and Hanby, Victor I.},
doi = {10.1016/j.enbuild.2012.12.005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korolija et al. - 2013 - Regression models for predicting UK office building energy consumption from heating and cooling demands.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Energy performance,HVAC systems,Parameters,Regression models,UK office buildings},
pages = {214--227},
publisher = {Elsevier B.V.},
title = {{Regression models for predicting UK office building energy consumption from heating and cooling demands}},
url = {http://dx.doi.org/10.1016/j.enbuild.2012.12.005},
volume = {59},
year = {2013}
}
@article{Berman1963,
author = {Berman, Mones},
doi = {10.1111/j.1749-6632.1963.tb13373.x},
file = {:home/sarah/OneDrive/Travail/Sources/Mod{\`{e}}les - Mod{\'{e}}lisation/Berman63copy.pdf:pdf},
issn = {00778923},
journal = {Annals of the New York Academy of Sciences},
keywords = {Modelling},
mendeley-tags = {Modelling},
month = {may},
number = {1},
pages = {182--194},
title = {{THE FORMULATION AND TESTING OF MODELS}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1963.tb13373.x},
volume = {108},
year = {1963}
}
@article{Farmer2016,
abstract = {This paper presents the methodology, along with some of the initial findings and observations from tests performed on two dwellings, of differing construction and form, in which a coheating test was performed using the dwelling's central heating system; this method is referred to as integrated coheating. Data obtained during the integrated coheating tests using a dwelling's heating system have been compared with data obtained during electric coheating of the same dwelling. In one instance, integrated coheating test data from one dwelling was compared to a similar adjoining control dwelling that was simultaneously subject to an electric coheating test. The results show a good agreement between the heat loss coefficients (HLC) obtained using a dwelling's own heating system and those obtained through electrical coheating. Initial analysis suggests the HLC estimate obtained from integrated coheating is likely to be more representative of how a dwelling performs in-use. The findings question the appropriateness of comparing current steady-state HLC predictions to those derived from in-use monitoring data. Integrated coheating has the potential to provide a more cost-effective and informative indication of whole house heat loss than electric coheating, as it enables in situ quantification of both fabric and heating system performance.},
author = {Farmer, David and Johnston, David and Miles-Shenton, Dominic},
doi = {10.1016/j.enbuild.2016.02.013},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farmer, Johnston, Miles-Shenton - 2016 - Obtaining the heat loss coefficient of a dwelling using its heating system (integrated coheatin.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building fabric,Coheating,Energy efficiency,Energy signature,Heat loss coefficient,Heat meter,Heating system,Performance gap,Thermal performance,Whole house heat loss},
pages = {1--10},
title = {{Obtaining the heat loss coefficient of a dwelling using its heating system (integrated coheating)}},
volume = {117},
year = {2016}
}
@phdthesis{Viot2016,
author = {Viot, Hugo},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viot - 2016 - Mod{\'{e}}lisation et instrumentation d'un b{\^{a}}timent et de ses syst{\`{e}}mes pour optimiser sa gestion {\'{e}}nerg{\'{e}}tique.pdf:pdf},
pages = {1--218},
title = {{Mod{\'{e}}lisation et instrumentation d'un b{\^{a}}timent et de ses syst{\`{e}}mes pour optimiser sa gestion {\'{e}}nerg{\'{e}}tique}},
year = {2016}
}
@techreport{Madsen2015a,
author = {Madsen, Henrik and Bacher, Peder and Bauwens, Geert and Deconinck, An-Heleen and Reynders, Glenn and Roels, Staf and Himpe, Eline and Leth{\'{e}}, Guillaume},
booktitle = {Reliable building energy performance characterisation based on full scale dynamic measurements},
doi = {10.13140/RG.2.1.1564.4241},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madsen et al. - 2015 - Thermal performance characterisation using time series data - statistical guidelines.pdf:pdf},
institution = {IEA},
isbn = {9789460189869},
title = {{IEA EBC Annex 58 : Thermal performance characterisation using time series data - statistical guidelines}},
year = {2015}
}
@phdthesis{Bauwens2015,
author = {Bauwens, Geert},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauwens - 2015 - In situ testing of a building ' s overall heat loss coefficient.pdf:pdf},
number = {November},
school = {KU Leuven},
title = {{In situ testing of a building ' s overall heat loss coefficient}},
year = {2015}
}
@inproceedings{Rivalin2014,
abstract = {Les outils de simulation sont couramment employ{\'{e}}s pour {\'{e}}valuer la consommation {\'{e}}nerg{\'{e}}tique d'un b{\^{a}}timent. Lors du processus de mod{\'{e}}lisation, des choix doivent {\^{e}}tre r{\'{e}}alis{\'{e}}s par l'utilisateur de l'outil, tels que la division du b{\^{a}}timent en zones thermiques. Le but de ce travail est d'{\'{e}}valuer l'influence du d{\'{e}}coupage en zones sur les r{\'{e}}sultats de la simulation thermique dynamique en incluant ou non les flux d'air et les transferts thermiques entre les zones. {\`{A}} cette fin, cinq d{\'{e}}coupages en zones (mod{\`{e}}les de 49 {\`{a}} 11 zones) sont appliqu{\'{e}}s au m{\^{e}}me immeuble de bureau. L'impact de la fusion des {\'{e}}tages est analys{\'{e}} en consid{\'{e}}rant diff{\'{e}}rents isolants de plancher et toiture et celui de l'union des orientations est {\'{e}}tudi{\'{e}} {\`{a}} l'aide de diff{\'{e}}rents taux de surface vitr{\'{e}}e. Les r{\'{e}}sultats des simulations thermiques dynamiques sont compar{\'{e}}s en termes de besoins {\'{e}}nerg{\'{e}}tiques (chauffage et},
author = {Rivalin, Lisa and Marchio, Dominique and Stabat, Pascal and Caciolo, Marcello and Rivalin, Lisa and Marchio, Dominique and Stabat, Pascal and Caciolo, Marcello},
booktitle = {Conf{\'{e}}rence IBPSA France Arras 2014},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rivalin et al. - 2014 - Influence du d ´ ecoupage en zones sur les besoins etiques annuels e To cite this version.pdf:pdf},
title = {{Influence du d{\'{e}}coupage en zones sur les besoins {\'{e}}nerg{\'{e}}tiques annuels}},
year = {2014}
}
@article{Akeret2015,
abstract = {Bayesian inference is often used in cosmology and astrophysics to derive con-straints on model parameters from observations. This approach relies on the ability to compute the likelihood of the data given a choice of model parameters. In many prac-tical situations, the likelihood function may however be unavailable or intractable due to non-gaussian errors, non-linear measurements processes, or complex data formats such as catalogs and maps. In these cases, the simulation of mock data sets can often be made through forward modeling. We discuss how Approximate Bayesian Computation (ABC) can be used in these cases to derive an approximation to the posterior constraints using simulated data sets. This technique relies on the sampling of the parameter set, a distance metric to quantify the difference between the observation and the simulations and summary statistics to compress the information in the data. We first review the principles of ABC and discuss its implementation using a Population Monte-Carlo (PMC) algorithm and the Mahalanobis distance metric. We test the performance of the implementation using a Gaussian toy model. We then apply the ABC technique to the practical case of the calibration of image simula-tions for wide field cosmological surveys. We find that the ABC analysis is able to provide reliable parameter constraints for this problem and is therefore a promising technique for other applications in cosmology and astrophysics. Our implementation of the ABC PMC method is made available via a public code release.},
author = {Akeret, Jo{\"{e}}l and Refregier, Alexandre and Amara, Adam and Seehars, Sebastian and Hasner, Caspar},
doi = {10.1088/1475-7516/2015/08/043},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2015 - Approximate Bayesian computation for forward modeling in cosmology On the non-Gaussian errors in high-z superno(2).pdf:pdf},
issn = {1475-7516},
journal = {Journal of Cosmology and Astroparticle Physics},
keywords = {cosmological simulations,non-gaussianity,weak gravitational lensing},
month = {aug},
number = {08},
pages = {043--043},
title = {{Approximate Bayesian computation for forward modeling in cosmology}},
url = {http://iopscience.iop.org/article/10.1088/1475-7516/2015/08/043/pdf http://stacks.iop.org/1475-7516/2015/i=08/a=043?key=crossref.d6e33c8d2994c1a8eec4b1ce66f23df3},
volume = {2015},
year = {2015}
}
@techreport{Hammarsten1984,
author = {Hammarsten, Stig},
institution = {Swedish Institute for Building Research},
language = {Swedish},
number = {Bulletin M84/18},
title = {{Estimation of energy balance for houses}},
year = {1984}
}
@article{Guillaume2019,
author = {Guillaume, Joseph H.A. and Jakeman, John D. and Marsili-Libelli, Stefano and Asher, Michael and Brunner, Philip and Croke, Barry and Hill, Mary C. and Jakeman, Anthony J. and Keesman, Karel J. and Razavi, Saman and Stigter, Johannes D.},
doi = {10.1016/j.envsoft.2019.07.007},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1-s2.0-S1364815218307278-main.pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling {\&} Software},
number = {July},
pages = {418--432},
publisher = {Elsevier},
title = {{Introductory overview of identifiability analysis: A guide to evaluating whether you have the right type of data for your modeling purpose}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364815218307278},
volume = {119},
year = {2019}
}
@inproceedings{Goffart2016,
address = {Marne-la-Vall{\'{e}}e},
author = {Goffart, Jeanne and Rabouille, Mickael and Mendes, Nathan},
booktitle = {Conf{\'{e}}rence IBPSA France},
file = {:home/sarah/OneDrive/Travail/Sources/Mesurage/Goffart - actesibpsa{\_}france{\_}2016.pdf:pdf},
title = {{Impact des incertitudes de mesure des variables m{\'{e}}t{\'{e}}orologiques sur le processus de comparaison mesure/simulation en simulation thermique dynamique}},
year = {2016}
}
@article{Vehtari2019,
abstract = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic {\$}\backslashwidehat{\{}R{\}}{\$} of Gelman and Rubin (1992) has serious flaws. Traditional {\$}\backslashwidehat{\{}R{\}}{\$} will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
archivePrefix = {arXiv},
arxivId = {1903.08008},
author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"{u}}rkner, Paul-Christian},
eprint = {1903.08008},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/1903.08008.pdf:pdf},
journal = {arXiv},
month = {mar},
pages = {1--26},
title = {{Rank-normalization, folding, and localization: An improved Rhat for assessing convergence of MCMC}},
url = {http://arxiv.org/abs/1903.08008},
year = {2019}
}
@article{Sta2011,
author = {Sta, P M P},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sta - 2011 - Chapitre 1 Comparaisons de deux distributions Tests non param ´ etriques Tests non param ´ etriques bas ´ es sur les (2).pdf:pdf},
pages = {1--27},
title = {{Chapitre 1 Comparaisons de deux distributions Tests non param ´ etriques Tests non param ´ etriques bas ´ es sur les rangs}},
year = {2011}
}
@article{MarkJenningsNeilHirst2012,
author = {{Mark Jennings, Neil Hirst}, Ajay Gambhir},
file = {:home/sarah/OneDrive/Travail/Sources/R{\'{e}}novation/Reduction-of-carbon-dioxide-emissions-in-the-global-building-sector-to-2050-GR-3.pdf:pdf},
number = {November},
pages = {1--33},
title = {{Reduction of Carbon Dioxide Emissions in the Global Building Sector To 2050}},
url = {papers2://publication/uuid/8758FC29-2123-4BC5-9D2B-612B8B62FA3E},
year = {2012}
}
@article{Chong2017a,
author = {Chong, Adrian and Lam, Khee Poh and Pozzi, Matteo and Yang, Junjing},
doi = {10.1016/j.enbuild.2017.08.069},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chong et al. - 2017 - Bayesian calibration of building energy models with large datasets.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Bayesian Calibration of Building Energy Models for Large Datasets.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,Building simulation,Hamiltonian Monte Carlo,No-U-Turn Sampler,Uncertainty analysis},
month = {nov},
number = {May},
pages = {343--355},
title = {{Bayesian calibration of building energy models with large datasets}},
url = {http://dx.doi.org/doi:10.1016/j.enbuild.2017.08.069 http://linkinghub.elsevier.com/retrieve/pii/S0378778817318741 http://www.sciencedirect.com.ucd.idm.oclc.org/science/article/pii/S0378778817318741 https://linkinghub.elsevier.com/retrieve/pii/S03787788173},
volume = {154},
year = {2017}
}
@article{Scales1992,
abstract = {A new method for the computation of the global minimum of a continu- ously differentiable realvalued function f of n variables is presented. This method, which is composed of two parts, is based on the combinatorial topology concept of the degree of a mapping associated with an oriented polyhedron. In the first part, interval arithmetic is implemented for a rough isolation of all the stationary points of f. In the second part, the isolated stationary points are characterized as minima, maxima or saddle points and the global minimum is determined among the mini- ma. The described algorithm can be successfully applied to problems with imprecise function and gradient values. The algorithm has been implemented and tested. It is primarily useful for small dimensions (n 10).},
author = {Scales, John A and Smith, Martin L and Fischer, Terri L},
doi = {10.1016/0021-9991(92)90400-S},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-002199919290400S-main.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
month = {dec},
number = {2},
pages = {258--268},
title = {{Global optimization methods for multimodal inverse problems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/002199919290400S},
volume = {103},
year = {1992}
}
@book{Parent2007,
address = {Paris},
annote = {BU Grenoble Alpes, Section Math{\'{e}}matiques RDC 519.22 PAR},
author = {Parent, Eric and Bernier, Jacques},
editor = {Springer-Verlag},
isbn = {978-2-287-3906-6},
keywords = {Bay{\'{e}}sien},
mendeley-tags = {Bay{\'{e}}sien},
pages = {364},
title = {{Le raisonnement bay{\'{e}}sien : Mod{\'{e}}lisation et inf{\'{e}}rence}},
year = {2007}
}
@article{Gram-Hanssen2018,
author = {Gram-Hanssen, Kirsten and Georg, Susse},
doi = {10.1080/09613218.2017.1356127},
file = {:home/sarah/OneDrive/Travail/Sources/Energy performance gaps promises people practices.pdf:pdf},
issn = {14664321},
journal = {Building Research and Information},
number = {1},
pages = {1--9},
publisher = {Taylor {\&} Francis},
title = {{Energy performance gaps: promises, people, practices}},
url = {https://doi.org/10.1080/09613218.2017.1356127},
volume = {46},
year = {2018}
}
@article{Yang2005,
author = {Yang, Y},
doi = {10.1093/biomet/92.4.937.This},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang - 2005 - Can the strangths of AIC adn BIC be shared A conflict between model identification and regression estimation.pdf:pdf},
journal = {Biometrika},
keywords = {Model selection Modelling Regression Linear model},
number = {June},
pages = {937--950 ST  -- Can the strangths of AIC adn BIC be },
title = {{Can the strangths of AIC adn BIC be shared? A conflict between model identification and regression estimation}},
volume = {92},
year = {2005}
}
@article{Baldi2016,
abstract = {Estimation of energy models from data is an important part of advanced fault detection and diagnosis tools for smart energy purposes. Estimated energy models can be used for a large variety of management and control tasks, spanning from model predictive building control to estimation of energy consumption and user behavior. In practical implementation, problems to be considered are the fact that some measurements of relevance are missing and must be estimated, and the fact that other measurements, collected at low sampling rate to save memory, make discretization of physics-based models critical. These problems make classical estimation tools inadequate and call for appropriate dual estimation schemes where states and parameters of a system are estimated simultaneously. In this work we develop dual estimation schemes based on Extended Kalman Filtering (EKF) and Unscented Kalman Filtering (UKF) for constructing building energy models from data: in order to cope with the low sampling rate of data (with sampling time 15 min), an implicit discretization (Euler backward method) is adopted to discretize the continuous-time heat transfer dynamics. It is shown that explicit discretization methods like the Euler forward method, combined with 15 min sampling time, are ineffective for building reliable energy models (the discrete-time dynamics do not match the continuous-time ones): even explicit methods of higher order like the Runge-Kutta method fail to provide a good approximation of the continuous-time dynamics which such large sampling time. Either smaller time steps or alternative discretization methods are required. We verify that the implicit Euler backward method provides good approximation of the continuous-time dynamics and can be easily implemented for our dual estimation purposes. The applicability of the proposed method in terms of estimation of both states and parameters is demonstrated via simulations and using historical data from a real-life building.},
author = {Baldi, Simone and Yuan, Shuai and Endel, Petr and Holub, Ondrej},
doi = {10.1016/j.apenergy.2016.02.019},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261916301428-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Building energy model,Dual estimation,Low sampling rate},
pages = {81--92},
publisher = {Elsevier Ltd},
title = {{Dual estimation: Constructing building energy models from data sampled at low rate}},
url = {http://dx.doi.org/10.1016/j.apenergy.2016.02.019},
volume = {169},
year = {2016}
}
@inproceedings{Rodnishchev2018,
author = {Rodnishchev, Nikolay and Denisov, Kirill},
booktitle = {ICNPAA 2018 World Congress},
doi = {10.1063/1.5081598},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodnishchev, Denisov - 2018 - Methods for identification of stochastic systems with application to control of flying vehicles.pdf:pdf},
isbn = {9780735417724},
title = {{Methods for identification of stochastic systems with application to control of flying vehicles}},
url = {http://aip.scitation.org/doi/abs/10.1063/1.5081598},
year = {2018}
}
@unpublished{Reddy2007,
author = {Reddy, T A and Maor, Itzhak},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reddy, Maor - 2007 - Calibrating detailed building energy simulation Programs with Measured Data — Part II Application to Three Case.pdf:pdf},
keywords = {model calibration},
mendeley-tags = {model calibration},
number = {2},
pages = {243--265},
title = {{Calibrating detailed building energy simulation Programs with Measured Data — Part II : Application to Three Case Study}},
volume = {13},
year = {2007}
}
@inproceedings{Sedoglavic2002a,
abstract = {Parmi les m{\'{e}}thodes utilis{\'{e}}es pour tester l'identifiabilit{\'{e}} locale d'un syst{\`{e}}me, on peut citer le d{\'{e}}veloppement en s{\'{e}}ries de Taylor des sorties et la m{\'{e}}thode des similarit{\'{e}}s (similarity transformation approach). Nous rappelons que les param{\`{e}}tres non identifiables d'un syst{\`{e}}me peuvent {\^{e}}tre d{\'{e}}termin{\'{e}}s par un algorithme probabiliste de complexit{\'{e}} polynomiale en la taille de l'entr{\'{e}}e. Cet algorithme est bas{\'{e}} sur la m{\'{e}}thode des d{\'{e}}veloppement en s{\'{e}}ries. Si le mod{\`{e}}le consid{\'{e}}r{\'{e}} est non identifiable, nous montrons que cette m{\'{e}}thode permet de calculer des groupes de transformations qui agissent sur les variables non observables et les param{\`{e}}tres non identifiable tout en laissant les entr{\'{e}}es, les sorties et les trajectoires du syst{\`{e}}me invariant. Ce calcul permet de certifier et compl{\'{e}}ter le r{\'{e}}sultat pr{\'{e}}c{\'{e}}dent. La m{\'{e}}thode des similarit{\'{e}}s se base sur la r{\'{e}}solution d'un syst{\`{e}}me d'{\'{e}}quations aux d{\'{e}}riv{\'{e}}es partielles pour trouver ce groupe. Notre approche ne repose que sur le calcul du noyau d'une matrice {\`{a}} coefficients polynomiaux et l'int{\'{e}}gration sous forme close d'un syst{\`{e}}me diff{\'{e}}rentiel ordinaire de petite taille. Pour finir, nous pr{\'{e}}sentons quelques exemples qui montrent l'efficacit{\'{e}} de notre approche.},
address = {Nantes},
author = {Sedoglavic, Alexandre and Ollivier, Francois},
booktitle = {Conf{\'{e}}rence internationale francophone d'Automatique},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedoglavic, Ollivier - 2002 - Algorithmes efficaces pour tester l'identifiabilit{\'{e}} locale(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ollivier, Sedoglavic - 2002 - Algorithmes efficaces pour tester l'identifiabilit{\'{e}} locale.pdf:pdf},
keywords = {Observabili{\'{e}},algorithmes seminum{\'{e}}riques,identifiabilit{\'{e}} alg{\'{e}}brique locale},
pages = {pp. 811--816},
publisher = {IEEE},
title = {{Algorithmes efficaces pour tester l'identifiabilit{\'{e}} locale}},
year = {2002}
}
@article{Macarulla2018,
abstract = {The measurement of ventilation air change rate is a difficult, expensive task in buildings. Usually, the tracer-gas mass balance equation is used to determine ventilation air change rates. This method uses an ordinary differential equation. Consequently, it cannot deal with disturbances that enter the system, such as the influence of unrecognized and unmodelled inputs or the measurement noise. The use of the stochastic grey-box modelling approach, which is less common in the ventilation field, can help to deal with disturbances that can affect the system. The objective of this paper is to assess the potential of using the stochastic grey-box modelling approach to estimate the ventilation air change rate. The modelling is based on the stochastic differential equation of tracer-gas mass balance. The results show that this approach produces robust estimations to determine the ventilation air change rate of a room.},
author = {Macarulla, Marcel and Casals, Miquel and Forcada, N{\'{u}}ria and Gangolells, Marta and Giretti, Alberto},
doi = {10.1016/j.measurement.2018.04.029},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0263224118303038-main.pdf:pdf},
issn = {02632241},
journal = {Measurement},
keywords = {Air change rate estimation,Indoor air quality,Low-order model,Stochastic methods,Ventilation},
month = {aug},
number = {April},
pages = {539--548},
publisher = {Elsevier},
title = {{Estimation of a room ventilation air change rate using a stochastic grey-box modelling approach}},
url = {https://doi.org/10.1016/j.measurement.2018.04.029 https://linkinghub.elsevier.com/retrieve/pii/S0263224118303038},
volume = {124},
year = {2018}
}
@article{Dynamic2019,
abstract = {Buildings contribute to nearly 30{\%} of global carbon dioxide emissions, making a significant impact on climate change. Despite advanced design methods, such as those based on dynamic simulation tools, a significant discrepancy exists between designed and actual performance. This so-called performance gap occurs as a result of many factors, including the discrepancies between theoretical properties of building materials and properties of the same materials in buildings in use, reflected in the physics properties of the entire building. There are several different ways in which building physics properties and the underlying properties of materials can be established: a co-heating test, which measures the overall heat loss coefficient of the building; a dynamic heating test, which, in addition to the overall heat loss coefficient, also measures the effective thermal capacitance and the time constant of the building; and a simulation of the dynamic heating test with a calibrated simulation model, which establishes the same three properties in a non-disruptive way in comparison with the actual physical tests. This article introduces a method of measuring building physics properties through actual and simulated dynamic heating tests. It gives insights into the properties of building materials in use and it documents significant discrepancies between theoretical and measured properties. It introduces a quality assurance method for building construction and retrofit projects, and it explains the application of results on energy efficiency improvements in building design and control. It calls for re-examination of material properties data and for increased safety margins in order to make significant improvements in building energy efficiency.},
author = {Jankovic, Ljubomir},
doi = {10.3390/en12081450},
file = {:home/sarah/OneDrive/Travail/Sources/energies-12-01450-v2.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {building physics properties,building thermal properties,deep energy retrofit,dynamic heating tests,retrofit quality assurance},
month = {apr},
number = {8},
pages = {1450},
title = {{Improving Building Energy Efficiency through Measurement of Building Physics Properties Using Dynamic Heating Tests}},
url = {https://www.mdpi.com/1996-1073/12/8/1450},
volume = {12},
year = {2019}
}
@phdthesis{Agbi2014,
author = {Agbi, Clarence},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agbi - 2014 - Scalable and Robust Design of Model-Based Control Strategies for Energy-Efficient Buildings.pdf:pdf},
school = {Carnegie Mellon University},
title = {{Scalable and Robust Design of Model-Based Control Strategies for Energy-Efficient Buildings}},
year = {2014}
}
@article{Bishop2001,
author = {Bishop, Gary and Welch, Greg},
doi = {10.1.1.117.6808},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop, Welch - 2001 - An introduction to the kalman filter 1.pdf:pdf},
isbn = {9780582403857},
issn = {10069313},
pages = {80},
pmid = {20578276},
title = {{An introduction to the kalman filter 1}},
url = {http://old.shahed.ac.ir/references/kalman{\_}filter{\_}notes.pdf},
year = {2001}
}
@article{Stuart2010,
author = {Stuart, Andrew M},
doi = {10.1017/S0962492910000061},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuart - 2010 - Inverse problems A Bayesian perspective.pdf:pdf},
isbn = {0962492910000},
issn = {0962-4929},
journal = {Acta Numerica},
month = {may},
number = {May 2010},
pages = {451--559},
title = {{Inverse problems: A Bayesian perspective}},
url = {http://www.journals.cambridge.org/abstract{\_}S0962492910000061},
volume = {19},
year = {2010}
}
@article{Iooss2010,
author = {Iooss, Bertrand},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iooss - 2014 - Metamodeling with Gaussian processes.pdf:pdf},
journal = {gdr-mascotnum.fr},
title = {{Metamodeling with Gaussian processes}},
url = {http://www.gdr-mascotnum.fr/media/sssamo14{\_}iooss.pdf},
year = {2010}
}
@article{Nassiopoulos2010,
abstract = {The work presented here deals with the reconstruction of the thermal field inside a three-dimensional structure when only some pointwise temperature measurements along a time interval [0, T] are available. The model-based reconstruction procedure builds upon optimal control theory applied to the determination of the unknown boundary conditions. The proposed dual approach enables one to reduce the on-line computational cost so that the resulting algorithm can be part of a real-time process. The complexity of the resulting algorithm does not depend on geometry. The paper details a novel methodology that enables to implement the reconstruction procedure using standard finite element tools, despite the difficulty to define the pointwise values of a three-dimensional field in the usual functional spaces where finite element methods converge.},
author = {Nassiopoulos, Alexandre and Bourquin, Fr{\'{e}}d{\'{e}}ric},
doi = {10.1016/j.cma.2010.06.022},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
month = {dec},
number = {49-52},
pages = {3169--3178},
title = {{Fast three-dimensional temperature reconstruction}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782510001891},
volume = {199},
year = {2010}
}
@article{Saltelli2010,
abstract = {Variance based methods have assessed themselves as versatile and effective among the various available techniques for sensitivity analysis of model output. Practitioners can in principle describe the sensitivity pattern of a model Y = f (X1, X2,..., Xk) with k uncertain input factors via a full decomposition of the variance V of Y into terms depending on the factors and their interactions. More often practitioners are satisfied with computing just k first order effects and k total effects, the latter describing synthetically interactions among input factors. In sensitivity analysis a key concern is the computational cost of the analysis, defined in terms of number of evaluations of f (X1, X2,..., Xk) needed to complete the analysis, as f (X1, X2,..., Xk) is often in the form of a numerical model which may take long processing time. While the computational cost is relatively cheap and weakly dependent on k for estimating first order effects, it remains expensive and strictly k-dependent for total effect indices. In the present note we compare existing and new practices for this index and offer recommendations on which to use.},
annote = {Article fondamental pour l'analyse de snesibilit{\'{e}} de Sobol},
author = {Saltelli, Andrea and Annoni, Paola and Azzini, Ivano and Campolongo, Francesca and Ratto, Marco and Tarantola, Stefano},
doi = {10.1016/j.cpc.2009.09.018},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saltelli et al. - 2010 - Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index.pdf:pdf},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {Analyse de sensibilit{\'{e}},sensitivity analysis},
mendeley-tags = {Analyse de sensibilit{\'{e}},sensitivity analysis},
month = {feb},
number = {2},
pages = {259--270},
title = {{Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index}},
url = {https://www.researchgate.net/profile/Andrea{\_}Saltelli/publication/220257174{\_}Variance{\_}based{\_}sensitivity{\_}analysis{\_}of{\_}model{\_}output{\_}Design{\_}and{\_}estimator{\_}for{\_}the{\_}total{\_}sensitivity{\_}index/links/0deec53908fc443f7a000000/Variance-based-sensitivity-analysis-of-model},
volume = {181},
year = {2010}
}
@article{Wang2006,
abstract = {Building thermal transfer models are essential to predict transient cooling or heating requirements for performance monitoring, diagnosis and control strategy analysis. Detailed physical models are time consuming and often not cost effective. Black box models require a significant amount of training data and may not always reflect the physical behaviors. In this study, a building is described using a simplified thermal network model. For the building envelope, the model parameters can be determined using easily available physical details. For building internal mass having thermal capacitance, including components such as furniture, partitions etc., it is very difficult to obtain detailed physical properties. To overcome this problem, this paper proposes to present the building internal mass with a thermal network structure of lumped thermal mass and estimate the lumped parameters using operation data. A genetic algorithm estimator is developed to estimate the lumped internal thermal parameters of the building thermal network model using the operation data collected from site monitoring. The simplified dynamic model of building internal mass is validated in different weather conditions. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
author = {Wang, Shengwei and Xu, Xinhua},
doi = {10.1016/j.enconman.2005.09.011},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0196890405002311-main.pdf:pdf},
issn = {01968904},
journal = {Energy Conversion and Management},
keywords = {Building internal mass,Dynamic thermal performance,Genetic algorithm,Lumped thermal parameter,Simplified model,Thermal network model},
month = {aug},
number = {13-14},
pages = {1927--1941},
title = {{Parameter estimation of internal thermal mass of building dynamic models using genetic algorithm}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0196890405002311},
volume = {47},
year = {2006}
}
@phdthesis{Anguelova2007,
author = {Anguelova, Milena},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anguelova - 2007 - Observability and identifiability of nonlinear systems with applications in biology.pdf:pdf},
isbn = {9789173850353},
school = {Chalmers University of Technology and G{\"{o}}teborg University},
title = {{Observability and identifiability of nonlinear systems with applications in biology}},
year = {2007}
}
@phdthesis{Sedoglavic2001,
author = {Sedoglavic, Alexandre},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedoglavic - 2001 - Alexandre Sedoglavic Septembre 2001.pdf:pdf},
school = {Ecole Polytechnique},
title = {{Alexandre Sedoglavic Septembre 2001}},
year = {2001}
}
@article{Spitz2012,
abstract = {Today, simulation tools are widely used to design buildings because their energy performance is increasing. Simulation is used at different stages to predict the building's energy performance and to improve the thermal comfort of its occupants, but also to reduce the environmental impact of the building over its whole life cycle and lower the cost of construction and operation. Simulation has become an essential decision support tool, but its reliability should not be overlooked. It is important to evaluate the reliability of simulation and measurement as well as uncertainty so as to improve building design. This work aimed to evaluate and order the uncertainty of the simulation results during the design process. A three-step methodology was developed to determine influential parameters in the building's energy performance and to identify the influence of parameter uncertainty on the building performance. This methodology was applied at the INCAS experimental platform of the French National Institute of Solar Energy (INES) in Le-Bourget-du-Lac to identify and measure the uncertainty in a simulation hypothesis. The method can be used during the entire design process of a building, from preliminary sketches to operating phase.},
author = {Spitz, Clara and Mora, Laurent and Wurtz, Etienne and Jay, Arnaud},
doi = {10.1016/j.enbuild.2012.08.013},
issn = {03787788},
journal = {Energy and Buildings},
month = {dec},
pages = {459--470},
title = {{Practical application of uncertainty analysis and sensitivity analysis on an experimental house}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778812004173},
volume = {55},
year = {2012}
}
@article{Bombois2006,
abstract = {All approaches to optimal experiment design for control have so far focused on deriving an input signal (or input signal spectrum) that minimizes some control-oriented measure of plant/model mismatch between the nominal closed-loop system and the actual closed-loop system, typically under a constraint on the total input power. In practical terms, this amounts to finding the (constrained) input signal that minimizes a measure of a control-oriented model uncertainty set. Here we address the experiment design problem from a "dual" point of view and in a closed-loop setting: given a maximum allowable control-oriented model uncertainty measure compatible with our robust control specifications, what is the cheapest identification experiment that will give us an uncertainty set that is within the required bounds? The identification cost can be measured by either the experiment time, the performance degradation during experimentation due to the added excitation signal, or a combination of both. Our results are presented for the situation where the control objective is disturbance rejection only. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Bombois, Xavier and Scorletti, G{\'{e}}rard and Gevers, Michel and {Van den Hof}, P. M.J. and Hildebrand, Roland},
doi = {10.1016/j.automatica.2006.05.016},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bombois et al. - 2006 - Least costly identification experiment for control.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Experiment design,Identification for control},
number = {10},
pages = {1651--1662},
publisher = {Elsevier},
title = {{Least costly identification experiment for control}},
url = {https://hal.archives-ouvertes.fr/hal-00413370},
volume = {42},
year = {2006}
}
@article{Vats2015,
abstract = {Markov chain Monte Carlo (MCMC) produces a correlated sample for estimating expectations with respect to a target distribution. A fundamental question is when should sampling stop so that we have good estimates of the desired quantities? The key to answering this question lies in assessing the Monte Carlo error through a multivariate Markov chain central limit theorem (CLT). The multivariate nature of this Monte Carlo error largely has been ignored in the MCMC literature. We present a multivariate framework for terminating simulation in MCMC. We define a multivariate effective sample size, estimating which requires strongly consistent estimators of the covariance matrix in the Markov chain CLT; a property we show for the multivariate batch means estimator. We then provide a lower bound on the number of minimum effective samples required for a desired level of precision. This lower bound depends on the problem only in the dimension of the expectation being estimated, and not on the underlying stochastic process. This result is obtained by drawing a connection between terminating simulation via effective sample size and terminating simulation using a relative standard deviation fixed-volume sequential stopping rule; which we demonstrate is an asymptotically valid procedure. The finite sample properties of the proposed method are demonstrated in a variety of examples.},
archivePrefix = {arXiv},
arxivId = {1512.07713},
author = {Vats, Dootika and Flegal, James M. and Jones, Galin L},
doi = {10.1093/biomet/asz002},
eprint = {1512.07713},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vats, James Flegal, Jones - 2017 - Multivariate Output Analysis for Markov Chain Monte Carlo(2).pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
month = {dec},
number = {2},
pages = {321--337},
title = {{Multivariate output analysis for Markov chain Monte Carlo}},
url = {https://arxiv.org/pdf/1512.07713.pdf http://arxiv.org/abs/1512.07713},
volume = {106},
year = {2019}
}
@article{Senave2019a,
abstract = {Recently, there has been an increasing interest in the development of an approach to characterize the as-built heat loss coefficient (HLC) of buildings based on a combination of on-board monitoring (OBM) and data-driven modeling. OBM is hereby defined as the monitoring of the energy consumption and interior climate of in-use buildings via non-intrusive sensors. The main challenge faced by researchers is the identification of the required input data and the appropriate data analysis techniques to assess the HLC of specific building types, with a certain degree of accuracy and/or within a budget constraint. A wide range of characterization techniques can be imagined, going from simplified steady-state models applied to smart energy meter data, to advanced dynamic analysis models identified on full OBM data sets that are further enriched with geometric info, survey results, or on-site inspections. This paper evaluates the extent to which these techniques result in different HLC estimates. To this end, it performs a sensitivity analysis of the characterization outcome for a case study dwelling. Thirty-five unique input data packages are defined using a tree structure. Subsequently, four different data analysis methods are applied on these sets: the steady-state average, Linear Regression and Energy Signature method, and the dynamic AutoRegressive with eXogenous input model (ARX). In addition to the sensitivity analysis, the paper compares the HLC values determined via OBM characterization to the theoretically calculated value, and explores the factors contributing to the observed discrepancies. The results demonstrate that deviations up to 26.9{\%} can occur on the characterized as-built HLC, depending on the amount of monitoring data and prior information used to establish the interior temperature of the dwelling. The approach used to represent the internal and solar heat gains also proves to have a significant influence on the HLC estimate. The impact of the selected input data is higher than that of the applied data analysis method.},
author = {Senave, Marieline and Roels, Staf and Verbeke, Stijn and Lambie, Evi and Saelens, Dirk},
doi = {10.3390/en12173322},
file = {:home/sarah/OneDrive/Travail/Sources/energies-12-03322.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {case study analysis,characterization,cient,data analysis methods,heat loss coe ffi,monitoring data,on-board,physical parameter identification,sensitivity,uncertainty},
month = {aug},
number = {17},
pages = {3322},
title = {{Sensitivity of Characterizing the Heat Loss Coefficient through On-Board Monitoring: A Case Study Analysis}},
url = {https://www.mdpi.com/1996-1073/12/17/3322},
volume = {12},
year = {2019}
}
@article{Mounier2014,
annote = {Spectres des temp��ratures d'enr��es de mod��le},
author = {Mounier, Audrey Le and Delinchant, Beno{\^{i}}t and Ploix, St{\'{e}}phane},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mounier, Delinchant, Ploix - 2014 - Choix de structures de mod{\`{e}}les pertinentes pour l'identification des syst{\`{e}}mes de gestion d'{\'{e}}n.pdf:pdf},
keywords = {building,parameter estimation,reduced order models},
pages = {1--8},
title = {{Choix de structures de mod{\`{e}}les pertinentes pour l'identification des syst{\`{e}}mes de gestion d'{\'{e}}nergie}},
year = {2014}
}
@article{Lee2018,
abstract = {In South Korea, about 40,000 buildings of low-income households have been diagnosed and remodeled annually by the Energy Welfare Program, using the normative method. The normative method is based on the heat gain elements of a building. In contrast, the performance-based method is based on the output derived from the thermal performance of each building part. In the normative method, there is no other building in which the input conditions of a building are perfectly matched. Further, cost-effective energy remodeling strategies vary according to the capacity of the diagnosis engineer. In this paper, we analyze the thermal performance of buildings by the performance-based method using indoor temperature, and examine the possibility of a database for the optimal remodeling method. For this, we analyzed more than 2500 simulation cases by combining thermal performance of each building part. The indoor temperature pattern can be similar even when the thermal performance of each building part is different. In buildings with similar indoor temperature patterns, the coefficient of variation of the root mean squared error of energy demand falls within the acceptable error range. Furthermore, changes in energy demand and predicted mean vote are similar when window thermal performance is changed.},
author = {Lee, Junghun and Kim, Seohoon and Kim, Jonghun and Song, Doosam and Jeong, Hakgeun},
doi = {10.1016/j.apenergy.2018.03.083},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261918304215-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Building thermal performance diagnostics,Envelope remodeling,Indoor temperature,Low-income households,Performance-based method},
number = {February},
pages = {425--436},
publisher = {Elsevier},
title = {{Thermal performance evaluation of low-income buildings based on indoor temperature performance}},
url = {https://doi.org/10.1016/j.apenergy.2018.03.083},
volume = {221},
year = {2018}
}
@article{Sarkka2019,
abstract = {This article is concerned with learning and stochastic control in physical systems which contain unknown input signals. These unknown signals are modeled as Gaussian processes (GP) with certain parametrized covariance structures. The resulting latent force models (LFMs) can be seen as hybrid models that contain a first-principles physical model part and a non-parametric GP model part. We briefly review the statistical inference and learning methods for this kind of models, introduce stochastic control methodology for the models, and provide new theoretical observability and controllability results for them.},
archivePrefix = {arXiv},
arxivId = {1709.05409},
author = {Sarkka, Simo and Alvarez, Mauricio A. and Lawrence, Neil D.},
doi = {10.1109/TAC.2018.2874749},
eprint = {1709.05409},
file = {:home/sarah/OneDrive/Travail/Sources/1709.05409.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Gaussian{\_}Process{\_}Latent{\_}Force{\_}Models{\_}for{\_}Learning{\_}.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Kalman filtering,machine learning,stochastic optimal control,stochastic systems,system identification},
month = {jul},
number = {7},
pages = {2953--2960},
title = {{Gaussian Process Latent Force Models for Learning and Stochastic Control of Physical Systems}},
url = {http://arxiv.org/abs/1709.05409 https://ieeexplore.ieee.org/document/8485787/},
volume = {64},
year = {2019}
}
@unpublished{Sabatier2003,
author = {Sabatier, Paul},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabatier - 2003 - Introduction ` a la th ´ eorie de l ' estimation et des tests param ´ etriques.pdf:pdf},
number = {0},
pages = {2002--2003},
title = {{Introduction ` a la th ´ eorie de l ' estimation et des tests param ´ etriques}},
year = {2003}
}
@book{Walter1994b,
abstract = {La construction de mod{\`{e}}les math{\'{e}}matiques {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales, activit{\'{e}} de base du chercheur et de l'ing{\'{e}}nieur, suscite de nombreuses interrogations. Comment choisir la structure de mod{\`{e}}les {\`{a}} utiliser ? Comment s'assurer avant toute mesure que ses param{\`{e}}tres pourront {\^{e}}tre estim{\'{e}}s {\`{a}} partir des exp{\'{e}}riences envisag{\'{e}}es ? Comment choisir un crit{\`{e}}re de qualit{\'{e}} pour la comparaison des mod{\`{e}}les sans se limiter au traditionnel crit{\`{e}}re des moindres carr{\'{e}}s ? Comment prendre en compte les informations disponibles a priori et le but poursuivi ? Comment se prot{\'{e}}ger contre des donn{\'{e}}es aberrantes {\'{e}}ventuelles ? Quelles techniques utiliser pour l'optimisation du crit{\`{e}}re ? Comment {\'{e}}valuer les caract{\'{e}}ristiques locales de ce dernier (gradient, Hessien) de fa{\c{c}}on simple mais exacte ? Comment {\'{e}}chapper aux optima locaux parasites ? Comment {\'{e}}valuer l'incertitude sur les param{\`{e}}tres estim{\'{e}}s ? Comment choisir les conditions exp{\'{e}}rimentales pour recueillir les donn{\'{e}}es les plus informatives compte tenu du but poursuivi et des informations disponibles a priori ? Comment utiliser les r{\'{e}}sidus de mod{\'{e}}lisation pour tester a posteriori la coh{\'{e}}rence des hypoth{\`{e}}ses formul{\'{e}}es a priori ? Cet ouvrage vise {\`{a}} r{\'{e}}pondre {\`{a}} ces questions de Fa{\c{c}}on aussi didactique que possible en fournissant une vision d'ensemble de la m{\'{e}}thodologie {\`{a}} mettre en oeuvre. Il s'adresse aussi bien -{\`{a}} l'{\'{e}}tudiant d{\'{e}}sireux de se Familiariser avec les techniques de mod{\'{e}}lisation param{\'{e}}trique (de nombreux exemples {\'{e}}l{\'{e}}mentaires sont trait{\'{e}}s en d{\'{e}}tail) ; -{\`{a}} l'ing{\'{e}}nieur ou au chercheur confront{\'{e}} {\`{a}} la pratique de la mod{\'{e}}lisation dons sa vie professionnelle (les avantages, mais aussi les limitations des m{\'{e}}thodes d{\'{e}}crites sont clairement indiqu{\'{e}}s) ; -au sp{\'{e}}cialiste du domaine, qui y trouvera en particulier une source bibliographique importante.},
annote = {From Duplicate 2 (Identification de mod{\`{e}}les param{\'{e}}triques {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales - Walter, Eric; Pronzato, Luc)

From Duplicate 1 (Identification de mod{\`{e}}les param{\'{e}}triques {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales - Walter, Eric; Pronzato, Luc)

page 4 : "le choix de M(.) encore appel{\'{e}} caract{\'{e}}risation, est une {\'{e}}tape d{\'{e}}licate et importante de la d{\'{e}}marche de mod{\'{e}}lisation".
page 4 : un crit{\`{e}}re est un scalaire qui sert {\`{a}} la comparaison entre les sorties du mod{\`{e}}le et du syst{\`{e}}me. On cherche alors {\`{a}} minimiser le crit{\`{e}}re. Le choix du crit{\`{e}}re doit traduire le but fix{\'{e}} {\`{a}} la mod{\'{e}}lisation. Quand il est choisi, on cherche la meilleure valeur de {\^{}}p des param{\`{e}}tres au sens du crit{\`{e}}re.
page 5 : algo d'optimisation est celui qui minimise j(.) pour calculer {\^{}}p. En partant de {\^{}}p(k), l'estimation de {\^{}}p {\`{a}} l'it{\'{e}}ration k, on cherche {\^{}}p(k+1) tel que j({\^{}}pk+1)page 5 : comme {\^{}}p n'est jamais parfaitemetn {\'{e}}gal {\`{a}} p*, ompte tenu des incertitudes, on conclut sur un ensemble de mod{\`{e}}les "acceptables" qu'il faudra caract{\'{e}}riser.
Page6 : il existe des techniques pour tester si un mod{\`{e}}le est mauvais (d{\'{e}}tection de fautes graves dans le mod{\`{e}}le).


CHAP 2 : Structures de Mod{\`{e}}les
Mod{\`{e}}les lin{\'{e}}aires ou non-lin{\'{e}}aires
un mod{\`{e}}le est lin{\'{e}}aire par rapport aux entr{\'{e}}es : y(t, p, L.u1+M.u2)=L.y(u1)+M.y(u2)
lin{\'{e}}aire par rapport aux param{\`{e}}tres : y(t, Lp1+Mp2,u)= L.y(t,p1,u) + M.y(t,p2,u)
affine par rapport aux param{\`{e}}tres y(t,p,u) = y1(t,u) + y2(t,p,u)
page 11
Mod{\`{e}}le {\`{a}} temps continu :
d/dt x(t) = f(x,p,u,t) et x(0)=x0(p)
y(t)=h(x,p,u,t)
Dans le cas lin{\'{e}}aire aux entr{\'{e}}es stationnaire :
d/dt x(t) = A(p).x(t) + B(p).u(t)
y(t) = C(p).x(t) + D(p).u(t)
Si les conditions initiales sont nulles, on peut passer {\`{a}} une repr{\'{e}}sentation par matrice de transfert : y(s,p) = H(s,p).u(s) o{\`{u}} s est la variable de Laplace.
Idem pour mod{\`{e}}les {\`{a}} temps discret (on utilise les matrices de transfert iscr{\`{e}}te H(z,p))
--{\textgreater}En temps discret, les informations a priori son inutilisales (??)


Echantillonnage : v{\'{e}}rifier la condition de Shannon (pas de composantes {\`{a}} des fr{\'{e}}quences sup{\'{e}}rieures {\`{a}} 1/2T). Sinon le ph{\'{e}}nom{\`{e}}ne de repliement des fr{\'{e}}quences peut rendre les donn{\'{e}}es unitilisables.


Une propri{\'{e}}t{\'{e}} de mod{\`{e}}le est dite "structurelle" quand elle est vraie pour presque toute valeur des param{\`{e}}tres (et {\'{e}}ventuellement fausse sur un sous-espace de mesure nulle de l'espace param{\'{e}}trique).


Identifiabilit{\'{e}} page 20
{\'{e}}tude structurelle, hypoth{\`{e}}ses :
- le processus et le mod{\`{e}}le ont des structures identiques (pas d'erreur de caract{\'{e}}risation)
- les donn{\'{e}}es sont sans bruit
- entr{\'{e}}e et instants de mesure choisis librement


un param{\`{e}}tre pi est structurellement globalement identifiable si pour presque tout p* de l'espace parm{\'{e}}trique,
M({\^{}}p)=M(p*) ={\textgreater}{\^{}}pi = pi*
Un mod{\`{e}}le est structurellement globalement identifiable si tous ses param{\`{e}}tres le sont.


Un param{\`{e}}tre est structurellement localement identifiable si pour presque tout p* de 'lespace param{\'{e}}trique, il existe un voisinage de p* tel que
{\^{}}p dans le voisinage et M({\^{}}p)=M(p*) ={\textgreater}{\^{}}pi = pi*


L'identifiabilit{\'{e}} locale est une condition n{\'{e}}cessaire {\`{a}} l'identifiabilit{\'{e}} globale.


Un param{\`{e}}tre est structurellement non identifiable si pour presque tout p* dans l'espace param{\'{e}}trique, il existe une infinit{\'{e}} non d{\'{e}}nombrable de valeurs {\^{}}pi telles que M({\^{}}p)=M(p*)
un mod{\`{e}}le est structurellement non identifiable si il a au moisn un param{\`{e}}tre non identifiable. Mais il peut avoir d'autres param{\`{e}}tres identifiables localement ou m{\^{e}}me globalement.


Page 22 : M{\'{e}}thode pour tester alg{\'{e}}briquement l'identifiailit{\'{e}} structurelle des mod{\`{e}}les : voir Walter 82, 87 et Walter et Pronzato 1993
M{\'{e}}thode pr{\'{e}}sent{\'{e}}e valable pour les mod{\`{e}}les lin{\'{e}}aires aux entr{\'{e}}es stationnaires
technique :
- calculer la matrice de transfert associ{\'{e}}e
- Mettre H(s,p) sous forme canonique Hc(s,p) c{\`{a}}d sous une forme tlele qu'il existe une fa{\c{c}}on unique de l'{\'{e}}crire.
- {\'{e}}crire les {\'{e}}quations {\^{}}p et p* traduisant l'identit{\'{e}} des coefficients Hc(s,{\^{}}p) et Hc(s,p*)
- r{\'{e}}soudre ces {\'{e}}quations en {\^{}}p
Si pour presque tout p* il existe une solution unique pour {\^{}}p, alors le mod{\`{e}}le structurellement globalement identifiable.
Si pour presque tout p* l'esnemble des solutions est d{\'{e}}nombrable (le plus souvent fini), le mod{\`{e}}le est structurellemtn localement identifiale.
Si pour presque tout p* l'ensemble des solutons n'est pas d{\'{e}}nombrable, le mod{\`{e}}le est structurellemtn non identifiable
Tout param{\`{e}}tre qui prend une la m{\^{e}}me valeur dasn toutes les solutions est structurellemtn globalement identifiable.
Tout param qui prend une ses valeurs dasn un ensemble d{\'{e}}nombrable est struturellement localemen idetnifiable.


les tests d'identifiabilit{\'{e}} n{\'{e}}cessitent des calculs formels lourds, facilit{\'{e}}s par les logiciels de calcul formel. (axiom, maxsyma, maple, reduce).
M{\'{e}}thode pour tester si M(.) est au moins localement identifiable :
- choisir une valeur nominale p0 des param{\`{e}}tres (tir{\'{e}} au hasard dans l'espace param{\'{e}}rique). Simuler M(p0) avec une grande pr{\'{e}}cision pour obtenir des donn{\'{e}}es fictives yf
- estimer p {\`{a}} partir de yf en minimisant un rit{\`{e}}re quadratique sur l'erreur de sortie {\`{a}} l'aide d'une m{\'{e}}thode du second-ordre (Newton ou gauss-Newton). Si {\`{a}} la k-i{\`{e}}me it{\'{e}}ration {\^{}}pk est stable en p0, M(.) est au moins localement identifiable en p0. S'il n'est pas stable, soit on a tir{\'{e}} un point trop proche d'une valeur atypique, soit la simulation est erron{\'{e}}e. Alors on tire un autre p0 pour trancher.


Page 25 Discernabilit{\'{e}} : "on h{\'{e}}site souvent entre plusieurs structures de mod{\`{e}}les pour la description des m{\^{e}}mes donn{\'{e}}es. Il est alors naturel de se demander si les mesures envisag{\'{e}}es sur le processus permettront de d{\'{e}}cider quelle est la meilleure. Cette question est celle de la discernabilit{\'{e}} des structures"


Page 29 "la caract{\'{e}}risation d'un mod{\`{e}}le n'est pas un choix initial une fois pour toute mais un choix temporaire destin{\'{e}} {\`{a}} {\^{e}}tre remis en question. La premi{\`{e}}re de ces mises en question peut avoir lieu avant toute mesure"
"la notion qualitative d'identifiabilit{\'{e}} structurelle conduit naturellement {\`{a}} une pr{\'{e}}ocuupation quantitative. sacahnt que la structure consid{\'{e}}r{\'{e}}e est (au moins) localement identifiable, il s'agit de l'identifier au mieux au sens d'un crit{\`{e}}re de pr{\'{e}}cision sur l'estim{\'{e}}e des param{\`{e}}tres."


CHAP 3 CRITERES
Une fois la caract{\'{e}}risation effectu{\'{e}}e (erreur de caract{\'{e}}risation c'est une erreur dans le choix du mod{\`{e}}le?)
Remarque sur les r{\'{e}}sulats exp{\'{e}}rimentaux : un vecteur contenant ces r{\'{e}}sultats est un vecteur al{\'{e}}atoire dans le sens o{\`{u}} reconduire plusieurs fois l'exp{\'{e}}rience dans les exactes m{\^{e}}mes conditions ne donnera pas exactement les m{\^{e}}mes ys.
{\^{}}p est appel{\'{e}} estimateur de p au sens de j(.) : car il conduit {\`{a}} une valeur optimale du crit{\`{e}}re j(.)


1/ les crti{\`{e}}res quadratiques
j(p) = transpos{\'{e}}e de e(p) . Q . e(p) (Q est une matrice de pond{\'{e}}ration, qui peut servir {\`{a}} normaliser une sortie, ou {\'{e}}liminier une donn{\'{e}}e non significative)
2/ crti{\`{e}}re en valeur absolue
j(p) = sommesur j somme sur tij de wij . e(p)
3/ Maximum de vraisemblance (c'est comme une densit{\'{e}} de probabilit{\'{e}} de ys variable sachant p sauf que ys est fixe et p varie)
Voir page 46 les propri{\'{e}}t{\'{e}}s des estimateurs de maximum de vraisemblance
4/ Estimation de la distribution de param{\`{e}}tres d'une population
Page 47. Utile si la connaissance de la distribution des param{\`{e}}tres dans une population d'individus permet d'estimer les param{\`{e}}tres de chaque nouvel individu de fa{\c{c}}on bay{\'{e}}sienne, ce qui n{\'{e}}cessite peu de mesure. permet de planifier de mani{\`{e}}re optimale (au sens de la moyenne sur la population) le recueil de donn{\'{e}}es {\`{a}} effectuer sur le prochain individu
Page 52 "diverses approches param{\'{e}}triques ont {\'{e}}t{\'{e}} propos{\'{e}}es pour estimer des lois dans le contexte de la biologie (pharmacocin{\'{e}}tique en particulier), o{\`{u}} la variabilit{\'{e}} interindividus des param{\`{e}}tres est g{\'{e}}n{\'{e}}ralement tr{\`{e}}s importante. Elles visent {\`{a}} l'estimation de la moyenne et de la covariance de la loi (ce qui ne la d{\'{e}}crit totalement que si elle est gaussienne). Certaines de ces approches permettent une mise en {\oe}uvre r{\'{e}}cursive contrairement aux approches non param{\'{e}}triques pr{\'{e}}c{\'{e}}dentes. Les observations recueillies sur un nouvel individu viennent alors enrichir la description de la population, sans que l'on ai {\`{a}} recourir {\`{a}} une nouvelle estimation reposant sur toutes les mesures recueillies sur tous les individus"
VOIR Mentr{\'{e}} 1984, Mentr{\'{e}}, mallet et Steimer 1988


Page 57 Crit{\`{e}}res de choix de la complexit{\'{e}}
On peut utiliser un crit{\`{e}}re {\`{a}} minimiser pour comparer les r{\'{e}}sultats entre plusieurs mod{\`{e}}les de complexit{\'{e}} diff{\'{e}}rente. Le crit{\`{e}}re fait intervenir un terme qui prend en compte la dimension du param{\`{e}}tre (i.e. le nombre de degr{\'{e}} de libert{\'{e}} du mod{\`{e}}le).
- AIC an information criterion d'Akaike
- Final Prediction Error
- Bayesian Information Error
VOIR S{\"{o}}derstr{\"{o}}m 1977 et Veres 1991


Page 59 Crit{\`{e}}res bay{\'{e}}siens.
L'approche du max de vraisemblance consid{\'{e}}rait p comme inconnu mais constant. Les approches bay{\'{e}}siennes attribuent une densit{\'{e}} de probabilit{\'{e}} a priori au vecteur p al{\'{e}}atoire.
Pour les connaissances a priori, on attribue la densit{\'{e}} de proba qui maximise l'entropie, cela {\'{e}}vite d'introduire de l'information parasite dans le mod{\`{e}}le.
VOIR Box et Tiao (1973) pour la notion de distribution a priori non informative.
on d{\'{e}}fini le crit{\`{e}}re du maximum a posteriori ou le crit{\`{e}}re du risque minimum.


Page 64 Contraintes sur les param{\`{e}}tres
pour que les param{\`{e}}tres v{\'{e}}rifient une contrainte ({\'{e}}galit{\'{e}} ou in{\'{e}}galit{\'{e}}) on introduit dans le crit{\`{e}}re un terme de p{\'{e}}nalisation.


Page 67 Robustesse des estimateurs
Un estimateur {\^{}}p est robuste si ses performances ne sont pas trop d{\'{e}}teriori{\'{e}}es quand les hypoth{\`{e}}ses sur lesquelles il repose ne sont pas {\'{e}}vrifi{\'{e}}es. Par exemple on suppose le bruit gaussien de var sigma² alors que sa densit{\'{e}} de proba a "des queues" plus importantes de pr{\'{e}}vues, ou que les donn{\'{e}}es sont contamin{\'{e}}es par des valeurs aberrantes.
Exemple : Robustesse aux incertitudes sur la distribution du bruit :
quand la distri est connue de fa{\c{c}}on fiable, la matrice d'infirmation de Fisher s'{\'{e}}crit en fonction d'uns calaire, l'information de Fisher, qui est d'autant plus petite que les incertitudes sur les param{\`{e}}tres seront grandes.
Si la distri n'est pas connue, on adopte une d{\'{e}}marche minimax (?) et choisir comme estimateur robuste {\^{}}pr l'estimateur au sens du max de vraisemlance associ{\'{e}} {\`{a}} la distri qui minimise l'information de Fisher.
Cette approche suppose cependant toujours que le bruit est une suite de var al{\'{e}}atoire indep. Coor{\'{e}}lations et non stationnarit{\'{e}}s ne sont pas prise en compte.


Point de rupture page 70
pourcentage de donn{\'{e}}es aberrantes {\`{a}} partir duquel le biais dans l'estimateur (d{\^{u}} aux donn{\'{e}}es aberrantes) est infini.


VOIR ENCORE CHAPITRES OPTIMISEURS ET INCERTITUDES SUR LES PARAMETRES

From Duplicate 2 (Identification de mod{\`{e}}les param{\'{e}}triques {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales - Walter, Eric; Pronzato, Luc)

From Duplicate 1 (Identification de modèles paramétriques à partir de données expérimentales - Walter, Eric; Pronzato, Luc)

page 4 : "le choix de M(.) encore appel{\'{e}} caract{\'{e}}risation, est une {\'{e}}tape d{\'{e}}licate et importante de la d{\'{e}}marche de mod{\'{e}}lisation".
page 4 : un crit{\`{e}}re est un scalaire qui sert {\`{a}} la comparaison entre les sorties du mod{\`{e}}le et du syst{\`{e}}me. On cherche alors {\`{a}} minimiser le crit{\`{e}}re. Le choix du crit{\`{e}}re doit traduire le but fix{\'{e}} {\`{a}} la mod{\'{e}}lisation. Quand il est choisi, on cherche la meilleure valeur de {\^{}}p des param{\`{e}}tres au sens du crit{\`{e}}re.
page 5 : algo d'optimisation est celui qui minimise j(.) pour calculer {\^{}}p. En partant de {\^{}}p(k), l'estimation de {\^{}}p {\`{a}} l'it{\'{e}}ration k, on cherche {\^{}}p(k+1) tel que j({\^{}}pk+1)page 5 : comme {\^{}}p n'est jamais parfaitemetn {\'{e}}gal {\`{a}} p*, ompte tenu des incertitudes, on conclut sur un ensemble de mod{\`{e}}les "acceptables" qu'il faudra caract{\'{e}}riser.
Page6 : il existe des techniques pour tester si un mod{\`{e}}le est mauvais (d{\'{e}}tection de fautes graves dans le mod{\`{e}}le).


CHAP 2 : Structures de Mod{\`{e}}les
Mod{\`{e}}les lin{\'{e}}aires ou non-lin{\'{e}}aires
un mod{\`{e}}le est lin{\'{e}}aire par rapport aux entr{\'{e}}es : y(t, p, L.u1+M.u2)=L.y(u1)+M.y(u2)
lin{\'{e}}aire par rapport aux param{\`{e}}tres : y(t, Lp1+Mp2,u)= L.y(t,p1,u) + M.y(t,p2,u)
affine par rapport aux param{\`{e}}tres y(t,p,u) = y1(t,u) + y2(t,p,u)
page 11
Mod{\`{e}}le {\`{a}} temps continu :
d/dt x(t) = f(x,p,u,t) et x(0)=x0(p)
y(t)=h(x,p,u,t)
Dans le cas lin{\'{e}}aire aux entr{\'{e}}es stationnaire :
d/dt x(t) = A(p).x(t) + B(p).u(t)
y(t) = C(p).x(t) + D(p).u(t)
Si les conditions initiales sont nulles, on peut passer {\`{a}} une repr{\'{e}}sentation par matrice de transfert : y(s,p) = H(s,p).u(s) o{\`{u}} s est la variable de Laplace.
Idem pour mod{\`{e}}les {\`{a}} temps discret (on utilise les matrices de transfert iscr{\`{e}}te H(z,p))
--{\textgreater}En temps discret, les informations a priori son inutilisales (??)


Echantillonnage : v{\'{e}}rifier la condition de Shannon (pas de composantes {\`{a}} des fr{\'{e}}quences sup{\'{e}}rieures {\`{a}} 1/2T). Sinon le ph{\'{e}}nom{\`{e}}ne de repliement des fr{\'{e}}quences peut rendre les donn{\'{e}}es unitilisables.


Une propri{\'{e}}t{\'{e}} de mod{\`{e}}le est dite "structurelle" quand elle est vraie pour presque toute valeur des param{\`{e}}tres (et {\'{e}}ventuellement fausse sur un sous-espace de mesure nulle de l'espace param{\'{e}}trique).


Identifiabilit{\'{e}} page 20
{\'{e}}tude structurelle, hypoth{\`{e}}ses :
- le processus et le mod{\`{e}}le ont des structures identiques (pas d'erreur de caract{\'{e}}risation)
- les donn{\'{e}}es sont sans bruit
- entr{\'{e}}e et instants de mesure choisis librement


un param{\`{e}}tre pi est structurellement globalement identifiable si pour presque tout p* de l'espace parm{\'{e}}trique,
M({\^{}}p)=M(p*) ={\textgreater}{\^{}}pi = pi*
Un mod{\`{e}}le est structurellement globalement identifiable si tous ses param{\`{e}}tres le sont.


Un param{\`{e}}tre est structurellement localement identifiable si pour presque tout p* de 'lespace param{\'{e}}trique, il existe un voisinage de p* tel que
{\^{}}p dans le voisinage et M({\^{}}p)=M(p*) ={\textgreater}{\^{}}pi = pi*


L'identifiabilit{\'{e}} locale est une condition n{\'{e}}cessaire {\`{a}} l'identifiabilit{\'{e}} globale.


Un param{\`{e}}tre est structurellement non identifiable si pour presque tout p* dans l'espace param{\'{e}}trique, il existe une infinit{\'{e}} non d{\'{e}}nombrable de valeurs {\^{}}pi telles que M({\^{}}p)=M(p*)
un mod{\`{e}}le est structurellement non identifiable si il a au moisn un param{\`{e}}tre non identifiable. Mais il peut avoir d'autres param{\`{e}}tres identifiables localement ou m{\^{e}}me globalement.


Page 22 : M{\'{e}}thode pour tester alg{\'{e}}briquement l'identifiailit{\'{e}} structurelle des mod{\`{e}}les : voir Walter 82, 87 et Walter et Pronzato 1993
M{\'{e}}thode pr{\'{e}}sent{\'{e}}e valable pour les mod{\`{e}}les lin{\'{e}}aires aux entr{\'{e}}es stationnaires
technique :
- calculer la matrice de transfert associ{\'{e}}e
- Mettre H(s,p) sous forme canonique Hc(s,p) c{\`{a}}d sous une forme tlele qu'il existe une fa{\c{c}}on unique de l'{\'{e}}crire.
- {\'{e}}crire les {\'{e}}quations {\^{}}p et p* traduisant l'identit{\'{e}} des coefficients Hc(s,{\^{}}p) et Hc(s,p*)
- r{\'{e}}soudre ces {\'{e}}quations en {\^{}}p
Si pour presque tout p* il existe une solution unique pour {\^{}}p, alors le mod{\`{e}}le structurellement globalement identifiable.
Si pour presque tout p* l'esnemble des solutions est d{\'{e}}nombrable (le plus souvent fini), le mod{\`{e}}le est structurellemtn localement identifiale.
Si pour presque tout p* l'ensemble des solutons n'est pas d{\'{e}}nombrable, le mod{\`{e}}le est structurellemtn non identifiable
Tout param{\`{e}}tre qui prend une la m{\^{e}}me valeur dasn toutes les solutions est structurellemtn globalement identifiable.
Tout param qui prend une ses valeurs dasn un ensemble d{\'{e}}nombrable est struturellement localemen idetnifiable.


les tests d'identifiabilit{\'{e}} n{\'{e}}cessitent des calculs formels lourds, facilit{\'{e}}s par les logiciels de calcul formel. (axiom, maxsyma, maple, reduce).
M{\'{e}}thode pour tester si M(.) est au moins localement identifiable :
- choisir une valeur nominale p0 des param{\`{e}}tres (tir{\'{e}} au hasard dans l'espace param{\'{e}}rique). Simuler M(p0) avec une grande pr{\'{e}}cision pour obtenir des donn{\'{e}}es fictives yf
- estimer p {\`{a}} partir de yf en minimisant un rit{\`{e}}re quadratique sur l'erreur de sortie {\`{a}} l'aide d'une m{\'{e}}thode du second-ordre (Newton ou gauss-Newton). Si {\`{a}} la k-i{\`{e}}me it{\'{e}}ration {\^{}}pk est stable en p0, M(.) est au moins localement identifiable en p0. S'il n'est pas stable, soit on a tir{\'{e}} un point trop proche d'une valeur atypique, soit la simulation est erron{\'{e}}e. Alors on tire un autre p0 pour trancher.


Page 25 Discernabilit{\'{e}} : "on h{\'{e}}site souvent entre plusieurs structures de mod{\`{e}}les pour la description des m{\^{e}}mes donn{\'{e}}es. Il est alors naturel de se demander si les mesures envisag{\'{e}}es sur le processus permettront de d{\'{e}}cider quelle est la meilleure. Cette question est celle de la discernabilit{\'{e}} des structures"


Page 29 "la caract{\'{e}}risation d'un mod{\`{e}}le n'est pas un choix initial une fois pour toute mais un choix temporaire destin{\'{e}} {\`{a}} {\^{e}}tre remis en question. La premi{\`{e}}re de ces mises en question peut avoir lieu avant toute mesure"
"la notion qualitative d'identifiabilit{\'{e}} structurelle conduit naturellement {\`{a}} une pr{\'{e}}ocuupation quantitative. sacahnt que la structure consid{\'{e}}r{\'{e}}e est (au moins) localement identifiable, il s'agit de l'identifier au mieux au sens d'un crit{\`{e}}re de pr{\'{e}}cision sur l'estim{\'{e}}e des param{\`{e}}tres."


CHAP 3 CRITERES
Une fois la caract{\'{e}}risation effectu{\'{e}}e (erreur de caract{\'{e}}risation c'est une erreur dans le choix du mod{\`{e}}le?)
Remarque sur les r{\'{e}}sulats exp{\'{e}}rimentaux : un vecteur contenant ces r{\'{e}}sultats est un vecteur al{\'{e}}atoire dans le sens o{\`{u}} reconduire plusieurs fois l'exp{\'{e}}rience dans les exactes m{\^{e}}mes conditions ne donnera pas exactement les m{\^{e}}mes ys.
{\^{}}p est appel{\'{e}} estimateur de p au sens de j(.) : car il conduit {\`{a}} une valeur optimale du crit{\`{e}}re j(.)


1/ les crti{\`{e}}res quadratiques
j(p) = transpos{\'{e}}e de e(p) . Q . e(p) (Q est une matrice de pond{\'{e}}ration, qui peut servir {\`{a}} normaliser une sortie, ou {\'{e}}liminier une donn{\'{e}}e non significative)
2/ crti{\`{e}}re en valeur absolue
j(p) = sommesur j somme sur tij de wij . e(p)
3/ Maximum de vraisemblance (c'est comme une densit{\'{e}} de probabilit{\'{e}} de ys variable sachant p sauf que ys est fixe et p varie)
Voir page 46 les propri{\'{e}}t{\'{e}}s des estimateurs de maximum de vraisemblance
4/ Estimation de la distribution de param{\`{e}}tres d'une population
Page 47. Utile si la connaissance de la distribution des param{\`{e}}tres dans une population d'individus permet d'estimer les param{\`{e}}tres de chaque nouvel individu de fa{\c{c}}on bay{\'{e}}sienne, ce qui n{\'{e}}cessite peu de mesure. permet de planifier de mani{\`{e}}re optimale (au sens de la moyenne sur la population) le recueil de donn{\'{e}}es {\`{a}} effectuer sur le prochain individu
Page 52 "diverses approches param{\'{e}}triques ont {\'{e}}t{\'{e}} propos{\'{e}}es pour estimer des lois dans le contexte de la biologie (pharmacocin{\'{e}}tique en particulier), o{\`{u}} la variabilit{\'{e}} interindividus des param{\`{e}}tres est g{\'{e}}n{\'{e}}ralement tr{\`{e}}s importante. Elles visent {\`{a}} l'estimation de la moyenne et de la covariance de la loi (ce qui ne la d{\'{e}}crit totalement que si elle est gaussienne). Certaines de ces approches permettent une mise en {\oe}uvre r{\'{e}}cursive contrairement aux approches non param{\'{e}}triques pr{\'{e}}c{\'{e}}dentes. Les observations recueillies sur un nouvel individu viennent alors enrichir la description de la population, sans que l'on ai {\`{a}} recourir {\`{a}} une nouvelle estimation reposant sur toutes les mesures recueillies sur tous les individus"
VOIR Mentr{\'{e}} 1984, Mentr{\'{e}}, mallet et Steimer 1988


Page 57 Crit{\`{e}}res de choix de la complexit{\'{e}}
On peut utiliser un crit{\`{e}}re {\`{a}} minimiser pour comparer les r{\'{e}}sultats entre plusieurs mod{\`{e}}les de complexit{\'{e}} diff{\'{e}}rente. Le crit{\`{e}}re fait intervenir un terme qui prend en compte la dimension du param{\`{e}}tre (i.e. le nombre de degr{\'{e}} de libert{\'{e}} du mod{\`{e}}le).
- AIC an information criterion d'Akaike
- Final Prediction Error
- Bayesian Information Error
VOIR S{\"{o}}derstr{\"{o}}m 1977 et Veres 1991


Page 59 Crit{\`{e}}res bay{\'{e}}siens.
L'approche du max de vraisemblance consid{\'{e}}rait p comme inconnu mais constant. Les approches bay{\'{e}}siennes attribuent une densit{\'{e}} de probabilit{\'{e}} a priori au vecteur p al{\'{e}}atoire.
Pour les connaissances a priori, on attribue la densit{\'{e}} de proba qui maximise l'entropie, cela {\'{e}}vite d'introduire de l'information parasite dans le mod{\`{e}}le.
VOIR Box et Tiao (1973) pour la notion de distribution a priori non informative.
on d{\'{e}}fini le crit{\`{e}}re du maximum a posteriori ou le crit{\`{e}}re du risque minimum.


Page 64 Contraintes sur les param{\`{e}}tres
pour que les param{\`{e}}tres v{\'{e}}rifient une contrainte ({\'{e}}galit{\'{e}} ou in{\'{e}}galit{\'{e}}) on introduit dans le crit{\`{e}}re un terme de p{\'{e}}nalisation.


Page 67 Robustesse des estimateurs
Un estimateur {\^{}}p est robuste si ses performances ne sont pas trop d{\'{e}}teriori{\'{e}}es quand les hypoth{\`{e}}ses sur lesquelles il repose ne sont pas {\'{e}}vrifi{\'{e}}es. Par exemple on suppose le bruit gaussien de var sigma² alors que sa densit{\'{e}} de proba a "des queues" plus importantes de pr{\'{e}}vues, ou que les donn{\'{e}}es sont contamin{\'{e}}es par des valeurs aberrantes.
Exemple : Robustesse aux incertitudes sur la distribution du bruit :
quand la distri est connue de fa{\c{c}}on fiable, la matrice d'infirmation de Fisher s'{\'{e}}crit en fonction d'uns calaire, l'information de Fisher,},
author = {Walter, Eric and Pronzato, Luc},
booktitle = {Mod{\'{e}}lisation Analyse Simulation Commande},
isbn = {2225844070, 9782225844072},
keywords = {MASC mod{\'{e}}lisation,analyse,commande,simulation},
pages = {371},
publisher = {Masson},
title = {{Identification de mod{\`{e}}les param{\'{e}}triques {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales}},
year = {1994}
}
@article{Kaipio2007,
abstract = {The article discusses the discretization of linear inverse problems. When an inverse problem is formulated in terms of infinite-dimensional function spaces and then discretized for computational purposes, a discretization error appears. Since inverse problems are typically ill-posed, neglecting this error may have serious consequences to the quality of the reconstruction. The Bayesian paradigm provides tools to estimate the statistics of the discretization error that is made part of the measurement and modelling errors of the estimation problem. This approach also provides tools to reduce the dimensionality of inverse problems in a controlled manner. The ideas are demonstrated with a computed example.},
author = {Kaipio, Jari P. and Somersalo, Erkki},
doi = {10.1016/j.cam.2005.09.027},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaipio, Somersalo - 2007 - Statistical inverse problems Discretization, model reduction and inverse crimes(2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaipio, Somersalo - 2007 - Statistical inverse problems Discretization, model reduction and inverse crimes.pdf:pdf},
isbn = {0377-0427},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {Bayesian statistics,Discretization,Inverse problems,Modelling error},
month = {jan},
number = {2},
pages = {493--504},
title = {{Statistical inverse problems: Discretization, model reduction and inverse crimes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377042705007296},
volume = {198},
year = {2007}
}
@article{Wu2019,
abstract = {Inverse Uncertainty Quantification (UQ), or Bayesian calibration, is the process to quantify the uncertainties of random input parameters based on experimental data. The introduction of model discrepancy term is significant because “over-fitting” can theoretically be avoided. But it also poses challenges in the practical applications. One of the mostly concerned and unresolved problem is the “lack of identifiability” issue. With the presence of model discrepancy, inverse UQ becomes “non-identifiable” in the sense that it is difficult to precisely distinguish between the parameter uncertainties and model discrepancy when estimating the calibration parameters. Previous research to alleviate the non-identifiability issue focused on using informative priors for the calibration parameters and the model discrepancy, which is usually not a viable solution because one rarely has such accurate and informative prior knowledge. In this work, we show that identifiability is largely related to the sensitivity of the calibration parameters with regards to the chosen responses. We adopted an improved modular Bayesian approach for inverse UQ that does not require priors for the model discrepancy term. The relationship between sensitivity and identifiability was demonstrated with a practical example in nuclear engineering. It was shown that, in order for a certain calibration parameter to be statistically identifiable, it should be significant to at least one of the responses whose data are used for inverse UQ. Good identifiability cannot be achieved for a certain calibration parameter if it is not significant to any of the responses. It is also demonstrated that “fake identifiability” is possible if model responses are not appropriately chosen, or if inaccurate but informative prior distributions are specified.},
author = {Wu, Xu and Shirvan, Koroush and Kozlowski, Tomasz},
doi = {10.1016/j.jcp.2019.06.032},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Shirvan, Kozlowski - Unknown - Demonstration of the Relationship between Sensitivity and Identifiability for Inverse Uncertainty (2).pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Shirvan, Kozlowski - 2018 - Demonstration of the Relationship between Sensitivity and Identifiability for Inverse Uncertainty Quanti.pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1-s2.0-S0021999119304401-main.pdf:pdf},
issn = {10902716},
journal = {Journal of Computational Physics},
keywords = {Identifiability,Inverse uncertainty quantification,Modular Bayesian approach,Sensitivity},
number = {January},
pages = {12--30},
title = {{Demonstration of the relationship between sensitivity and identifiability for inverse uncertainty quantification}},
url = {https://arxiv.org/pdf/1801.10309.pdf},
volume = {396},
year = {2019}
}
@phdthesis{Josse2017,
author = {Josse, Rozenn},
file = {:home/sarah/OneDrive/Travail/Sources/JOSSE{\_}2017{\_}diffusion.pdf:pdf},
pages = {253},
school = {Universit{\'{e}} Grenoble Alpes},
title = {{M{\'{e}}thode et outils pour l'identification de d{\'{e}}fauts des b{\^{a}}timents connect{\'{e}}s performants}},
year = {2017}
}
@article{ZOUARI2014,
author = {ZOUARI, Talel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ZOUARI - 2014 - Diagnostic des syst{\`{e}}mes dynamiques hybrides {\`{a}} modes non lin{\'{e}}aires.pdf:pdf},
title = {{Diagnostic des syst{\`{e}}mes dynamiques hybrides {\`{a}} modes non lin{\'{e}}aires}},
year = {2014}
}
@article{Catalina2013,
abstract = {Nowadays, heating energy demand has become a significant estimator used during the design stage of any new building. In this paper we are proposing a model to predict the heating energy demand, based on the main factors that influence a building's heat consumption. It was found out that these factors are: the building global heat loss coefficient (G), the south equivalent surface (SES) and the difference between the indoor set point temperature and the sol-air temperature. In the second part of this paper, multiple dynamic simulations were carried out in order to determine the values of the inputs and output data of the future prediction model. Using the obtained database, a multiple regression prediction model was further used to develop the prediction model. In the last part of this paper the model results was validated with the measured data from 17 blocks of flats. Moreover, in this article it is also shown the comparison with the results calculated using the building's energy certification methodology. A detailed error analysis showed that the model presents a very good accuracy (correlation coefficient of 0.987). In conclusion, the proposed model presents the following characteristics: three inputs and one output, simplicity, large applicability, good match with the simulations and with the energy certification calculations, human behavior correction. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Catalina, Tiberiu and Iordache, Vlad and Caracaleanu, Bogdan},
doi = {10.1016/j.enbuild.2012.11.010},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Catalina, Iordache, Caracaleanu - 2013 - Multiple regression model for fast prediction of the heating energy demand.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Heating energy demand,Main factors,Prediction model,Residential buildings},
pages = {302--312},
publisher = {Elsevier B.V.},
title = {{Multiple regression model for fast prediction of the heating energy demand}},
url = {http://dx.doi.org/10.1016/j.enbuild.2012.11.010},
volume = {57},
year = {2013}
}
@article{Forbes2011,
abstract = {In this paper, we compare uncertainty evaluation procedures based on the measurement and observation equation approaches applied to a class of models covering many practical measuring systems. We derive general conditions for when the two approaches give the same distributions associated with the measurand and give examples of how and where they differ. We argue that while it is possible to interpret the measurement equation approach as determining a state of knowledge distribution for the measurand, for some problems there are conceptual, and for highly nonlinear models, practical difficulties with this interpretation. These conceptual difficulties do not arise if the measurement equation approach is interpreted as characterising the behaviour of a measuring system. The discussion presented here is relevant to the revision of the GUM, currently being undertaken by the Joint Committee for Guides in Metrology.},
author = {Forbes, A. B. and Sousa, J. A.},
doi = {10.1016/j.measurement.2011.05.007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbes, Sousa - 2011 - The GUM, Bayesian inference and the observation and measurement equations.pdf:pdf},
issn = {02632241},
journal = {Measurement: Journal of the International Measurement Confederation},
keywords = {Bayesian inference,Measurement equation,Measurement uncertainty,Observation equation},
number = {8},
pages = {1422--1435},
publisher = {Elsevier Ltd},
title = {{The GUM, Bayesian inference and the observation and measurement equations}},
url = {http://dx.doi.org/10.1016/j.measurement.2011.05.007},
volume = {44},
year = {2011}
}
@article{Tuominen2012,
abstract = {In this study the barriers to energy savings and the policy measures set up to overcome these barriers were mapped by interviewing stakeholders in ten European Union member states (MS). In addition, an estimate of energy savings potential was calculated. It seems that in most countries cost-effective energy savings of about 10{\%} can be achieved by 2020 and 20{\%} by 2030. A total annual energy saving of approx. 150 TWh by 2020 and approx. 280 TWh by 2030 appears possible. This can be compared to the total annual primary energy consumption of 21,000 TWh in all EU countries combined. Barriers and policies to overcome them were also studied. This was based on a literature review, stakeholder interviews and in-depth homeowner interviews in ten MS. A commonly cited problem was that people are not keen to improve energy efficiency of their homes as it does not proportionately increase the value of the property. Another widespread problem was that energy prices do not include all the negative external costs that the use of energy causes, such as pollution. The most commonly reported public policy measures in use related to information dissemination and subsidies for energy efficiency retrofits. {\textcopyright} 2012 Elsevier B.V.},
author = {Tuominen, Pekka and Klobut, Krzysztof and Tolman, Anne and Adjei, Afi and {De Best-Waldhober}, Marjolein},
doi = {10.1016/j.enbuild.2012.04.015},
file = {:home/sarah/OneDrive/Travail/Sources/R{\'{e}}novation/1-s2.0-S0378778812002289-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Energy efficiency,Market barriers,Policy measures,Savings potential},
pages = {48--55},
publisher = {Elsevier B.V.},
title = {{Energy savings potential in buildings and overcoming market barriers in member states of the European Union}},
url = {http://dx.doi.org/10.1016/j.enbuild.2012.04.015},
volume = {51},
year = {2012}
}
@inproceedings{Jedidi,
annote = {Pour r{\'{e}}duire la complexit{\'{e}} de l'{\'{e}}tude d'un syst{\`{e}}me de grande taille, une approche est de consid{\'{e}}rer le probl{\`{e}}me comme une collection de sous-syst{\`{e}}mes plus simples.
Les auteurs consid{\`{e}}rent un ensemble de syst{\`{e}}mes lin{\'{e}}aires coupl{\'{e}}s par leurs sorties. "De nombreux processus peuvent {\^{e}}tre mod{\'{e}}lis{\'{e}}s sous cette forme, c'est le cas par exemple des syst{\`{e}}mes thermiques dans les b{\^{a}}timents".

Tester l'identifiabilit{\'{e}} structurelle est une {\'{e}}tape importante dans la validation th{\'{e}}orique d'un mod{\`{e}}le.

Les auteurs rappellent les d{\'{e}}finitions d'un syst{\`{e}}me commandable et observable.

L'int{\'{e}}r{\^{e}}t de leur approche est de faciliter l'identification des param{\`{e}}tres en estimant les param{\`{e}}tres de chaque sous-syst{\`{e}}mes.

Sur un cas id{\'{e}}al non bruit{\'{e}}, la m{\'{e}}thode d{\'{e}}centralis{\'{e}}e permet de g{\'{e}}rer des syst{\`{e}}mes beaucoup plus gros : l'erreur param{\'{e}}trique minimale est plus faible, les temps de calcul moins {\'{e}}lev{\'{e}}s et le fit meilleur dans tous les cas.
Sur un cas bruit{\'{e}} (gaussien), m{\^{e}}mes r{\'{e}}sultats.
Cela signifie que cette m{\'{e}}thode est moins sensible aux bruits de mesure.},
author = {Jedidi, Safa and Bourdais, Romain and Buisson, Jean and Lefebvre, Marie-anne},
booktitle = {JDMACS 2015},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jedidi et al. - Unknown - Identifiabilit{\'{e}} structurelle et identification de syst{\`{e}}mes coupl{\'{e}}s par les sorties.pdf:pdf},
title = {{Identifiabilit{\'{e}} structurelle et identification de syst{\`{e}}mes coupl{\'{e}}s par les sorties}}
}
@article{Nguyen-Hong2017,
abstract = {This paper presents an approach which is called meta -optimization combining with scattering analysis used to enhance on-site real-time temperature anticipation for energy management. The aim of this approach is to analyse the sensitivity of the parameters in order to simplify, and then attain, the best reduced model able to match with measurements regularly in a robust manner. This will be done with the effort of keeping their physical properties. Indeed, parameter identification is a key challenge for modelling system that are used with many uncertainties such as construction and material quality, weather conditions, and occupant behaviour that are changing during building life. This method is applied for a nearly-zero energy building in France to validate our approach.},
author = {Nguyen-Hong, Quan and {Le Mounier}, Audrey and Dinh, Van-Binh and Delinchant, Benoit and Ploix, Stephane and Wurtz, Fr{\'{e}}d{\'{e}}ric},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen-Hong et al. - 2017 - Meta-Optimization and Scattering Parameters Analysis for Improving On Site Building Model Identification for.pdf:pdf},
pages = {2587--2591},
title = {{Meta-Optimization and Scattering Parameters Analysis for Improving On Site Building Model Identification for Optimal Operation}},
year = {2017}
}
@article{Wittman8888,
abstract = {Fisher matrix techniques are used widely in astronomy (and, we are told, in many other fields) to forecast the precision of future experiments while they are still in the design phase. Although the mathematics of the formalism is widely reproduced (DETF report, Wikipedia, etc), it is difficult to find simple examples to help the beginner. This document works through a few simple examples to emphasize the concepts.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0506614},
author = {Wittman, D},
doi = {10.1088/0004-637X/749/2/127},
eprint = {0506614},
isbn = {0004-6361},
issn = {00358711},
journal = {Tutorial},
pages = {1--9},
primaryClass = {astro-ph},
title = {{Fisher Matrix for Beginners}},
year = {8888}
}
@inproceedings{Menberg2017,
abstract = {In this study, we examine the efficiency and reliability of a Bayesian calibration setup using temperature point measurements. Hamiltonian Monte Carlo sampling is found to be significantly more efficient with regard to convergence of the posterior distributions, which is as- sessed using different visual and quantitative measures. The examination of posterior realizations from different data sets and different prior distributions reveals that in- ference about model parameters is in general quite relia- ble, while learning about the magnitude of different error terms, such as model discrepancy and random errors, proves to be more difficult. Finally, predictive simulation results based on these inferred posterior distributions are generally in good agreement with measured data},
author = {Menberg, Kathrin and Heo, Yeonsook and Choudhary, Ruchi},
booktitle = {Proceedings of the 15th IBPSA Conference San Francisco, CA, USA},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Menberg, Heo, Choudhary - 2017 - Efficiency and Reliability of Bayesian Calibration of Energy Supply System Models University of Cambrid.pdf:pdf},
number = {1},
pages = {1594--1603},
title = {{Efficiency and Reliability of Bayesian Calibration of Energy Supply System Models}},
year = {2017}
}
@article{Maillet2011,
abstract = {Ce dossier est le dernier d'une s{\'{e}}rie de trois, intitul{\'{e}}e « Probl{\`{e}}mes inverses en diffusion thermique ». On a vu dans les dossiers [BE 8 265] « Mod{\`{e}}les diffusifs, mesures, sensibilit{\'{e}}s » et [BE 8 266] « Formulation et r{\'{e}}solution du probl{\`{e}}me des moindres carr{\'{e}}s », que la simple application des m{\'{e}}thodes num{\'{e}}riques et analytiques d'inversion n'{\'{e}}tait pas une garantie d'obtention de bons r{\'{e}}sultats. Afin d'am{\'{e}}liorer les r{\'{e}}sultats, il est n{\'{e}}cessaire d'affiner ces m{\'{e}}thodes pour analyser et r{\'{e}}soudre ce type de probl{\`{e}}me. C'est ce qui va {\^{e}}tre entrepris ici, en se focalisant d'abord sur les six composantes de l'erreur d'estimation, puis en passant en revue les « Outils sp{\'{e}}cifiques de conduction inverse et de r{\'{e}}gularisation », avant de d{\'{e}}tailler ces derniers et de mettre en exergue quelques questions importantes que doit se poser, d{\`{e}}s le d{\'{e}}but de sa d{\'{e}}marche, l'inverseur de mesures en thermique.Les symboles et notations de ce dossier sont donn{\'{e}}s dans le tableau 1.},
author = {Maillet, Denis and Jarny, Yvon and Petit, Daniel},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillet, Jarny, Petit - 2011 - Probl{\`{e}}mes inverses en diffusion thermique Outils sp{\'{e}}cifiques de conduction inverse et de r{\'{e}}gularisatio.pdf:pdf},
isbn = {7200031372},
journal = {Techniques de l'ing{\'{e}}nieur},
pages = {1--2},
title = {{Probl{\`{e}}mes inverses en diffusion thermique Outils sp{\'{e}}cifiques de conduction inverse et de r{\'{e}}gularisation}},
url = {http://www.techniques-ingenieur.fr/base-documentaire/energies-th4/transferts-thermiques-42214210/problemes-inverses-en-diffusion-thermique-be8267/},
year = {2011}
}
@article{Rothenberg1971,
author = {Rothenberg, Thomas J.},
doi = {10.2307/1913267},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rothenberg - 1971 - Identification in Parametric Models.pdf:pdf},
issn = {00129682},
journal = {Econometrica},
month = {may},
number = {3},
pages = {577},
title = {{Identification in Parametric Models}},
url = {http://www.jstor.org/stable/1913267?origin=crossref},
volume = {39},
year = {1971}
}
@article{Gustafson2006,
abstract = {Realistic statistical modelling of observational data often suggests a statistical model which is not fully identified, owing to potential biases that are not under the control of study investigators. Bayesian inference can be implemented with such a model, ideally with the most precise prior knowledge that can be ascertained. However, as a consequence of the non-identifiability, inference cannot be made arbitrarily accurate by choosing the sample size to be sufficiently large. In turn, this has consequences for sample size determination. The paper presents a sample size criterion that is based on a quantification of how much Bayesian learning can arise in a given non-identified model. A global perspective is adopted, whereby choosing larger sample sizes for some studies necessarily implies that some other potentially worthwhile studies cannot be undertaken. This suggests that smaller sample sizes should be selected with non-identified models, as larger sample sizes constitute a squandering of resources in making estimator variances very small compared with their biases. Particularly, consider two investigators planning the same study, one of whom admits to the potential biases at hand and consequently uses a non-identified model, whereas the other pretends that there are no biases, leading to an identified but less realistic model. It is seen that the former investigator always selects a smaller sample size than the latter, with the difference being quite marked in some illustrative cases. {\textcopyright} 2006 Royal Statistical Society.},
author = {Gustafson, Paul},
doi = {10.1111/j.1467-985X.2006.00436.x},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Gustafson-2006-Journal{\_}of{\_}the{\_}Royal{\_}Statistical{\_}Society{\_}{\_}Series{\_}A{\_}(Statistics{\_}in{\_}Society).pdf:pdf},
issn = {09641998},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Bayesian inference,Bias,Epidemiology,Measurement error,Misclassification,Non-identified model,Observational studies,Residual confounding,Sample size,Study design},
number = {4},
pages = {865--881},
title = {{Sample size implications when biases are modelled rather than ignored}},
volume = {169},
year = {2006}
}
@article{Yang2019,
author = {Yang, Yingying and Wu, Tingting Vogt and Sempey, Alain and Dumoulin, Jean and Batsale, Jean-christophe},
doi = {10.1016/j.enbuild.2018.12.002},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - Short time non-destructive evaluation of thermal performances of building walls by studying transient heat transfer.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Short time NDSE,Thick building walls,Unit-step res},
month = {feb},
pages = {141--151},
publisher = {Elsevier B.V.},
title = {{Short time non-destructive evaluation of thermal performances of building walls by studying transient heat transfer}},
url = {https://doi.org/10.1016/j.enbuild.2018.12.002 https://linkinghub.elsevier.com/retrieve/pii/S0378778818324277},
volume = {184},
year = {2019}
}
@phdthesis{Bozonnet2005,
abstract = {Les syst{\`{e}}mes de conditionnement des ambiances int{\'{e}}rieures participent pour une part importante {\`{a}} la demande {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents, notamment en {\'{e}}t{\'{e}}. L'objectif de cette {\'{e}}tude est de d{\'{e}}finir par des simulations thermoa{\'{e}}rauliques l'interaction du microclimat urbain avec le b{\^{a}}ti et sa demande {\'{e}}nerg{\'{e}}tique de climatisation dans le cas d'une rue canyon. Le mod{\`{e}}le choisi, de type zonal, nous permet de d{\'{e}}crire les param{\`{e}}tres de temp{\'{e}}rature et de vitesse d'air dans la rue, avec un degr{\'{e}} de pr{\'{e}}cision interm{\'{e}}diaire entre la mod{\'{e}}lisation CFD fine et les approches nodales simplifi{\'{e}}es. L'ensoleillement et les inter-r{\'{e}}flexions dans la rue sont ensuite mod{\'{e}}lis{\'{e}}s par une m{\'{e}}thode simplifi{\'{e}}e, d{\'{e}}velopp{\'{e}}e et appliqu{\'{e}}e {\`{a}} l'{\'{e}}tude de la convection naturelle dans une rue. Les {\'{e}}coulements dominants dus au vent sont par ailleurs {\'{e}}tudi{\'{e}}s {\`{a}} partir de donn{\'{e}}es exp{\'{e}}rimentales, sur la base desquelles un mod{\`{e}}le simplifi{\'{e}} est propos{\'{e}}, en conditions isothermes. Le couplage des effets du vent et de la convection naturelle a {\'{e}}t{\'{e}} {\'{e}}tudi{\'{e}} dans le cas d'une rue canyon sur 28 jours. La conclusion se porte sur l'importance de la mod{\'{e}}lisation thermoa{\'{e}}raulique pour la d{\'{e}}termination de l'effet d'{\^{i}}lot de chaleur urbain, ainsi que la demande {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents.},
author = {Bozonnet, Emmanuel},
booktitle = {Universit{\'{e}} de la Rochelle},
doi = {10.1038/nmat3167},
issn = {14761122},
pages = {807--807},
publisher = {Universit{\'{e}} de la Rochelle,},
title = {{Impact des microclimats urbains sur la demande {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents : Cas de la rue canyon}},
url = {http://www.nature.com/doifinder/10.1038/nmat3167},
volume = {10},
year = {2005}
}
@article{Rasmussen2020,
abstract = {Modelling the effects of solar irradiation plays an important role in various applications. This paper describes a semi-parametric (combined grey-box and spline-based), data-driven technique that can be used to model systems in which the solar gain depends on the sun position. The solar gain factor is introduced, i.e. the absorbed fraction of measured solar irradiation, and estimated as a continuous non-parametric function of the sun position. The implementation of the spline-based solar gain factor in a grey-box model framework is described. The method is tested in two case studies—in a model of the internal temperature of a dwelling in Aalborg, Denmark, and a model of the return temperature of a solar collector field in Solr{\o}d, Denmark. It is shown that the solar gain factor as a function of sun position is able to account for structural variations in solar gain that may occur due to factors such as shading obstacles and window or absorber orientation. In both test cases, the spline-based solar gain function improved the model accuracy significantly, and largely reduced structural errors in prediction residuals. In addition, the shape of the estimated function provided insight into the dynamics of the system and the local solar input characteristics. Accurate representation of such site characteristics was not possible with any data-driven method found in the literature. Besides the grey-box models used in this study, the solar gain factor can be used in a variety of data-driven models, for example in linear regression models.},
author = {Rasmussen, Christoffer and Fr{\"{o}}lke, Linde and Bacher, Peder and Madsen, Henrik and Rode, Carsten},
doi = {10.1016/j.solener.2019.11.023},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0038092X19311235-main.pdf:pdf},
issn = {0038092X},
journal = {Solar Energy},
keywords = {Building energy,Grey-box modelling,Solar gain modelling,Solar heat collectors,Splines,Thermal dynamics},
number = {October 2019},
pages = {249--258},
publisher = {Elsevier},
title = {{Semi-parametric modelling of sun position dependent solar gain using B-splines in grey-box models}},
url = {https://doi.org/10.1016/j.solener.2019.11.023},
volume = {195},
year = {2020}
}
@article{Li2019a,
abstract = {Physics-based simulation of energy use in buildings is widely used in building design and performance rating, controls design and operations. However, various challenges exist in the modeling process. Model parameters such as people count and air infiltration rate are usually highly uncertain, yet they have significant impacts on the simulation accuracy. With the increasing availability and affordability of sensors and meters in buildings, a large amount of measured data has been collected including indoor environmental parameters, such as room air dry-bulb temperature, humidity ratio, and CO2 concentration levels. Fusing these sensor data with traditional energy modeling poses new opportunities to improve simulation accuracy. This study develops a set of physics-based inverse algorithms which can solve the highly uncertain and hard-to-measure building parameters such as zone-level people count and air infiltration rate. A simulation-based case study is conducted to verify the inverse algorithms implemented in EnergyPlus covering various sensor measurement scenarios and different modeling use cases. The developed inverse models can solve the zone people count and air infiltration at sub-hourly resolution using the measured zone air temperature, humidity and/or CO2 concentration given other easy-to-measure model parameters are known.},
author = {Li, Han and Hong, Tianzhen and Sofos, Marina},
doi = {10.1016/j.enbuild.2019.06.008},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-S0378778819306401-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {EnergyPlus,Inverse problems,infiltration,people count,sensor data,zone air parameters},
month = {jun},
publisher = {Elsevier B.V.},
title = {{An Inverse Approach to Solving Zone Air Infiltration Rate and People Count using Indoor Environmental Sensor Data}},
url = {https://www-sciencedirect-com.camphrier-1.grenet.fr/science/article/pii/S0378778819306401 https://doi.org/10.1016/j.enbuild.2019.06.008 https://linkinghub.elsevier.com/retrieve/pii/S0378778819306401},
year = {2019}
}
@article{Rissanen1978,
abstract = {Estimates of both integer-valued structure parameters and real-valued system parameters may be obtained from a model based on the shortest data description principle. Summary--The number of digits it takes to write down an observed sequence xl,...,x N of a time series depends on the model with its parameters that one assumes to have generated the observed data. Accordingly, by finding the model which minimizes the description length one obtains estimates of both the integer-valued structure parameters and the real-valued system parameters.},
author = {Rissanen, J.},
doi = {10.1016/0005-1098(78)90005-5},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rissanen - 1978 - Modeling by shortest data description.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Key Word Index--Modeling,identification,parameter estimation,statistics,stochastic systems},
month = {sep},
number = {5},
pages = {465--471},
title = {{Modeling by shortest data description}},
url = {http://msol.people.uic.edu/ECE531/papers/Modeling By Shortest Data Description.pdf http://linkinghub.elsevier.com/retrieve/pii/0005109878900055},
volume = {14},
year = {1978}
}
@article{Vajda1983,
abstract = {Deterministic identifiability of finite dimensional dynamical systems is analysed using a generalized concept of structural invariants. Results applied to time-invariant bilinear and time-variable linear systems yield algebraic conditions for identifiability which are natural generalizations of the well known identifiability criteria for time-invariant linear systems. {\textcopyright} 1983 Taylor {\&} Francis Ltd.},
author = {Vajda, Sandor},
doi = {10.1080/00207728308926526},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/vajda1983.pdf:pdf},
issn = {0020-7721},
journal = {International Journal of Systems Science},
month = {nov},
number = {11},
pages = {1229--1247},
title = {{Structural identifiability of dynamical systems}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00207728308926526},
volume = {14},
year = {1983}
}
@article{Brohus2012,
abstract = {Traditional building energy consumption calculation methods are characterised by rough approaches providing approximate figures with high and unknown levels of uncertainty. Lack of reliable energy resources and increasing concerns about climate change call for improved predictive tools. A new approach for the prediction of building energy consumption is presented. The approach quantifies the uncertainty of building energy consumption by means of stochastic differential equations. The approach is applied to a general heat balance for an arbitrary number of loads and zones in a building to determine the dynamic thermal response under random conditions. Two test cases are presented. The approach is found to work well, although computation time may be rather high. The results indicate that the impact of a stochastic description compared with a deterministic description may be modest for the dynamic thermal behaviour of buildings. However, for air flow and energy consumption it is found to be much more significant due to less "damping". Probabilistic methods establish a new approach to the prediction of building energy consumption, enabling designers to include stochastic parameters like inhabitant behaviour, operation and maintenance to predict the performance of the systems and the level of certainty for fulfiling design requirements under random conditions. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Brohus, H. and Frier, C. and Heiselberg, P. and Haghighat, F.},
doi = {10.1016/j.enbuild.2012.07.013},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brohus et al. - 2012 - Quantification of uncertainty in predicting building energy consumption A stochastic approach.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building simulation tool,Building thermal behaviour,Net-zero energy buildings,Occupants' behaviour,Stochastic differential equation,Uncertainty quantification},
pages = {127--140},
publisher = {Elsevier B.V.},
title = {{Quantification of uncertainty in predicting building energy consumption: A stochastic approach}},
url = {http://dx.doi.org/10.1016/j.enbuild.2012.07.013},
volume = {55},
year = {2012}
}
@article{Division,
author = {Division, Earth Sciences},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Division - Unknown - Fourier ' s Heat Conduction Equation History , Influence , and Connections.pdf:pdf},
title = {{Fourier ' s Heat Conduction Equation : History , Influence , and Connections}}
}
@article{Sahu1999,
author = {Sahu, S.K. and Gelfand, Alan E},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/10.1.1.51.5644.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {convergence,embedded posterior,estimability,integrability,non-full-rank models},
number = {445},
pages = {247--254},
title = {{Identifiability, Improper Priors, and Gibbs Sampling for Generalized Linear Models.}},
url = {http://www.jstor.org/stable/2669699},
volume = {94},
year = {1999}
}
@article{Betancourt2018,
abstract = {As the frontiers of applied statistics progress through increasingly complex experiments we must exploit increasingly sophisticated inferential models to analyze the observations we make. In order to avoid misleading or outright erroneous inferences we then have to be increasingly diligent in scrutinizing the consequences of those modeling assumptions. Fortunately model-based methods of statistical inference naturally define procedures for quantifying the scope of inferential outcomes and calibrating corresponding decision making processes. In this paper I review the construction and implementation of the particular procedures that arise within frequentist and Bayesian methodologies.},
archivePrefix = {arXiv},
arxivId = {1803.08393},
author = {Betancourt, Michael},
eprint = {1803.08393},
file = {:home/sarah/OneDrive/Travail/Sources/Calibration de mod{\`{e}}le - Identification/1803.08393.pdf:pdf},
journal = {arXiv},
month = {mar},
pages = {1--35},
title = {{Calibrating Model-Based Inferences and Decisions}},
url = {http://arxiv.org/abs/1803.08393},
year = {2018}
}
@techreport{Ripley,
author = {Ripley, B D},
file = {:home/sarah/OneDrive/Travail/Sources/Nelder80.pdf:pdf},
title = {{Presentation on model selection criterion and AIC}}
}
@article{Gerdin2006,
author = {Gerdin, Markus and Glad, Torkel},
doi = {10.3182/20060329-3-AU-2901.00129},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gerdin, Glad - 2006 - ON IDENTIFIABILITY OF OBJECT-ORIENTED MODELS.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {algebraic methods,descriptor systems,identifiability,identification,modelling,nonlinear systems,object oriented},
number = {1},
pages = {820--825},
title = {{ON IDENTIFIABILITY OF OBJECT-ORIENTED MODELS}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667015353659},
volume = {39},
year = {2006}
}
@inproceedings{Juricic2012,
abstract = {Buildings sometimes use much more energy than expected and occupants show high levels of health symptoms and low perceived comfort. This paper aims at showing that some building characteristics or combinations of building characteristics simultaneously lead to low energy use and higher perceived health and comfort and are therefore considered to be more "robust", meaning that these building types better live up to the expectations set up during design stage. This study is based on the statistical analyses of two different existing field study databases. The influence of various building characteristics and systems, like HVAC characteristics, design related characteristics or user interaction to the building characteristics, on perceived health and comfort and on energy use has been studied independently for each database and then compared. Specific combinations called 'design profiles' have been defined and have been compared with the same indicators. Statistically significant results showed that certain single characteristics and some design profiles clearly contributed to reasonable energy use, better health and comfort perception or to both, which confirms the robustness hypothesis.},
author = {Juricic, Sarah and {Van Den Ham}, E.R. and Kurvers, S.R.},
booktitle = {Proceedings of 7th Windsor Conference: The Changing Context of Comfort in an Unpredictable World},
keywords = {Energy use,Hvac,Perce,[Building characteristics},
title = {{Robustness of a building Relationship between building characteristics and energy use and health and comfort perception}},
year = {2012}
}
@phdthesis{Goffart2013,
author = {Goffart, Jeanne},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goffart - 2013 - Impact de la variabilit{\'{e}} des donn{\'{e}}es m{\'{e}}t{\'{e}}orologiques sur une maison basse consommation. Application des analyses.pdf:pdf},
keywords = {Analyse de sensibilit{\'{e}},Bootstrap,RBD-Fast,m{\'{e}}t{\'{e}}o},
mendeley-tags = {Analyse de sensibilit{\'{e}},Bootstrap,RBD-Fast,m{\'{e}}t{\'{e}}o},
school = {USMB},
title = {{Impact de la variabilit{\'{e}} des donn{\'{e}}es m{\'{e}}t{\'{e}}orologiques sur une maison basse consommation. Application des analyses de sensibilit{\'{e}} pour les entr{\'{e}}es temporelles}},
url = {https://hal.archives-ouvertes.fr/file/index/docid/982150/filename/GOFFART{\_}JEANNE{\_}2013{\_}archivage.pdf},
year = {2013}
}
@article{Chernodarov2018,
author = {Chernodarov, Alexander V.},
doi = {10.1016/j.ifacol.2018.09.092},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chernodarov - 2018 - Identification and an Inverse Filtering Problem.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Kalman filter,error damping,identification of coefficients,inverse problem of dynamics,nonlinear system},
number = {15},
pages = {66--71},
publisher = {Elsevier B.V.},
title = {{Identification and an Inverse Filtering Problem}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S240589631831752X},
volume = {51},
year = {2018}
}
@article{Kumar2019,
author = {Kumar, Ravin and Carroll, Colin and Hartikainen, Ari and Martin, Osvaldo},
doi = {10.21105/joss.01143},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {jan},
number = {33},
pages = {1143},
title = {{ArviZ a unified library for exploratory analysis of Bayesian models in Python}},
url = {http://joss.theoj.org/papers/10.21105/joss.01143},
volume = {4},
year = {2019}
}
@article{OliveiraPanao2016,
abstract = {Most current building thermal codes impose upper limits to the predicted annual building energy demand for heating, ventilation and air conditioning. In the building design phase these predictions are obtained using thermal simulations with variable complexity. The simplest approach uses a single lumped thermal capacitance to model the high thermal mass building elements, combined with five thermal resistances (known as the 5R1C model proposed in EN ISO 13790 standard). This model is used by many European countries as the reference simplified methodology to assess overheating risk and calculate yearly building energy demand. This paper presents a successful extension of this model that allows for its application to the prediction of the internal air temperature of free-running buildings with double skin fa??ades. The extension consists in an increased number of thermal resistances used to model the double skin fa??ade zone. The extended model is validated using a set of detailed thermal measurements obtained in a free-running double skin test cell. For the case analysed the simplifications used in the RC model do not reduce the overall accuracy: the mean absolute error for room air temperature is approximately 1 ??C, the same order of magnitude of more detailed EnergyPlus simulations (1.2 ??C).},
author = {{Oliveira Pan{\~{a}}o}, Marta J.N. and Santos, Carolina A.P. and Mateus, Nuno M. and {Carrilho da Gra{\c{c}}a}, Guilherme},
doi = {10.1016/j.enbuild.2016.03.054},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira Pan{\~{a}}o et al. - 2016 - Validation of a lumped RC model for thermal simulation of a double skin natural and mechanical ventilate.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Double skin fa??ade,Free-running,RC model,Test cell,Validation},
month = {jun},
pages = {92--103},
title = {{Validation of a lumped RC model for thermal simulation of a double skin natural and mechanical ventilated test cell}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378778816302109},
volume = {121},
year = {2016}
}
@article{RamosRuiz2017,
abstract = {Nowadays there is a growing concern about climate change and the global warming effect produced by the concentration of greenhouse gases (GHG). At the Paris climate conference (COP21), 195 countries adopted a global climate agreement, limiting global warming to well below 2 °C. Buildings are large producers of GHG and therefore international standards such as ISO 50001 focus on improving their energy performance, including energy efficiency, use and consumption. To achieve this goal it is important to have a detailed knowledge of the thermal behaviour of buildings. The International Performance Measurement and Verification Protocol (IPMVP), proposes a calibrated simulation model (Option D) to gather this knowledge and to determine the savings associated with Energy Conservation Measures (ECMs). This paper improves the calibration methodology proposed by Ramos et al. (2016) [1], solving the limitations regarding the number of thermal zones and the use of free-floating time periods. Through a real case-study that guides the process, the paper explains how to achieve a calibrated Building Energy Simulation (BES) model using an optimisation process based on a meta-heuristic strategy (genetic algorithm - NSGA-II). Different uncertainty indices such as: CV(RMSE) and Goodness of Fit (GOF) are used as objective function to obtain the calibrated model. These indices, frequently used to measure the accuracy of models, are combined to provide a double possibility to find the best solution, as they are an objective function and a model accuracy measure.},
author = {{Ramos Ruiz}, Germ{\'{a}}n and {Fern{\'{a}}ndez Bandera}, Carlos},
doi = {10.1016/j.apenergy.2016.10.054},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261916314982-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Energy simulation,Genetic algorithm (NSGA-II),Multi-objective optimisation,Multi-zone calibration,Uncertainty analysis},
pages = {82--94},
title = {{Analysis of uncertainty indices used for building envelope calibration}},
volume = {185},
year = {2017}
}
@article{Arendt2016,
abstract = {When using physical experimental data to adjust, or calibrate, computer simulation models, two general sources of uncertainty that must be accounted for are calibration parameter uncertainty and model discrepancy. This is complicated by the well-known fact that systems to be calibrated are often subject to identifiability problems, in the sense that it is difficult to estimate the parameters precisely and to distinguish between the effects of parameter uncertainty versus model discrepancy. We develop a form of preposterior analysis that can be used, prior to conducting physical experiments but after conducting the computer simulations, to predict the degree of identifiability that will result after conducting the physical experiments for a given experimental design. Specifically, we calculate the preposterior covariance matrix of the calibration parameters and demonstrate that, in the examples that we consider, it provides a reasonable prediction of the actual posterior covariance that is calculated after the experimental data are collected. Consequently, the preposterior covariance can be used as a criterion for designing physical experiments to help achieve better identifiability in calibration problems. Supplementary materials are available for this article at the publisher's online edition of IIE Transaction, datasets, additional tables, detailed proofs, etc.},
author = {Arendt, Paul D and Apley, Daniel W and Chen, Wei},
doi = {10.1080/0740817X.2015.1064554},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arendt, Apley, Chen - 2015 - A Preposterior Analysis to Predict Identifiability in Experimental Calibration of Computer Models.pdf:pdf},
issn = {0740-817X},
journal = {IIE Transactions},
keywords = {Bayesian Calibration,Computer Experiments page 2,Gaussian Process Models,Kriging},
month = {jan},
number = {1},
pages = {75--88},
title = {{A preposterior analysis to predict identifiability in the experimental calibration of computer models}},
url = {http://ai2-s2-pdfs.s3.amazonaws.com/7e1b/664b5f19dfca7631864cbf9a7ed459126391.pdf http://www.tandfonline.com/doi/full/10.1080/0740817X.2015.1064554},
volume = {48},
year = {2016}
}
@article{Roels2017,
author = {Roels, Staf and Bacher, Peder and Bauwens, Geert and Casta{\~{n}}o, Sergio and Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Madsen, Henrik},
doi = {10.1016/j.enbuild.2017.08.006},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roels et al. - 2017 - On site characterisation of the overall heat loss coefficient Comparison of different assessment methods by a blin.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Annex 58},
mendeley-tags = {Annex 58},
month = {oct},
pages = {179--189},
title = {{On site characterisation of the overall heat loss coefficient: Comparison of different assessment methods by a blind validation exercise on a round robin test box}},
url = {http://ac.els-cdn.com.camphrier-1.grenet.fr/S037877881731681X/1-s2.0-S037877881731681X-main.pdf?{\_}tid=1d3453c0-8734-11e7-a145-00000aacb362{\&}acdnat=1503404535{\_}8c64d57c1339728859ea0aaa451da432 http://linkinghub.elsevier.com/retrieve/pii/S037877881731681X},
volume = {153},
year = {2017}
}
@article{Vehtari2017,
abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
archivePrefix = {arXiv},
arxivId = {1507.04544},
author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
doi = {10.1007/s11222-016-9696-4},
eprint = {1507.04544},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Vehtari2017{\_}Article{\_}PracticalBayesianModelEvaluati.pdf:pdf},
issn = {15731375},
journal = {Statistics and Computing},
keywords = {Bayesian computation,K-fold cross-validation,Leave-one-out cross-validation (LOO),Pareto smoothed importance sampling (PSIS),Stan,Widely applicable information criterion (WAIC)},
number = {5},
pages = {1413--1432},
publisher = {Springer US},
title = {{Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC}},
volume = {27},
year = {2017}
}
@inproceedings{Batista2011,
abstract = {The ubiquity of time series data across almost all human endeavors has produced a great interest in time series data mining in the last decade. While there is a plethora of classification algorithms that can be applied to time series, all of the current empirical evidence suggests that simple nearest neighbor classification is exceptionally difficult to beat. The choice of distance measure used by the nearest neighbor algorithm depends on the invariances required by the domain. For example, motion capture data typically requires invariance to warping. In this work we make a surprising claim. There is an invariance that the community has missed, complexity invariance. Intuitively, the problem is that in many domains the different classes may have different complexities, and pairs of complex objects, even those which subjectively may seem very similar to the human eye, tend to be further apart under current distance measures than pairs of simple objects. This fact introduces errors in nearest neighbor classification, where complex objects are incorrectly assigned to a simpler class. We introduce the first complexity-invariant distance measure for time series, and show that it generally produces significant improvements in classification accuracy. We further show that this improvement does not compromise efficiency, since we can lower bound the measure and use a modification of triangular inequality, thus making use of most existing indexing and data mining algorithms. We evaluate our ideas with the largest and most comprehensive set of time series classification experiments ever attempted, and show that complexity-invariant distance measures can produce improvements in accuracy in the vast majority of cases. Copyright {\textcopyright} SIAM.},
author = {Batista, Gustavo E.A.P.A. and Wang, Xiaoyue and Keogh, Eamonn J},
booktitle = {Proceedings of the 11th SIAM International Conference on Data Mining, SDM 2011},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Batista, Wang, Keogh - Unknown - A Complexity-Invariant Distance Measure for Time Series.pdf:pdf},
isbn = {9780898719925},
keywords = {Classification,Complexity,Similarity Measures,Time Series},
pages = {699--710},
title = {{A complexity-invariant distance measure for time series}},
url = {http://www.cs.ucr.edu/{~}eamonn/Complexity-Invariant Distance Measure.pdf},
year = {2011}
}
@book{Walter,
author = {Walter, Eric},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter - Unknown - Lecture Notes in Biomathematics of State Space Models.pdf:pdf},
isbn = {3540115900},
title = {{Lecture Notes in Biomathematics of State Space Models}}
}
@article{Hollick2020,
abstract = {The accurate determination of the in-use heat transfer coefficient (HTC) of a dwelling can support efficiency improvements and understanding of energy costs, potentially addressing the performance gap. This paper introduces a dynamic grey-box framework combining Bayesian methods and lumped thermal capacitance models for the estimation of the performance of in-use buildings. It focuses on methods to account for solar gains, a significant contributor to the heat transfer. Six simple first-order lumped models of occupied homes are presented, which explicitly include gains from solar radiation with varying complexity. Specifically, the models use solar radiation as a single heat input, divided by fa{\c{c}}ade according to the angle of the sun, and including diffuse radiation. Two case study houses in the UK, monitored over two different seasons, were used to illustrate the models' performance. Bayesian model comparison was used, in conjunction with other methods, to determine the most suitable model for each sub-dataset analysed; this indicates that the most appropriate model is both season and case-study dependent, highlighting the importance of local topography and weather experienced. For each case study, the models selected provided HTC estimates within 15{\%} of each other, including during the summer, using only 5–10 days of data. Such techniques have the potential to estimate the thermal performance of dwellings year-round, with minimum disturbance to the occupants and could be developed to improve quality assurance processes for new build and retrofit, identify opportunities for targeted retrofit, and close the performance gap.},
author = {Hollick, Frances P. and Gori, Virginia and Elwell, Clifford A.},
doi = {10.1016/j.enbuild.2019.109669},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778819314999-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian statistics,Dynamic grey-box,Heat power loss coefficient,Heat transfer coefficient,In-situ monitoring,Solar gains},
pages = {109669},
publisher = {Elsevier B.V.},
title = {{Thermal performance of occupied homes: A dynamic grey-box method accounting for solar gains}},
url = {https://doi.org/10.1016/j.enbuild.2019.109669},
volume = {208},
year = {2020}
}
@misc{Tarantola2006,
abstract = {Using observations to infer the values of some parameters corresponds to solving an 'inverse problem'. Practitioners usually seek the 'best solution' implied by the data, but observations should only be used to falsify possible solutions, not to deduce any particular solution.},
annote = {Let me fi rst argue that the very idea of using
observations to infer one model of the system (the ‘best model' or the ‘mean model' or whatever) is wrong. Observations cannot produce models, they can only falsify models.},
author = {Tarantola, Albert},
booktitle = {Nature Physics},
doi = {10.1038/nphys375},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarantola - 2006 - Popper, Bayes and the inverse problem.pdf:pdf},
isbn = {0898715725},
issn = {1745-2473},
number = {8},
pages = {492--494},
title = {{Popper, Bayes and the inverse problem}},
url = {http://www.nature.com/doifinder/10.1038/nphys375},
volume = {2},
year = {2006}
}
@article{DeConinck2016,
abstract = {As automatic sensing and information and communication technology get cheaper, building monitoring data becomes easier to obtain. The availability of data leads to new opportunities in the context of energy efficiency in buildings. This paper describes the development and validation of a data-driven grey-box modelling toolbox for buildings. The Python toolbox is based on a Modelica library with thermal building and Heating, Ventilation and Air-Conditioning models and the opti- mization framework in JModelica.org. The toolchain facilitates and automates the different steps in the system identification procedure, like data handling, model selection, parameter estimation and validation. To validate the methodology, different grey-box models are identified for a single-family dwelling with detailed monitoring data from two experiments. Validated models for forecasting and control can be identified. However, in one experiment the model performance is reduced, likely due to a poor information content in the identification data set.},
author = {{De Coninck}, Roel and Magnusson, Fredrik and {\AA}kesson, Johan and Helsen, Lieve},
doi = {10.1080/19401493.2015.1046933},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Coninck et al. - 2016 - Toolbox for development and validation of grey-box building models for forecasting and control.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {Mod{\`{e}}les RC},
mendeley-tags = {Mod{\`{e}}les RC},
month = {may},
number = {3},
pages = {288--303},
title = {{Toolbox for development and validation of grey-box building models for forecasting and control}},
url = {http://www.tandfonline.com/loi/tbps20 http://www.tandfonline.com/doi/full/10.1080/19401493.2015.1046933},
volume = {9},
year = {2016}
}
@article{Edgerton1996,
abstract = {Most Monte Carlo studies of test properties use the same values of the exogenous variables in all replications. We show that a considerable improvement in precision can be obtained by drawing separate samples at each replication.},
author = {Edgerton, David L},
doi = {10.1016/S0165-1765(96)00906-8},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edgerton - 1996 - Should stochastic or non-stochastic exogenous variables be used in Monte Carlo experiments.pdf:pdf},
issn = {01651765},
journal = {Economics Letters},
keywords = {Monte Carlo simulation,Test properties},
number = {2},
pages = {153--159},
title = {{Should stochastic or non-stochastic exogenous variables be used in Monte Carlo experiments?}},
volume = {53},
year = {1996}
}
@phdthesis{Jack2015,
author = {Jack, Richard},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/Thesis-2015-Jack.pdf:pdf},
pages = {274},
school = {Loughborough University},
title = {{Building diagnostics : practical measurement of the fabric thermal performance of houses}},
year = {2015}
}
@phdthesis{Heo2011,
abstract = {Retrofitting of existing buildings is essential to reach reduction targets in energy consumption and greenhouse gas emission. In the current practice of a retrofit decision process, professionals perform energy audits, and construct dynamic simulation models to benchmark the performance of existing buildings and predict the effect of retrofit interventions. In order to enhance the reliability of simulation models, they typically calibrate simulation models based on monitored energy use data. The calibration techniques used for this purpose are manual and expert-driven. The current practice has major drawbacks: (1) the modeling and calibration methods do not scale to large portfolio of buildings due to their high costs and heavy reliance on expertise, and (2) the resulting deterministic models do not provide insight into underperforming risks associated with each retrofit intervention. This thesis has developed a new retrofit analysis framework that is suitable for large-scale analysis and risk-conscious decision-making. The framework is based on the use of normative models and Bayesian calibration techniques. Normative models are light-weight quasi-steady state energy models that can scale up to large sets of buildings, i.e. to city and regional scale. In addition, they do not require modeling expertise since they follow a set of modeling rules that produce a standard measure for energy performance. The normative models are calibrated under a Bayesian approach such that the resulting calibrated models quantify uncertainties in the energy outcomes of a building. Bayesian calibration models can also incorporate additional uncertainties associated with retrofit interventions to generate probability distributions of retrofit performance. Probabilistic outputs can be straightforwardly translated into a measure that quantifies underperforming risks of retrofit interventions and thus enable decision making relative to the decision-makers' rational objectives and risk attitude. This thesis demonstrates the feasibility of the new framework on retrofit applications by verifying the following two hypotheses: (1) normative models supported by Bayesian calibration have sufficient model fidelity to adequately support retrofit decisions, and (2) they can support risk-conscious decision-making by explicitly quantifying risks associated with retrofit options. The first and second hypotheses are examined through case studies that compare outcomes from the calibrated normative model with those from a similarly calibrated transient simulation model and compare decisions derived by the proposed framework with those derived by standard practices respectively. The new framework will enable cost-effective retrofit analysis at urban scale with explicit management of uncertainties.},
author = {Heo, Yeonsook},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heo - 2011 - Bayesian Calibration of Building Energy Models for Energy Retrofit Decision-Making under Uncertainty.pdf:pdf},
pages = {1--115},
school = {Georgia Tech},
title = {{Bayesian Calibration of Building Energy Models for Energy Retrofit Decision-Making under Uncertainty}},
year = {2011}
}
@phdthesis{Ollivier,
author = {Ollivier, Francois},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ollivier - Unknown - Th{\`{e}}se - Chap 5.pdf:pdf},
title = {{Th{\`{e}}se - Chap 5}}
}
@article{Baker2008,
abstract = {The PASLINK test facilities and analysis procedures aim to obtain the thermal and solar characteristics of building components under real dynamic outdoor conditions. Both the analysis and the test methodology have evolved since the start of the PASSYS Project in 1985. A programme of upgrading the original PASSYS test cells has improved measurement accuracy. The emphasis has moved from steady state to dynamic methods with shorter test durations yielding improved information and more accurate results. Dynamic test procedures aim to de-couple the different thermal processes within the test cell in order to obtain separation between the thermal transmission and the solar aperture of a component. In parallel with improvements in test methodology, software tools have been developed to enable the identification of the component characteristics and provide statistical information on their accuracies from the dynamic test data. The PASLINK Network has implemented quality procedures and promoted the development of participants' expertise in the design, preparation and execution of tests and the analysis of test data. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Baker, Paul and van Dijk, H.A.L.},
doi = {10.1016/j.buildenv.2006.10.009},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, van Dijk - 2008 - PASLINK and dynamic outdoor testing of building components.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Dynamic testing,Parameter identification,Test cells,Thermal and solar properties},
month = {feb},
number = {2},
pages = {143--151},
title = {{PASLINK and dynamic outdoor testing of building components}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360132306002940},
volume = {43},
year = {2008}
}
@article{ONeill2005,
abstract = {The importance of posterior consistency in the robustness of Bayesian analysis is examined and discussed. The notions of sufficient and minimal sufficient parameters are introduced and important consistency results for such parameters are derived. We see that minimal sufficient parameters are fundamental in characterising the relationship between data and parameters. The concept of identifiability is then introduced and several equivalent definitions are given. The relationship between consistency and identifiability is examined and means of establishing identifiability are examined with a view to finding useful practical tests of identifiability. These results are applied to a simple example involving non response.},
author = {O'Neill, B.},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/156615259.pdf:pdf},
journal = {Finance},
title = {{Consistency and identifiability in bayesian analysis}},
year = {2005}
}
@phdthesis{Chaffar2012,
author = {Chaffar, Khaled},
file = {:home/sarah/OneDrive/Travail/Sources/Thse{\_}finale{\_}Chaffar{\_}Khaled.pdf:pdf},
school = {Universit{\'{e}} d'Artois},
title = {{Thermographie active appliquee a la caracterisation in situ de parois de batiment}},
year = {2012}
}
@article{Andersen2014,
abstract = {This paper presents grey-box modeling of the heat dynamics of an apartment in a highly insulated test building located in the Arctic. Data from a 16-day-long experiment is analyzed and used to fit lumped parameter models formulated as coupled stochastic differential equations. The output of the models is the measured indoor air temperature, and the models are fitted using maximum likelihood techniques with the software CTSM-R. Models are compared using likelihood-ratio tests and validated considering autocorrelation and periodograms of residuals. The fitted models facilitate description of both the fast responses to mechanical ventilation and solar radiation through a large window facade, and the slow responses to floor heating and outdoor temperature. To successfully describe the dynamics of the system, solar radiation is given special attention in modeling of both the physical system and the observational noise. The estimated physical parameters which include UA-value, total heat capacity, and time constants for the apartment are discussed. Simulations are performed to illustrate step and impulse responses of inputs.},
author = {Andersen, Philip Delff and Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Madsen, Henrik and Rode, Carsten},
doi = {10.1007/s12273-014-0185-4},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andersen et al. - 2014 - Characterization of heat dynamics of an arctic low-energy house with floor heating.pdf:pdf},
isbn = {1996-3599},
issn = {19968744},
journal = {Building Simulation},
keywords = {arctic technology,grey-box models,low-energy buildings,statistical modeling,time series analysis},
month = {dec},
number = {6},
pages = {595--614},
publisher = {Tsinghua University Press},
title = {{Characterization of heat dynamics of an arctic low-energy house with floor heating}},
url = {http://link.springer.com/10.1007/s12273-014-0185-4},
volume = {7},
year = {2014}
}
@article{Betancourt2017,
abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous under- standing of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is con- fined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any ex- haustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
archivePrefix = {arXiv},
arxivId = {1701.02434},
author = {Betancourt, Michael},
eprint = {1701.02434},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Betancourt - 2017 - A Conceptual Introduction to Hamiltonian Monte Carlo(2).pdf:pdf},
journal = {arXiv},
title = {{A Conceptual Introduction to Hamiltonian Monte Carlo}},
url = {http://arxiv.org/abs/1701.02434 https://arxiv.org/pdf/1701.02434.pdf},
year = {2017}
}
@article{Kristensen2004a,
abstract = {An efficient and flexible parameter estimation scheme for grey-box models in the sense of discretely, partially observed Ito stochastic differential equations with measurement noise is presented along with a corresponding software implementation. The estimation scheme is based on the extended Kalman filter and features maximum likelihood as well as maximum a posteriori estimation on multiple independent data sets, including irregularly sampled data sets and data sets with occasional outliers and missing observations. The software implementation is compared to an existing software tool and proves to have better performance both in terms of quality of estimates for nonlinear systems with significant diffusion and in terms of reproducibility. In particular, the new tool provides more accurate and more consistent estimates of the parameters of the diffusion term.},
author = {Kristensen, Niels Rode and Madsen, Henrik and J{\o}rgensen, Sten Bay},
doi = {10.1016/j.automatica.2003.10.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kristensen, Madsen, J{\o}rgensen - 2004 - Parameter estimation in stochastic grey-box models.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Estimation with missing observations,Grey-box models,Parameter,Robust estimation,Stochastic differential equations,Stochastic equations of grey box models,estimation accuracy,extended Kalman filter,maximum likelihood estimation,software tools},
mendeley-tags = {Stochastic equations of grey box models},
month = {feb},
number = {2},
pages = {225--237},
title = {{Parameter estimation in stochastic grey-box models}},
url = {http://www.matematik.lu.se/matstat/kurser/fms110mas222/Parameter.estimation.sde.pdf http://linkinghub.elsevier.com/retrieve/pii/S000510980300298X},
volume = {40},
year = {2004}
}
@article{Gori2017a,
abstract = {A dynamic method, comprising a two lumped-thermal-mass model and Markov Chain Monte Carlo sampler, was used to analyze in-situ-monitored data and estimate the thermophysical properties of two walls of different construction. This method, unlike maximum a posteriori approaches, estimates the parameters' probability distributions, providing insight into the wall's thermal structure. Total R-values were well defined for both walls, whilst constituent estimated R-values for a solid wall having layers of materials with similar thermal properties were anticorrelated (thermal mass locations weakly constrained), but were not correlated for an insulated cavity wall with thermally distinct layers (thermal mass locations strongly thermally constrained).},
author = {Gori, Virginia and Elwell, Clifford A.},
doi = {10.1016/j.egypro.2017.09.723},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gori, Elwell - 2017 - Characterization of the thermal structure of different building constructions using in-situ measurements and Bayes.pdf:pdf},
isbn = {1876-6102},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Bayesian statistics,External wall,Grey-box model,Heat transfer,In-situ measurements,MCMC,R-value,Thermal mass,U-value},
pages = {537--542},
publisher = {Elsevier B.V.},
title = {{Characterization of the thermal structure of different building constructions using in-situ measurements and Bayesian analysis}},
url = {https://doi.org/10.1016/j.egypro.2017.09.723},
volume = {132},
year = {2017}
}
@article{Goodman2010,
abstract = {We propose a family of Markov chain Monte Carlo methods whose performance is unaffected by affine tranformations of space. These algorithms are easy to construct and require little or no additional computational overhead. They should be particularly useful for sampling badly scaled distributions. Computational tests show that the affine invariant methods can be significantly faster than standard MCMC methods on highly skewed distributions.},
author = {Goodman, Jonathan and Weare, Jonathan},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodman, Weare - 2010 - ENSEMBLE SAMPLERS WITH AFFINE INVARIANCE.pdf:pdf},
journal = {COMM. APP. MATH. AND COMP. SCI},
keywords = {emcee},
mendeley-tags = {emcee},
number = {1},
title = {{ENSEMBLE SAMPLERS WITH AFFINE INVARIANCE}},
url = {http://msp.org/camcos/2010/5-1/camcos-v5-n1-p04-s.pdf},
volume = {5},
year = {2010}
}
@article{Audoly2001,
abstract = {A prerequisite for well-posedness of parameter estimation of biological and physiological systems is a priori global identifiability, a property which concerns uniqueness of the solution for the unknown model parameters. Assessing a priori global identifiability is particularly difficult for nonlinear dynamic models. Various approaches have been proposed in the literature but no solution exists in the general case. In this paper, we present a new algorithm for testing global identifiability of nonlinear dynamic models, based on differential algebra. The characteristic set associated to the dynamic equations is calculated in an efficient way and computer algebra techniques are used to solve the resulting set of nonlinear algebraic equations. The algorithm is capable of handling many features arising in biological system models, including zero initial conditions and time-varying parameters. Examples of usage of the algorithm for analyzing a priori global identifiability of nonlinear models of biological and physiological systems are presented.},
author = {Audoly, Stefania and Bellu, Giuseppina and D'Angio, L. and Saccomani, M.P. and Cobelli, C.},
doi = {10.1109/10.900248},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Audoly et al. - 2001 - Global identifiability of nonlinear models of biological systems.pdf:pdf},
isbn = {0018-9294 VO - 48},
issn = {00189294},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {A priori identifiability,Compartmental models,Differential algebra,Gri??bner basis,Model identification,Parameter estimation},
number = {1},
pages = {55--65},
pmid = {11235592},
title = {{Global identifiability of nonlinear models of biological systems}},
url = {http://ieeexplore.ieee.org/document/900248/},
volume = {48},
year = {2001}
}
@article{VanDoren2008,
abstract = {In this paper identifiable parameterizations are determined for models of flow in porous media as applied in the field of petroleum reservoir engineering. Starting from a large-scale, physics-based model parameterization with an extensive parameter space, the best identifiable reduced dimensional parameterization is constructed. This is achieved through the development of an analytical expression for the (finite-time) information matrix of the problem. It is shown that the information matrix can be expressed in terms of controllability and observability properties of the model and the sensitivity of the state space matrices w.r.t. the parameter vector. A reduced dimensional subspace is then obtained after a singular value decomposition of the information matrix, leading to the use of basis functions (spatial patterns) in the original parameter space. The approach is applied to two reservoir models: a siso model with 49 parameters and a mimo model with 441 parameters.},
author = {{Van Doren}, Jorn F.M. and {Van den Hof}, Paul M.J. and Jansen, Jan Dirk and Bosgra, Okko H},
doi = {10.3182/20080706-5-KR-1001.01935},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Doren et al. - 2008 - Determining Identifiable Parameterizations for Large-scale Physical Models in Reservoir Engineering ⋆.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Grey box modelling},
number = {2},
pages = {11421--11426},
title = {{Determining Identifiable Parameterizations for Large-scale Physical Models in Reservoir Engineering}},
url = {http://www.pvandenhof.nl/Paperfiles/VanDoren{\&}etal{\_}IFAC2008{\_}2118.pdf https://linkinghub.elsevier.com/retrieve/pii/S1474667016408037},
volume = {41},
year = {2008}
}
@article{Ballarini2014,
abstract = {Retrofit actions applied to the existent building stock aim at increasing the energy performance, considering the optimal trade-off between energy savings and costs, according to the Directive 2010/31/EU. To select effective refurbishment measures and to quantify the energy saving potentials of the existent building stock, the analysis should be performed on "reference buildings".This article presents a methodology for the identification of reference buildings, according to the IEE-TABULA project (2009-12) aimed at creating a harmonised structure for "European Building Typologies". Among the possible applications of the building typology, this work focuses on the potentialities of energy savings and CO2 emission reductions for the European residential building stock. In particular, the Italian approach to model the energy balance of a subset of the national building stock is described; the results show the enormous potentialities of energy savings even with basic energy retrofit actions. Cost analyses were not in the scope of the project, but the results of this study are the basis for further investigations aimed at assessing the cost effectiveness of sets of measures. In this regard, the TABULA building-types are being applied by the Italian government for calculating cost-optimal levels of energy performance, complying with the Directive 2010/31/EU objectives. {\textcopyright} 2014 Elsevier Ltd.},
author = {Ballarini, Ilaria and Corgnati, Stefano Paolo and Corrado, Vincenzo},
doi = {10.1016/j.enpol.2014.01.027},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0301421514000329-main.pdf:pdf},
issn = {03014215},
journal = {Energy Policy},
keywords = {Energy saving,Reference building,Residential building stock},
pages = {273--284},
publisher = {Elsevier},
title = {{Use of reference buildings to assess the energy saving potentials of the residential building stock: The experience of TABULA project}},
url = {http://dx.doi.org/10.1016/j.enpol.2014.01.027},
volume = {68},
year = {2014}
}
@article{Sandberg2016,
abstract = {A dynamic building stock model is applied to simulate the development of dwelling stocks in 11 European countries, over half of all European dwellings, between 1900 and 2050. The model uses time series of population and number of persons per dwelling, as well as demolition and renovation probability functions that have been derived for each country. The model performs well at simulating the long-term changes in dwelling stock composition and expected annual renovation activities. Despite differences in data collection and reporting, the modelled future trends for construction, demolition and renovation activities lead to similar patterns emerging in all countries. The model estimates future renovation activity due to the stock's need for maintenance as a result of ageing. The simulations show only minor future increases in the renovation rates across all 11 countries to between 0.6–1.6{\%}, falling short of the 2.5–3.0{\%} renovation rates that are assumed in many decarbonisation scenarios. Despite this, 78{\%} of all dwellings could benefit from energy efficiency measures by 2050, either as they are constructed (31{\%}) or undergo deep renovation (47{\%}). However, as no more than one deep renovation cycle is likely on this timeframe, it is crucial to install the most energy efficient measures available at these opportunities.},
author = {Sandberg, Nina Holck and Sartori, Igor and Heidrich, Oliver and Dawson, Richard and Dascalaki, Elena and Dimitriou, Stella and Vimm-r, Tom{\'{a}}{\v{s}} and Filippidou, Faidra and Stegnar, Ga{\v{s}}per and {{\v{S}}ijanec Zavrl}, Marjana and Bratteb{\o}, Helge},
doi = {10.1016/j.enbuild.2016.05.100},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0378778816304893-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Comparative analysis,Dwelling stock,Dynamic modelling,Energy efficiency,Europe,Housing,Renovation},
pages = {26--38},
title = {{Dynamic building stock modelling: Application to 11 European countries to support the energy efficiency and retrofit ambitions of the EU}},
volume = {132},
year = {2016}
}
@article{Velilla2018,
author = {Velilla, Santiago and Thu, Huong Nguyen},
doi = {10.1016/j.jspi.2018.01.002},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Velilla, Nguyen Thu - 2018 - A goodness-of-fit test for VARMA(p,q) models(2).pdf:pdf},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Identifiability condition of Hannan 1969},
mendeley-tags = {Identifiability condition of Hannan 1969},
month = {dec},
pages = {126--140},
title = {{A goodness-of-fit test for VARMA( p, q ) models}},
url = {https://doi.org/10.1016/j.jspi.2018.01.002. https://linkinghub.elsevier.com/retrieve/pii/S0378375818300041},
volume = {197},
year = {2018}
}
@book{Booth2008,
abstract = {In order to engage with your readers while writing a research paper, you would have to create roles. For example, if you are writing a research about you must have in mind the audience you would like to appeal to, whether the readers know the subject you are about to touch upon, or just start from scratch, giving the readers the background and etc. about the topic being research.},
author = {Booth, Wayne C and Colomb, Gregory G and Williams, Joseph M},
file = {:home/sarah/OneDrive/Travail/Sources/Orga Perso/Book Research seminar by Booth.pdf:pdf},
isbn = {9780226065656;0226065650;9780226065663;0226065669;},
keywords = {Methodology,Research,Technical writing},
pages = {N/A--N/A},
title = {{The craft of research: Wayne C. Booth, Gregory G. Colomb, Joseph M. Williams}},
volume = {3rd},
year = {2008}
}
@article{Menberg2019,
abstract = {{\textcopyright} 2018 The Author(s). Published by Informa UK Limited, trading as Taylor {\&} Francis Group. Calibration represents a crucial step in the modelling process to obtain accurate simulation results and quantify uncertainties. We scrutinize the statistical Kennedy {\&} O'Hagan framework, which quantifies different sources of uncertainty in the calibration process, including both model inputs and errors in the model. In specific, we evaluate the influence of error terms on the posterior predictions of calibrated model inputs. We do so by using a simulation model of a heat pump in cooling mode. While posterior values of many parameters concur with the expectations, some parameters appear not to be inferable. This is particularly true for parameters associated with model discrepancy, for which prior knowledge is typically scarce. We reveal the importance of assessing the identifiability of parameters by exploring the dependency of posteriors on the assigned prior knowledge. Analyses with random datasets show that results are overall consistent, which confirms the applicability and reliability of the framework.},
author = {Menberg, Kathrin and Heo, Yeonsook and Choudhary, Ruchi},
doi = {10.1080/19401493.2018.1475506},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/Influence of error terms in Bayesian calibration of energy system models.pdf:pdf},
issn = {1940-1493},
journal = {Journal of Building Performance Simulation},
keywords = {Bayesian inference,building energy model,energy system model,inverse problems,model calibration,uncertainty quantification},
month = {jan},
number = {1},
pages = {82--96},
publisher = {Taylor {\&} Francis},
title = {{Influence of error terms in Bayesian calibration of energy system models}},
url = {https://www.tandfonline.com/doi/full/10.1080/19401493.2018.1475506},
volume = {12},
year = {2019}
}
@phdthesis{SRINIVASARENGAN2018,
author = {SRINIVASARENGAN, Krishnan},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/SRINIVASARENGAN - 2018 - Estimation d'{\'{e}}tat , estimation param{\'{e}}trique et identifiabilit{\'{e}} des mod{\`{e}}les quasi-LPV.pdf:pdf},
pages = {164},
school = {Universit{\'{e}} de Lorraine},
title = {{Estimation d'{\'{e}}tat , estimation param{\'{e}}trique et identifiabilit{\'{e}} des mod{\`{e}}les quasi-LPV}},
year = {2018}
}
@article{Wilkinson2013a,
author = {Wilkinson, Richard David},
doi = {10.1515/sagmb-2013-0010},
issn = {1544-6115},
journal = {Statistical Applications in Genetics and Molecular Biology},
month = {jan},
number = {2},
title = {{Approximate Bayesian computation (ABC) gives exact results under the assumption of model error}},
url = {https://www.degruyter.com/view/j/sagmb.2013.12.issue-2/sagmb-2013-0010/sagmb-2013-0010.xml},
volume = {12},
year = {2013}
}
@article{Gordon1993,
abstract = {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linear-ity or Gaussian noise: it may be applied to any state transition or measurement model. A simula-tion example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.},
annote = {Annonc{\'{e}} comme plus efficace que le filtre de Kalman {\'{e}}tendu !

M{\'{e}}thode de filtrage bay{\'{e}}sien : nouvel algorithme?

Mais les auteurs avouent eux-m{\^{e}}mes},
author = {Gordon, N.J. and Salmond, D.J. and Smith, A.F.M.},
doi = {10.1049/ip-f-2.1993.0015},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon, Salmond, Smith - 1993 - Novel approach to nonlinearnon-Gaussian Bayesian state estimation.pdf:pdf},
issn = {0956375X},
journal = {IEE Proceedings F Radar and Signal Processing},
number = {2},
pages = {107},
title = {{Novel approach to nonlinear/non-Gaussian Bayesian state estimation}},
url = {http://www3.nd.edu/{~}lemmon/courses/ee67033/pubs/GordonSalmondSmith93.pdf http://digital-library.theiet.org/content/journals/10.1049/ip-f-2.1993.0015},
volume = {140},
year = {1993}
}
@phdthesis{Zayane2011b,
author = {Zayane, Chadia},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chadia - 2011 - Identification d'un mod{\`{e}}le de comportement thermique de b{\^{a}}timent {\`{a}} partir de sa courbe de charge.pdf:pdf},
keywords = {Identification,Inversion bay{\'{e}}sienne,Simulation stochastique,tableaux,{\'{E}}chantillonneur de Gibbs},
school = {ParisTech Ecole nationale sup{\'{e}}rieure des mines de Paris},
title = {{Identification d'un mod{\`{e}}le de comportement thermique de b{\^{a}}timent {\`{a}} partir de sa courbe de charge}},
year = {2011}
}
@book{Nocedal2006,
author = {Nocedal, Jorge and Wright, Stephen J.},
doi = {10.1007/978-0-387-40065-5},
file = {:home/sarah/OneDrive/Travail/Sources/Jorge Nocedal, Stephen Wright - Numerical Optimization-Springer (2006).pdf:pdf},
isbn = {978-0-387-30303-1},
number = {2nd edition},
publisher = {Springer New York},
series = {Springer Series in Operations Research and Financial Engineering},
title = {{Numerical Optimization}},
url = {http://link.springer.com/10.1007/978-0-387-40065-5},
year = {2006}
}
@article{Fonnesbeck2013,
author = {Fonnesbeck, Christopher J},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fonnesbeck - 2013 - PyMC Documentation.pdf:pdf},
title = {{PyMC Documentation}},
year = {2013}
}
@book{Features2005,
author = {Features, K E Y},
booktitle = {Signal Processing},
doi = {10.1016/S0165-1684(05)00059-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Features - 2005 - Contents.pdf:pdf},
issn = {01651684},
month = {may},
number = {5},
title = {{Contents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168405000599},
volume = {85},
year = {2005}
}
@article{Kroll2017,
abstract = {A multitude of new applications in bioprocess technology strongly depend on model-based methods as they feature prediction and control capabilities. The critical path is usually the availability of suitable models. In this work a workflow for the generation of substantial target-oriented mechanistic process models is presented. This workflow is based on backpropagation starting from a material balance for a certain target variable. Iteratively, necessary states as well as mechanistic links are included in the model using a model library reducing the computational effort. The parameters of these links are estimated using a simplex algorithm whose objective function depends on the target variable only. Practical identifiability analysis is used for the assessment of the need of further iterations and for validating the mechanistic model. To demonstrate the workflow, a model describing a mammalian cell culture process aiming at modeling viable cell count is used as an example. The generated model satisfies the predefined requirements and is very simple, consisting of three states and seven model parameters only. The presented workflow is simple, generic, transparent, so that also applications in a regulatory environment should be possible. It also provides additional process knowledge that can be used in bioprocess development and optimization.},
author = {Kroll, Paul and Hofer, Alexandra and Stelzer, Ines V and Herwig, Christoph},
doi = {10.1016/j.procbio.2017.07.017},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kroll et al. - 2017 - Workflow to set up substantial target-oriented mechanistic process models in bioprocess engineering.pdf:pdf},
issn = {13595113},
journal = {Process Biochemistry},
keywords = {Bioprocess engineering,Mechanistic links,Modeling workflow,Practical identifiability,Substantial target-oriented mechanistic models},
month = {nov},
pages = {24--36},
title = {{Workflow to set up substantial target-oriented mechanistic process models in bioprocess engineering}},
url = {http://ac.els-cdn.com.camphrier-2.grenet.fr/S1359511316303981/1-s2.0-S1359511316303981-main.pdf?{\_}tid=a95157ba-8651-11e7-8dab-00000aab0f6c{\&}acdnat=1503307279{\_}0c8d1b9a6e9f52c08e5042795c54a0d0 https://linkinghub.elsevier.com/retrieve/pii/S1359511316303981},
volume = {62},
year = {2017}
}
@techreport{Johnston2013,
abstract = {1: In the UK, as in most industrialised countries, the domestic sector contributes substantially to national energy use and CO2 emissions. Currently, there are over 25 million dwellings in the UK accounting for just under 30{\%} of the UK's total CO2 emissions (DECC, 2011). This is a substantial figure given that the UK housing stock is categorised by long physical lifetimes and slow stock turnover. Therefore, if we are to mitigate the effects of climate change and achieve the Government's target of an 80{\%} reduction in national CO2 emissions by 2050 based on 1990 levels, then significant reductions in the carbon emissions from both new and existing dwellings will be required. 2: One factor that can have a significant impact on the energy use and CO2 emissions attributable to dwellings is the performance of the building fabric. However, the performance of the building fabric is very rarely understood and is often taken for granted, particularly in in-use monitoring studies. Therefore, in the past, there has been a tendency for any discrepancies that are found between the monitored and predicted performance of the dwelling to be attributed to occupant behaviour. However, recent work undertaken by Leeds Metropolitan University (see Wingfield et al., 2009 and Zero Carbon Hub, 2010) has found that the performance of the building fabric can have a significant influence on overall energy and CO2 emissions. Consequently, very few conclusions can be drawn from in-use monitoring studies unless the performance of the building fabric is understood. It should also be remembered that the domestic building fabric in the UK tends to have long physical lifetimes and slow replacement cycles. Therefore, it is crucial that we not only measure and analyse the performance of the building fabric as built, but in doing so, take the opportunities that arise to improve our understanding of fabric performance under real life conditions and the factors that influence this performance. Otherwise, there is a very real risk that we will leave a legacy of dwellings with poorly performing building fabric for generations to come 3: A wide range of techniques are available that can be used to measure the performance of various aspects of the building fabric once constructed. These include pressurisation testing, leakage detection, tracer gas measurement, cavity temperature measurement, heat flux measurement, thermal imaging, partial deconstruction and air flow measurements. Central to all of these techniques is the co-heating test (see Figure 1).},
author = {Johnston, David and Miles-Shenton, Dominic and Farmer, David and Wingfield, Jez},
file = {:home/sarah/OneDrive/Travail/Sources/cebe{\_}coheating{\_}test{\_}method{\_}june2013.pdf:pdf},
institution = {Centre for Built Environment},
title = {{Whole House Heat Loss Test Method (Coheating)}},
year = {2013}
}
@article{Bacher2011,
abstract = {The present paper suggests a procedure for identification of suitable models for the heat dynamics of a building. Such a procedure for model identification is essential for better usage of readings from smart meters, which is expected to be installed in almost all buildings in the coming years. The models can be used for different purposes, e.g. control of the indoor climate, forecasting of energy consumption, and for accurate description of energy performance of the building. Grey-box models based on prior physical knowledge and data-driven modelling are applied. This facilitates insight into otherwise hidden information about the physical properties of the building. A hierarchy of models of increasing complexity is formulated based on prior physical knowledge and a forward selection strategy is suggested enabling the modeller to iteratively select suitable models of increasing complexity. The performance of the models is compared using likelihood ratio tests, and they are validated using a combination of appropriate statistics and physical interpretation of the results. A case study is described in which a suitable model is sought after for a single storey 120 m 2 building. The result is a set of different models of increasing complexity, with which building characteristics, such as: thermal conductivity, heat capacity of different parts, and window area, are estimated. ?? 2011 Elsevier B.V. All rights reserved.},
annote = {From Duplicate 2 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

From Duplicate 1 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

From Duplicate 1 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

Sur la base d'un mod{\`{e}}le RC de b{\^{a}}timent, les auteurs ont d{\'{e}}velopp{\'{e}} un algo de s{\'{e}}lection de mod{\`{e}}le sur la base d'un test statistique. En partant d'un mod{\`{e}}le simple, on complexifie le mod{\`{e}}le puis on {\'{e}}value le ratio de vraisemblance pour d{\'{e}}terminer sur le mod{\`{e}}le plus complexe donne significativement de meilleurs r{\'{e}}sultats que le sous-mod{\`{e}}le. La s{\'{e}}lection s'arr{\^{e}}te si aucun des mod{\`{e}}les candidats n'am{\'{e}}liore la vraisemblance.
Ce n'est pas un algo {\`{a}} proprement parler car l'expert doit {\^{e}}tre partie active dans la strat{\'{e}}gie de choix (tout n'est pas cod{\'{e}} en somme, l'expert lui-m{\^{e}}me doit {\'{e}}valuer la n{\'{e}}cessit{\'{e}} ou non de continuer, {\'{e}}tant donn{\'{e}}s les r{\'{e}}sultats obtenus pr{\'{e}}c{\'{e}}demment)
L'expert {\'{e}}value les r{\'{e}}sultats des estimations donn{\'{e}}es par le mod{\`{e}}le en analysant les residuals et les estimations. Si les estimations obtenues ne collent pas {\`{a}} la r{\'{e}}alit{\'{e}}, il a l'initiative d'influencer le choix du mod{\`{e}}le suivant, de choisir l'am{\'{e}}lioration qui conviendrait le mieux.
1) des mod{\`{e}}les am{\'{e}}lior{\'{e}}s du mod{\`{e}}le actuel est calibr{\'{e}} par maximum likelihood estimation
2) test du ratio de vraisemblance : calcul du test pour le mod{\`{e}}le actuel et chacun des mod{\`{e}}les am{\'{e}}lior{\'{e}}s. Si aucun des tests effectu{\'{e}}s ne donne un valeur p inf{\'{e}}rieure {\`{a}} 5{\%}, alors le mod{\`{e}}le actuel est le meilleur et on peut le garder. Sinon, parmi ceux qui ont une valeur p inf{\'{e}}rieure {\`{a}} 5 {\%}, on garde le mod{\`{e}}le am{\'{e}}lior{\'{e}} qui a la plus petite valeur p. Dans tous les cas, on analyse les r{\'{e}}sultats obtenus pour voir quels ph{\'{e}}nom{\`{e}}nes physiques sont mal pris en compte et on am{\'{e}}liore le mod{\`{e}}le actuel vis {\`{a}} vis de ces d{\'{e}}ficiences.


Les auteurs proposent une auto-correlation function et un cumulated periodogram pour {\'{e}}valuer les manquements du mod{\`{e}}le {\'{e}}valu{\'{e}} vis {\`{a}} vis des ph{\'{e}}nom{\`{e}}nes physiques non expliqu{\'{e}}s. Si le bruit qui reste est clairement d{\'{e}}pendant des donn{\'{e}}es, on n'a pas fini. En revanche, d{\`{e}}s que les r{\'{e}}siduels ressemblent {\`{a}} du bruit blanc, le mod{\`{e}}le est correct.
Dans cet exercice en particulier, il reste deux zones clairement non prises en compte physiquement. Les mod{\`{e}}les RC propos{\'{e}}s, y/c leurs am{\'{e}}liorations, ne peuvent prendre ne compte ces ph{\'{e}}nom{\`{e}}nes car l'algo de s{\'{e}}lection de mod{\`{e}}le ne donne plus rien d'int{\'{e}}ressant.
Cela signifie qu'il faut changer qqch dans la description physique de base : prise en compte de la radiation solaire ou int{\'{e}}gration de la radiation solaire dans le processus Wiener...


Description en annexe des 15 mod{\`{e}}les RC propos{\'{e}}s.

From Duplicate 2 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

From Duplicate 2 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

From Duplicate 1 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

Sur la base d'un mod{\`{e}}le RC de b{\^{a}}timent, les auteurs ont d{\'{e}}velopp{\'{e}} un algo de s{\'{e}}lection de mod{\`{e}}le sur la base d'un test statistique. En partant d'un mod{\`{e}}le simple, on complexifie le mod{\`{e}}le puis on {\'{e}}value le ratio de vraisemblance pour d{\'{e}}terminer sur le mod{\`{e}}le plus complexe donne significativement de meilleurs r{\'{e}}sultats que le sous-mod{\`{e}}le. La s{\'{e}}lection s'arr{\^{e}}te si aucun des mod{\`{e}}les candidats n'am{\'{e}}liore la vraisemblance.
Ce n'est pas un algo {\`{a}} proprement parler car l'expert doit {\^{e}}tre partie active dans la strat{\'{e}}gie de choix (tout n'est pas cod{\'{e}} en somme, l'expert lui-m{\^{e}}me doit {\'{e}}valuer la n{\'{e}}cessit{\'{e}} ou non de continuer, {\'{e}}tant donn{\'{e}}s les r{\'{e}}sultats obtenus pr{\'{e}}c{\'{e}}demment)
L'expert {\'{e}}value les r{\'{e}}sultats des estimations donn{\'{e}}es par le mod{\`{e}}le en analysant les residuals et les estimations. Si les estimations obtenues ne collent pas {\`{a}} la r{\'{e}}alit{\'{e}}, il a l'initiative d'influencer le choix du mod{\`{e}}le suivant, de choisir l'am{\'{e}}lioration qui conviendrait le mieux.
1) des mod{\`{e}}les am{\'{e}}lior{\'{e}}s du mod{\`{e}}le actuel est calibr{\'{e}} par maximum likelihood estimation
2) test du ratio de vraisemblance : calcul du test pour le mod{\`{e}}le actuel et chacun des mod{\`{e}}les am{\'{e}}lior{\'{e}}s. Si aucun des tests effectu{\'{e}}s ne donne un valeur p inf{\'{e}}rieure {\`{a}} 5{\%}, alors le mod{\`{e}}le actuel est le meilleur et on peut le garder. Sinon, parmi ceux qui ont une valeur p inf{\'{e}}rieure {\`{a}} 5 {\%}, on garde le mod{\`{e}}le am{\'{e}}lior{\'{e}} qui a la plus petite valeur p. Dans tous les cas, on analyse les r{\'{e}}sultats obtenus pour voir quels ph{\'{e}}nom{\`{e}}nes physiques sont mal pris en compte et on am{\'{e}}liore le mod{\`{e}}le actuel vis {\`{a}} vis de ces d{\'{e}}ficiences.


Les auteurs proposent une auto-correlation function et un cumulated periodogram pour {\'{e}}valuer les manquements du mod{\`{e}}le {\'{e}}valu{\'{e}} vis {\`{a}} vis des ph{\'{e}}nom{\`{e}}nes physiques non expliqu{\'{e}}s. Si le bruit qui reste est clairement d{\'{e}}pendant des donn{\'{e}}es, on n'a pas fini. En revanche, d{\`{e}}s que les r{\'{e}}siduels ressemblent {\`{a}} du bruit blanc, le mod{\`{e}}le est correct.
Dans cet exercice en particulier, il reste deux zones clairement non prises en compte physiquement. Les mod{\`{e}}les RC propos{\'{e}}s, y/c leurs am{\'{e}}liorations, ne peuvent prendre ne compte ces ph{\'{e}}nom{\`{e}}nes car l'algo de s{\'{e}}lection de mod{\`{e}}le ne donne plus rien d'int{\'{e}}ressant.
Cela signifie qu'il faut changer qqch dans la description physique de base : prise en compte de la radiation solaire ou int{\'{e}}gration de la radiation solaire dans le processus Wiener...


Description en annexe des 15 mod{\`{e}}les RC propos{\'{e}}s.},
author = {Bacher, Peder and Madsen, Henrik},
doi = {10.1016/j.enbuild.2011.02.005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bacher, Madsen - 2011 - Identifying suitable models for the heat dynamics of buildings(2).pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Buildings,Continuous time modelling,Grey-box models,Heat dynamics,Likelihood ratio tests,Lumped models,Model selection,Parameter estimation,Thermal dynamics,continuous time modelling,likelihood ratio tests},
month = {jul},
number = {7},
pages = {1511--1522},
publisher = {Elsevier B.V.},
title = {{Identifying suitable models for the heat dynamics of buildings}},
url = {http://dx.doi.org/10.1016/j.enbuild.2011.02.005 https://linkinghub.elsevier.com/retrieve/pii/S0378778811000491},
volume = {43},
year = {2011}
}
@article{Kreutz2018,
abstract = {The feasibility of uniquely estimating parameters of dynamical systems from observations is a widely discussed aspect of mathematical modelling. Several approaches have been published for analyzing identifiability. However, they are typically computationally demanding, difficult to perform and/or not applicable in many application settings. Here, an intuitive approach is presented which enables quickly testing of parameter identifiability. Numerical optimization with a penalty in radial direction enforcing displacement of the parameters is used to check whether estimated parameters are unique, or whether the parameters can be altered without loss of agreement with the data indicating non-identifiability. This Identifiability-Test by Radial Penalization (ITRP) can be employed for every model where optimization-based fitting like least-squares or maximum likelihood is feasible and is therefore applicable for all typical deterministic models. The approach is illustrated and tested using 11 ordinary differential equation (ODE) models. The presented approach can be implemented without great efforts in any modelling framework. It is available within the free Matlab-based modelling toolbox Data2Dynamics. Source code is available at https://github.com/Data2Dynamics.},
author = {Kreutz, Clemens},
doi = {10.1093/bioinformatics/bty035},
editor = {Berger, Bonnie},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kreutz - 2018 - An easy and efficient approach for testing identifiability(2).pdf:pdf;:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/bty035.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jun},
number = {11},
pages = {1913--1921},
title = {{An easy and efficient approach for testing identifiability}},
url = {https://academic.oup.com/bioinformatics/article/34/11/1913/4820336},
volume = {34},
year = {2018}
}
@article{Stuart2013b,
abstract = {These lecture notes provide an introduction to the forthcoming book "Bayesian Inverse Problems in Differential Equations" by M. Dashti, M. Hairer and A.M. Stuart},
archivePrefix = {arXiv},
arxivId = {1302.6989},
author = {Stuart, Andrew M},
eprint = {1302.6989},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuart - 2013 - The Bayesian Approach To Inverse Problems.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stuart - 2013 - The Bayesian Approach To Inverse Problems(2).pdf:pdf},
journal = {arXiv preprint},
keywords = {bayesian inversion,inverse problems,markov chain monte carlo,monte carlo,sequential,stochastic partial differential equations},
pages = {1--36},
title = {{The Bayesian Approach To Inverse Problems}},
url = {http://arxiv.org/abs/1302.6989},
year = {2013}
}
@techreport{Sengupta2015,
abstract = {As the world looks for low-carbon sources of energy, solar power stands out as the single most abundant energy resource on Earth. Harnessing this energy is the challenge for this century. Photovoltaics, solar heating and cooling, and concentrating solar power (CSP) are primary forms of energy applications using sunlight. These solar energy systems use different technologies, collect different fractions of the solar resource, and have different siting requirements and production capabilities. Reliable information about the solar resource is required for every solar energy application. This holds true for small installations on a rooftop as well as for large solar power plants. However, solar resource information is of particular interest for large installations, because they require a substantial investment, sometimes exceeding {\$}1 billion in construction costs. Before such a project is undertaken, the best possible information about the quality and reliability of the fuel source must be made available. That is, project developers need to have reliable data about the solar resource available at specific locations, including historic trends with seasonal, daily, hourly, and (preferably) subhourly variability to predict the daily and annual performance of a proposed power plant. Without this data, an accurate financial analysis is not possible.},
author = {Sengupta, M and Habte, A and Kurtz, S and Dobos, A and Wilbert, S and Lorenz, E and Stoffel, T and Renn{\'{e}}, D and Gueymard, C and Myers, D and Wilcox, S and Blanc, P and Perez, R},
booktitle = {Technical Report - NREL/TP-5D00-63112},
doi = {10.1016/j.solener.2003.12.003},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sengupta et al. - 2015 - Best Practices Handbook for the Collection and Use of Solar Resource Data for Solar Energy Applications Best Pr.pdf:pdf},
institution = {National Renewable Energy Laboratory},
isbn = {0038-092X},
issn = {0038092X},
keywords = {February 2015,NREL,NREL/TP-5D00-63112,National Renewable Energy Laboratory,concentrating solar power,photovoltaics,solar data,solar heating and cooling,solar power},
number = {February},
pages = {1--255},
title = {{Best Practices Handbook for the Collection and Use of Solar Resource Data for Solar Energy Applications Best Practices Handbook for the Collection and Use of Solar Resource Data for Solar Energy Applications(www.nrel.gov/publications)}},
year = {2015}
}
@inproceedings{Berger2010,
address = {Kuwait},
author = {Berger, Julian and Sihem, Tasca-Guernouti and Myriam, Humbert},
booktitle = {10th International Conference for Enhanced Building Operations},
file = {:home/sarah/OneDrive/Travail/Sources/ESL-IC-10-10-37.pdf:pdf},
keywords = {EBBE},
mendeley-tags = {EBBE},
title = {{Experimental method to determine the energy envelope performance of buildings}},
year = {2010}
}
@article{Reynders2014,
abstract = {The integration of buildings in a Smart Grid, enabling demand-side management and thermal storage, requires robust reduced-order building models that allow for the development and evaluation of demand-side management control strategies. To develop such models for existing buildings, with often unknown the thermal properties, data-driven system identification methods are proposed. In this paper, system identification is carried out to identify suitable reduced-order models. Therefore, grey-box models of increasing complexity are identified on results from simulations with a detailed physical model, deployed in the integrated district energy assessment simulation (IDEAS) package in Modelica. Firstly, the robustness of identified grey-box models for day-ahead predictions and simulations of the thermal response of a dwelling, as well as the physical interpretation of the identified parameters, are analyzed. The influence of the identification dataset is quantified, comparing the added value of dedicated identification experiments against identification on data from in use buildings. Secondly, the influence of the data used for identification on model performance and the reliability of the parameter estimates is quantified. Both alternative measurements and the influence of noise on the data are considered. ?? 2014 Elsevier B.V.},
annote = {5 mod{\`{e}}les RC simplifi{\'{e}}s : page ??

Probl{\`{e}}me inverse sur des donn{\'{e}}es de simulation  de deux maisons venant du projt TABULA (typique belge).
     --{\textgreater} Utiliser les mod{\`{e}}les MOZART de EDF?
Analyse des r{\'{e}}siduals pour estimer les {\'{e}}l{\'{e}}ments mal pris en compte dans le mod{\`{e}}le.
Conclusions : ordre 4 et 5 fit bien les donn{\'{e}}es de la simul d{\'{e}}taill{\'{e}}e.
Incertitude sur les r{\'{e}}sultats du mod{\`{e}}le d'ordre 5 sont tr{\`{e}}s d{\'{e}}pendantes de la qualit{\'{e}} des donn{\'{e}}es d'entr{\'{e}}e (normal puisque le probl{\`{e}}me est peut-{\^{e}}tre mal pos{\'{e}}, ou mal identifiable!)




Notes perso : L'article met en {\'{e}}vidence un probl{\`{e}}me d'identifiabilit{\'{e}} sur les ordres 4 et 5 (surtout 5) de ses mod{\`{e}}les RC, mise en {\'{e}}vidence mais pas quantifi{\'{e}}e.Les r{\'{e}}sultats sont compar{\'{e}}s au mod{\`{e}}le simul{\'{e}} en d{\'{e}}tail, mais plut{\^{o}}t subjectivement.
Cette m{\'{e}}thodo ne pourra pas {\^{e}}tre utilis{\'{e}}e en aveugle, dans le cadre o{\`{u}} on ne sait pas ce qu'on doit obtenir.
--{\textgreater} Int{\'{e}}r{\^{e}}t de ma th{\`{e}}se : trouver des crit{\`{e}}res objectifs pour juger de la non-identifiabilit{\'{e}}.
Pouvoir juger de l'identifiabilit{\'{e}} par des crit{\`{e}}res objetifs permettra de travailler "en aveugle" c{\`{a}}d dans un cadre o{\`{u}} on ne conna{\^{i}}t pas les r{\'{e}}sultats qu'on doit obtenir.},
author = {Reynders, Glenn and Diriken, J. and Saelens, Dirk},
doi = {10.1016/j.enbuild.2014.07.025},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reynders, Diriken, Saelens - 2014 - Quality of grey-box models and identified parameters as function of the accuracy of input and observ.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building energy simulation,Grey box,Grey-box modelling,Reduced-order models,calibration,identification,prediction},
mendeley-tags = {Grey box,calibration,identification,prediction},
number = {0},
pages = {263--274},
title = {{Quality of grey-box models and identified parameters as function of the accuracy of input and observation signals}},
volume = {82},
year = {2014}
}
@article{Pathak2019,
abstract = {Modeling buildings' heat dynamics is a complex process which depends on various factors including weather, building thermal capacity, insulation preservation, and residents' behavior. Gray-box models offer a causal inference of those dynamics expressed in few parameters specific to built environments. These parameters can provide compelling insights into the characteristics of building artifacts and have various applications such as forecasting HVAC usage, indoor temperature control monitoring of built environments, etc. In this paper, we present a systematic study of modeling buildings' thermal characteristics and thus derive the parameters of built conditions with a Bayesian approach. We build a Bayesian state-space model that can adapt and incorporate buildings' thermal equations and propose a generalized solution that can easily adapt prior knowledge regarding the parameters. We show that a faster approximate approach using variational inference for parameter estimation can provide similar parameters as that of a more time-consuming Markov Chain Monte Carlo (MCMC) approach. We perform extensive evaluations on two datasets to understand the generative process and show that the Bayesian approach is more interpretable. We further study the effects of prior selection for the model parameters and transfer learning, where we learn parameters from one season and use them to fit the model in the other. We perform extensive evaluations on controlled and real data traces to enumerate buildings' parameter within a 95{\%} credible interval.},
archivePrefix = {arXiv},
arxivId = {1901.07469},
author = {Pathak, Nilavra and Foulds, James and Roy, Nirmalya and Banerjee, Nilanjan and Robucci, Ryan},
eprint = {1901.07469},
file = {:home/sarah/OneDrive/Travail/Sources/EstimatingBuildingsParametersoverTimeIncludingPriorKnowledge.pdf:pdf},
number = {February},
title = {{Estimating Buildings' Parameters over Time Including Prior Knowledge}},
url = {http://arxiv.org/abs/1901.07469},
year = {2019}
}
@article{Ghiaus2006,
author = {Ghiaus, Cristian},
doi = {10.1016/j.enbuild.2005.08.014},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiaus - 2006 - Experimental estimation of building energy performance by robust regression.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
month = {jun},
number = {6},
pages = {582--587},
title = {{Experimental estimation of building energy performance by robust regression}},
url = {https://www.researchgate.net/profile/Christian{\_}Ghiaus/publication/245196862{\_}Experimental{\_}estimation{\_}of{\_}building{\_}energy{\_}performance{\_}by{\_}robust{\_}regression/links/54da12260cf25013d043e9b8.pdf http://linkinghub.elsevier.com/retrieve/pii/S0378778805001799},
volume = {38},
year = {2006}
}
@article{Hearon1963,
abstract = {It is the purpose of this paper to set forth certain properties of linear systems and to note and discuss some physical and operational implications of these properties.},
author = {Hearon, John Z.},
doi = {10.1111/j.1749-6632.1963.tb13364.x},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/hearon2006.pdf:pdf},
issn = {00778923},
journal = {Annals of the New York Academy of Sciences},
month = {may},
number = {1},
pages = {36--68},
title = {{THEOREMS ON LINEAR SYSTEMS*}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1963.tb13364.x},
volume = {108},
year = {1963}
}
@inproceedings{Urge-Vorsatz2014,
abstract = {Many recent major studies, including the IPCC's Fourth As-sessment Report, have attested that energy efficiency is human-ity's prime option to combat climate change in the short-to mid-term. The potential to avoid CO 2 emissions cost-effectively has been reported to be significant through efficiency policies. However, the review of global research findings on the quantifi-cation of cost-effectiveness of opportunities through improved efficiency has highlighted that there is a major shortcoming in the vast majority of such calculations. It is common that such studies normally consider only direct costs in their assess-ment. Whereas there have been several trans-national efforts to quantify external cost, external " benefits " , or co-, ancillary-or non-energy benefits are rarely monetized and included in cost-benefit analyses. Since several studies have attested that these benefits often amount to more than the direct energy benefits, the omission of these values severely distorts the results of such assessments and, therefore, it is of utmost importance to con-sider these for in global and national policy-making and target-setting. The aim of the present paper is to assist in laying the foundations for this process, and demonstrates this on the case of the building sector. The paper reviews and synthesises the granules of research in this field. It first provides a taxonomy of co-benefits, and then collates case studies found in the pub-lic domain in which certain co-benefits have been monetized/ quantified. Then, the paper summarises the various method-ologies applied for the quantification of these. Finally, it offers equations on how different co-benefits could be integrated into a more holistic cost-benefit and/or cost-effectiveness as-sessment.},
address = {La Colle sur Loup},
author = {{\"{U}}rge-Vorsatz, Diana and Novikova, Aleksandra and Sharmina, Maria},
booktitle = {European Council for an Energy Efficient Economy (ECEEE) Summer Study},
file = {:home/sarah/OneDrive/Travail/Sources/Counting{\_}good{\_}Quantifying{\_}the{\_}co-benefits{\_}of{\_}impro.pdf:pdf},
keywords = {NEBs,buildings,climate policy,co-benefits,cost bene-fit,energy efficiency,energy policy,greenhouse gas mitigation,non-energy benefits},
title = {{Counting good: quantifying the co-benefits of improved efficiency in buildings}},
year = {2014}
}
@inproceedings{VanSchijndel2009,
address = {Istanbul},
author = {{Van Schijndel}, A. W. M.},
booktitle = {4th International Building Physics Conference},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/Metis218548.pdf:pdf},
isbn = {9789755613505},
pages = {91--98},
title = {{The Exploration of an Inverse Problem Technique to Obtain Material Properties of a Building Construction}},
url = {???},
year = {2009}
}
@article{Radaideh2019,
abstract = {A framework for model evaluation and uncertainty quantification (UQ)is presented with applications oriented to nuclear engineering simulation codes. Our framework is inspired by the previous research on Bayesian statistics and model averaging. The methodology is demonstrated by performing UQ of three thermal-hydraulic computer codes used for two-phase flow simulation inside nuclear reactors, and conclusions regarding their performance are drawn. The complexity of the framework implementation depends upon the information to be drawn about the models as well as the nature of the models and the data. Uncertainties inherent in the input parameters and experimental data, along with predictive and model-form uncertainty can be quantified in this methodology. A composite (average)model based on the competent models can be created for improved response prediction. Two benchmarks featuring steady-state void fraction data in full-scale light water reactor (LWR)channels are used to demonstrate the methodology. The results show that the three models/codes demonstrate variable competitiveness in reproducing the data (i.e. goodness of fit with the data). There is no consistent trend at which each code excels. The predictive uncertainty (representing individual model deficiency or discrepancy)dominates the model-form uncertainty for many cases in this study due to two reasons: (1)presence of a single competent model for a specific response and (2)poor agreement with experimental data for certain responses at which nuclear codes struggle, such as low pressure and subcooled boiling conditions. In general, improvements in composite predictions (based on posterior model weights)are observed for BFBT data, while slight improvement is found for PSBT. For PSBT, the predictive uncertainty of RELAP5 and TRACE dominates the response uncertainty causing weak improvement. Additional efforts are needed to improve the closure models of these codes in future to reduce the model discrepancy contribution. This framework can be utilized for this purpose at which various closure models for the same code can be assessed in terms of their effect on the final response uncertainty. The proposed framework is flexible and extendable to other types of physics, models, and data. Developing the underlying methodology of calculating the model weights is the main focus in the subsequent studies.},
author = {Radaideh, Majdi I. and Borowiec, Katarzyna and Kozlowski, Tomasz},
doi = {10.1016/j.ress.2019.04.020},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0951832018313772-main.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Bayesian model averaging,Model validation,Model-form uncertainty,Nuclear thermal-hydraulics,Uncertainty quantification},
number = {November 2018},
pages = {357--377},
publisher = {Elsevier Ltd},
title = {{Integrated framework for model assessment and advanced uncertainty quantification of nuclear computer codes under Bayesian statistics}},
url = {https://doi.org/10.1016/j.ress.2019.04.020},
volume = {189},
year = {2019}
}
@article{Li2014,
abstract = {Buildings consume about 41.1{\%} of primary energy and 74{\%} of the electricity in the U.S. Better or even optimal building energy control and operation strategies provide great opportunities to reduce building energy consumption. Moreover, it is estimated by the National Energy Technology Laboratory that more than one-fourth of the 713 GW of U.S. electricity demand in 2010 could be dispatchable if only buildings could respond to that dispatch through advanced building energy control and operation strategies and smart grid infrastructure. Energy forecasting models for building energy systems are essential to building energy control and operation. Three general categories of building energy forecasting models have been reported in the literature which include white-box (physics-based), black-box (data-driven), and gray-box (combination of physics based and data-driven) modeling approaches. This paper summarizes the existing efforts in this area as well as other critical areas related to building energy modeling, such as short-term weather forecasting. An up-to-date overview of research on application of building energy modeling methods in optimal control for single building and multiple buildings is also summarized in this paper. Different model-based and model-free optimization methods for building energy system operation are reviewed and compared in this paper. Agent based modeling, as a new modeling strategy, has made a remarkable progress in distributed energy systems control and optimization in the past years. The research literature on application of agent based model in building energy system control and operation is also identified and discussed in this paper. ?? 2014 Elsevier Ltd.},
author = {Li, Xiwang and Wen, Jin},
doi = {10.1016/j.rser.2014.05.056},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Wen - 2014 - Review of building energy modeling for control and operation.pdf:pdf},
isbn = {1364-0321},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {Building energy modeling,Building optimal control,Demand response,Energy generation system,Energy storage system},
pages = {517--537},
publisher = {Elsevier},
title = {{Review of building energy modeling for control and operation}},
url = {http://dx.doi.org/10.1016/j.rser.2014.05.056},
volume = {37},
year = {2014}
}
@article{Macdonald2002,
abstract = {Uncertainty affects all aspects of building simulation: from the development of algo- rithms, through the implementation of software, to the use of the resulting systems. This work has focused on the problem of quantifying the effect of uncertainty on the predictions made by simulation tools. Two approaches to quantifying this effect are pursued in this thesis: external and internal methods. The external approach treats the simulation engine as a black box and alters only the input model. Methods within this approach require multiple simulations of systematically altered models and the subsequent analysis of the differences in the predictions in order to draw conclusions on the effect of uncertainty. Three methods were identified for use in the present work: differential, factorial and Monte Carlo. The differential method alters one parameter at a time to quantify the effect of each parameter and requires 2N+1 simulations for N uncertain parameters. The factorial method alters groups of parameters simultaneously to determine interactions between effects and requires 2N simulations. The Monte Carlo method alters all parameters simultaneously to quantify the overall effect of uncertainty. The number of simulations required for the Monte Carlo method is independent of the number of parameters and is typically 80. Each of these methods require a significant number of simulations. To quantify the individual contributions, the interactions between these contributions and the effects overall would require the use of all three methods.},
author = {Macdonald, Iain},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Macdonald - 2002 - Quantifying the Effects of Uncertainty in Building Simulation.pdf:pdf},
journal = {Regulation},
number = {July},
pages = {267},
title = {{Quantifying the Effects of Uncertainty in Building Simulation}},
url = {http://www.strath.ac.uk/media/departments/mechanicalengineering/esru/research/phdmphilprojects/macdonald{\_}thesis.pdf},
volume = {Ph D},
year = {2002}
}
@article{Hu2018,
author = {Hu, Zhen and Hu, Chao and Mourelatos, Zissimos P. and Mahadevan, Sankaran},
doi = {10.1115/1.4041483},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2018 - Model Discrepancy Quantification in Simulation-Based Design of Dynamical Systems.pdf:pdf},
issn = {1050-0472},
journal = {Journal of Mechanical Design},
keywords = {discrete-time,dynamical systems,model discrepancy,state variables,state-},
month = {oct},
number = {1},
pages = {011401},
title = {{Model Discrepancy Quantification in Simulation-Based Design of Dynamical Systems}},
url = {http://mechanicaldesign.asmedigitalcollection.asme.org/article.aspx?doi=10.1115/1.4041483},
volume = {141},
year = {2018}
}
@article{Iman1982,
author = {Iman, Ronald L. and Conover, W. J.},
doi = {10.1080/03610918208812265},
issn = {0361-0918},
journal = {Communications in Statistics - Simulation and Computation},
month = {jan},
number = {3},
pages = {311--334},
title = {{A distribution-free approach to inducing rank correlation among input variables}},
url = {http://www.tandfonline.com/doi/abs/10.1080/03610918208812265},
volume = {11},
year = {1982}
}
@article{Kramer2013,
annote = {Page 92 : 5 mod{\`{e}}les RC simplifi{\'{e}}s. A exploiter?},
author = {Kramer, Rick and van Schijndel, Jos and Schellen, Henk},
doi = {10.1016/j.buildenv.2013.06.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kramer, van Schijndel, Schellen - 2013 - Inverse modeling of simplified hygrothermal building models to predict and characterize indoor.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
month = {oct},
number = {June 2012},
pages = {87--99},
title = {{Inverse modeling of simplified hygrothermal building models to predict and characterize indoor climates}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360132313001790},
volume = {68},
year = {2013}
}
@article{Wei2014,
abstract = {Occupant behaviour has a large impact on the energy consumption of buildings, and therefore a better understanding can assist in many building-related applications, such as facility management, building performance simulation and occupant guidance. As occupant space-heating operation has a significant influence on the energy consumption of residential buildings in winter, an investigation of drivers for this behaviour was undertaken and the result is expressed in this paper. From the analysis, 27 drivers have been evaluated in previous behavioural studies and at present none of them can be identified confidently as having no influence. Following the identification of these key drivers, the modelling of occupant space-heating behaviour in traditional building performance simulation was reviewed and the result indicates that most of these factors are typically ignored when modelling space-heating operation in building performance simulation. It is concluded that future behavioural studies into the drivers discussed in this paper are needed to gain a better understanding and quantification of the impact of these factors on building energy use. {\textcopyright} 2013 Elsevier B.V.},
author = {Wei, Shen and Jones, Rory and de Wilde, Pieter},
doi = {10.1016/j.enbuild.2013.11.001},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S037877881300683X-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building simulation,Energy consumption,Occupant behaviour,Residential buildings,Space heating drivers},
month = {feb},
pages = {36--44},
publisher = {Elsevier B.V.},
title = {{Driving factors for occupant-controlled space heating in residential buildings}},
url = {http://dx.doi.org/10.1016/j.enbuild.2013.11.001 https://linkinghub.elsevier.com/retrieve/pii/S037877881300683X},
volume = {70},
year = {2014}
}
@phdthesis{Seem1989,
author = {Seem, J.E.},
school = {University of Wisconsin-Madison},
title = {{Modeling of heat transfer in buildings}},
year = {1989}
}
@article{Raue2013,
abstract = {Increasingly complex applications involve large datasets in combination with nonlinear and highdimensional mathematical models. In this context, statistical inference is a challenging issue that calls for pragmatic approaches that take advantage of both Bayesian and frequentist methods. The elegance of Bayesian methodology is founded in the propagation of information content provided by experimental data and prior assumptions to the posterior probability distribution of model predictions. However, for complex applications, experimental data and prior assumptions potentially constrain the posterior probability distribution insufficiently. In these situations, Bayesian Markov chain Monte Carlo sampling can be infeasible. From a frequentist point of view, insufficient experimental data and prior assumptions can be interpreted as non-identifiability. The profile-likelihood approach offers to detect and to resolve non-identifiability by experimental design iteratively. Therefore, it allows one to better constrain the posterior probability distribution until Markov chain Monte Carlo sampling can be used securely. Using an application from cell biology, we compare both methods and show that a successive application of the two methods facilitates a realistic assessment of uncertainty in model predictions. {\textcopyright} 2012 The Author(s) Published by the Royal Society. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1202.4605},
author = {Raue, Andreas and Kreutz, Clemens and Theis, Fabian Joachim and Timmer, Jens},
doi = {10.1098/rsta.2011.0544},
eprint = {1202.4605},
file = {:home/sarah/OneDrive/Travail/Sources/rsta.2011.0544.pdf:pdf},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Bayesian Markov chain Monte Carlo sampling,Identifiability,Posterior propriety,Prediction uncertainty,Profile likelihood,Propagation of uncertainty},
month = {feb},
number = {1984},
pages = {20110544},
title = {{Joining forces of Bayesian and frequentist methodology: a study for inference in the presence of non-identifiability}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0544},
volume = {371},
year = {2013}
}
@article{Bayarri2004,
abstract = {Statistics has struggled for nearly a century over the issue of whether the Bayesian or frequentist paradigm is superior. This debate is far from over and, indeed, should continue, since there are fundamental philosophical and pedagogical issues at stake. At the methodological level, however, the debate has become considerably muted, with the recognition that each approach has a great deal to contribute to statistical practice and each is actually essential for full development of the other approach. In this article, we embark upon a rather idiosyncratic walk through some of these issues.},
author = {Bayarri, M. J. and Berger, J. O.},
doi = {10.1214/088342304000000116},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/4144373.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Admissibility,Bayesian model checking,Conditional frequentist,Confidence intervals,Consistency,Coverage,Design,Hierarchical models,Nonparametric Bayes,Objective Bayesian methods,P-values,Reference priors,Testing},
number = {1},
pages = {58--80},
title = {{The interplay of Bayesian and frequentist analysis}},
volume = {19},
year = {2004}
}
@incollection{Shumway2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Shumway, Robert and Stoffer, David},
doi = {10.1002/9781118619193},
eprint = {arXiv:1011.1669v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shumway, Stoffer - 2017 - Time Series Analysis.pdf:pdf},
isbn = {9781118619193},
issn = {02664666},
number = {5},
pages = {1--16},
pmid = {20681388},
publisher = {Springer},
title = {{Time Series Analysis}},
volume = {2},
year = {2017}
}
@article{Fraisse2002,
author = {Fraisse, Gilles and Viardot, Christelle and Lafabrie, Olivier and Achard, Gilbert},
doi = {10.1016/S0378-7788(02)00019-1},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fraisse et al. - 2002 - Development of a simplified and accurate building model based on electrical analogy.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Heating floor,electrical analogy,thermal modeling,time-frequency analysis},
month = {nov},
number = {10},
pages = {1017--1031},
title = {{Development of a simplified and accurate building model based on electrical analogy}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378778802000191},
volume = {34},
year = {2002}
}
@book{Ferlay2012,
author = {Ferlay, Philippe},
isbn = {2954145102},
keywords = {Signature {\'{e}}nerg{\'{e}}tique},
mendeley-tags = {Signature {\'{e}}nerg{\'{e}}tique},
pages = {96},
publisher = {Editions parisiennes},
title = {{Mesure du Coefficient Ubat d'un B{\^{a}}timent existant}},
url = {https://books.google.fr/books/about/Mesure{\_}du{\_}coefficient{\_}Ubat{\_}d{\_}un{\_}b{\^{a}}timen.html?id=yeeQMwEACAAJ{\&}redir{\_}esc=y},
year = {2012}
}
@phdthesis{Bourgeois2010,
author = {Bourgeois, Laurent},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bourgeois - 2010 - Automates cellulaires et estimation {\'{e}}tat-param{\`{e}}tres pour la mod{\'{e}}lisation semi-physique application de donn{\'{e}}es en.pdf:pdf},
keywords = {Filtre de Kalman},
mendeley-tags = {Filtre de Kalman},
school = {Universit{\'{e}} du Littoral C{\^{o}}te d'Opale},
title = {{Automates cellulaires et estimation {\'{e}}tat-param{\`{e}}tres pour la mod{\'{e}}lisation semi-physique : application de donn{\'{e}}es environnementales}},
url = {http://www-lisic.univ-littoral.fr/IMG/pdf/PhD{\_}Laurent.pdf},
year = {2010}
}
@article{Henninger2004,
author = {Henninger, Robert H and Witte, Michael J},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henninger, Witte - 2004 - EnergyPlus Testing with ANSIASHRAE Standard 140-2001 (BESTEST).pdf:pdf},
journal = {U.S. Department of Energy},
keywords = {ANSI/ASHRAE Standard 140-2001,BESTEST,EnergyPlus,Testing},
number = {EnergyPlus Version 1.2.0.029 - June 2004},
title = {{EnergyPlus testing with ANSI/ASHRAE standard 140-2001 (BESTEST)}},
url = {http://simulationresearch.lbl.gov/dirpubs/epl{\_}bestest{\_}ash.pdf},
year = {2004}
}
@article{Wu2008,
abstract = {We use a technique from engineering (Xia and Moog, in IEEE Trans. Autom. Contr. 48(2):330–336, 2003; Jeffrey and Xia, in Tan, W.Y., Wu, H. (Eds.), Deterministic and Stochastic Models of AIDS Epidemics and HIV Infections with Intervention, 2005) to investigate the algebraic identifiability of a popular three-dimensional HIV/AIDS dy-namic model containing six unknown parameters. We find that not all six parameters in the model can be identified if only the viral load is measured, instead only four para-meters and the product of two parameters (N and $\lambda$) are identifiable. We introduce the concepts of an identification function and an identification equation and propose the mul-tiple time point (MTP) method to form the identification function which is an alternative to the previously developed higher-order derivative (HOD) method (Xia and Moog, in IEEE Trans. Autom. Contr. 48(2):330–336, 2003; Jeffrey and Xia, in Tan, W.Y., Wu, H. (Eds.), Deterministic and Stochastic Models of AIDS Epidemics and HIV Infections with Intervention, 2005). We show that the newly proposed MTP method has advantages over the HOD method in the practical implementation. We also discuss the effect of the initial values of state variables on the identifiability of unknown parameters. We conclude that the initial values of output (observable) variables are part of the data that can be used to estimate the unknown parameters, but the identifiability of unknown parameters is not affected by these initial values if the exact initial values are measured with error. These noisy initial values only increase the estimation error of the unknown parameters. How-ever, having the initial values of the latent (unobservable) state variables exactly known may help to identify more parameters. In order to validate the identifiability results, sim-ulation studies are performed to estimate the unknown parameters and initial values from simulated noisy data. We also apply the proposed methods to a clinical data set to estimate HIV dynamic parameters. Although we have developed the identifiability methods based on an HIV dynamic model, the proposed methodologies are generally applicable to any ordinary differential equation systems.},
author = {Wu, Hulin and Zhu, Haihong and Miao, Hongyu and Perelson, Alan S.},
doi = {10.1007/s11538-007-9279-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2008 - Parameter identifiability and estimation of HIVAIDS dynamic models.pdf:pdf},
isbn = {0092-8240},
issn = {00928240},
journal = {Bulletin of Mathematical Biology},
keywords = {Identifiability,Inverse problem,Statistical estimation,Viral dynamics},
number = {3},
pages = {785--799},
pmid = {18247096},
title = {{Parameter identifiability and estimation of HIV/AIDS dynamic models}},
volume = {70},
year = {2008}
}
@inproceedings{Juricic2019,
address = {Rome},
author = {Juricic, Sarah and Bacher, Peder and Goffart, Jeanne and Rouchier, Simon and Fraisse, Gilles},
booktitle = {Proceedings of the 16th IBPSA Building Simulation Conference},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/BS2019 article - SJ.pdf:pdf},
title = {{Identifiability of the heat transfer coefficient in buildings with unheated spaces}},
year = {2019}
}
@misc{ISO9869,
author = {{ISO 9869-1}},
publisher = {International Organization for Standardisation},
title = {{ISO 9869 Thermal insulation — Building elements — In-situ measurement of thermal resistance and thermal transmittance — Part 1: Heat flow meter method}},
url = {https://www.iso.org/fr/standard/59697.html},
volume = {ISO 9869-1},
year = {2014}
}
@article{Michalak2015,
abstract = {The author has noted 2 errors in the equations presented in the above article. The first is in equation (6), which is in the form: (H tr,em þ H tr,ms þ H ve) • T m {\`{A}} H tr,ms • T s ¼ f m {\`{A}} f c þ H tr,em • T e The correct equation is: (H tr,em þ H tr,ms) • T m {\`{A}} H tr,ms • T s ¼ f m {\`{A}} f c þ H tr,em • T e (i.e., without " þ Hve " component in the first pair of brackets). The second error is in equation (11). The expression at the heat flow rate fst is in the form: H tr, ms • H tr,is /M The correct equation is: (H ve þ H tr,is)/M},
author = {Michalak, Piotr},
doi = {10.1016/j.energy.2015.07.066},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michalak - 2015 - Corrigendum to {\&}quot The simple hourly method of EN ISO 13790 standard in MatlabSimulink A comparative study for the c.pdf:pdf},
journal = {Energy},
pages = {973},
title = {{Corrigendum to "The simple hourly method of EN ISO 13790 standard in Matlab/Simulink: A comparative study for the climatic conditions of Poland" [Energy 75 (2015) 568e578]}},
url = {http://dx.doi.org/10.1016/j.energy.2014.08.019. http://dx.doi.org/10.1016/j.energy.2015.07.066},
volume = {88},
year = {2015}
}
@phdthesis{Bastogne2008,
author = {Bastogne, Thierry},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastogne - 2008 - Mod{\'{e}}lisation Exp{\'{e}}rimentale des Syst{\`{e}}mes Dynamiques Interconnect{\'{e}}s – Applications en Biologie Syst{\'{e}}mique –.pdf:pdf},
keywords = {HDR},
mendeley-tags = {HDR},
school = {Nancy},
title = {{Mod{\'{e}}lisation Exp{\'{e}}rimentale des Syst{\`{e}}mes Dynamiques Interconnect{\'{e}}s – Applications en Biologie Syst{\'{e}}mique –}},
year = {2008}
}
@misc{BigLadderSoftwareVentilation,
author = {{Big Ladder Software}},
booktitle = {EnergyPlus 8.6},
title = {{EnergyPlus 8.6 Engineering reference Infiltration/Ventilation}},
url = {https://bigladdersoftware.com/epx/docs/8-6/input-output-reference/group-airflow.html{\#}zoneventilationdesignflowrate https://bigladdersoftware.com/epx/docs/8-6/engineering-reference/infiltration-ventilation.html{\#}infiltrationventilation},
year = {2016}
}
@article{Vanlier2012,
abstract = {MOTIVATION: Systems biology employs mathematical modelling to further our understanding of biochemical pathways. Since the amount of experimental data on which the models are parameterized is often limited, these models exhibit large uncertainty in both parameters and predictions. Statistical methods can be used to select experiments that will reduce such uncertainty in an optimal manner. However, existing methods for optimal experiment design (OED) rely on assumptions that are inappropriate when data are scarce considering model complexity.$\backslash$n$\backslash$nRESULTS: We have developed a novel method to perform OED for models that cope with large parameter uncertainty. We employ a Bayesian approach involving importance sampling of the posterior predictive distribution to predict the efficacy of a new measurement at reducing the uncertainty of a selected prediction. We demonstrate the method by applying it to a case where we show that specific combinations of experiments result in more precise predictions.$\backslash$n$\backslash$nAVAILABILITY AND IMPLEMENTATION: Source code is available at: http://bmi.bmt.tue.nl/sysbio/software/pua.html.},
author = {Vanlier, J. and Tiemann, C. A. and Hilbers, P. A J and van Riel, N. A W},
doi = {10.1093/bioinformatics/bts092},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanlier et al. - 2012 - A Bayesian approach to targeted experiment design.pdf:pdf},
isbn = {1367480314602059},
issn = {13674803},
journal = {Bioinformatics},
number = {8},
pages = {1136--1142},
pmid = {22368245},
title = {{A Bayesian approach to targeted experiment design}},
volume = {28},
year = {2012}
}
@phdthesis{Mounier2016,
annote = {Analyse de la sensiblit�� de chacun des param��tres (par MORRIS)
Solution pour am��liorer l'identification : fixer les param��tres les moins influents.

SOLUTION alternative : un param��tre pas influent c'est un param��tre qui ne s'exprime pas vu les sollicitations (qui sont r��elles donc par d��finition limit��es). N'est-ce pas aussi une question de nombre minimal de capteurs �� avoir pour voir s'exprimer au max le param��tre?
De plus, si on travaille sur un mod��le identifiable a priori, on ne se pose plus la question de savoir si fixer un param��tre am��liore l'identification car on sait que le r��sultat est unique. On reste juste avec un param��tre dont on ne peut se prononcer sur la valeur, sasn avoir besoin de le fixer pr��alablement.
Cela pourrait seulement servir �� acc��l��rer les temps de simul...

Dans la th��se, pour pallier le manque de richesse de la sollicitiation, mise en place de plan d'exp��rience sur la pompe �� chaleur.

Relire les parties sur l'analyse de la diff��rence des r��sultats de calibration entre saisons},
author = {Mounier, Audrey Le},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mounier - 2016 - M{\'{e}}ta-optimisation pour la calibration automatique de mod{\`{e}}les {\'{e}}nerg{\'{e}}tiques b{\^{a}}timent pour le pilotage anticipatif.pdf:pdf},
school = {Universit{\'{e}} Grenoble Alpes},
title = {{M{\'{e}}ta-optimisation pour la calibration automatique de mod{\`{e}}les {\'{e}}nerg{\'{e}}tiques b{\^{a}}timent pour le pilotage anticipatif}},
year = {2016}
}
@article{Svensson2018,
author = {Svensson, Andreas and Zachariah, Dave and Sch{\"{o}}n, Thomas B.},
doi = {10.1016/j.ifacol.2018.09.179},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Svensson, Zachariah, Sch{\"{o}}n - 2018 - How consistent is my model with the data Information-Theoretic Model Check.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Dynamic models,Information theory,Model criticism,Model tests,Nonlinear models,Portmanteau test,and},
number = {15},
pages = {407--412},
publisher = {Elsevier B.V.},
title = {{How consistent is my model with the data? Information-Theoretic Model Check}},
url = {https://doi.org/10.1016/j.ifacol.2018.09.179 https://linkinghub.elsevier.com/retrieve/pii/S2405896318318469},
volume = {51},
year = {2018}
}
@article{Arendt2010,
abstract = {Model updating, which utilizes mathematical means to combine model simulations with physical observations for improving model predictions, has been viewed as an integral part of a model validation process. While calibration is often used to "tune" uncertain model parameters, bias-correction has been used to capture model inadequacy due to a lack of knowledge of the physics of a problem. While both sources of uncertainty co-exist, these two techniques are often implemented separately in model updating. This paper examines existing approaches to model updating and presents a modular Bayesian approach as a comprehensive framework that accounts for many sources of uncertainty in a typical model updating process and provides stochastic predictions for the purpose of design. In addition to the uncertainty in the computer model parameters and the computer model itself, this framework accounts for the experimental uncertainty and the uncertainty due to the lack of data in both computer simulations and physical experiments using the Gaussian process model. Several challenges are apparent in the implementation of the modular Bayesian approach. We argue that distinguishing between uncertain model parameters (calibration) and systematic inadequacies (bias correction) is often quite challenging due to an identifiability issue. We present several explanations and examples of this issue and bring up the needs of future research in distinguishing between the two sources of uncertainty. {\textcopyright} 2010 by ASME.},
author = {Arendt, Paul D and Chen, Wei and Apley, Daniel W},
doi = {10.1115/DETC2010-28828},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/Sci-Hub | Updating Predictive Models  Calibration, Bias Correction and Identifiability. Volume 1  36th Design Automation Conference, Parts A and B | 10.1115{\_}DETC2010-28828{\_}fichiers/arendt2010{\_}002.pdf:pdf},
isbn = {9780791844090},
journal = {Proceedings of the ASME Design Engineering Technical Conference},
keywords = {DETC2010-28828},
number = {PARTS A AND B},
pages = {1089--1098},
title = {{Updating predictive models: Calibration, bias correction and identifiability}},
volume = {1},
year = {2010}
}
@incollection{Gevers,
abstract = {This paper aims at introducing the reader to the various issues that arise in the development of a coherent methodology for the development of robust control design on the basis of models identified from data. When a reduced complexity model is identified with the purpose of designing a robust controller, the model is just a vehicle for the computation of a controller. The design of the identification and of the controller must be seen as two parts of a joint design problem. The central message of this paper is to show that the global control performance criterion must determine the identification criterion. This leads to non standard identification criteria, which can be minimized by appropriate experimental setups .},
author = {Gevers, Michel},
booktitle = {Essays on Control},
doi = {10.1007/978-1-4612-0313-1_5},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gevers - Unknown - Towrads a joint design of identification and control.pdf:pdf},
pages = {111--151},
title = {{Towards a Joint Design of Identification and Control ?}},
url = {http://perso.uclouvain.be/michel.gevers/PublisMig/ECC93.pdf},
year = {1993}
}
@article{Dimitriou2015,
abstract = {A simple 1storder data-driven lumped parameter model of a domestic building is developed to explore the effect of using different model parameter values in the model outputs. The adequacy of the Ordinary Least Square estimation technique is explored. Results show that an improved fit to the measured data can be achieved by varying the initial model parameter values of capacitance (up to 78{\%}), resistance (-46{\%}) and effective window area (-59{\%}). This highlights the importance of having a reference set of parameters based on the known physical characteristics of the building. Finally, the model residuals are deemed appropriate to inform the decision making process for further model development.},
annote = {conclusion : les param calibr{\'{e}}s d'un 1R1C sont tout {\`{a}} fait diff{\'{e}}rent des valeurs calcul{\'{e}}es sur papier...
--{\textgreater} sans blague},
archivePrefix = {arXiv},
arxivId = {10.1016/j.rser.2014.05.007},
author = {Dimitriou, Vanda and Firth, Steven K. and Hassan, Tarek M. and Kane, Tom and Coleman, Michael},
doi = {10.1016/j.egypro.2015.11.322},
eprint = {j.rser.2014.05.007},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitriou et al. - 2015 - Data-driven simple thermal models The importance of the parameter estimates.pdf:pdf},
isbn = {1364-0321},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Dynamic,Estimation,Lumped Parameter,Model calibration,Modelling,Ordinary Least Squares,Parameter,Thermal},
pages = {2614--2619},
primaryClass = {10.1016},
publisher = {Elsevier B.V.},
title = {{Data-driven simple thermal models: The importance of the parameter estimates}},
url = {http://dx.doi.org/10.1016/j.egypro.2015.11.322},
volume = {78},
year = {2015}
}
@article{Gupta2018,
abstract = {This paper presents new evidence from a nationwide cross-project meta-study investigating the magnitude and extent of the difference between designed and measured thermal performance of the building fabric of 188 low energy dwellings in the UK. The dataset was drawn from the UK Government's national Building Performance Evaluation programme, and comprises 50 Passivhaus (PH) and 138 non-Passivhaus (NPH) dwellings, covering different built forms and construction systems. The difference between designed and measured values of air permeability (AP), external wall/roof thermal transmittance (U-value) and whole house heat loss were statistically analysed, along with a review of thermal imaging data to explain any discrepancies. The results showed that fabric thermal performance gap was widespread especially in terms of AP, although the magnitude of underperformance was much less in PH dwellings. While measured AP had good correlation with measured space heating energy for PH dwellings, there was no relationship between the two for NPH dwellings. The regression analysis indicated that for every 1 m3/h/m2 reduction in designed air permeability, the gap increased by 0.8 m3/h/m2@50 Pa. Monte Carlo analysis showed that likelihood of AP gap was 78{\%} in NPH dwellings designed to 5 m3/h/m2@50 Pa or lower. The study provides useful evidence for improving the fabric thermal performance of new housing through in-situ testing.},
author = {Gupta, Rajat and Kotopouleas, Alkis},
doi = {10.1016/j.apenergy.2018.03.096},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S0306261918304343-main.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Airtightness,Building fabric,Co-heating test,Heat loss,Low energy dwellings,Passivhaus,Thermal transmittance},
number = {March},
pages = {673--686},
publisher = {Elsevier},
title = {{Magnitude and extent of building fabric thermal performance gap in UK low energy housing}},
url = {https://doi.org/10.1016/j.apenergy.2018.03.096},
volume = {222},
year = {2018}
}
@article{Beskhyroun2011,
abstract = {Abstract Vibration-based damage detection (VBDD) comprises a promising set of techniques for damage detection and health monitoring of civil engineering structures. However, the successful application of these methods to real structures is still a challenging task, due primarily to the large size of such structures and the relatively high levels of variability in their dynamic response under operational load conditions. In this paper, a new methodology is introduced for the application of VBDD techniques, with the goal of enhancing their effectiveness for identifying and locating low damage levels and improving their applicability to the continuous or periodic health monitoring of structures. The basic features of the methodology include the use of a controlled and consistent excitation force, the use of operational deflection shapes (ODSs) at all measured frequency increments rather than only at natural frequencies, the use of a logarithmic scale for representing the ODS amplitudes at each frequency increment and the establishment of a threshold level for damage detection that accounts for experimental variability. The performance of the proposed methodology is verified and demonstrated by applying several Level 1 (damage detection) and Level 2 (damage localization) VBDD techniques using experimental data measured on a steel girder taken from a railway bridge. The proposed approach is shown to perform very well at detecting, locating and monitoring the growth of damage. Copyright 2011 John Wiley {\&} Sons, Ltd},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Beskhyroun, Sherif and Wegner, Leon D and Sparling, Bruce F},
doi = {10.1002/stc},
eprint = {arXiv:1011.1669v3},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beskhyroun, Wegner, Sparling - 2011 - New methodology for the application of vibration-based damage detection techniques.pdf:pdf},
isbn = {1545-2263},
issn = {15452255},
journal = {Structural Control and Health Monitoring},
keywords = {2,bridge,civil engineering,civil engineering structures,damage,damage detection,damage localization,dynamic,dynamic response,engineering,frequency,health,health monitoring,health monitoring structure,methodology,modal analysis,mode shapes,monitoring,natural frequencies,natural frequency,performance,railway,structural health monitoring,structure,variability,vibration based damage detection},
number = {May 2011},
pages = {n/a--n/a},
pmid = {25246403},
title = {{New methodology for the application of vibration-based damage detection techniques}},
url = {http://dx.doi.org/10.1002/stc.456},
year = {2011}
}
@article{Mara2016,
abstract = {a b s t r a c t Statistical calibration of model parameters conditioned on observations is performed in a Bayesian framework by evaluating the joint posterior probability density function (pdf) of the parameters. The posterior pdf is very often inferred by sampling the parameters with Markov Chain Monte Carlo (MCMC) algorithms. Recently, an alternative technique to calculate the so-called Maximal Conditional Posterior Distribution (MCPD) appeared. This technique infers the individual probability distribution of a given parameter under the condition that the other parameters of the model are optimal. Whereas the MCMC approach samples probable draws of the parameters, the MCPD samples the most probable draws when one of the parameters is set at various prescribed values. In this study, the results of a user-friendly MCMC sampler called DREAM (ZS) and those of the MCPD sampler are compared. The differences be-tween the two approaches are highlighted before running a comparison inferring two analytical dis-tributions with collinearity and multimodality. Then, the performances of both samplers are compared on an artificial multistep outflow experiment from which the soil hydraulic parameters are inferred. The results show that parameter and predictive uncertainties can be accurately assessed with both the MCMC and MCPD approaches.},
author = {Mara, Thierry A and Delay, Frederick and Lehmann, Fran{\c{c}}ois and Younes, Anis},
doi = {10.1016/j.envsoft.2016.04.010},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mara et al. - 2016 - A comparison of two Bayesian approaches for uncertainty quantification.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mara et al. - Unknown - A comparison of two Bayesian approaches for uncertainty quantification(2).pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling {\&} Software},
keywords = {Bayesian parameter estimation,DREAM(ZS),MCMC,MCPD sampler,Parameter uncertainty,Predictive uncertainty,Soil hydraulic parameter identification},
month = {aug},
pages = {21--30},
title = {{A comparison of two Bayesian approaches for uncertainty quantification}},
url = {https://ac-els-cdn-com.camphrier-1.grenet.fr/S1364815216301001/1-s2.0-S1364815216301001-main.pdf?{\_}tid=78d6b220-c2cd-11e7-8249-00000aab0f02{\&}acdnat=1509957521{\_}0d55b8d8e83b503eeab04f6df8ec062c https://linkinghub.elsevier.com/retrieve/pii/S1364815216301001},
volume = {82},
year = {2016}
}
@article{Vazquez2014,
author = {V{\'{a}}zquez, {\'{A}}lvarez and Pascual, P{\'{e}}rez and Pedro, a and Ciencias, Facultad De},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/V{\'{a}}zquez et al. - 2014 - A simple test for white noise based on spectral analysis.pdf:pdf},
keywords = {c01,c15,c22,harmonic analysis,jel codes,la econom{\'{i}}a,m,matilla,m{\'{e}}todos estad{\'{i}}sticos aplicados a,n,p,periodogram,p{\'{e}}rez,simulation,white noise,{\'{a}}lvarez,{\'{a}}rea tem{\'{a}}tica},
number = {January 2007},
pages = {1--12},
title = {{A simple test for white noise based on spectral analysis}},
year = {2014}
}
@article{Raue2010,
abstract = {Dynamical models of cellular processes promise to yield new insights into the underlying systems and their biological interpretation. The processes are usually nonlinear, high dimensional, and time-resolved experimental data of the processes are sparse. Therefore, parameter estimation faces the challenges of structural and practical nonidentifiability. Nonidentifiability of parameters induces nonobservability of trajectories, reducing the predictive power of the model. We will discuss a generic approach for nonlinear models that allows for identifiability and observability analysis by means of a realistic example from systems biology. The results will be utilized to design new experiments that enhance model predictiveness, illustrating the iterative cycle between modeling and experimentation in systems biology. {\textcopyright} 2010 American Institute of Physics.},
author = {Raue, A. and Becker, V. and Klingm{\"{u}}ller, U. and Timmer, J.},
doi = {10.1063/1.3528102},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/CHAOEH204045105{\_}1.pdf:pdf},
issn = {1054-1500},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
month = {dec},
number = {4},
pages = {045105},
title = {{Identifiability and observability analysis for experimental design in nonlinear dynamical models}},
url = {http://aip.scitation.org/doi/10.1063/1.3528102},
volume = {20},
year = {2010}
}
@inproceedings{Bacher2010,
address = {Brussels},
author = {Bacher, Peder and Madsen, Henrik and Thavlov, Anders},
booktitle = {DYNASTEE international workshop : Dynamic Methods for Building Energy Assessment},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bacher, Madsen, Thavlov - 2010 - Statistical models describing the energy signature of buildings.pdf:pdf},
keywords = {building data,buildings,continuous time modelling,grey-box,heat consumption,heat dynamics,model selection,models,smart meters,thermal dynamics},
title = {{Statistical models describing the energy signature of buildings}},
year = {2010}
}
@unpublished{Berno,
author = {Berno},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berno - Unknown - RAPPORT DE STAGE FI4 D{\'{e}}veloppement et param{\'{e}}trisation de mod{\`{e}}les g{\'{e}}n{\'{e}}riques du b{\^{a}}timent.pdf:pdf},
title = {{RAPPORT DE STAGE FI4 D{\'{e}}veloppement et param{\'{e}}trisation de mod{\`{e}}les g{\'{e}}n{\'{e}}riques du b{\^{a}}timent}}
}
@article{Bienvenido-Huertas2019,
author = {Bienvenido-Huertas, David and Moyano, Juan and Mar{\'{i}}n, David and Fresco-Contreras, Rafael},
doi = {10.1016/j.rser.2018.12.016},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S1364032118308116-main.pdf:pdf},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
month = {mar},
pages = {356--371},
title = {{Review of in situ methods for assessing the thermal transmittance of walls}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364032118308116},
volume = {102},
year = {2019}
}
@article{Saltelli2019,
abstract = {Sensitivity analysis provides information on the relative importance of model input parameters and assumptions. It is distinct from uncertainty analysis, which addresses the question ‘How uncertain is the prediction?' Uncertainty analysis needs to map what a model does when selected input assumptions and parameters are left free to vary over their range of existence, and this is equally true of a sensitivity analysis. Despite this, many uncertainty and sensitivity analyses still explore the input space moving along one-dimensional corridors leaving space of the input factors mostly unexplored. Our extensive systematic literature review shows that many highly cited papers (42{\%} in the present analysis) fail the elementary requirement to properly explore the space of the input factors. The results, while discipline-dependent, point to a worrying lack of standards and recognized good practices. We end by exploring possible reasons for this problem, and suggest some guidelines for proper use of the methods.},
archivePrefix = {arXiv},
arxivId = {1711.11359},
author = {Saltelli, Andrea and Aleksankina, Ksenia and Becker, William and Fennell, Pamela and Ferretti, Federico and Holst, Niels and Li, Sushan and Wu, Qiongli},
doi = {10.1016/j.envsoft.2019.01.012},
eprint = {1711.11359},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/1-s2.0-S1364815218302822-main.pdf:pdf},
issn = {13648152},
journal = {Environmental Modelling and Software},
number = {January},
pages = {29--39},
publisher = {Elsevier},
title = {{Why so many published sensitivity analyses are false: A systematic review of sensitivity analysis practices}},
url = {https://doi.org/10.1016/j.envsoft.2019.01.012},
volume = {114},
year = {2019}
}
@article{Reddy1999,
abstract = {We propose an inverse method to estimate building and ventilation parameters from non-intrusive monitoring of heating and cooling thermal energy use of large commercial buildings. The procedure involves first deducing the loads of an ideal one-zone building from the monitored data, and then in the framework of a mechanistic macro-model, using a multistep linear regression approach to determine the regression coefficients (along with their standard errors) which can be finally translated into estimates of the physical parameters (along with the associated errors). Several different identification schemes have been evaluated using heating and cooling data generated from a detailed building simulation program for two different building geometries and building mass at two different climatic locations. A multistep identification scheme has been found to yield very accurate results, and an explanation as to why it should be so is also given. This approach has been shown to remove much of the bias introduced in multiple linear regression approach with correlated regressor variables. We have found that the parameter identification process is very accurate when daily data over an entire year are used. Parameter identification accuracy using twelve monthly data points and daily data over three months of the year was also investigated. Identification with twelve monthly data points seems to be fairly accurate while that using daily data over a season does not yield very good results. This latter issue needs to be investigated further because of its practical relevance.},
author = {Reddy, T. A. and Deng, S. and Claridge, D. E.},
doi = {10.1115/1.2888141},
file = {:home/sarah/OneDrive/Travail/Sources/reddy1999.pdf:pdf},
issn = {0199-6231},
journal = {Journal of Solar Energy Engineering},
month = {feb},
number = {1},
pages = {40--46},
title = {{Development of an Inverse Method to Estimate Overall Building and Ventilation Parameters of Large Commercial Buildings}},
url = {https://asmedigitalcollection.asme.org/solarenergyengineering/article/121/1/40/437736/Development-of-an-Inverse-Method-to-Estimate},
volume = {121},
year = {1999}
}
@article{Ramallo-Gonzalez2013,
abstract = {There are many sophisticated building simulators capable of accurately modelling the thermal performance of buildings. Lumped Parameter Models (LPMs) are an alternative which, due to their shorter computational time, can be used where many runs are needed, for example when completing computer-based optimisation. In this paper, a new, more accurate, analytic method is presented for creating the parameters of a second order LPM, consisting of three resistors and two capacitors, that can be used to represent multi-layered constructions. The method to create this LPM is more intuitive than the alternatives in the literature and has been named the Dominant Layer Model. This new method does not require complex numerical or algebraic operations, but is obtained using a simple analysis of the relative influence of the different layers within a construction on its overall dynamic behaviour. The method has been used to compare the dynamic response of four different typical constructions of varying thickness and materials as well as two more complex constructions as a proof of concept. When compared with a model that truthfully represents all layers in the construction, the new method is surprisingly accurate and outperforms the only other analytical method in the literature.},
annote = {From Duplicate 2 (Lumped parameter models for building thermal modelling: An analytic approach to simplifying complex multi-layered constructions - Ramallo-Gonz{\'{a}}lez, Alfonso P.; Eames, Matthew E.; Coley, David A)

From Duplicate 1 (Lumped parameter models for building thermal modelling: An analytic approach to simplifying complex multi-layered constructions - Ramallo-Gonz{\'{a}}lez, Alfonso P.; Eames, Matthew E.; Coley, David A)

From Duplicate 1 (Lumped parameter models for building thermal modelling: An analytic approach to simplifying complex multi-layered constructions - Ramallo-Gonz{\'{a}}lez, Alfonso P.; Eames, Matthew E; Coley, David A)

M{\'{e}}thode de r{\'{e}}duction de mod{\`{e}}le alternative {\`{a}} la m{\'{e}}thode Fraisse. Utile pour la pr{\'{e}}diction.
Comparaison en domaine fr{\'{e}}quentiel},
author = {Ramallo-Gonz{\'{a}}lez, Alfonso P. and Eames, Matthew E. and Coley, David A},
doi = {10.1016/j.enbuild.2013.01.014},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramallo-Gonz{\'{a}}lez, Eames, Coley - 2013 - Lumped parameter models for building thermal modelling An analytic approach to simplifying comp.pdf:pdf;:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramallo-Gonz{\'{a}}lez, Eames, Coley - 2013 - Lumped parameter models for building thermal modelling An analytic approach to simplifying c(2).pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building,Buildings,Construction,Constructions,DLM,Dominant Layer Model,Dominant layer model,Lumped Parameter Model,Lumped Parameter Models,Thermal Simulations,Thermal simulation},
month = {may},
pages = {174--184},
publisher = {Elsevier B.V.},
title = {{Lumped parameter models for building thermal modelling: An analytic approach to simplifying complex multi-layered constructions}},
url = {http://dx.doi.org/10.1016/j.enbuild.2013.01.014 https://ore.exeter.ac.uk/repository/bitstream/handle/10871/20278/LPM{\_}pre-print.pdf?sequence=1 http://linkinghub.elsevier.com/retrieve/pii/S0378778813000315 https://linkinghub.elsevier.com/retrieve/pii/S03787},
volume = {60},
year = {2013}
}
@book{Walter2016,
author = {Walter, Eric},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walter - 2016 - M{\'{e}}thodes num{\'{e}}riques et optimisation , un guide du consommateur.pdf:pdf},
title = {{M{\'{e}}thodes num{\'{e}}riques et optimisation , un guide du consommateur}},
year = {2016}
}
@article{Trobisch2010,
abstract = {Distance or similarity measures are essential to solve many pattern recognition problems such as classification, clustering, and retrieval problems. Various distance/similarity measures that are applicable to compare two probability density functions, pdf in short, are reviewed and categorized in both syntactic and semantic relationships. A correlation coefficient and a hierarchical clustering technique are adopted to reveal similarities among numerous distance/similarity measures.},
author = {Trobisch, Per David and Bauman, Matthias and Weise, Kuno and Stuby, Fabian and Hak, David J.},
doi = {10.1007/s00167-009-0884-z},
file = {:home/sarah/OneDrive/Travail/Sources/10.1.1.154.8446.pdf:pdf},
issn = {14337347},
journal = {Knee Surgery, Sports Traumatology, Arthroscopy},
keywords = {Quadriceps tendon rupture,Tendon degeneration},
number = {1},
pages = {85--88},
pmid = {19672579},
title = {{Histologic analysis of ruptured quadriceps tendons}},
volume = {18},
year = {2010}
}
@article{Crawley2001,
abstract = {Many of the popular building energy simulation programs around the world are reaching maturity - some use simulation methods (and even code) that originated in the 1960s. For more than two decades, the US government supported development of two hourly building energy simulation programs, BLAST and DOE-2. Designed in the days of mainframe computers, expanding their capabilities further has become difficult, time-consuming, and expensive. At the same time, the 30 years have seen significant advances in analysis and computational methods and power - providing an opportunity for significant improvement in these tools. In 1996, a US federal agency began developing a new building energy simulation tool, EnergyPlus, building on development experience with two existing programs: DOE-2 and BLAST. EnergyPlus includes a number of innovative simulation features - such as variable time steps, user-configurable modular systems that are integrated with a heat and mass balance-based zone simulation - and input and output data structures tailored to facilitate third party module and interface development. Other planned simulation capabilities include multizone airflow, and electric power and solar thermal and photovoltaic simulation. Beta testing of EnergyPlus began in late 1999 and the first release is scheduled for early 2001.},
author = {Crawley, Drury B. and Lawrie, Linda K. and Winkelmann, Frederick C. and Buhl, W.F. and Huang, Y.Joe and Pedersen, Curtis O. and Strand, Richard K. and Liesen, Richard J. and Fisher, Daniel E. and Witte, Michael J. and Glazer, Jason},
doi = {10.1016/S0378-7788(00)00114-6},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/1-s2.0-0017931085900134-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {building performance,energy performance,heat balance,mass balance,modular simulation,simulation},
month = {apr},
number = {4},
pages = {319--331},
title = {{EnergyPlus: creating a new-generation building energy simulation program}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778800001146},
volume = {33},
year = {2001}
}
@article{Reiersol1950,
author = {Reiersol, Olav},
doi = {10.2307/1907835},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1907835.pdf:pdf},
issn = {00129682},
journal = {Econometrica},
month = {oct},
number = {4},
pages = {375},
title = {{Identifiability of a Linear Relation between Variables Which Are Subject to Error}},
url = {https://www.jstor.org/stable/1907835?origin=crossref},
volume = {18},
year = {1950}
}
@book{Douc2014,
author = {Douc, Randal and Moulines, Eric and Stoffer, David S},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Douc, Moulines, Stoffer - 2014 - Nonlinear Time Series - Theory, Methods, and Applications with R examples.pdf:pdf},
isbn = {9781466502253},
pages = {531},
title = {{Nonlinear Time Series - Theory, Methods, and Applications with R examples}},
year = {2014}
}
@article{Absi2016,
abstract = {a b s t r a c t This paper investigates the use of structural dynamics computational models with multiple levels of fidelity in the calibration of system parameters. Different types of models may be available for the estimation of unmeasured system properties, with different levels of physics fidelity, mesh resolution and boundary condition assumptions. In order to infer these system properties, Bayesian calibration uses information from multiple sources (including experimental data and prior knowledge), and comprehen-sively quantifies the uncertainty in the calibration parameters. Estimating the posteriors is done using Markov Chain Monte Carlo sampling, which requires a large number of computations, thus making the use of a high-fidelity model for calibration prohibitively expensive. On the other hand, use of a low-fidelity model could lead to significant error in calibration and prediction. Therefore, this paper develops an approach for model parameter calibration with a low-fidelity model corrected using higher fidelity simula-tions, and investigates the trade-off between accuracy and computational effort. The methodology is illustrated for a curved panel located in the vicinity of a hypersonic aircraft engine, subjected to acoustic loading. Two models (a frequency response analysis and a full time history analysis) are combined to calibrate the damping characteristics of the panel.},
author = {Absi, Ghina N and Mahadevan, Sankaran},
doi = {10.1016/j.ymssp.2015.07.019},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Absi, Mahadevan - 2015 - Multi-fidelity approach to dynamics model calibration.pdf:pdf},
issn = {08883270},
journal = {Mechanical Systems and Signal Processing},
keywords = {Bayesian calibration,Damping coefficient,Hypersonic vehicle,Information fusion,Model uncertainty,Multi-fidelity},
month = {feb},
pages = {189--206},
title = {{Multi-fidelity approach to dynamics model calibration}},
url = {https://ac-els-cdn-com.camphrier-2.grenet.fr/S0888327015003386/1-s2.0-S0888327015003386-main.pdf?{\_}tid=603d4f3a-d0f1-11e7-ae58-00000aacb360{\&}acdnat=1511512258{\_}e682c0f8358e58d230a9ccf5a040b0f2 https://linkinghub.elsevier.com/retrieve/pii/S0888327015003386},
volume = {68-69},
year = {2016}
}
@article{Brastein2019,
abstract = {Obtaining accurate dynamic models of building thermal behaviour requires a statistically solid foundation for estimating unknown parameters. This is especially important for thermal network grey-box models, since all their parameters normally need to be estimated from data. One attractive solution is to maximise the likelihood function, under the assumption of Gaussian distributed residuals. This technique was developed previously and implemented in the Continuous Time Stochastic Modelling framework, where an Extended Kalman Filter is used to compute residuals and their covariances. The main result of this paper is a similar method applied to a thermal network grey-box model of a building, simulated as an electric circuit in an external tool. The model is described as a list of interconnected components without deriving explicit equations. Since this model implementation is not differentiable, an alternative Kalman filter formulation is needed. The Unscented and Ensemble Kalman Filters are designed to handle non-linear models without using Jacobians, and can therefore also be used with models in a non-differentiable form. Both Kalman filter implementations are tested and compared with respect to estimation accuracy and computation time. The Profile Likelihood method is used to analyse structural and practical parameter identifiability. This method is extended to compute two-dimensional profiles, which can also be used to analyse parameter interdependence by providing insight into the parameter space topology.},
annote = {Compraison de m{\'{e}}thodes de calibration (notamment filtres de kalman unscented et ensemble) les r{\'{e}}sidus sont blancs ou presque, mais le profile likelihood montre une mauvaise identifiabilit{\'{e}} pratique --{\textgreater} param{\`{e}}tres tr{\`{e}}s incertains.
on peut leur reprocher de donner des {\'{e}}sultats de calibration sans leurs incertitudes},
author = {Brastein, O. M. and Lie, B. and Sharma, R. and Skeie, N.-O.},
doi = {10.1016/J.ENBUILD.2019.03.018},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brastein et al. - 2019 - Parameter estimation for externally simulated thermal network models.pdf:pdf},
issn = {0378-7788},
journal = {Energy and Buildings},
keywords = {Ensemble Kalman Filter,Grey-box models,Unscented Kalman Filter,parameter estimation,profile likelihood,stochastic differential equations,thermal network models},
publisher = {Elsevier B.V.},
title = {{Parameter estimation for externally simulated thermal network models}},
url = {https://www.sciencedirect.com/science/article/pii/S0378778818335175?dgcid=rss{\_}sd{\_}all},
year = {2019}
}
@article{Mangematin2012,
abstract = {a r t i c l e i n f o a b s t r a c t Article history: Available online 3 May 2012 Keywords: Energy efficiency of buildings Rapid thermodynamic measurements Transient states Heat loss coefficient Heat capacity Mots-cl{\'{e}}s : Efficacit{\'{e}} {\'{e}}nerg{\'{e}}tique des b{\^{a}}timents Mesures thermodynamique rapide {\'{E}}tats transitoires Capacit{\'{e}} calorifique Coefficient de fuite thermique In this study, we propose a way to develop rapid measurements of the energy efficiency of buildings. We show that measuring transient states during the heating and free cooling of an empty low-consumption house can lead to a rather good estimate of the total heat loss coefficient K and of the apparent heat capacity C of the building. These measurements can be made typically within a couple of days. r {\'{e}} s u m {\'{e}} Dans cette {\'{e}}tude nous proposons une m{\'{e}}thode pour mesurer rapidement l'efficacit{\'{e}} {\'{e}}nerg{\'{e}}tique de b{\^{a}}timents. Nous montrons qu'en mesurant les {\'{e}}tats transitoires lors du chauffage et du refroidissement d'une maison basse consommation vide, on acc{\`{e}}de au coefficient de fuite thermique K et {\`{a}} la capacit{\'{e}} calorifique apparente du b{\^{a}}timent. Ces mesures peuvent {\^{e}}tre obtenues en un ou deux jours.},
author = {Mangematin, Eric and Pandraud, Guillaume and Roux, Didier},
doi = {10.1016/j.crhy.2012.04.001},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangematin, Pandraud, Roux - 2012 - Quick measurements of energy efficiency of buildings.pdf:pdf},
issn = {16310705},
journal = {Comptes Rendus Physique},
keywords = {QUB},
mendeley-tags = {QUB},
month = {may},
number = {4},
pages = {383--390},
title = {{Quick measurements of energy efficiency of buildings}},
url = {http://ac.els-cdn.com.camphrier-2.grenet.fr/S1631070512000424/1-s2.0-S1631070512000424-main.pdf?{\_}tid=cc16c668-5032-11e7-a69b-00000aacb35d{\&}acdnat=1497356656{\_}cbf936a6d746fea5d099efb956715376 https://linkinghub.elsevier.com/retrieve/pii/S1631070512000424},
volume = {13},
year = {2012}
}
@article{Meeker1995,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. This content downloaded from 130.190.247.202 on Fri, 16 Jun 2017 12:08:28 UTC All use subject to http://about.jstor.org/terms TEACHER'S CORNER In this department The Amer-ican Statistician publishes articles, reviews, under the section heading. Articles and notes for the department, but not and notes of interest to teachers of the first mathematical statistics course intended specifically for the section, should be useful to a substantial number and of applied statistics courses. The department includes the Accent on of teachers of the indicated types of courses or should have the potential for Teaching Materials section; suitable contents for the section are described fundamentally affecting the way in which a course is taught. Teaching About Approximate Confidence Regions Based on Maximum Likelihood Estimation William Q. MEEKER and Luis A. ESCOBAR Maximum likelihood (ML) provides a powerful and ex-tremely general method for making inferences over a wide range of data/model combinations. The likelihood func-tion and likelihood ratios have clear intuitive meanings that make it easy for students to grasp the important concepts. Modern computing technology has made it possible to use these methods over a wide range of practical applications. However, many mathematical statistics textbooks, partic-ularly those at the Senior/Masters level, do not give this important topic coverage commensurate with its place in the world of modern applications. Similarly, in nonlin-ear estimation problems, standard practice (as reflected by procedures available in the popular commercial statis-tical packages) has been slow to recognize the advantages of likelihood-based confidence regions/intervals over the commonly use "normal-theory" regions/intervals based on the asymptotic distribution of the "Wald statistic." In this note we outline our approach for presenting, to students, confidence regions/intervals based on ML estimation.},
author = {Meeker, William Q and Escobar, Luis A},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meeker, Escobar - 1995 - Teaching about Approximate Confidence Regions Based on Maximum Likelihood Estimation.pdf:pdf},
journal = {Source: The American Statistician},
keywords = {Asymptotic approximation,Confidence interval,Large sample approximation,Profile likelihood},
number = {1},
pages = {48--53},
title = {{Teaching about Approximate Confidence Regions Based on Maximum Likelihood Estimation}},
url = {http://www.jstor.org/stable/2684811 http://www.jstor.org/stable/2684811?seq=1{\&}cid=pdf-reference{\#}references{\_}tab{\_}contents http://about.jstor.org/terms},
volume = {49},
year = {1995}
}
@article{Bouache2013,
abstract = {The coupling of a direct thermal calculation with an optimization algorithm to achieve the identification of the thermal characteristics of a building structure is presented in this paper. The resolution of the direct thermal calculation is based on an electric network representation, based on a numerical solution using the finite differences method. The optimization model minimizes a criterion such as « least squares » between the wished temperatures inside the building and the model respond (time domain) by an inverse iterative algorithm « Reflective Newton ». The proposed optimization model is then validated with an experimental case, a closed wooden structure with one heated side.},
author = {Bouache, Toufik and Ginestet, St{\'{e}}phane and Limam, Karim and Lindner, Guilherme and Bosschaerts, Walter},
doi = {10.1016/j.egypro.2013.11.028},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouache et al. - 2013 - Identification of Thermal Characteristics of a Building.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {{\`{a}} lire},
mendeley-tags = {{\`{a}} lire},
pages = {280--288},
title = {{Identification of Thermal Characteristics of a Building}},
url = {http://ac.els-cdn.com/S187661021301730X/1-s2.0-S187661021301730X-main.pdf?{\_}tid=5d24241a-0e35-11e7-8eab-00000aab0f6c{\&}acdnat=1490100981{\_}e867b21d89609e575a94742b73476d8c http://linkinghub.elsevier.com/retrieve/pii/S187661021301730X https://linkinghub.elsevie},
volume = {42},
year = {2013}
}
@article{Barker2006,
abstract = {This tutorial paper focuses on a number of designs for perturbation (input) signals for system identification; all of the signals can be designed using software readily available on the World Wide Web. Pseudorandom signals have fixed spectra, and both binary and multilevel signals based on maximum-length sequences are discussed. Other classes of pseudorandom binary signals that greatly increase the number of available signal periods are described. Computer-optimized signals have spectra that can be specified by the user, and the paper deals with three types – multisine (sum of harmonics) signals, and binary and multilevel multiharmonic signals. Perturbation signal quality measures are also considered in the paper.},
author = {Barker, H. Anthony and Rivera, D.E. and Tan, A.H. and Godfrey, Keith Richard},
doi = {10.3182/20060329-3-AU-2901.00180},
file = {:home/sarah/OneDrive/Travail/Sources/1-s2.0-S1474667015354161-main.pdf:pdf},
isbn = {8528760006},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Binary signals,Frequency responses,Input signals,Multilevel codes,Pseudorandom signals,System identification,Time-domain responses,binary signals,frequency responses,input signals,multilevel codes,pseudorandom signals,system identification,time-domain responses},
number = {1},
pages = {1121--1126},
publisher = {IFAC},
title = {{PERTURBATION SIGNAL DESIGN}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667015354161},
volume = {39},
year = {2006}
}
@article{Pohjanpalo1978,
author = {Pohjanpalo, H},
doi = {10.1016/0025-5564(78)90063-9},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pohjanpalo - 1978 - System identifiability based on the power series expansion of the solution.pdf:pdf},
issn = {00255564},
journal = {Mathematical Biosciences},
month = {sep},
number = {1-2},
pages = {21--33},
title = {{System identifiability based on the power series expansion of the solution}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0025556478900639},
volume = {41},
year = {1978}
}
@inproceedings{Juricic2018a,
address = {Syracuse (NY)},
author = {Juricic, Sarah and Rouchier, Simon and Foucquier, Aur{\'{e}}lie and Fraisse, Gilles},
booktitle = {7th International Building Physics Conference},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Juricic et al. - 2018 - Evaluation of the physical interpretability of calibrated building model parameters.pdf:pdf},
keywords = {lumped models,model calibration,parameter estimation,practical identifiability},
pages = {1199--1204},
title = {{Evaluation of the physical interpretability of calibrated building model parameters}},
year = {2018}
}
@article{Frank2019,
author = {Frank, Stephen and Lin, Guanjing and Jin, Xin and Singla, Rupam and Farthing, Amanda and Granderson, Jessica},
doi = {10.1016/j.enbuild.2019.03.024},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank et al. - 2019 - A Performance Evaluation Framework for Building Fault Detection and Diagnosis Algorithms.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Algorithm testing,Benchmarking,Building energy performance,Building systems,Fault detection and diagnosis,Performance evaluation},
publisher = {Elsevier B.V.},
title = {{A Performance Evaluation Framework for Building Fault Detection and Diagnosis Algorithms}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818335680},
year = {2019}
}
@incollection{Mosegaard2002,
author = {Mosegaard, Klaus and Tarantola, Albert},
booktitle = {International Handbook of Earthquake {\&} Engineering Seismology (Part A)},
doi = {10.1016/S0074-6142(02)80219-4},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/InverseProblemHandbk.pdf:pdf},
issn = {00746142},
pages = {237--265},
publisher = {Academic Press},
title = {{16 Probabilistic approach to inverse problems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0074614202802194},
volume = {81},
year = {2002}
}
@article{Robert2018,
abstract = {Markov chain Monte Carlo algorithms are used to simulate from complex statistical distributions by way of a local exploration of these distributions. This local feature avoids heavy requests on understanding the nature of the target, but it also potentially induces a lengthy exploration of this target, with a requirement on the number of simulations that grows with the dimension of the problem and with the complexity of the data behind it. Several techniques are available towards accelerating the convergence of these Monte Carlo algorithms, either at the exploration level (as in tempering, Hamiltonian Monte Carlo and partly deterministic methods) or at the exploitation level (with Rao-Blackwellisation and scalable methods).},
archivePrefix = {arXiv},
arxivId = {1804.02719},
author = {Robert, Christian P. and Elvira, V{\'{i}}ctor and Tawn, Nick and Wu, Changye},
doi = {10.1002/wics.1435},
eprint = {1804.02719},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robert et al. - 2018 - Accelerating MCMC algorithms.pdf:pdf},
issn = {19390068},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {Bayesian analysis,Hamiltonian Monte Carlo,Monte Carlo methods,Rao-Blackwellisation,computational statistics,convergence of algorithms,efficiency of algorithms,simulation,tempering},
number = {5},
pages = {1--22},
title = {{Accelerating MCMC algorithms}},
volume = {10},
year = {2018}
}
@article{Lin,
annote = {Article trouv{\'{e}} dans Cai et Braun (2015) le 5 octobre 2016
Dans le cadre du Model Predictive Control, on cherche {\`{a}} d{\'{e}}terminer le mod{\`{e}}le le plsu adapt{\'{e}} ({\'{e}}tant donn{\'{e}}e une pr{\'{e}}cision voulue), et on cherche {\`{a}} en identifier les param{\`{e}}tres.
Les mod{\`{e}}les qu'on cherche {\`{a}} identifier sont des mod{\`{e}}les RC, dont un des termes est non lin{\'{e}}aire (celui qui d{\'{e}}crit les {\'{e}}changes enthalpiques entre l'air ext et int).

Questions 
- Quel est la complexit{\'{e}} minimale qu'un mod{\`{e}}le doit avoir pour pr{\'{e}}dire la temp{\'{e}}rature dans un pi{\`{e}}ce de mani{\`{e}}re assez pr{\'{e}}cise?
- Comment identifier les param{\`{e}}tres du mod{\`{e}}le {\`{a}} partir des donn{\'{e}}es disponibles (quelles donn{\'{e}}es sont disponibles), pour atteindre le degr{\'{e}} de pr{\'{e}}cision voulu?

Quelques m{\'{e}}thodes cit{\'{e}}es :
- subspace method [11]? Pas applicable pour identification RC
- ARMA model identification method and adaptative identification methods

Trois r{\'{e}}sultats particuliers :
- la complexit{\'{e}} minimale est du second ordre, 8 param{\`{e}}tres (13 {\'{e}}tats et 32 param{\`{e}}tres). Deux C suffisent.
- le mod{\`{e}}le RC est capable de reproduire la dynamique thermique dans une pi{\`{e}}ce avec pr{\'{e}}cision. les donn{\'{e}}es n{\'{e}}cessaires {\`{a}} la calibration doivent {\^{e}}tre des donn{\'{e}}es issues de consignes, pour que les param{\`{e}}tres pr{\'{e}}disent avec pr{\'{e}}cision des sc{\'{e}}narii vari{\'{e}}s. Des donn{\'{e}}es issues de b{\^{a}}timent en cours d'usage peuvent mener  des erreurs grossi{\`{e}}res dans l'identification (m{\^{e}}me en phase d'excitation permanente, hiver?). Parfois, des donn{\'{e}}es jug{\'{e}}es riches peuvent ne pas suffire {\`{a}} identifier certains param{\`{e}}tres (ceux qui sont le moins sensible dans le mod{\`{e}}le?)
- il est n{\'{e}}cessaire d'avoir des donn{\'{e}}es sur l'ouverture des portes dans du multi-zonal. Sans quoi la pr{\'{e}}diction de climate control est tr{\`{e}}s probablement pas faisable.

Page 5 : "An information metric is computed to evaluate the difficulty of parameter estimation" : une forme de quantification de l'identifiabilit{\'{e}} du mod{\`{e}}le... --{\textgreater} A CREUSER

Algo d'identification utilis{\'{e}} ici : Quasi-Newton search method},
author = {Lin, Yashen and Middelkoop, Timothy and Barooah, Prabir},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Middelkoop, Barooah - Unknown - Identification of control-oriented thermal models of rooms in multi-room buildings.pdf:pdf},
journal = {Ieee Cdc},
pages = {1--27},
title = {{Identification of control-oriented thermal models of rooms in multi-room buildings}}
}
@article{Hong2018,
abstract = {Many real-world processes and phenomena are modeled using systems of ordinary differential equations with parameters. Given such a system, we say that a parameter is globally identifiable if it can be uniquely recovered from input and output data. The main contribution of this paper is to provide theory, an algorithm, and software for deciding global identifiability. First, we rigorously derive an algebraic criterion for global identifiability (this is an analytic property), which yields a deterministic algorithm. Second, we improve the efficiency by randomizing the algorithm while guaranteeing probability of correctness. With our new algorithm, we can tackle problems that could not be tackled before.},
archivePrefix = {arXiv},
arxivId = {1801.08112},
author = {Hong, Hoon and Ovchinnikov, Alexey and Pogudin, Gleb and Yap, Chee},
eprint = {1801.08112},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong et al. - Unknown - Global Identifiability of Differential Models.pdf:pdf},
journal = {arXiv},
month = {jan},
title = {{Global Identifiability of Differential Models}},
url = {http://qcpages.qc.cuny.edu/{~}aovchinnikov/papers/global.pdf http://arxiv.org/abs/1801.08112},
year = {2018}
}
@article{Pedretscher2019,
author = {Pedretscher, B. and Kaltenbacher, B. and Pfeiler, O.},
doi = {10.1016/j.apnum.2019.06.020},
file = {:home/sarah/OneDrive/Travail/Sources/Identifiabilit{\'{e}}/1-s2.0-S0168927419301722-main.pdf:pdf},
issn = {01689274},
journal = {Applied Numerical Mathematics},
month = {jul},
number = {June},
publisher = {Elsevier B.V.},
title = {{Parameter identification and uncertainty quantification in stochastic state space models and its application to texture analysis}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168927419301722},
year = {2019}
}
@article{Michalak2019,
author = {Michalak, Piotr},
doi = {10.1016/j.enbuild.2019.109337},
file = {:home/sarah/OneDrive/Travail/Sources/Analogie RC/1-s2.0-S037877881930787X-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {4R1C,5R1C,BESTEST,EN 15265,EN ISO 13790,EnergyPlus,Lumped capacity,Nodal potential method,RC model,Thermal network model,Time varying ventilation},
month = {jul},
pages = {109337},
publisher = {Elsevier B.V.},
title = {{A thermal network model for the dynamic simulation of the energy performance of buildings with the time varying ventilation flow}},
url = {https://doi.org/10.1016/j.enbuild.2019.109337 https://linkinghub.elsevier.com/retrieve/pii/S037877881930787X},
year = {2019}
}
@article{Agbi2014a,
author = {Agbi, Clarence and Krogh, Bruce},
doi = {10.1109/ACC.2014.6859128},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agbi, Krogh - 2014 - Decentralized identification of building models.pdf:pdf},
isbn = {9781479932726},
issn = {07431619},
journal = {Proceedings of the American Control Conference},
keywords = {Building and facility automation,Grey-box modeling,Identification},
number = {November},
pages = {1070--1075},
title = {{Decentralized identification of building models}},
year = {2014}
}
@book{Gustafson2015,
abstract = {This paper proposes novel Bayesian procedures for partially identified models when the identified set is convex with a smooth boundary, whose support function is locally smooth with respect to the data distribution. Using the posterior of the identified set, we construct Bayesian credible sets for the identified set, the partially identified parameter and their scalar transformations. These constructions, based on the support function, benefit from several computationally attractive algorithms when the identified set is convex, and are proved to have valid large sample frequentist coverages. These results are based on a local linear expansion of the support function of the identified set. We provide primitive conditions to verify such an expansion.},
author = {Gustafson, Paul},
doi = {10.1201/b18308},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/9780429192289{\_}googlepreview.pdf:pdf},
isbn = {9781439869406},
keywords = {Bayesian credible sets,Bernstein–von Mises theorem,Moment inequality models,Partial identification,Support function},
month = {apr},
publisher = {Chapman and Hall/CRC},
title = {{Bayesian Inference for Partially Identified Models}},
url = {https://www.taylorfrancis.com/books/9781439869406},
year = {2015}
}
@article{Andriamamonjy2019,
author = {Andriamamonjy, Ando and Klein, Ralf and Saelens, Dirk},
doi = {10.1016/j.enbuild.2019.01.046},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andriamamonjy, Klein, Saelens - 2019 - Automated grey box model implementation using BIM and Modelica.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building Information Model,Building envelop,Fault detection and diagnosis,Multi-objective optimisation,building,building information model,fault detection and diagnosis,grey box model,multi-objective optimisation},
publisher = {Elsevier B.V.},
title = {{Automated grey box model implementation using BIM and Modelica}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0378778818325878},
year = {2019}
}
@article{Neath2012,
abstract = {The Bayesian information criterion (BIC) is one of the most widely known and pervasively used tools in statistical model selection. Its popularity is derived from its computational simplicity and effective performance in many modeling frameworks, including Bayesian applications where prior distributions may be elusive. The criterion was derived by Schwarz (Ann Stat 1978, 6:461-464) to serve as an asymptotic approximation to a transformation of the Bayesian posterior probability of a candidate model. This article reviews the conceptual and theoretical foundations for BIC, and also discusses its properties and applications. {\textcopyright} 2011 Wiley Periodicals, Inc.},
author = {Neath, Andrew A. and Cavanaugh, Joseph E.},
doi = {10.1002/wics.199},
file = {:home/sarah/OneDrive/Travail/Sources/Neath{\_}et{\_}al-2012-Wiley{\_}Interdisciplinary{\_}Reviews{\_}{\_}Computational{\_}Statistics.pdf:pdf},
issn = {19395108},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {BIC,Bayes factors,Model selection criterion,Schwarz information criterion},
number = {2},
pages = {199--203},
title = {{The Bayesian information criterion: Background, derivation, and applications}},
volume = {4},
year = {2012}
}
@article{Jimenez2008a,
abstract = {This paper presents the application of the IDENT Graphical User Interface of MATLAB to estimate the thermal properties of building components from outdoor dynamic testing, imposing appropriate physical constraints and assuming linear and time invariant parametric models. The theory is briefly described to provide the background for a first understanding of the models used. The relationship between commonly used RC-network models and the parametric models proposed is presented. The analysis is generalised for different possibilities in the assignment of inputs and outputs and even multiple output. Step by step guidance illustrated by an example is included. Results obtained using the different possibilities in selecting inputs and outputs are reported. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Jim{\'{e}}nez, Mar{\'{i}}a Jos{\'{e}} and Madsen, Henrik and Andersen, Klaus Kaae},
doi = {10.1016/j.buildenv.2006.10.030},
file = {:home/sarah/OneDrive/Travail/Sources/Analogie RC/1-s2.0-S0360132306002976-main.pdf:pdf},
issn = {03601323},
journal = {Building and Environment},
keywords = {Building energy,Outdoor testing,System identification,Thermal parameters},
month = {feb},
number = {2},
pages = {170--180},
title = {{Identification of the main thermal characteristics of building components using MATLAB}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0360132306002976},
volume = {43},
year = {2008}
}
@article{Kruschke2013,
abstract = {Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms. (PsycINFO Database Record (c) 2012 APA, all rights reserved).},
author = {Kruschke, John K.},
doi = {10.1037/a0029146},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/kruschke2012jepg.pdf:pdf},
issn = {1939-2222},
journal = {Journal of Experimental Psychology: General},
keywords = {bayes factor,bayesian statistics,confidence interval,effect size,robust estimation},
number = {2},
pages = {573--603},
pmid = {22774788},
title = {{Bayesian estimation supersedes the t test.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0029146},
volume = {142},
year = {2013}
}
@article{Oberpriller2018,
abstract = {Fitting a simplifying model with several parameters to real data of complex objects is a highly nontrivial task, but enables the possibility to get insights into the objects physics. Here, we present a method to infer the parameters of the model, the model error as well as the statistics of the model error. This method relies on the usage of many data sets in a simultaneous analysis in order to overcome the problems caused by the degeneracy between model parameters and model error. Errors in the modeling of the measurement instrument can be absorbed in the model error allowing for applications with complex instruments.},
archivePrefix = {arXiv},
arxivId = {1812.08194},
author = {Oberpriller, Johannes and En{\ss}lin, T. A.},
eprint = {1812.08194},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oberpriller, En{\ss}lin - 2018 - Bayesian parameter estimation of miss-specified models.pdf:pdf},
keywords = {bayesian methods,data analysis,information theory,model fitting},
month = {dec},
pages = {1--11},
title = {{Bayesian parameter estimation of miss-specified models}},
url = {http://arxiv.org/abs/1812.08194},
year = {2018}
}
@article{Thorel2014,
abstract = {Nous passons la majeure partie de notre vie dans des b{\^{a}}timents. Ces derniers ont {\'{e}}t{\'{e}} construits, pour la plupart, avant les chocs p{\'{e}}troliers de 1974 et 1979, et offrent une performance {\'{e}}nerg{\'{e}}tique m{\'{e}}diocre ainsi que des conditions de confort (thermique, acoustique, {\'{e}}clairement naturel) largement am{\'{e}}liorables. En France, avec 32 millions de logements et un taux de renouvellement annuel du parc existant inf{\'{e}}rieur {\`{a}} 1 {\%}, la r{\'{e}}novation {\'{e}}nerg{\'{e}}tique des logements devient une n{\'{e}}cessit{\'{e}}. Cela, autant pour des raisons politiques (ind{\'{e}}pendances {\'{e}}nerg{\'{e}}tiques), {\'{e}}conomiques (relance des emplois de la construction, valorisation du patrimoine), sociales (bien-{\^{e}}tre des occupants, lutte contre la pr{\'{e}}carit{\'{e}}), qu'environnementales (diminutions des {\'{e}}missions des gaz {\`{a}} effet de serre). Ce travail de th{\`{e}}se vise {\`{a}} proposer des connaissances ainsi qu'une m{\'{e}}thodologie afin de contribuer {\`{a}} l'aide {\`{a}} la d{\'{e}}cision pour la prescription de sc{\'{e}}narios d'am{\'{e}}lioration {\'{e}}nerg{\'{e}}tique efficaces des maisons individuelles construites durant la p{\'{e}}riode 1945-1974. Trois probl{\'{e}}matiques sont mises en avant dans cette recherche. 1) l'int{\'{e}}gration de l'approche globale (syst{\'{e}}mique et multicrit{\`{e}}re) de la r{\'{e}}novation afin d'{\'{e}}viter des contre-performances collat{\'{e}}rales dues {\`{a}} des mauvais choix ; 2) l'aide {\`{a}} la formalisation des pr{\'{e}}f{\'{e}}rences des propri{\'{e}}taires-occupants (notre ma{\^{i}}trise d'ouvrage) dans un format interpr{\'{e}}table par des outils d'analyses multicrit{\`{e}}res ; 3) l'int{\'{e}}gration des incertitudes li{\'{e}}es {\`{a}} la caract{\'{e}}risation des b{\^{a}}timents existants dans le processus d'{\'{e}}laboration des sc{\'{e}}narios et d'aide {\`{a}} la d{\'{e}}cision. {\`{A}} travers une description syst{\'{e}}mique des b{\^{a}}timents et une {\'{e}}valuation multicrit{\`{e}}res des performances des actions d'am{\'{e}}lioration retenues, nous proposons une m{\'{e}}thodologie innovante, constitu{\'{e}}e de 6 sous-mod{\`{e}}les techniques modulables et interchangeables, qui vise {\`{a}} automatiser le processus de construction, d'{\'{e}}valuation et de hi{\'{e}}rarchisation performantielle de sc{\'{e}}narios de r{\'{e}}novation. Le c{\oe}ur de notre m{\'{e}}thodologie est bas{\'{e}} sur la formalisation de l'expertise m{\'{e}}tier des sp{\'{e}}cialistes du b{\^{a}}timent dans deux de nos 6 sous-mod{\`{e}}les. Le premier est une matrice d'influence permettant de passer des enjeux de r{\'{e}}novation les plus courants ({\'{e}}quivalent aux pr{\'{e}}f{\'{e}}rences exprim{\'{e}}es par la ma{\^{i}}trise d'ouvrage) en profil de poids relatifs et profil de niveaux-cibles de performance sur les indicateurs mod{\'{e}}lis{\'{e}}s. Le second, est un outil d'inf{\'{e}}rence probabiliste (utilisant la technologie des r{\'{e}}seaux bay{\'{e}}siens) permettant {\`{a}} la fois d'optimiser les assemblages d'actions d'am{\'{e}}lioration (programmation par contraintes successives) et de r{\'{e}}aliser une {\'{e}}valuation multicrit{\`{e}}re de ces assemblages (par l'usage de fonctions d'agr{\'{e}}gation de performances locales). Un sixi{\`{e}}me et dernier sous-mod{\`{e}}le utilise les m{\'{e}}thodes de surclassement ELECTRE pour trier et classer les alternatives de r{\'{e}}novation pr{\'{e}}alablement g{\'{e}}n{\'{e}}r{\'{e}}es par ordre de pr{\'{e}}f{\'{e}}rence. Notre m{\'{e}}thodologie offre enfin la possibilit{\'{e}} de laisser l'utilisateur tester ses propres sc{\'{e}}narios d'am{\'{e}}lioration {\'{e}}nerg{\'{e}}tique afin d'analyser leurs performances multicrit{\`{e}}res et leur compatibilit{\'{e}} avec les caract{\'{e}}ristiques de l'existant capitalis{\'{e}}es lors du diagnostic technique d'une op{\'{e}}ration. La m{\'{e}}thodologie d{\'{e}}velopp{\'{e}}e se veut p{\'{e}}dagogique et transposable dans un prototype d'outil informatique fonctionnel. Une premi{\`{e}}re version a {\'{e}}t{\'{e}} d{\'{e}}velopp{\'{e}}e et utilis{\'{e}}e pour appliquer notre processus d'aide {\`{a}} la d{\'{e}}cision {\`{a}} un cas r{\'{e}}el de maison individuelle {\`{a}} r{\'{e}}nover. Les premiers r{\'{e}}sultats obtenus sont coh{\'{e}}rents et permettent de valider la d{\'{e}}marche. N{\'{e}}anmoins, il faut garder {\`{a}} l'esprit que comme tout mod{\`{e}}le utilisant des connaissances expertes, sa robustesse et la limite de validit{\'{e}} de son p{\'{e}}rim{\`{e}}tre d'application d{\'{e}}pendent de la qualit{\'{e}} du savoir m{\'{e}}tier capitalis{\'{e}}.},
author = {Thorel, Mathieu},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thorel - 2014 - Aide {\`{a}} la d{\'{e}}cision multicrit{\`{e}}re pour la prescription de sc{\'{e}}narios d'am{\'{e}}lioration {\'{e}}nerg{\'{e}}tique via une approche glo.pdf:pdf},
keywords = {Aide {\`{a}} la d{\'{e}}cision, r{\'{e}}habilitation, r{\'{e}}seaux bay{\'{e}}si},
title = {{Aide {\`{a}} la d{\'{e}}cision multicrit{\`{e}}re pour la prescription de sc{\'{e}}narios d'am{\'{e}}lioration {\'{e}}nerg{\'{e}}tique via une approche globale}},
url = {https://tel.archives-ouvertes.fr/tel-01136935/document{\%}5Cnhttps://tel.archives-ouvertes.fr/tel-01136935/},
year = {2014}
}
@article{Goupy2014,
author = {Goupy, Jacques},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goupy - 2014 - Par Les Plans D ' Exp{\'{e}}riences(2).pdf:pdf},
isbn = {7200049069},
journal = {Techniques de l'ing{\'{e}}nieur},
number = {0},
pages = {0--23},
title = {{Par Les Plans D ' Exp{\'{e}}riences}},
volume = {33},
year = {2014}
}
@article{Taylor1991,
author = {Taylor, Russell D and Pedersen, Curtis O and Fisher, Daniel E and Liesen, Richard J and Lawrie, Linda K},
file = {:home/sarah/OneDrive/Travail/Sources/A classer/BS91{\_}227{\_}234.pdf:pdf},
journal = {BS 1991 - 2nd Int. IBPSA Conference},
pages = {227--234},
title = {{Impact of simultaneous simulation of buildings and mechanical systems in heat balance based energy analysis programs on system response and control}},
year = {1991}
}
@article{Goffart2018,
abstract = {. L'article pr{\'{e}}sente la m{\'{e}}thode RBD-FAST bas{\'{e}}e sur la variance, qui couple analyse de sensibilit{\'{e}} et analyse d'incertitude. Ces deux types d'analyses sont des outils indispensables pour la garantie de performance {\'{e}}nerg{\'{e}}tique. Les informations obtenues sont de m{\^{e}}me qualit{\'{e}} que la m{\'{e}}thode de SOBOL, mais avec un nombre r{\'{e}}duit de simulation et du m{\^{e}}me ordre de grandeur que le criblage de Morris. Ainsi la rapidit{\'{e}} d'{\'{e}}valuation de la sensibilit{\'{e}} des diff{\'{e}}rents param{\`{e}}tres n'a plus {\`{a}} se faire au d{\'{e}}triment de la qualit{\'{e}} de l'information extraite par analyse de sensibilit{\'{e}}. Avec le m{\^{e}}me nombre de simulation, la comparaison entre RBD-FAST et Morris est r{\'{e}}alis{\'{e}}e sur l'{\'{e}}tude des besoins de chauffage d'une maison individuelle BEPOS avec 50 param{\`{e}}tres incertains. Les r{\'{e}}sultats illustrent la richesse et la qualit{\'{e}} des informations extraites en une analyse avec RBD-FAST : quantification de la part d'influence de chaque entr{\'{e}}e sur la dispersion de sortie, analyse d'incertitude rigoureuse, analyse graphique des tendances. Ces atouts en font donc une m{\'{e}}thode privil{\'{e}}gi{\'{e}}e pour la garantie de performance {\'{e}}nerg{\'{e}}tique.},
author = {Goffart, Jeanne and Woloszyn, Monika},
file = {:home/sarah/OneDrive/Travail/Sources/Analyse de sensibilit{\'{e}} {\&} Incertitudes/RBDFAST{\_}Goffart{\_}2018{\_}FinalReviewed.pdf:pdf},
journal = {Conf{\'{e}}rence Francophone de l'International Building Performance Simulation Association IBPSA,},
keywords = {energy performance guarantee,good practice,sensitivity analysis},
pages = {1--8},
title = {{RBD-FAST : une m{\'{e}}thode d'analyse de sensibilit{\'{e}} rapide et rigoureuse pour la garantie de performance {\'{e}}nerg{\'{e}}tique}},
url = {https://hal.archives-ouvertes.fr/hal-01873694},
year = {2018}
}
@incollection{Rogelj2018,
abstract = {, 2018, Mitigation pathways compatible with 1.5°C in the context of sustainable development. In: Global warming of 1.5°C. An IPCC Special Report on the impacts of global warming of 1.5°C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change, sustainable development, and efforts to eradicate poverty},
author = {Rogelj, J. and Shindell, D. and Jiang, K. and Fifita, S. and Forster, P. and Ginzburg, V. and Handa, C. and Kheshgi, H. and Kobayashi, S. and Kriegler, E. and Mundaca, L. and S{\'{e}}f{\'{e}}rian, R. and Vilari{\~{n}}o, M.V.},
booktitle = {Global Warming of 1.5°C. An IPCC Special Report on the impacts of global warming of 1.5°C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change,},
file = {:home/sarah/OneDrive/Travail/Sources/SR15{\_}Chapter2{\_}Low{\_}Res.pdf:pdf},
pages = {2},
publisher = {Masson-Delmotte},
title = {{Mitigation Pathways Compatible with 1.5°C in the Context of Sustainable Development}},
year = {2018}
}
@article{Alzetto2018b,
abstract = {QUB is an innovative method enabling the experimental measurement of the total heat loss coefficient (HLC) of a building envelope in one night only. It is based on a simple theory, yet can be demonstrated to be accurate even in a short time and in real buildings, as long as certain experimental conditions are fulfilled. This study combines analytical and numerical approaches to exactly solve the temperature response of an equivalent building submitted to a QUB test. This allows understanding that even with a short time experiment (less than a night), a reasonable accuracy on the estimated HLC can be obtained. The experiment has to be designed following a simple heating power criterion. Calculation is then tested experimentally in various cases whether in climate chamber or in real field, and whether on light weight/not insulated building or a heavy weight/highly insulated building. Results show that the QUB method performed by fulfilling this criterion is a promising method to estimate the HLC of a real building in the field with a reasonable accuracy in one night.},
author = {Alzetto, Florent and Pandraud, Guillaume and Fitton, Richard and Heusler, Ingo and Sinnesbichler, Herbert},
doi = {10.1016/j.enbuild.2018.06.002},
file = {:home/sarah/OneDrive/Travail/Sources/Diagnostic/1-s2.0-S037877881831716X-main.pdf:pdf},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Building thermal performance,Coheating,Dwellings,Energy,Heat loss coefficient (HLC),In-situ measurement,Performance gap,Thermal quadrupole},
month = {sep},
pages = {124--133},
publisher = {Elsevier B.V.},
title = {{QUB: A fast dynamic method for in-situ measurement of the whole building heat loss}},
url = {https://doi.org/10.1016/j.enbuild.2018.06.002 https://linkinghub.elsevier.com/retrieve/pii/S037877881831716X},
volume = {174},
year = {2018}
}
@article{Viot2015,
abstract = {Energy consumption depends on buildings usage. For this reason energy management is a main goal. A building model embedded controller involves model choice and validation step. Models have to be both simple and reliable for real-time or predictive control application. This paper describes hybrid models approach using physics knowledge and measures. First a test is performed on a reduced scale building model. Secondly an experimental room including a floor heating system (FHS) is used. Three resistance-capacity (RC) models are proposed corresponding to different ways to consider FHS effect on inner temperature. The study reveals that knowledge of surface temperatures leads to the best description.},
author = {Viot, Hugo and Sempey, Alain and Mora, Laurent and Batsale, Jean-Christophe},
doi = {10.1016/j.egypro.2015.11.107},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viot et al. - 2015 - Fast on-site measurement campaigns and simple building models identification for heating control.pdf:pdf},
issn = {18766102},
journal = {Energy Procedia},
keywords = {Building,Identification,Infrared thermography,Reduced model},
pages = {812--817},
publisher = {Elsevier B.V.},
title = {{Fast on-site measurement campaigns and simple building models identification for heating control}},
url = {http://dx.doi.org/10.1016/j.egypro.2015.11.107},
volume = {78},
year = {2015}
}
@article{Braems2002,
author = {Braems, I and Jaulin, L and Kieffer, Michel and Walter, Eric},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Braems et al. - 2002 - Identifiabilit{\{}{\'{e}}{\}}s, discernabilit{\{}{\'{e}}{\}}s et analyse par intervalles.pdf:pdf},
journal = {Conf{\{}{\'{e}}{\}}rence Internationale Francophone d' Automatique},
pages = {823--828},
title = {{Identifiabilit{\{}{\'{e}}{\}}s, discernabilit{\{}{\'{e}}{\}}s et analyse par intervalles}},
year = {2002}
}
@inproceedings{Boisson2014,
abstract = {The development of high energy performance buildings requires specific tools in order to assess their actual thermal performances, regardless of building use and climatic conditions. The scope of this work is to assess “intrinsic” energy performance of a building by developing a measurement methodology applicable at the acceptance step during the construction process of a new building or after deep refurbishment works on an existing building. This methodology must be short enough and is only applicable in buildings without occupant inside. The general principle is to inject a controlled heating power inside the tested building and to measure its thermal reaction in order to deduce the thermal properties of the envelope. To achieve that, an identification method has been developed, based on the thermal model used in the international standard ISO 13790. The aim is to identify the heat loss coefficient by transmission through the building envelope Htr, and thermal inertia parameters. A comparison between this identification method and numerical experiments based on more detailed modeling tools (SIMBAD) has validated the principle for several parameters (thermal inertia, insulation level{\ldots}). The final aim is to detect gaps between the design and as-built thermal performances of the envelope, especially for heat losses.},
address = {Li{\`{e}}ge},
author = {Boisson, P. and Bouchi{\'{e}}, R{\'{e}}mi},
booktitle = {System simulation in buildings},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boisson, Bouchi{\'{e}} - 2014 - ISABELE method In situ assessment of the building envelope performances.pdf:pdf},
isbn = {9782930772103},
keywords = {ISABELE,building envelope,heat loss coefficient,identification,in-situ measure protocol,numerical experiments,performance assessment},
mendeley-tags = {ISABELE},
pages = {19},
title = {{ISABELE method : In situ assessment of the building envelope performances}},
year = {2014}
}
@article{Deconinck2017,
author = {Deconinck, An-Heleen and Roels, Staf},
doi = {10.1177/1744259116688384},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deconinck, Roels - 2017 - Is stochastic grey-box modelling suited for physical properties estimation of building components from on-site.pdf:pdf},
issn = {1744-2591},
journal = {Journal of Building Physics},
keywords = {building components,calibration,data-based identifiability,grey-box models,identifiability,in-situ,maximum likelihood estimation,measurements,parameter estimation,profile likelihood,thermal performance,uncertainty},
mendeley-tags = {calibration,identifiability,parameter estimation,uncertainty},
month = {mar},
number = {5},
pages = {444--471},
title = {{Is stochastic grey-box modelling suited for physical properties estimation of building components from on-site measurements?}},
url = {http://journals.sagepub.com/doi/10.1177/1744259116688384},
volume = {40},
year = {2017}
}
@incollection{Lucon2014,
abstract = {Climate Change 2014: Mitigation of Climate Change is the third part of the Fifth Assessment Report (AR5) of the Intergovernmental Panel on Climate Change (IPCC) — Climate Change 2013 / 2014 — and was prepared by its Working Group III. The volume provides a comprehensive and transparent assessment of relevant options for mitigating climate change through limiting or preventing greenhouse gas (GHG) emissions, as well as activities that reduce their concentrations in the atmosphere.},
address = {Cambridge},
author = {Lucon, O. and {\"{U}}rge-Vorsatz, A. and {Ahmed Zain}, A. and Akbari, H. and Bertoldi, P. and Cabeza, L. F. and Eyre, N. and Gadgil, A. and Harvey, L. D. D. and Jiang, Y. and Liphoto, E. and Mirasgedis, S. and Murakami, S. and Parikh, J. and Pyke, C. and Vilari{\~{n}}o, M. V.},
booktitle = {Climate Change 2014: Mitiga- tion of Climate Change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change},
file = {:home/sarah/OneDrive/Travail/Sources/ipcc{\_}wg3{\_}ar5{\_}chapter9.pdf:pdf},
pages = {671--738},
publisher = {Cambridge University Press},
title = {{Buildings}},
year = {2014}
}
@article{Hastings1970,
abstract = {SUMMARY: A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed. {\textcopyright} 1970 Oxford University Press.},
author = {Hastings, W. K.},
doi = {10.1093/biomet/57.1.97},
file = {:home/sarah/OneDrive/Travail/Sources/Bay{\'{e}}sien/Maths/57-1-97.pdf:pdf},
issn = {1464-3510},
journal = {Biometrika},
month = {apr},
number = {1},
pages = {97--109},
title = {{Monte Carlo sampling methods using Markov chains and their applications}},
url = {https://academic.oup.com/biomet/article/57/1/97/284580},
volume = {57},
year = {1970}
}
@article{Jack2018,
abstract = {This paper provides powerful evidence empirically demonstrating for the first time the reliability of the co-heating test. The test is widely used throughout Europe to measure the total heat transfer through the fabric of buildings and to calculate the heat-transfer coefficient (HTC; units W/K). A reliable test is essential to address the ‘performance gap', where in-use energy performance is consistently, and often substantially, poorer than predicted. The co-heating test could meet this need, but its reliability requires confirmation. Seven teams independently conducted co-heating tests on the same detached house near Watford, UK. Despite differences in the weather and in the experimental and analytical approaches, the teams' final reported HTC measurements were within ±10{\%} of the mean. With further standardization it is likely to be possible to improve upon this reproducibility. Furthermore, uncertainty analysis based upon a 95{\%} confidence interval resulted in an estimated uncertainty in HTC mea...},
author = {Jack, Richard and Loveday, Dennis and Allinson, David and Lomas, Kevin},
doi = {10.1080/09613218.2017.1299523},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jack et al. - 2018 - First evidence for the reliability of building co-heating tests.pdf:pdf},
issn = {14664321},
journal = {Building Research and Information},
keywords = {co-heating,energy performance,heat transfer,heat-transfer coefficient,houses,in-situ,performance assessment,performance gap},
number = {4},
pages = {383--401},
publisher = {Taylor {\&} Francis},
title = {{First evidence for the reliability of building co-heating tests}},
volume = {46},
year = {2018}
}
@article{Papastamoulis2017,
abstract = {The BayesBinMix package offers a Bayesian framework for clustering binary data with or without missing values by fitting mixtures of multivariate Bernoulli distributions with an unknown number of components. It allows the joint estimation of the number of clusters and model parameters using Markov chain Monte Carlo sampling. Heated chains are run in parallel and accelerate the convergence to the target posterior distribution. Identifiability issues are addressed by implementing label switching algorithms. The package is demonstrated and benchmarked against the Expectation- Maximization algorithm using a simulation study as well as a real dataset.},
author = {Papastamoulis, P. and Rattray, M.},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papastamoulis, Rattray - 2017 - BayesBinMix An R package for model based clustering of multivariate binary data.pdf:pdf},
issn = {20734859},
journal = {R Journal},
number = {1},
title = {{BayesBinMix: An R package for model based clustering of multivariate binary data}},
volume = {9},
year = {2017}
}
@article{Strachan1993,
abstract = {(on behalf of the participants of the Model Validation and Development Subgroup, PASSYS Project) This paper focuses on the empirical whole model validation effort being undertaken as part of the CEC PASSYS project, placing it in the context of an overall validation methodology. High quality datasets lie at the heart of empirical validation, and reasons are given as to why test cells are considered to provide the best available environment for their acquisition. Criteria are set out that help ensure that the collected datasets are of value for validation, and the various elements of an empirical validation methodology are elaborated. Finally, some preliminary results and analysis are presented.},
author = {Strachan, Paul},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strachan - 1993 - Model Validation using the PASSYS Test Cells(2).pdf:pdf},
journal = {Building and Environment},
number = {2},
pages = {53--165},
title = {{Model Validation using the PASSYS Test Cells}},
url = {http://ac.els-cdn.com.camphrier-1.grenet.fr/0360132393900499/1-s2.0-0360132393900499-main.pdf?{\_}tid=573e572a-5348-11e7-a1a3-00000aacb361{\&}acdnat=1497695762{\_}d9ae78b7c972d14bc9dbed941da379e4},
volume = {28},
year = {1993}
}
@article{Meijer2009,
abstract = {Greater potential energy savings can be achieved in the large stock of existing dwellings than in the relatively small proportion of newly built dwellings. Although the energy performance of existing dwellings is much poorer than new dwellings, the stock of existing dwellings is very large in a 'mature' built environment of most developed countries. In the past decade, awareness of the potential energy savings has spread widely among the many stakeholders involved. Nonetheless, most regulations and instruments are still aimed at achieving sustainable newly built construction. An evidenced-based overview of the current state of the residential building stock is provided for eight northern European countries along with current renovation data. Comparisons are made on the characteristics, physical quality and developments of the residential building stock. Existing policies and incentives to reduce energy use and CO2 emissions are analysed for their impacts on the existing building stock as well as the barriers preventing successful sustainable renovation. Common denominators in the current state of renovation of residential building stock are used to identify possible future instruments and incentives that are needed to overcome current barriers.},
author = {Meijer, Frits and Itard, Laure and Sunikka-Blank, Minna},
doi = {10.1080/09613210903189376},
file = {:home/sarah/OneDrive/Travail/Sources/meijer2009.pdf:pdf},
issn = {09613218},
journal = {Building Research and Information},
keywords = {Building quality,Building stock,Energy performance,Energy policy,Energy savings,Housing policy,Renovation,Sustainability,Thermal quality},
number = {5-6},
pages = {533--551},
title = {{Comparing European residential building stocks: Performance, renovation and policy opportunities}},
volume = {37},
year = {2009}
}
@article{Sokol2017c,
abstract = {Urban Building Energy Modeling (UBEM) is an emerging method for exploring energy efficiency solutions at urban or district scales. More versatile than statistical models, physical bottom-up UBEMs allow planners to quantitatively assess retrofit strategies and energy supply options, leading to more effective policies and management of energy demand. The most common approach for formulating an UBEM involves segmenting a building stock into archetypes, characterizing each type, and validating the model by comparing its output to aggregated measured energy consumption. This paper presents a more detailed methodology for setting up UBEMs while faced with incomplete information about the buildings. The procedure calls for defining unknown or uncertain parameters in archetype descriptions as probability distributions and, if available, using measured energy data to update these distributions by Bayesian calibration. The methodology is validated on residential houses in Cambridge, Massachusetts. Distributions for uncertain parameters are initially generated using a training set of 399 homes with monthly electricity and gas consumption records and then applied to a larger test set of 2263 homes. The procedure is applied both for monthly and annual metered energy usage data. Results show that both annual and monthly Bayesian calibration lead to significantly better annual energy use intensity (EUI) fits compared to traditional deterministic archetype definitions. As expected, an UBEM calibrated with monthly metered data more truthfully mimics monthly EUI distributions than one based on annual data, revealing the benefit of calibrating UBEMs using the smallest measurement time step available.},
annote = {From Duplicate 1 (Validation of a Bayesian-based method for defining residential archetypes in urban building energy models - Sokol, Julia; Cerezo Davila, Carlos; Reinhart, Christoph F.)

From Duplicate 1 (Validation of a Bayesian-based method for defining residential archetypes in urban building energy models - Sokol, Julia; Cerezo Davila, Carlos; Reinhart, Christoph F.)

C:$\backslash$Users$\backslash$merlety$\backslash$Drive$\backslash$These$\backslash$Biblio$\backslash$$\backslash$2017$\backslash$Sokol{\_}Cerezo Davila{\_}Reinhart$\backslash$Sokol{\_}Cerezo Davila{\_}Reinhart{\_}2017{\_}Validation of a Bayesian-based method for defining residential archetypes in urban.pdf
Contents
* 1 Introduction
2 Existing UBEM formulation approaches
2.1 Archetype classification
2.2 Archetype characterization
2.2.1 Characterization from literature
2.2.2 Characterization from building data
2.2.3 Characterization with probabilistic parameters
2.3 Calibration of UBEMs
3 Methodology
3.1 Overview
3.2 Bayesian calibration framework
4 Case study
4.1 Data collection
4.2 Model iterations
4.3 Archetype classification
4.4 Archetype characterization
4.4.1 Characterization of deterministic parameters
4.4.2 Characterization of probabilistic parameters
4.5 Calibration of probabilistic parameters
4.6 Model evaluation
4.7 Implementation
5 Results
5.1 Analysis of existing building stock
5.2 Effect of archetype characterization on model accuracy
5.3 Effect of parameter calibration on model accuracy
5.4 Effect of energy data availability on parameter distributions
5.5 Validation of the methodology
6 Discussion
7 Conclusion
Acknowledgments
References

From Duplicate 3 (Validation of a Bayesian-based method for defining residential archetypes in urban building energy models - Sokol, Julia; Cerezo Davila, Carlos; Reinhart, Christoph F.)

C:$\backslash$Users$\backslash$merlety$\backslash$Drive$\backslash$These$\backslash$Biblio$\backslash$$\backslash$2017$\backslash$Sokol{\_}Cerezo Davila{\_}Reinhart$\backslash$Sokol{\_}Cerezo Davila{\_}Reinhart{\_}2017{\_}Validation of a Bayesian-based method for defining residential archetypes in urban.pdf
Contents
* 1 Introduction
2 Existing UBEM formulation approaches
2.1 Archetype classification
2.2 Archetype characterization
2.2.1 Characterization from literature
2.2.2 Characterization from building data
2.2.3 Characterization with probabilistic parameters
2.3 Calibration of UBEMs
3 Methodology
3.1 Overview
3.2 Bayesian calibration framework
4 Case study
4.1 Data collection
4.2 Model iterations
4.3 Archetype classification
4.4 Archetype characterization
4.4.1 Characterization of deterministic parameters
4.4.2 Characterization of probabilistic parameters
4.5 Calibration of probabilistic parameters
4.6 Model evaluation
4.7 Implementation
5 Results
5.1 Analysis of existing building stock
5.2 Effect of archetype characterization on model accuracy
5.3 Effect of parameter calibration on model accuracy
5.4 Effect of energy data availability on parameter distributions
5.5 Validation of the methodology
6 Discussion
7 Conclusion
Acknowledgments
References},
author = {Sokol, Julia and {Cerezo Davila}, Carlos and Reinhart, Christoph F.},
doi = {10.1016/j.enbuild.2016.10.050},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Bayesian calibration,Building archetypes,Residential building stock,Urban building energy modeling},
mendeley-tags = {Bayesian calibration,Building archetypes,Residential building stock,Urban building energy modeling},
month = {jan},
pages = {11--24},
title = {{Validation of a Bayesian-based method for defining residential archetypes in urban building energy models}},
url = {https://www.sciencedirect.com/science/article/pii/S037877881631372X http://www.sciencedirect.com.camphrier-2.grenet.fr/science/article/pii/S037877881631372X},
volume = {134},
year = {2017}
}
@article{Deconinck2017a,
author = {Deconinck, An-heleen and Roels, Staf},
doi = {10.1177/1744259116688384},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deconinck, Roels - 2017 - Is stochastic grey-box modelling suited for physical properties estimation of building components from on-site.pdf:pdf},
issn = {1744-2591},
journal = {Journal of Building Physics},
keywords = {building components,calibration,data-based identifiability,grey-box models,identifiability,in-situ,maximum likelihood estimation,measurements,parameter estimation,profile likelihood,thermal performance,uncertainty},
mendeley-tags = {calibration,identifiability,parameter estimation,uncertainty},
month = {feb},
pages = {174425911668838},
title = {{Is stochastic grey-box modelling suited for physical properties estimation of building components from on-site measurements?}},
url = {http://journals.sagepub.com/doi/10.1177/1744259116688384},
year = {2017}
}
@article{Bacher2011,
abstract = {The present paper suggests a procedure for identification of suitable models for the heat dynamics of a building. Such a procedure for model identification is essential for better usage of readings from smart meters, which is expected to be installed in almost all buildings in the coming years. The models can be used for different purposes, e.g. control of the indoor climate, forecasting of energy consumption, and for accurate description of energy performance of the building. Grey-box models based on prior physical knowledge and data-driven modelling are applied. This facilitates insight into otherwise hidden information about the physical properties of the building. A hierarchy of models of increasing complexity is formulated based on prior physical knowledge and a forward selection strategy is suggested enabling the modeller to iteratively select suitable models of increasing complexity. The performance of the models is compared using likelihood ratio tests, and they are validated using a combination of appropriate statistics and physical interpretation of the results. A case study is described in which a suitable model is sought after for a single storey 120 m 2 building. The result is a set of different models of increasing complexity, with which building characteristics, such as: thermal conductivity, heat capacity of different parts, and window area, are estimated. ?? 2011 Elsevier B.V. All rights reserved.},
annote = {From Duplicate 1 (Identifying suitable models for the heat dynamics of buildings - Bacher, Peder; Madsen, Henrik)

Sur la base d'un mod{\`{e}}le RC de b{\^{a}}timent, les auteurs ont d{\'{e}}velopp{\'{e}} un algo de s{\'{e}}lection de mod{\`{e}}le sur la base d'un test statistique. En partant d'un mod{\`{e}}le simple, on complexifie le mod{\`{e}}le puis on {\'{e}}value le ratio de vraisemblance pour d{\'{e}}terminer sur le mod{\`{e}}le plus complexe donne significativement de meilleurs r{\'{e}}sultats que le sous-mod{\`{e}}le. La s{\'{e}}lection s'arr{\^{e}}te si aucun des mod{\`{e}}les candidats n'am{\'{e}}liore la vraisemblance.
Ce n'est pas un algo {\`{a}} proprement parler car l'expert doit {\^{e}}tre partie active dans la strat{\'{e}}gie de choix (tout n'est pas cod{\'{e}} en somme, l'expert lui-m{\^{e}}me doit {\'{e}}valuer la n{\'{e}}cessit{\'{e}} ou non de continuer, {\'{e}}tant donn{\'{e}}s les r{\'{e}}sultats obtenus pr{\'{e}}c{\'{e}}demment)
L'expert {\'{e}}value les r{\'{e}}sultats des estimations donn{\'{e}}es par le mod{\`{e}}le en analysant les residuals et les estimations. Si les estimations obtenues ne collent pas {\`{a}} la r{\'{e}}alit{\'{e}}, il a l'initiative d'influencer le choix du mod{\`{e}}le suivant, de choisir l'am{\'{e}}lioration qui conviendrait le mieux.
1) des mod{\`{e}}les am{\'{e}}lior{\'{e}}s du mod{\`{e}}le actuel est calibr{\'{e}} par maximum likelihood estimation
2) test du ratio de vraisemblance : calcul du test pour le mod{\`{e}}le actuel et chacun des mod{\`{e}}les am{\'{e}}lior{\'{e}}s. Si aucun des tests effectu{\'{e}}s ne donne un valeur p inf{\'{e}}rieure {\`{a}} 5{\%}, alors le mod{\`{e}}le actuel est le meilleur et on peut le garder. Sinon, parmi ceux qui ont une valeur p inf{\'{e}}rieure {\`{a}} 5 {\%}, on garde le mod{\`{e}}le am{\'{e}}lior{\'{e}} qui a la plus petite valeur p. Dans tous les cas, on analyse les r{\'{e}}sultats obtenus pour voir quels ph{\'{e}}nom{\`{e}}nes physiques sont mal pris en compte et on am{\'{e}}liore le mod{\`{e}}le actuel vis {\`{a}} vis de ces d{\'{e}}ficiences.


Les auteurs proposent une auto-correlation function et un cumulated periodogram pour {\'{e}}valuer les manquements du mod{\`{e}}le {\'{e}}valu{\'{e}} vis {\`{a}} vis des ph{\'{e}}nom{\`{e}}nes physiques non expliqu{\'{e}}s. Si le bruit qui reste est clairement d{\'{e}}pendant des donn{\'{e}}es, on n'a pas fini. En revanche, d{\`{e}}s que les r{\'{e}}siduels ressemblent {\`{a}} du bruit blanc, le mod{\`{e}}le est correct.
Dans cet exercice en particulier, il reste deux zones clairement non prises en compte physiquement. Les mod{\`{e}}les RC propos{\'{e}}s, y/c leurs am{\'{e}}liorations, ne peuvent prendre ne compte ces ph{\'{e}}nom{\`{e}}nes car l'algo de s{\'{e}}lection de mod{\`{e}}le ne donne plus rien d'int{\'{e}}ressant.
Cela signifie qu'il faut changer qqch dans la description physique de base : prise en compte de la radiation solaire ou int{\'{e}}gration de la radiation solaire dans le processus Wiener...


Description en annexe des 15 mod{\`{e}}les RC propos{\'{e}}s.},
author = {Bacher, Peder and Madsen, Henrik},
doi = {10.1016/j.enbuild.2011.02.005},
file = {:home/sarah/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bacher, Madsen - 2011 - Identifying suitable models for the heat dynamics of buildings.pdf:pdf},
isbn = {0378-7788},
issn = {0378-7788},
journal = {Energy {\&} Buildings},
keywords = {Buildings,Continuous time modelling,Grey-box models,Heat dynamics,Likelihood ratio tests,Lumped models,Model selection,Parameter estimation,Thermal dynamics,continuous time modelling,likelihood ratio tests},
month = {jul},
number = {7},
pages = {1511--1522},
publisher = {Elsevier B.V.},
title = {{Identifying suitable models for the heat dynamics of buildings}},
url = {http://dx.doi.org/10.1016/j.enbuild.2011.02.005 http://linkinghub.elsevier.com/retrieve/pii/S0378778811000491},
volume = {43},
year = {2011}
}
